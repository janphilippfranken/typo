[2024-02-24 15:12:46,851][root][INFO] - beta: 0.5
[2024-02-24 15:12:46,851][root][INFO] - loss with_labels
[2024-02-24 15:12:46,851][root][INFO] - max_iter: 0
[2024-02-24 15:12:46,852][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Epoch 0, Step 0: train/loss = 0.7013961672782898, train/raw-loss = 0.700703501701355, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001385421957820654
Epoch 0, Step 1: train/loss = 0.6955360174179077, train/raw-loss = 0.6946866512298584, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016988443676382303
Epoch 0, Step 2: train/loss = 0.6925863027572632, train/raw-loss = 0.6923112869262695, train/logprobs = tensor([[-1.0892, -2.0869],
        [-1.1206, -2.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005500263068825006
Epoch 0, Step 3: train/loss = 0.6878634691238403, train/raw-loss = 0.6862989068031311, train/logprobs = tensor([[-0.5922, -1.4420],
        [-0.5997, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031291749328374863
Epoch 0, Step 4: train/loss = 0.6826633214950562, train/raw-loss = 0.6821818947792053, train/logprobs = tensor([[-0.9682, -2.2517],
        [-1.0031, -2.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009627505205571651
Epoch 0, Step 5: train/loss = 0.7003986239433289, train/raw-loss = 0.6991856098175049, train/logprobs = tensor([[-1.2526, -1.8470],
        [-1.2661, -1.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024260750506073236
Epoch 0, Step 6: train/loss = 0.6916100382804871, train/raw-loss = 0.6907837390899658, train/logprobs = tensor([[-0.9823, -1.5991],
        [-1.0011, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016527380794286728
Epoch 0, Step 7: train/loss = 0.7028842568397522, train/raw-loss = 0.7020244598388672, train/logprobs = tensor([[-1.0630, -1.5507],
        [-1.1077, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017196990083903074
Epoch 0, Step 8: train/loss = 0.6937832832336426, train/raw-loss = 0.6930682063102722, train/logprobs = tensor([[-0.8023, -1.7333],
        [-0.7871, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014302500057965517
Epoch 0, Step 9: train/loss = 0.6998004913330078, train/raw-loss = 0.6962793469429016, train/logprobs = tensor([[-1.0835, -1.7181],
        [-1.0813, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007042370270937681
Epoch 0, Step 10: train/loss = 0.7067813277244568, train/raw-loss = 0.6965494155883789, train/logprobs = tensor([[-1.1971, -2.5060],
        [-1.2764, -2.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020463809370994568
Epoch 0, Step 11: train/loss = 0.686495840549469, train/raw-loss = 0.6862969398498535, train/logprobs = tensor([[-0.7466, -1.5640],
        [-0.7228, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039786301204003394
Epoch 0, Step 12: train/loss = 0.7224103808403015, train/raw-loss = 0.7148674726486206, train/logprobs = tensor([[-0.7433, -1.8789],
        [-0.7825, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015085747465491295
Epoch 0, Step 13: train/loss = 0.6881805658340454, train/raw-loss = 0.6869643926620483, train/logprobs = tensor([[-0.7519, -1.6611],
        [-0.7745, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002432220848277211
Epoch 0, Step 14: train/loss = 0.6857860088348389, train/raw-loss = 0.684917688369751, train/logprobs = tensor([[-1.1222, -1.7514],
        [-1.1230, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017367040272802114
Epoch 0, Step 15: train/loss = 0.7052810192108154, train/raw-loss = 0.7035808563232422, train/logprobs = tensor([[-1.0901, -1.5558],
        [-1.0901, -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034001865424215794
Epoch 0, Step 16: train/loss = 0.7184815406799316, train/raw-loss = 0.705668568611145, train/logprobs = tensor([[-0.9616, -2.0296],
        [-0.9940, -1.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025626003742218018
Epoch 0, Step 17: train/loss = 0.6933890581130981, train/raw-loss = 0.6924867033958435, train/logprobs = tensor([[-1.0904, -1.5065],
        [-1.0878, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018046624027192593
Epoch 0, Step 18: train/loss = 0.6944319009780884, train/raw-loss = 0.6928467154502869, train/logprobs = tensor([[-1.1498, -1.6923],
        [-1.1412, -1.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031702592968940735
Epoch 0, Step 19: train/loss = 0.6992740631103516, train/raw-loss = 0.6973589658737183, train/logprobs = tensor([[-0.7575, -1.3558],
        [-0.7511, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038300659507513046
Epoch 0, Step 20: train/loss = 0.7615203857421875, train/raw-loss = 0.751427173614502, train/logprobs = tensor([[-0.6982, -1.6722],
        [-0.7384, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020186442881822586
Epoch 0, Step 21: train/loss = 0.6950615644454956, train/raw-loss = 0.6941919326782227, train/logprobs = tensor([[-0.9935, -1.2997],
        [-0.9919, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017392875161021948
Epoch 0, Step 22: train/loss = 0.6892591118812561, train/raw-loss = 0.6880555152893066, train/logprobs = tensor([[-1.1048, -1.2115],
        [-1.1166, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002407266292721033
Epoch 0, Step 23: train/loss = 0.7327304482460022, train/raw-loss = 0.7249387502670288, train/logprobs = tensor([[-1.1101, -1.9440],
        [-1.1279, -2.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015583477914333344
Epoch 0, Step 24: train/loss = 0.6903525590896606, train/raw-loss = 0.6900442838668823, train/logprobs = tensor([[-0.9510, -2.1814],
        [-0.9490, -2.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006165502709336579
Epoch 0, Step 25: train/loss = 0.6856604218482971, train/raw-loss = 0.6853428483009338, train/logprobs = tensor([[-0.8277, -2.2563],
        [-0.8247, -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006352229975163937
Epoch 0, Step 26: train/loss = 0.6989668607711792, train/raw-loss = 0.6981753706932068, train/logprobs = tensor([[-0.5759, -2.1066],
        [-0.6087, -2.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015831212513148785
Epoch 0, Step 27: train/loss = 0.6977221965789795, train/raw-loss = 0.6973809003829956, train/logprobs = tensor([[-1.0402, -2.5564],
        [-1.0804, -2.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006825224263593554
Epoch 0, Step 28: train/loss = 0.7010762691497803, train/raw-loss = 0.6975324153900146, train/logprobs = tensor([[-0.8392, -1.7205],
        [-0.8369, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007087648846209049
Epoch 0, Step 29: train/loss = 0.6936860084533691, train/raw-loss = 0.6934842467308044, train/logprobs = tensor([[-0.5879, -1.8914],
        [-0.5988, -1.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040351462666876614
Epoch 0, Step 30: train/loss = 0.6928040981292725, train/raw-loss = 0.6918355822563171, train/logprobs = tensor([[-0.8561, -1.1920],
        [-0.8388, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001937028020620346
Epoch 0, Step 31: train/loss = 0.6757000684738159, train/raw-loss = 0.672492265701294, train/logprobs = tensor([[-1.0550, -2.2670],
        [-1.0818, -2.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006415537558495998
Epoch 0, Step 32: train/loss = 0.6913647651672363, train/raw-loss = 0.6886965036392212, train/logprobs = tensor([[-0.9240, -1.9170],
        [-0.9467, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005336553789675236
Epoch 0, Step 33: train/loss = 0.7030938267707825, train/raw-loss = 0.7009933590888977, train/logprobs = tensor([[-0.8779, -1.8828],
        [-0.8573, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004200874827802181
Epoch 0, Step 34: train/loss = 0.7017703056335449, train/raw-loss = 0.6958221793174744, train/logprobs = tensor([[-1.0511, -1.5128],
        [-1.0826, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011896110139787197
Epoch 0, Step 35: train/loss = 0.7112126350402832, train/raw-loss = 0.7038596868515015, train/logprobs = tensor([[-0.9902, -1.8427],
        [-0.9916, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014705857262015343
Epoch 0, Step 36: train/loss = 0.7064070701599121, train/raw-loss = 0.6996639966964722, train/logprobs = tensor([[-1.2729, -1.4568],
        [-1.2776, -1.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013486114330589771
Epoch 0, Step 37: train/loss = 0.688489556312561, train/raw-loss = 0.6881989240646362, train/logprobs = tensor([[-0.6132, -1.4763],
        [-0.6105, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005811454029753804
Epoch 0, Step 38: train/loss = 0.6955756545066833, train/raw-loss = 0.6917117834091187, train/logprobs = tensor([[-0.8017, -1.5622],
        [-0.8207, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007727716118097305
Epoch 0, Step 39: train/loss = 0.6987912058830261, train/raw-loss = 0.6974338889122009, train/logprobs = tensor([[-0.6779, -1.3967],
        [-0.6694, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027145948261022568
Epoch 0, Step 40: train/loss = 0.6946728229522705, train/raw-loss = 0.6939688920974731, train/logprobs = tensor([[-0.7632, -1.1195],
        [-0.7654, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014077682280912995
Epoch 0, Step 41: train/loss = 0.6814106702804565, train/raw-loss = 0.6795097589492798, train/logprobs = tensor([[-0.8216, -1.7078],
        [-0.8400, -1.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003801777958869934
Epoch 0, Step 42: train/loss = 0.6960018277168274, train/raw-loss = 0.694367527961731, train/logprobs = tensor([[-0.6560, -1.7110],
        [-0.6654, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032684793695807457
Epoch 0, Step 43: train/loss = 0.6870541572570801, train/raw-loss = 0.6866177916526794, train/logprobs = tensor([[-1.0934, -2.2801],
        [-1.0771, -2.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008726525702513754
Epoch 0, Step 44: train/loss = 0.690687894821167, train/raw-loss = 0.6903976798057556, train/logprobs = tensor([[-0.9415, -1.1740],
        [-0.9243, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005802650121040642
Epoch 0, Step 45: train/loss = 0.7080854177474976, train/raw-loss = 0.7042211294174194, train/logprobs = tensor([[-0.8766, -1.8393],
        [-0.8959, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007728645112365484
Epoch 0, Step 46: train/loss = 0.7264948487281799, train/raw-loss = 0.7230007648468018, train/logprobs = tensor([[-1.1262, -2.6505],
        [-1.1680, -2.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006988189183175564
Epoch 0, Step 47: train/loss = 0.6950525641441345, train/raw-loss = 0.6937203407287598, train/logprobs = tensor([[-0.7199, -1.4910],
        [-0.7111, -1.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026645706966519356
Epoch 0, Step 48: train/loss = 0.7095362544059753, train/raw-loss = 0.7070211172103882, train/logprobs = tensor([[-1.3350, -1.4101],
        [-1.3527, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005030433181673288
Epoch 0, Step 49: train/loss = 0.6939435005187988, train/raw-loss = 0.6914311051368713, train/logprobs = tensor([[-0.8395, -1.8763],
        [-0.8370, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005024871788918972
Epoch 0, Step 50: train/loss = 0.6912357807159424, train/raw-loss = 0.6909155249595642, train/logprobs = tensor([[-1.0832, -1.3937],
        [-1.0782, -1.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405673339031637
Epoch 0, Step 51: train/loss = 0.6876543164253235, train/raw-loss = 0.6857802867889404, train/logprobs = tensor([[-0.9913, -1.7751],
        [-0.9906, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037480113096535206
Epoch 0, Step 52: train/loss = 0.6878581643104553, train/raw-loss = 0.687508761882782, train/logprobs = tensor([[-0.7081, -0.7210],
        [-0.7282, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006987795932218432
Epoch 0, Step 53: train/loss = 0.7120514512062073, train/raw-loss = 0.7088227868080139, train/logprobs = tensor([[-0.6088, -1.0795],
        [-0.5906, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064574312418699265
Epoch 0, Step 54: train/loss = 0.6850500106811523, train/raw-loss = 0.682507336139679, train/logprobs = tensor([[-1.2230, -1.6885],
        [-1.2433, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005085480399429798
Epoch 0, Step 55: train/loss = 0.7114070653915405, train/raw-loss = 0.7028936743736267, train/logprobs = tensor([[-1.3000, -1.1052],
        [-1.3418, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017026763409376144
Epoch 0, Step 56: train/loss = 0.682807445526123, train/raw-loss = 0.6819606423377991, train/logprobs = tensor([[-0.8773, -1.4545],
        [-0.8995, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016936644678935409
Epoch 0, Step 57: train/loss = 0.6898714900016785, train/raw-loss = 0.6851555109024048, train/logprobs = tensor([[-0.6412, -1.4265],
        [-0.6492, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009431957267224789
Epoch 0, Step 58: train/loss = 0.6740976572036743, train/raw-loss = 0.6735333204269409, train/logprobs = tensor([[-0.6794, -1.6542],
        [-0.6772, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001128867152146995
Epoch 0, Step 59: train/loss = 0.6931465864181519, train/raw-loss = 0.6919022798538208, train/logprobs = tensor([[-0.8279, -1.2489],
        [-0.8414, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024887453764677048
Epoch 0, Step 60: train/loss = 0.692626953125, train/raw-loss = 0.6914083957672119, train/logprobs = tensor([[-1.1025, -1.5208],
        [-1.0788, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024371917825192213
Epoch 0, Step 61: train/loss = 0.6787550449371338, train/raw-loss = 0.6773156523704529, train/logprobs = tensor([[-0.5136, -1.4002],
        [-0.5257, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028787010814994574
Epoch 0, Step 62: train/loss = 0.7129407525062561, train/raw-loss = 0.7092434763908386, train/logprobs = tensor([[-1.1946, -1.5974],
        [-1.1819, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007394595071673393
Epoch 0, Step 63: train/loss = 0.6974267959594727, train/raw-loss = 0.6964080333709717, train/logprobs = tensor([[-0.9767, -1.3460],
        [-0.9932, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002037512604147196
Epoch 0, Step 64: train/loss = 0.6909778714179993, train/raw-loss = 0.6902614831924438, train/logprobs = tensor([[-0.9298, -1.6377],
        [-0.9230, -1.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014327240642160177
Epoch 0, Step 65: train/loss = 0.6951013803482056, train/raw-loss = 0.6941920518875122, train/logprobs = tensor([[-0.8753, -1.5697],
        [-0.8672, -1.5572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001818489283323288
Epoch 0, Step 66: train/loss = 0.7125683426856995, train/raw-loss = 0.7086559534072876, train/logprobs = tensor([[-1.0548, -1.9557],
        [-1.0042, -1.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007824767380952835
Epoch 0, Step 67: train/loss = 0.6960287690162659, train/raw-loss = 0.6936912536621094, train/logprobs = tensor([[-0.6817, -1.8677],
        [-0.6683, -1.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004675170406699181
Epoch 0, Step 68: train/loss = 0.706365704536438, train/raw-loss = 0.7022433280944824, train/logprobs = tensor([[-0.8045, -2.7955],
        [-0.7888, -2.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008244798518717289
Epoch 0, Step 69: train/loss = 0.6882819533348083, train/raw-loss = 0.6873049139976501, train/logprobs = tensor([[-1.2771, -1.7102],
        [-1.2871, -1.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019541364163160324
Epoch 0, Step 70: train/loss = 0.6898083686828613, train/raw-loss = 0.6889727115631104, train/logprobs = tensor([[-0.5960, -1.9425],
        [-0.5926, -1.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016713044606149197
Epoch 0, Step 71: train/loss = 0.6975122094154358, train/raw-loss = 0.6921864748001099, train/logprobs = tensor([[-1.0513, -1.9623],
        [-1.0396, -1.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01065143197774887
Epoch 0, Step 72: train/loss = 0.6834346652030945, train/raw-loss = 0.6829015016555786, train/logprobs = tensor([[-0.4523, -1.9873],
        [-0.4532, -1.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010661862324923277
Epoch 0, Step 73: train/loss = 0.698910117149353, train/raw-loss = 0.6972681283950806, train/logprobs = tensor([[-0.7373, -1.1117],
        [-0.7714, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032838257029652596
Epoch 0, Step 74: train/loss = 0.6985875368118286, train/raw-loss = 0.6977624893188477, train/logprobs = tensor([[-1.5998, -2.0033],
        [-1.5766, -1.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016500119818374515
Epoch 0, Step 75: train/loss = 0.6912165284156799, train/raw-loss = 0.6905814409255981, train/logprobs = tensor([[-0.7798, -1.8981],
        [-0.7725, -1.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012701851082965732
Epoch 0, Step 76: train/loss = 0.6712746024131775, train/raw-loss = 0.6697449088096619, train/logprobs = tensor([[-0.9836, -1.5836],
        [-1.0579, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030595280695706606
Epoch 0, Step 77: train/loss = 0.6943480968475342, train/raw-loss = 0.6932022571563721, train/logprobs = tensor([[-1.2784, -1.4951],
        [-1.2875, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022915536537766457
Epoch 0, Step 78: train/loss = 0.6852647066116333, train/raw-loss = 0.6847133040428162, train/logprobs = tensor([[-0.8913, -1.9043],
        [-0.9033, -1.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011027561267837882
Epoch 0, Step 79: train/loss = 0.6850671768188477, train/raw-loss = 0.6847375631332397, train/logprobs = tensor([[-0.5505, -1.2752],
        [-0.5535, -1.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006592871504835784
Epoch 0, Step 80: train/loss = 0.6859961152076721, train/raw-loss = 0.6853229403495789, train/logprobs = tensor([[-1.0805, -2.1475],
        [-1.0749, -2.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013463824288919568
Epoch 0, Step 81: train/loss = 0.7036861181259155, train/raw-loss = 0.7033001184463501, train/logprobs = tensor([[-0.8323, -1.9020],
        [-0.8423, -1.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007720249122940004
Epoch 0, Step 82: train/loss = 0.697616696357727, train/raw-loss = 0.6953122615814209, train/logprobs = tensor([[-1.2444, -1.0746],
        [-1.2470, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004608801566064358
Epoch 0, Step 83: train/loss = 0.6955578923225403, train/raw-loss = 0.6918206214904785, train/logprobs = tensor([[-0.6397, -1.7171],
        [-0.6420, -1.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007474556099623442
Epoch 0, Step 84: train/loss = 0.6875075101852417, train/raw-loss = 0.6872358322143555, train/logprobs = tensor([[-0.5644, -2.0531],
        [-0.5607, -2.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005434107733890414
Epoch 0, Step 85: train/loss = 0.7049648761749268, train/raw-loss = 0.7008020281791687, train/logprobs = tensor([[-0.9265, -2.1887],
        [-0.9314, -2.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008325804956257343
Epoch 0, Step 86: train/loss = 0.6875048875808716, train/raw-loss = 0.6865978240966797, train/logprobs = tensor([[-0.6502, -1.8401],
        [-0.6534, -1.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018142140470445156
Epoch 0, Step 87: train/loss = 0.7068085670471191, train/raw-loss = 0.7051491141319275, train/logprobs = tensor([[-1.3981, -1.5903],
        [-1.3917, -1.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003318838542327285
Epoch 0, Step 88: train/loss = 0.7004499435424805, train/raw-loss = 0.6983426809310913, train/logprobs = tensor([[-0.8154, -2.0678],
        [-0.8247, -2.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004214618820697069
Epoch 0, Step 89: train/loss = 0.7010762691497803, train/raw-loss = 0.6953358054161072, train/logprobs = tensor([[-1.1095, -1.9282],
        [-1.1037, -1.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011481000110507011
Epoch 0, Step 90: train/loss = 0.695562481880188, train/raw-loss = 0.6938470005989075, train/logprobs = tensor([[-0.8569, -1.8150],
        [-0.8975, -1.8378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034309118054807186
Epoch 0, Step 91: train/loss = 0.6868893504142761, train/raw-loss = 0.6867875456809998, train/logprobs = tensor([[-1.3167, -1.1845],
        [-1.3469, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020368437981233
Epoch 0, Step 92: train/loss = 0.6972661018371582, train/raw-loss = 0.6911544799804688, train/logprobs = tensor([[-0.9182, -1.7332],
        [-0.9839, -1.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012223410420119762
Epoch 0, Step 93: train/loss = 0.7005707621574402, train/raw-loss = 0.6972322463989258, train/logprobs = tensor([[-1.0097, -1.4975],
        [-1.0235, -1.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006677023135125637
Epoch 0, Step 94: train/loss = 0.7183730602264404, train/raw-loss = 0.7093076109886169, train/logprobs = tensor([[-1.2801, -2.7481],
        [-1.3192, -2.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01813080720603466
Epoch 0, Step 95: train/loss = 0.6936503648757935, train/raw-loss = 0.6909185647964478, train/logprobs = tensor([[-1.5620, -2.2800],
        [-1.5809, -2.2385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005463535897433758
Epoch 0, Step 96: train/loss = 0.6915501356124878, train/raw-loss = 0.6909695863723755, train/logprobs = tensor([[-0.8741, -1.7082],
        [-0.8728, -1.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011612136149778962
Epoch 0, Step 97: train/loss = 0.7016347646713257, train/raw-loss = 0.7011577486991882, train/logprobs = tensor([[-1.7938, -2.7701],
        [-1.7919, -2.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009539825841784477
Epoch 0, Step 98: train/loss = 0.6938573718070984, train/raw-loss = 0.6915621161460876, train/logprobs = tensor([[-1.1016, -1.6260],
        [-1.1131, -1.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004590435419231653
Epoch 0, Step 99: train/loss = 0.6904973983764648, train/raw-loss = 0.6891137361526489, train/logprobs = tensor([[-0.8660, -1.5823],
        [-0.8621, -1.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027672946453094482
Epoch 0, Step 100: train/loss = 0.693412721157074, train/raw-loss = 0.690688967704773, train/logprobs = tensor([[-1.0238, -1.3505],
        [-1.0222, -1.3139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005447491072118282
Epoch 0, Step 101: train/loss = 0.6863174438476562, train/raw-loss = 0.684230625629425, train/logprobs = tensor([[-1.1547, -2.3775],
        [-1.1537, -2.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004173708148300648
Epoch 0, Step 102: train/loss = 0.6695535182952881, train/raw-loss = 0.6689720749855042, train/logprobs = tensor([[-0.7605, -1.8073],
        [-0.7433, -1.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011628801003098488
Epoch 0, Step 103: train/loss = 0.6826401352882385, train/raw-loss = 0.6805273294448853, train/logprobs = tensor([[-0.8663, -1.7522],
        [-0.8909, -1.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004225545097142458
Epoch 0, Step 104: train/loss = 0.6885157227516174, train/raw-loss = 0.6863085031509399, train/logprobs = tensor([[-0.8408, -1.5273],
        [-0.8408, -1.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004414567723870277
Epoch 0, Step 105: train/loss = 0.690217137336731, train/raw-loss = 0.6885687112808228, train/logprobs = tensor([[-0.9840, -1.8099],
        [-0.9837, -1.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003296835348010063
Epoch 0, Step 106: train/loss = 0.6897079944610596, train/raw-loss = 0.6886006593704224, train/logprobs = tensor([[-0.7332, -1.7989],
        [-0.7088, -1.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002214516745880246
Epoch 0, Step 107: train/loss = 0.6981536149978638, train/raw-loss = 0.6931666135787964, train/logprobs = tensor([[-1.2936, -1.7090],
        [-1.3091, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009974054992198944
Epoch 0, Step 108: train/loss = 0.6924501061439514, train/raw-loss = 0.6902596950531006, train/logprobs = tensor([[-0.7424, -0.8713],
        [-0.7387, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004380754195153713
Epoch 0, Step 109: train/loss = 0.6999424695968628, train/raw-loss = 0.6962488889694214, train/logprobs = tensor([[-0.8069, -1.7912],
        [-0.8069, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007387225050479174
Epoch 0, Step 110: train/loss = 0.6721416711807251, train/raw-loss = 0.6712837815284729, train/logprobs = tensor([[-0.9596, -2.1839],
        [-0.9328, -2.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017156992107629776
Epoch 0, Step 111: train/loss = 0.7015446424484253, train/raw-loss = 0.7004367113113403, train/logprobs = tensor([[-0.9225, -1.7991],
        [-0.9121, -1.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002215857384726405
Epoch 0, Step 112: train/loss = 0.6971138715744019, train/raw-loss = 0.6963221430778503, train/logprobs = tensor([[-1.4954, -1.4432],
        [-1.5201, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015835822559893131
Epoch 0, Step 113: train/loss = 0.6878326535224915, train/raw-loss = 0.6870850324630737, train/logprobs = tensor([[-1.0543, -1.4048],
        [-1.0390, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014951812336221337
Epoch 0, Step 114: train/loss = 0.6884299516677856, train/raw-loss = 0.6873266100883484, train/logprobs = tensor([[-0.9411, -1.1967],
        [-0.9482, -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022067315876483917
Epoch 0, Step 115: train/loss = 0.6659959554672241, train/raw-loss = 0.6650730967521667, train/logprobs = tensor([[-0.7639, -1.7900],
        [-0.7430, -1.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018455906538292766
Epoch 0, Step 116: train/loss = 0.6929373741149902, train/raw-loss = 0.6928953528404236, train/logprobs = tensor([[-0.6456, -1.4476],
        [-0.6509, -1.4511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.403895481023937e-05
Epoch 0, Step 117: train/loss = 0.682467520236969, train/raw-loss = 0.6811960935592651, train/logprobs = tensor([[-0.9032, -1.7931],
        [-0.9125, -1.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025428133085370064
Epoch 0, Step 118: train/loss = 0.691042959690094, train/raw-loss = 0.6887187957763672, train/logprobs = tensor([[-0.9848, -1.9308],
        [-1.0259, -1.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0046483189798891544
Epoch 0, Step 119: train/loss = 0.6992402076721191, train/raw-loss = 0.6974175572395325, train/logprobs = tensor([[-1.4385, -1.8502],
        [-1.4662, -1.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036451073829084635
Epoch 0, Step 120: train/loss = 0.72600919008255, train/raw-loss = 0.7231651544570923, train/logprobs = tensor([[-1.1320, -2.1866],
        [-1.1195, -2.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005688050761818886
Epoch 0, Step 121: train/loss = 0.6916066408157349, train/raw-loss = 0.6897040605545044, train/logprobs = tensor([[-0.7498, -1.1900],
        [-0.7637, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038051633164286613
Epoch 0, Step 122: train/loss = 0.6890109777450562, train/raw-loss = 0.6885119676589966, train/logprobs = tensor([[-1.0447, -2.8060],
        [-1.0253, -2.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009979179594665766
Epoch 0, Step 123: train/loss = 0.6915655136108398, train/raw-loss = 0.6885963082313538, train/logprobs = tensor([[-1.1979, -1.4315],
        [-1.1980, -1.3848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059384535998106
Epoch 0, Step 124: train/loss = 0.6908040046691895, train/raw-loss = 0.6888045072555542, train/logprobs = tensor([[-0.6293, -1.4107],
        [-0.5842, -1.3294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003999031148850918
Epoch 0, Step 125: train/loss = 0.682540774345398, train/raw-loss = 0.6812291145324707, train/logprobs = tensor([[-0.8282, -2.3683],
        [-0.8610, -2.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026232253294438124
Epoch 0, Step 126: train/loss = 0.6960868239402771, train/raw-loss = 0.6953462362289429, train/logprobs = tensor([[-1.1818, -2.9308],
        [-1.2310, -2.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014811475994065404
Epoch 0, Step 127: train/loss = 0.6862305998802185, train/raw-loss = 0.6850816607475281, train/logprobs = tensor([[-0.9878, -1.8393],
        [-0.9442, -1.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022979825735092163
Epoch 0, Step 128: train/loss = 0.7110101580619812, train/raw-loss = 0.7091569900512695, train/logprobs = tensor([[-1.0255, -1.5332],
        [-1.0040, -1.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003706212155520916
Epoch 0, Step 129: train/loss = 0.7067625522613525, train/raw-loss = 0.7049587368965149, train/logprobs = tensor([[-1.1495, -1.9663],
        [-1.1387, -1.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003607684513553977
Epoch 0, Step 130: train/loss = 0.6991182565689087, train/raw-loss = 0.6972491145133972, train/logprobs = tensor([[-1.2199, -2.6717],
        [-1.1658, -2.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037382892332971096
Epoch 0, Step 131: train/loss = 0.6881378889083862, train/raw-loss = 0.686215877532959, train/logprobs = tensor([[-1.5756, -1.5009],
        [-1.6000, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038440339267253876
Epoch 0, Step 132: train/loss = 0.6981207132339478, train/raw-loss = 0.6900719404220581, train/logprobs = tensor([[-1.0386, -2.2119],
        [-1.1398, -2.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016097480431199074
Epoch 0, Step 133: train/loss = 0.6921040415763855, train/raw-loss = 0.6911511421203613, train/logprobs = tensor([[-1.4987, -1.8861],
        [-1.5179, -1.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019058953039348125
Epoch 0, Step 134: train/loss = 0.6883475184440613, train/raw-loss = 0.6864171028137207, train/logprobs = tensor([[-1.0428, -1.7296],
        [-1.0470, -1.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038609332405030727
Epoch 0, Step 135: train/loss = 0.6851276755332947, train/raw-loss = 0.6847190856933594, train/logprobs = tensor([[-1.5757, -1.6620],
        [-1.5691, -1.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008170563960447907
Epoch 0, Step 136: train/loss = 0.6861568093299866, train/raw-loss = 0.6798779368400574, train/logprobs = tensor([[-1.5651, -2.3913],
        [-1.6027, -2.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01255776360630989
Epoch 0, Step 137: train/loss = 0.6844401359558105, train/raw-loss = 0.683949887752533, train/logprobs = tensor([[-1.6558, -1.5294],
        [-1.6756, -1.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009804351720958948
Epoch 0, Step 138: train/loss = 0.6976139545440674, train/raw-loss = 0.6950036883354187, train/logprobs = tensor([[-1.2173, -2.0498],
        [-1.1710, -1.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052204434759914875
Epoch 0, Step 139: train/loss = 0.7205137610435486, train/raw-loss = 0.70903480052948, train/logprobs = tensor([[-1.1851, -2.5053],
        [-1.2097, -2.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02295790985226631
Epoch 0, Step 140: train/loss = 0.6872981786727905, train/raw-loss = 0.6867064237594604, train/logprobs = tensor([[-1.0911, -2.3016],
        [-1.0986, -2.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011832849122583866
Epoch 0, Step 141: train/loss = 0.6817812919616699, train/raw-loss = 0.680654764175415, train/logprobs = tensor([[-0.8784, -2.1325],
        [-0.8662, -2.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022529903799295425
Epoch 0, Step 142: train/loss = 0.6814002394676208, train/raw-loss = 0.6792538166046143, train/logprobs = tensor([[-1.3528, -1.9424],
        [-1.3572, -1.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004292843863368034
Epoch 0, Step 143: train/loss = 0.6948807239532471, train/raw-loss = 0.6899423003196716, train/logprobs = tensor([[-1.6143, -1.7650],
        [-1.6343, -1.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009876745752990246
Epoch 0, Step 144: train/loss = 0.6940087080001831, train/raw-loss = 0.6913016438484192, train/logprobs = tensor([[-0.9692, -1.8725],
        [-0.9603, -1.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005414226092398167
Epoch 0, Step 145: train/loss = 0.6954666376113892, train/raw-loss = 0.6927218437194824, train/logprobs = tensor([[-1.1674, -1.5896],
        [-1.1581, -1.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005489710718393326
Epoch 0, Step 146: train/loss = 0.6897889375686646, train/raw-loss = 0.6874349117279053, train/logprobs = tensor([[-0.7800, -1.8418],
        [-0.7891, -1.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004707890562713146
Epoch 0, Step 147: train/loss = 0.685763418674469, train/raw-loss = 0.6849453449249268, train/logprobs = tensor([[-1.3528, -1.8242],
        [-1.3425, -1.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001636219210922718
Epoch 0, Step 148: train/loss = 0.6854430437088013, train/raw-loss = 0.6851781010627747, train/logprobs = tensor([[-1.0356, -1.4883],
        [-1.0409, -1.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005298900650814176
Epoch 0, Step 149: train/loss = 0.686173141002655, train/raw-loss = 0.6861005425453186, train/logprobs = tensor([[-1.0286, -1.8409],
        [-1.0199, -1.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014526178711093962
Epoch 0, Step 150: train/loss = 0.6898893117904663, train/raw-loss = 0.6894222497940063, train/logprobs = tensor([[-1.1404, -1.8091],
        [-1.0983, -1.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009342611883766949
Epoch 0, Step 151: train/loss = 0.7030633687973022, train/raw-loss = 0.7007792592048645, train/logprobs = tensor([[-0.9536, -1.5022],
        [-0.9536, -1.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004568204283714294
Epoch 0, Step 152: train/loss = 0.686277449131012, train/raw-loss = 0.6860311031341553, train/logprobs = tensor([[-0.9630, -1.9808],
        [-0.9479, -1.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004926594556309283
Epoch 0, Step 153: train/loss = 0.7009791135787964, train/raw-loss = 0.6997209787368774, train/logprobs = tensor([[-1.1033, -1.7867],
        [-1.0951, -1.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025161460507661104
Epoch 0, Step 154: train/loss = 0.6910641193389893, train/raw-loss = 0.6884475350379944, train/logprobs = tensor([[-1.4286, -2.1810],
        [-1.4289, -2.1385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005233250092715025
Epoch 0, Step 155: train/loss = 0.691961407661438, train/raw-loss = 0.69142746925354, train/logprobs = tensor([[-0.8927, -1.6920],
        [-0.8758, -1.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001067795092239976
Epoch 0, Step 156: train/loss = 0.6891263127326965, train/raw-loss = 0.6886776685714722, train/logprobs = tensor([[-1.0711, -2.3198],
        [-1.0502, -2.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008972391951829195
Epoch 0, Step 157: train/loss = 0.6980544328689575, train/raw-loss = 0.6954432725906372, train/logprobs = tensor([[-0.9997, -1.3402],
        [-0.9767, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005222412757575512
Epoch 0, Step 158: train/loss = 0.6802882552146912, train/raw-loss = 0.6790196895599365, train/logprobs = tensor([[-0.8405, -0.8399],
        [-0.8489, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025371313095092773
Epoch 0, Step 159: train/loss = 0.6896589994430542, train/raw-loss = 0.6876919269561768, train/logprobs = tensor([[-0.8810, -1.3305],
        [-0.8606, -1.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003934177570044994
Epoch 0, Step 160: train/loss = 0.6879044771194458, train/raw-loss = 0.6868934035301208, train/logprobs = tensor([[-0.8499, -1.3826],
        [-0.8264, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002022139262408018
Epoch 0, Step 161: train/loss = 0.6904204487800598, train/raw-loss = 0.6895579099655151, train/logprobs = tensor([[-0.9357, -2.0146],
        [-0.9678, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001725030248053372
Epoch 0, Step 162: train/loss = 0.6678183674812317, train/raw-loss = 0.6670506000518799, train/logprobs = tensor([[-0.7172, -2.3904],
        [-0.6889, -2.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015356680378317833
Epoch 0, Step 163: train/loss = 0.6788883805274963, train/raw-loss = 0.6764262914657593, train/logprobs = tensor([[-1.2868, -1.8622],
        [-1.2711, -1.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049242498353123665
Epoch 0, Step 164: train/loss = 0.6866964101791382, train/raw-loss = 0.6820933222770691, train/logprobs = tensor([[-1.5636, -1.8126],
        [-1.5796, -1.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009206139482557774
Epoch 0, Step 165: train/loss = 0.6918493509292603, train/raw-loss = 0.6899087429046631, train/logprobs = tensor([[-1.1642, -2.0461],
        [-1.1494, -1.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038813010323792696
Epoch 0, Step 166: train/loss = 0.6887509822845459, train/raw-loss = 0.6877756118774414, train/logprobs = tensor([[-0.8966, -2.1543],
        [-0.8979, -2.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019507624674588442
Epoch 0, Step 167: train/loss = 0.6803844571113586, train/raw-loss = 0.6793591976165771, train/logprobs = tensor([[-1.2893, -1.2934],
        [-1.3474, -1.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020505220163613558
Epoch 0, Step 168: train/loss = 0.6931778788566589, train/raw-loss = 0.6914680600166321, train/logprobs = tensor([[-1.0628, -1.3645],
        [-1.0611, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003419701009988785
Epoch 0, Step 169: train/loss = 0.6894400119781494, train/raw-loss = 0.6885769367218018, train/logprobs = tensor([[-0.8894, -1.6329],
        [-0.9077, -1.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017260332824662328
Epoch 0, Step 170: train/loss = 0.6798365116119385, train/raw-loss = 0.6793133020401001, train/logprobs = tensor([[-0.6295, -2.1268],
        [-0.6298, -2.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010466311359778047
Epoch 0, Step 171: train/loss = 0.7018802165985107, train/raw-loss = 0.6962968707084656, train/logprobs = tensor([[-1.2885, -1.5661],
        [-1.2706, -1.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011166609823703766
Epoch 0, Step 172: train/loss = 0.6961556077003479, train/raw-loss = 0.6908423900604248, train/logprobs = tensor([[-1.0404, -1.9026],
        [-1.0281, -1.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010626486502587795
Epoch 0, Step 173: train/loss = 0.6929730176925659, train/raw-loss = 0.6881112456321716, train/logprobs = tensor([[-1.1508, -2.5598],
        [-1.1897, -2.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00972350500524044
Epoch 0, Step 174: train/loss = 0.7145737409591675, train/raw-loss = 0.7091901302337646, train/logprobs = tensor([[-1.2877, -2.7430],
        [-1.2624, -2.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010767164640128613
Epoch 0, Step 175: train/loss = 0.6948392391204834, train/raw-loss = 0.6946759223937988, train/logprobs = tensor([[-1.6553, -1.8044],
        [-1.5755, -1.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032651054789312184
Epoch 0, Step 176: train/loss = 0.6805086731910706, train/raw-loss = 0.6780749559402466, train/logprobs = tensor([[-0.8433, -2.0499],
        [-0.8247, -1.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0048674470745027065
Epoch 0, Step 177: train/loss = 0.6780036091804504, train/raw-loss = 0.6771392822265625, train/logprobs = tensor([[-0.9446, -1.6481],
        [-0.9476, -1.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017287798691540956
Epoch 0, Step 178: train/loss = 0.6890126466751099, train/raw-loss = 0.6871885657310486, train/logprobs = tensor([[-0.7771, -1.9395],
        [-0.7719, -1.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003648033831268549
Epoch 0, Step 179: train/loss = 0.6908313035964966, train/raw-loss = 0.6894286870956421, train/logprobs = tensor([[-1.3593, -2.0438],
        [-1.3530, -2.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002805243479087949
Epoch 0, Step 180: train/loss = 0.6842519640922546, train/raw-loss = 0.6820728182792664, train/logprobs = tensor([[-1.2104, -1.6028],
        [-1.2156, -1.5358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00435823667794466
Epoch 0, Step 181: train/loss = 0.6984142661094666, train/raw-loss = 0.6968488097190857, train/logprobs = tensor([[-0.9734, -1.6700],
        [-0.9821, -1.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003130862955003977
Epoch 0, Step 182: train/loss = 0.6886130571365356, train/raw-loss = 0.685735821723938, train/logprobs = tensor([[-1.1351, -1.5598],
        [-1.1474, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005754311569035053
Epoch 0, Step 183: train/loss = 0.6817033886909485, train/raw-loss = 0.6769623756408691, train/logprobs = tensor([[-0.8673, -1.9161],
        [-0.8835, -1.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009482002817094326
Epoch 0, Step 184: train/loss = 0.6759888529777527, train/raw-loss = 0.6754715442657471, train/logprobs = tensor([[-1.0072, -2.0921],
        [-1.0217, -2.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010347056668251753
Epoch 0, Step 185: train/loss = 0.7142598628997803, train/raw-loss = 0.7055134177207947, train/logprobs = tensor([[-0.9014, -1.7964],
        [-0.8972, -1.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017492860555648804
Epoch 0, Step 186: train/loss = 0.691871702671051, train/raw-loss = 0.6897801756858826, train/logprobs = tensor([[-0.8349, -1.9169],
        [-0.8182, -1.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004183112643659115
Epoch 0, Step 187: train/loss = 0.6965339183807373, train/raw-loss = 0.6935791969299316, train/logprobs = tensor([[-0.9794, -1.6957],
        [-0.9753, -1.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005909494124352932
Epoch 0, Step 188: train/loss = 0.6852859854698181, train/raw-loss = 0.6847444772720337, train/logprobs = tensor([[-1.2326, -1.9616],
        [-1.2038, -1.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010831240797415376
Epoch 0, Step 189: train/loss = 0.7068382501602173, train/raw-loss = 0.7015628814697266, train/logprobs = tensor([[-1.1458, -1.6448],
        [-1.1384, -1.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010550791397690773
Epoch 0, Step 190: train/loss = 0.687364935874939, train/raw-loss = 0.68233722448349, train/logprobs = tensor([[-1.5328, -1.6212],
        [-1.5901, -1.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0100556043908
Epoch 0, Step 191: train/loss = 0.6918544769287109, train/raw-loss = 0.6894339323043823, train/logprobs = tensor([[-1.0207, -1.6327],
        [-1.0186, -1.5912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004841146990656853
Epoch 0, Step 192: train/loss = 0.6820099949836731, train/raw-loss = 0.6754233837127686, train/logprobs = tensor([[-1.1728, -1.4222],
        [-1.2150, -1.3368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013173244893550873
Epoch 0, Step 193: train/loss = 0.7004337906837463, train/raw-loss = 0.6991547346115112, train/logprobs = tensor([[-0.7017, -1.2699],
        [-0.7353, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025579233188182116
Epoch 0, Step 194: train/loss = 0.6786563992500305, train/raw-loss = 0.6778149604797363, train/logprobs = tensor([[-1.0911, -1.2162],
        [-1.1314, -1.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016829253872856498
Epoch 0, Step 195: train/loss = 0.6821001768112183, train/raw-loss = 0.681237518787384, train/logprobs = tensor([[-0.6022, -1.4902],
        [-0.6028, -1.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017252466641366482
Epoch 0, Step 196: train/loss = 0.687163770198822, train/raw-loss = 0.6866040229797363, train/logprobs = tensor([[-1.4984, -2.0512],
        [-1.4380, -1.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011194219114258885
Epoch 0, Step 197: train/loss = 0.6757580041885376, train/raw-loss = 0.6739840507507324, train/logprobs = tensor([[-0.9352, -1.4783],
        [-0.9219, -1.3720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003547727596014738
Epoch 0, Step 198: train/loss = 0.6746252775192261, train/raw-loss = 0.6737326383590698, train/logprobs = tensor([[-0.8439, -0.9449],
        [-0.8589, -0.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017853539902716875
Epoch 0, Step 199: train/loss = 0.6752442121505737, train/raw-loss = 0.674493670463562, train/logprobs = tensor([[-0.9219, -1.1301],
        [-0.9619, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001500988146290183
Epoch 0, Step 200: train/loss = 0.6742763519287109, train/raw-loss = 0.667475163936615, train/logprobs = tensor([[-1.1373, -2.3073],
        [-1.1599, -2.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013602454215288162
Epoch 0, Step 201: train/loss = 0.6756325960159302, train/raw-loss = 0.6742556095123291, train/logprobs = tensor([[-0.6501, -1.7914],
        [-0.6570, -1.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027538109570741653
Epoch 0, Step 202: train/loss = 0.6770120859146118, train/raw-loss = 0.6764994859695435, train/logprobs = tensor([[-0.6876, -1.9636],
        [-0.6908, -1.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010250862687826157
Epoch 0, Step 203: train/loss = 0.6309235692024231, train/raw-loss = 0.6255987882614136, train/logprobs = tensor([[-1.1188, -1.3643],
        [-1.2330, -1.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010649548843502998
Epoch 0, Step 204: train/loss = 0.6654815673828125, train/raw-loss = 0.6651394963264465, train/logprobs = tensor([[-1.3380, -1.4155],
        [-1.3562, -1.3187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006841113790869713
Epoch 0, Step 205: train/loss = 0.6701719760894775, train/raw-loss = 0.6684163808822632, train/logprobs = tensor([[-0.6593, -1.4681],
        [-0.6556, -1.3441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003511149436235428
Epoch 0, Step 206: train/loss = 0.6602697372436523, train/raw-loss = 0.6587415933609009, train/logprobs = tensor([[-0.8295, -1.4156],
        [-0.8259, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030562232714146376
Epoch 0, Step 207: train/loss = 0.6520980596542358, train/raw-loss = 0.6514357924461365, train/logprobs = tensor([[-0.7445, -1.9754],
        [-0.7717, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013245918089523911
Epoch 0, Step 208: train/loss = 0.6701133251190186, train/raw-loss = 0.6677569150924683, train/logprobs = tensor([[-1.3206, -2.3516],
        [-1.3584, -2.2625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047128768637776375
Epoch 0, Step 209: train/loss = 0.6920977234840393, train/raw-loss = 0.6906652450561523, train/logprobs = tensor([[-0.9352, -1.8527],
        [-0.9223, -1.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002864954760298133
Epoch 0, Step 210: train/loss = 0.66815185546875, train/raw-loss = 0.6637439727783203, train/logprobs = tensor([[-1.5561, -1.5898],
        [-1.6235, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008815725333988667
Epoch 0, Step 211: train/loss = 0.6876691579818726, train/raw-loss = 0.6843619346618652, train/logprobs = tensor([[-1.1453, -2.1264],
        [-1.1346, -2.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006614455953240395
Epoch 0, Step 212: train/loss = 0.6814783811569214, train/raw-loss = 0.6806535720825195, train/logprobs = tensor([[-0.7495, -1.2048],
        [-0.7397, -1.1381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001649608020670712
Epoch 0, Step 213: train/loss = 0.6839362382888794, train/raw-loss = 0.6795371770858765, train/logprobs = tensor([[-1.3846, -1.9402],
        [-1.3981, -1.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008798087015748024
Epoch 0, Step 214: train/loss = 0.6927624344825745, train/raw-loss = 0.6910207271575928, train/logprobs = tensor([[-0.8737, -1.1756],
        [-0.8706, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034834551624953747
Epoch 0, Step 215: train/loss = 0.6566216349601746, train/raw-loss = 0.6556589007377625, train/logprobs = tensor([[-1.0846, -1.5902],
        [-1.1169, -1.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019254141952842474
Epoch 0, Step 216: train/loss = 0.6852909326553345, train/raw-loss = 0.6826255321502686, train/logprobs = tensor([[-1.6261, -1.5226],
        [-1.6279, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053309788927435875
Epoch 0, Step 217: train/loss = 0.6820130348205566, train/raw-loss = 0.6811423301696777, train/logprobs = tensor([[-0.8713, -1.6361],
        [-0.8975, -1.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017414992908015847
Epoch 0, Step 218: train/loss = 0.6688381433486938, train/raw-loss = 0.6676311492919922, train/logprobs = tensor([[-0.8165, -2.1798],
        [-0.8259, -2.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024138838052749634
Epoch 0, Step 219: train/loss = 0.6946021318435669, train/raw-loss = 0.6944267749786377, train/logprobs = tensor([[-1.0223, -0.9640],
        [-0.9925, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003505772619973868
Epoch 0, Step 220: train/loss = 0.6667492389678955, train/raw-loss = 0.6662774085998535, train/logprobs = tensor([[-1.2241, -2.9376],
        [-1.2356, -2.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000943628023378551
Epoch 0, Step 221: train/loss = 0.6754684448242188, train/raw-loss = 0.6749210953712463, train/logprobs = tensor([[-1.5210, -0.8334],
        [-1.5145, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010947189293801785
Epoch 0, Step 222: train/loss = 0.6859204769134521, train/raw-loss = 0.6848716139793396, train/logprobs = tensor([[-1.0017, -1.2858],
        [-0.9866, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002097788732498884
Epoch 0, Step 223: train/loss = 0.6835634112358093, train/raw-loss = 0.67741459608078, train/logprobs = tensor([[-0.9474, -2.0274],
        [-0.9923, -1.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012297607958316803
Epoch 0, Step 224: train/loss = 0.6766921281814575, train/raw-loss = 0.6735862493515015, train/logprobs = tensor([[-1.3467, -2.8137],
        [-1.3271, -2.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006211854517459869
Epoch 0, Step 225: train/loss = 0.6649777889251709, train/raw-loss = 0.6629298329353333, train/logprobs = tensor([[-0.8353, -2.1841],
        [-0.8032, -2.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004095911979675293
Epoch 0, Step 226: train/loss = 0.678237795829773, train/raw-loss = 0.6775266528129578, train/logprobs = tensor([[-1.0555, -2.5145],
        [-1.0788, -2.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014224128099158406
Epoch 0, Step 227: train/loss = 0.6744944453239441, train/raw-loss = 0.6738961935043335, train/logprobs = tensor([[-0.7557, -1.4342],
        [-0.7548, -1.3503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011964294826611876
Epoch 0, Step 228: train/loss = 0.6720555424690247, train/raw-loss = 0.6706708669662476, train/logprobs = tensor([[-1.1911, -2.5796],
        [-1.1717, -2.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002769188489764929
Epoch 0, Step 229: train/loss = 0.6553579568862915, train/raw-loss = 0.6539009809494019, train/logprobs = tensor([[-0.9729, -1.8158],
        [-1.0009, -1.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002914019860327244
Epoch 0, Step 230: train/loss = 0.6706604361534119, train/raw-loss = 0.6703548431396484, train/logprobs = tensor([[-1.1921, -2.7031],
        [-1.1763, -2.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006110664689913392
Epoch 0, Step 231: train/loss = 0.6779096126556396, train/raw-loss = 0.6765837669372559, train/logprobs = tensor([[-1.2695, -1.4820],
        [-1.2598, -1.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026515789795666933
Epoch 0, Step 232: train/loss = 0.6722829937934875, train/raw-loss = 0.670866847038269, train/logprobs = tensor([[-1.2153, -2.3650],
        [-1.2031, -2.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028323144651949406
Epoch 0, Step 233: train/loss = 0.6816938519477844, train/raw-loss = 0.679698646068573, train/logprobs = tensor([[-1.7309, -1.9793],
        [-1.6891, -1.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00399045692756772
Epoch 0, Step 234: train/loss = 0.6422298550605774, train/raw-loss = 0.6408242583274841, train/logprobs = tensor([[-1.0773, -2.0722],
        [-1.1034, -1.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028111934661865234
Epoch 0, Step 235: train/loss = 0.7016787528991699, train/raw-loss = 0.6958684921264648, train/logprobs = tensor([[-1.1748, -1.7603],
        [-1.1380, -1.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011620632372796535
Epoch 0, Step 236: train/loss = 0.6848770380020142, train/raw-loss = 0.6845417022705078, train/logprobs = tensor([[-0.7066, -1.5098],
        [-0.6937, -1.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006708269356749952
Epoch 0, Step 237: train/loss = 0.6765075922012329, train/raw-loss = 0.6746466159820557, train/logprobs = tensor([[-0.7830, -1.0815],
        [-0.7745, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037219813093543053
Epoch 0, Step 238: train/loss = 0.682468056678772, train/raw-loss = 0.6817851662635803, train/logprobs = tensor([[-0.7402, -1.6869],
        [-0.7410, -1.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013658548705279827
Epoch 0, Step 239: train/loss = 0.7016668319702148, train/raw-loss = 0.6966217160224915, train/logprobs = tensor([[-2.1282, -1.7957],
        [-2.0902, -1.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010090122930705547
Epoch 0, Step 240: train/loss = 0.691984236240387, train/raw-loss = 0.6862099170684814, train/logprobs = tensor([[-1.1375, -1.4952],
        [-1.1409, -1.4224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011548704467713833
Epoch 0, Step 241: train/loss = 0.6763813495635986, train/raw-loss = 0.6729114055633545, train/logprobs = tensor([[-1.0567, -2.0319],
        [-1.0952, -1.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006939745508134365
Epoch 0, Step 242: train/loss = 0.6632204055786133, train/raw-loss = 0.6620138883590698, train/logprobs = tensor([[-1.3103, -1.7471],
        [-1.3066, -1.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002413141541182995
Epoch 0, Step 243: train/loss = 0.6726671457290649, train/raw-loss = 0.6682090759277344, train/logprobs = tensor([[-1.4080, -1.7625],
        [-1.3981, -1.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008916138671338558
Epoch 0, Step 244: train/loss = 0.6812223196029663, train/raw-loss = 0.6806780099868774, train/logprobs = tensor([[-1.0458, -1.8258],
        [-1.0072, -1.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010885954834520817
Epoch 0, Step 245: train/loss = 0.6836745738983154, train/raw-loss = 0.6833561658859253, train/logprobs = tensor([[-1.2583, -1.7758],
        [-1.2426, -1.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006370334886014462
Epoch 0, Step 246: train/loss = 0.691318154335022, train/raw-loss = 0.6878204345703125, train/logprobs = tensor([[-1.0946, -1.6183],
        [-1.0808, -1.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00699545256793499
Epoch 0, Step 247: train/loss = 0.6917097568511963, train/raw-loss = 0.6879186630249023, train/logprobs = tensor([[-1.0210, -1.9419],
        [-0.9621, -1.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007582185789942741
Epoch 0, Step 248: train/loss = 0.6716934442520142, train/raw-loss = 0.6713385581970215, train/logprobs = tensor([[-1.0367, -2.5331],
        [-1.0033, -2.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007096526678651571
Epoch 0, Step 249: train/loss = 0.6740828156471252, train/raw-loss = 0.6737233400344849, train/logprobs = tensor([[-1.3898, -1.4948],
        [-1.4161, -1.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007189340540207922
Epoch 0, Step 250: train/loss = 0.6599920392036438, train/raw-loss = 0.6589711904525757, train/logprobs = tensor([[-0.6165, -2.2426],
        [-0.5810, -2.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002041588071733713
Epoch 0, Step 251: train/loss = 0.6922041177749634, train/raw-loss = 0.6918644905090332, train/logprobs = tensor([[-0.9875, -2.3007],
        [-1.0299, -2.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000679304706864059
Epoch 0, Step 252: train/loss = 0.7083836197853088, train/raw-loss = 0.7024679183959961, train/logprobs = tensor([[-1.2191, -1.2519],
        [-1.1695, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011831356212496758
Epoch 0, Step 253: train/loss = 0.6844803094863892, train/raw-loss = 0.6841868162155151, train/logprobs = tensor([[-1.3073, -1.5905],
        [-1.3093, -1.5542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005869696033187211
Epoch 0, Step 254: train/loss = 0.701655924320221, train/raw-loss = 0.6960946321487427, train/logprobs = tensor([[-0.9542, -1.1452],
        [-0.9770, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011122559197247028
Epoch 0, Step 255: train/loss = 0.670059859752655, train/raw-loss = 0.6684929132461548, train/logprobs = tensor([[-0.9306, -2.2672],
        [-0.9488, -2.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031339232809841633
Epoch 0, Step 256: train/loss = 0.6492157578468323, train/raw-loss = 0.648428201675415, train/logprobs = tensor([[-0.8010, -2.0211],
        [-0.7968, -1.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015750431921333075
Epoch 0, Step 257: train/loss = 0.6826984882354736, train/raw-loss = 0.6779621243476868, train/logprobs = tensor([[-1.4108, -2.5130],
        [-1.3768, -2.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009472809731960297
Epoch 0, Step 258: train/loss = 0.6785245537757874, train/raw-loss = 0.6727161407470703, train/logprobs = tensor([[-1.7281, -2.2149],
        [-1.7261, -2.0584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011616806499660015
Epoch 0, Step 259: train/loss = 0.6809605360031128, train/raw-loss = 0.6799781322479248, train/logprobs = tensor([[-1.8256, -1.7096],
        [-1.7554, -1.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019648317247629166
Epoch 0, Step 260: train/loss = 0.6555941104888916, train/raw-loss = 0.6545577049255371, train/logprobs = tensor([[-1.2186, -2.0506],
        [-1.1859, -1.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002072871197015047
Epoch 0, Step 261: train/loss = 0.660735011100769, train/raw-loss = 0.6572084426879883, train/logprobs = tensor([[-0.9228, -2.3596],
        [-0.8438, -2.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007053125649690628
Epoch 0, Step 262: train/loss = 0.7051364779472351, train/raw-loss = 0.7021273374557495, train/logprobs = tensor([[-1.4490, -1.8794],
        [-1.4010, -1.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060182977467775345
Epoch 0, Step 263: train/loss = 0.668676495552063, train/raw-loss = 0.6673582196235657, train/logprobs = tensor([[-1.8286, -2.6083],
        [-1.7652, -2.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002636516699567437
Epoch 0, Step 264: train/loss = 0.6691490411758423, train/raw-loss = 0.6655623912811279, train/logprobs = tensor([[-1.1561, -2.3355],
        [-1.0951, -2.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007173283025622368
Epoch 0, Step 265: train/loss = 0.6774653196334839, train/raw-loss = 0.6758902668952942, train/logprobs = tensor([[-1.3397, -1.9143],
        [-1.3408, -1.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031500495970249176
Epoch 0, Step 266: train/loss = 0.685896635055542, train/raw-loss = 0.6837756037712097, train/logprobs = tensor([[-1.2365, -1.1556],
        [-1.2098, -1.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004242002964019775
Epoch 0, Step 267: train/loss = 0.6761467456817627, train/raw-loss = 0.6727548241615295, train/logprobs = tensor([[-1.3993, -1.7357],
        [-1.4062, -1.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006783822551369667
Epoch 0, Step 268: train/loss = 0.6540288329124451, train/raw-loss = 0.6529991626739502, train/logprobs = tensor([[-1.1171, -1.8315],
        [-1.0912, -1.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020594028756022453
Epoch 0, Step 269: train/loss = 0.641572117805481, train/raw-loss = 0.6354985237121582, train/logprobs = tensor([[-0.9861, -1.8093],
        [-1.1153, -1.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012147147208452225
Epoch 0, Step 270: train/loss = 0.6823384761810303, train/raw-loss = 0.6817953586578369, train/logprobs = tensor([[-0.9117, -1.8255],
        [-0.8458, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010863171191886067
Epoch 0, Step 271: train/loss = 0.6461805105209351, train/raw-loss = 0.6432515978813171, train/logprobs = tensor([[-0.6777, -2.0998],
        [-0.6662, -1.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0058577340096235275
Epoch 0, Step 272: train/loss = 0.6736202239990234, train/raw-loss = 0.671798586845398, train/logprobs = tensor([[-1.0037, -1.6275],
        [-0.9742, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003643439617007971
Epoch 0, Step 273: train/loss = 0.6571438312530518, train/raw-loss = 0.6562275886535645, train/logprobs = tensor([[-0.5556, -2.1322],
        [-0.5659, -1.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001832660287618637
Epoch 0, Step 274: train/loss = 0.6649620532989502, train/raw-loss = 0.6617656946182251, train/logprobs = tensor([[-1.3798, -2.1040],
        [-1.3891, -1.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006392843089997768
Epoch 0, Step 275: train/loss = 0.6610003113746643, train/raw-loss = 0.6569110155105591, train/logprobs = tensor([[-1.0799, -2.1612],
        [-1.0285, -1.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008178602904081345
Epoch 0, Step 276: train/loss = 0.6454581022262573, train/raw-loss = 0.6446654796600342, train/logprobs = tensor([[-0.6447, -2.5569],
        [-0.6329, -2.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015852695796638727
Epoch 0, Step 277: train/loss = 0.6289358139038086, train/raw-loss = 0.6254738569259644, train/logprobs = tensor([[-1.6302, -2.1769],
        [-1.6294, -1.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006923825480043888
Epoch 0, Step 278: train/loss = 0.6586743593215942, train/raw-loss = 0.6512970924377441, train/logprobs = tensor([[-1.4247, -2.6121],
        [-1.4374, -2.3696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014754444360733032
Epoch 0, Step 279: train/loss = 0.6732662916183472, train/raw-loss = 0.6729717254638672, train/logprobs = tensor([[-1.2637, -1.6841],
        [-1.2788, -1.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005890233442187309
Epoch 0, Step 280: train/loss = 0.6585954427719116, train/raw-loss = 0.6574339866638184, train/logprobs = tensor([[-1.0036, -1.8622],
        [-0.9913, -1.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023228577338159084
Epoch 0, Step 281: train/loss = 0.6810617446899414, train/raw-loss = 0.6793737411499023, train/logprobs = tensor([[-1.5121, -1.8787],
        [-1.4571, -1.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033761016093194485
Epoch 0, Step 282: train/loss = 0.6519398093223572, train/raw-loss = 0.6512192487716675, train/logprobs = tensor([[-0.7197, -1.9504],
        [-0.7156, -1.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014411831507459283
Epoch 0, Step 283: train/loss = 0.6441095471382141, train/raw-loss = 0.6416447162628174, train/logprobs = tensor([[-0.7757, -2.3641],
        [-0.7958, -2.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004929607734084129
Epoch 0, Step 284: train/loss = 0.6846988201141357, train/raw-loss = 0.6792898178100586, train/logprobs = tensor([[-1.0342, -1.4556],
        [-1.0645, -1.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010817969217896461
Epoch 0, Step 285: train/loss = 0.6713341474533081, train/raw-loss = 0.6695092916488647, train/logprobs = tensor([[-1.1199, -2.6444],
        [-1.0819, -2.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036497567780315876
Epoch 0, Step 286: train/loss = 0.6923601627349854, train/raw-loss = 0.6874589323997498, train/logprobs = tensor([[-0.9500, -1.5539],
        [-0.9242, -1.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009802420623600483
Epoch 0, Step 287: train/loss = 0.681044340133667, train/raw-loss = 0.6776456832885742, train/logprobs = tensor([[-1.1652, -1.3329],
        [-1.1672, -1.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006797380745410919
Epoch 0, Step 288: train/loss = 0.7042374610900879, train/raw-loss = 0.6894887685775757, train/logprobs = tensor([[-1.4826, -2.6678],
        [-1.6054, -2.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029497358947992325
Epoch 0, Step 289: train/loss = 0.6588141918182373, train/raw-loss = 0.6575353145599365, train/logprobs = tensor([[-1.0814, -1.4920],
        [-1.1002, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025578588247299194
Epoch 0, Step 290: train/loss = 0.6729166507720947, train/raw-loss = 0.6700891256332397, train/logprobs = tensor([[-1.0893, -1.7810],
        [-1.0584, -1.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056550088338553905
Epoch 0, Step 291: train/loss = 0.6862890720367432, train/raw-loss = 0.6849336624145508, train/logprobs = tensor([[-0.7343, -0.9907],
        [-0.7618, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002710800152271986
Epoch 0, Step 292: train/loss = 0.6440442800521851, train/raw-loss = 0.6422132253646851, train/logprobs = tensor([[-1.0343, -1.8939],
        [-1.0206, -1.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036619657184928656
Epoch 0, Step 293: train/loss = 0.6426057815551758, train/raw-loss = 0.6385015845298767, train/logprobs = tensor([[-0.8988, -2.4047],
        [-0.9765, -2.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008208352141082287
Epoch 0, Step 294: train/loss = 0.6641247868537903, train/raw-loss = 0.6621840596199036, train/logprobs = tensor([[-1.0236, -2.0867],
        [-1.0732, -1.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038814337458461523
Epoch 0, Step 295: train/loss = 0.6608281135559082, train/raw-loss = 0.6596253514289856, train/logprobs = tensor([[-1.7585, -1.9412],
        [-1.7243, -1.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002405524253845215
Epoch 0, Step 296: train/loss = 0.6397408246994019, train/raw-loss = 0.6342872381210327, train/logprobs = tensor([[-1.1219, -2.5368],
        [-1.1630, -2.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010907294228672981
Epoch 0, Step 297: train/loss = 0.6540689468383789, train/raw-loss = 0.6533767580986023, train/logprobs = tensor([[-1.1774, -2.2778],
        [-1.2810, -2.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013844427885487676
Epoch 0, Step 298: train/loss = 0.643861711025238, train/raw-loss = 0.6428103446960449, train/logprobs = tensor([[-0.7978, -2.1052],
        [-0.8905, -1.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002102830447256565
Epoch 0, Step 299: train/loss = 0.666923999786377, train/raw-loss = 0.6650623083114624, train/logprobs = tensor([[-1.2984, -1.2850],
        [-1.3814, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037233405746519566
Epoch 0, Step 300: train/loss = 0.6765114068984985, train/raw-loss = 0.6753910779953003, train/logprobs = tensor([[-1.3793, -1.4546],
        [-1.3214, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022406422067433596
Epoch 0, Step 301: train/loss = 0.6735877990722656, train/raw-loss = 0.6729577779769897, train/logprobs = tensor([[-0.8400, -1.2140],
        [-0.8590, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012601211201399565
Epoch 0, Step 302: train/loss = 0.6244817972183228, train/raw-loss = 0.6209172010421753, train/logprobs = tensor([[-1.0085, -2.1364],
        [-1.0836, -1.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007129164878278971
Epoch 0, Step 303: train/loss = 0.6889652013778687, train/raw-loss = 0.6861911416053772, train/logprobs = tensor([[-0.8109, -1.6634],
        [-0.8363, -1.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005548133514821529
Epoch 0, Step 304: train/loss = 0.6564381718635559, train/raw-loss = 0.6544796228408813, train/logprobs = tensor([[-1.2434, -2.0167],
        [-1.2444, -1.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003917100839316845
Epoch 0, Step 305: train/loss = 0.6796997785568237, train/raw-loss = 0.6750545501708984, train/logprobs = tensor([[-1.0627, -1.0883],
        [-1.0903, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00929038506001234
Epoch 0, Step 306: train/loss = 0.6544768810272217, train/raw-loss = 0.6525395512580872, train/logprobs = tensor([[-0.9051, -1.9152],
        [-0.9309, -1.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038746879436075687
Epoch 0, Step 307: train/loss = 0.6599392294883728, train/raw-loss = 0.6563966274261475, train/logprobs = tensor([[-0.8799, -1.9697],
        [-0.9510, -1.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00708524975925684
Epoch 0, Step 308: train/loss = 0.6597400903701782, train/raw-loss = 0.6528564691543579, train/logprobs = tensor([[-1.2830, -1.8993],
        [-1.3036, -1.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013767320662736893
Epoch 0, Step 309: train/loss = 0.6606268286705017, train/raw-loss = 0.6595854759216309, train/logprobs = tensor([[-0.8206, -1.4524],
        [-0.8615, -1.3500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020826123654842377
Epoch 0, Step 310: train/loss = 0.6265594959259033, train/raw-loss = 0.625099778175354, train/logprobs = tensor([[-1.0698, -2.5535],
        [-1.0972, -2.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029194774106144905
Epoch 0, Step 311: train/loss = 0.6645467281341553, train/raw-loss = 0.6628131866455078, train/logprobs = tensor([[-0.7233, -1.4615],
        [-0.7744, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034670939203351736
Epoch 0, Step 312: train/loss = 0.659878671169281, train/raw-loss = 0.6591449975967407, train/logprobs = tensor([[-1.3604, -1.8382],
        [-1.3881, -1.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014673317782580853
Epoch 0, Step 313: train/loss = 0.6429605484008789, train/raw-loss = 0.6403993368148804, train/logprobs = tensor([[-0.9354, -2.7123],
        [-0.9382, -2.4679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005122467875480652
Epoch 0, Step 314: train/loss = 0.6727008819580078, train/raw-loss = 0.6707080006599426, train/logprobs = tensor([[-0.8926, -2.6119],
        [-1.0024, -2.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039858222007751465
Epoch 0, Step 315: train/loss = 0.665000319480896, train/raw-loss = 0.6641753911972046, train/logprobs = tensor([[-0.7869, -2.5108],
        [-0.7842, -2.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016499398043379188
Epoch 0, Step 316: train/loss = 0.6560254096984863, train/raw-loss = 0.6543887853622437, train/logprobs = tensor([[-1.2478, -1.9668],
        [-1.2482, -1.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032732768449932337
Epoch 0, Step 317: train/loss = 0.6662129759788513, train/raw-loss = 0.6653274893760681, train/logprobs = tensor([[-1.0603, -1.6698],
        [-1.1283, -1.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017710392130538821
Epoch 0, Step 318: train/loss = 0.6662943363189697, train/raw-loss = 0.6646221876144409, train/logprobs = tensor([[-1.1590, -2.0659],
        [-1.1857, -1.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00334447855129838
Epoch 0, Step 319: train/loss = 0.6532729864120483, train/raw-loss = 0.6514770984649658, train/logprobs = tensor([[-1.2020, -2.0222],
        [-1.2824, -1.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035917393397539854
Epoch 0, Step 320: train/loss = 0.6344897747039795, train/raw-loss = 0.632330060005188, train/logprobs = tensor([[-0.6856, -1.7412],
        [-0.7920, -1.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004319401923567057
Epoch 0, Step 321: train/loss = 0.6244736313819885, train/raw-loss = 0.6210403442382812, train/logprobs = tensor([[-1.3988, -2.5137],
        [-1.5398, -2.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006866557523608208
Epoch 0, Step 322: train/loss = 0.6477667093276978, train/raw-loss = 0.6358857750892639, train/logprobs = tensor([[-1.1170, -2.2506],
        [-1.1988, -1.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02376188337802887
Epoch 0, Step 323: train/loss = 0.6859577298164368, train/raw-loss = 0.6853837966918945, train/logprobs = tensor([[-1.1091, -0.8862],
        [-1.1069, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011478990782052279
Epoch 0, Step 324: train/loss = 0.6441858410835266, train/raw-loss = 0.6429654359817505, train/logprobs = tensor([[-1.5148, -2.2699],
        [-1.5868, -2.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024408495519310236
Epoch 0, Step 325: train/loss = 0.6284542083740234, train/raw-loss = 0.614557147026062, train/logprobs = tensor([[-2.1542, -2.0182],
        [-2.3148, -1.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027794023975729942
Epoch 0, Step 326: train/loss = 0.6368278861045837, train/raw-loss = 0.6336584687232971, train/logprobs = tensor([[-1.3265, -2.2131],
        [-1.5179, -2.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006338828708976507
Epoch 0, Step 327: train/loss = 0.6781237721443176, train/raw-loss = 0.6726419925689697, train/logprobs = tensor([[-1.3080, -1.7976],
        [-1.3774, -1.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010963672772049904
Epoch 0, Step 328: train/loss = 0.6850358843803406, train/raw-loss = 0.6828186511993408, train/logprobs = tensor([[-1.1477, -1.5371],
        [-1.1303, -1.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044343965128064156
Epoch 0, Step 329: train/loss = 0.6348319053649902, train/raw-loss = 0.6314210891723633, train/logprobs = tensor([[-1.4587, -2.1628],
        [-1.5763, -1.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006821684539318085
Epoch 0, Step 330: train/loss = 0.6505870819091797, train/raw-loss = 0.649139940738678, train/logprobs = tensor([[-1.1944, -2.3666],
        [-1.3026, -2.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028942925855517387
Epoch 0, Step 331: train/loss = 0.6811615228652954, train/raw-loss = 0.6795328855514526, train/logprobs = tensor([[-1.4575, -2.1621],
        [-1.4092, -2.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032573933713138103
Epoch 0, Step 332: train/loss = 0.6542986035346985, train/raw-loss = 0.6522477865219116, train/logprobs = tensor([[-1.8854, -1.5094],
        [-1.9669, -1.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004101567901670933
Epoch 0, Step 333: train/loss = 0.6027133464813232, train/raw-loss = 0.5983093976974487, train/logprobs = tensor([[-1.3905, -2.5556],
        [-1.4996, -2.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008807886391878128
Epoch 0, Step 334: train/loss = 0.6518549919128418, train/raw-loss = 0.6490193605422974, train/logprobs = tensor([[-1.5965, -2.2601],
        [-1.6327, -2.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005671225022524595
Epoch 0, Step 335: train/loss = 0.6428011655807495, train/raw-loss = 0.6390371322631836, train/logprobs = tensor([[-0.8586, -1.5713],
        [-0.9320, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007528185378760099
Epoch 0, Step 336: train/loss = 0.6563632488250732, train/raw-loss = 0.653512716293335, train/logprobs = tensor([[-1.0314, -1.7052],
        [-1.1052, -1.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005701138637959957
Epoch 0, Step 337: train/loss = 0.6825463771820068, train/raw-loss = 0.6763779520988464, train/logprobs = tensor([[-1.1985, -2.5361],
        [-1.2901, -2.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012336758896708488
Epoch 0, Step 338: train/loss = 0.684337317943573, train/raw-loss = 0.6823493838310242, train/logprobs = tensor([[-1.3651, -1.9099],
        [-1.3508, -1.8198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003975878935307264
Epoch 0, Step 339: train/loss = 0.6829650402069092, train/raw-loss = 0.6795204281806946, train/logprobs = tensor([[-1.5072, -1.5767],
        [-1.5949, -1.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006889105774462223
Epoch 0, Step 340: train/loss = 0.610322117805481, train/raw-loss = 0.604784369468689, train/logprobs = tensor([[-1.5990, -2.3035],
        [-1.7072, -2.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011075478047132492
Epoch 0, Step 341: train/loss = 0.670993983745575, train/raw-loss = 0.6549904346466064, train/logprobs = tensor([[-1.5984, -2.1828],
        [-1.7435, -2.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032007183879613876
Epoch 0, Step 342: train/loss = 0.6333839893341064, train/raw-loss = 0.6300716996192932, train/logprobs = tensor([[-1.1630, -1.7092],
        [-1.2606, -1.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006624671630561352
Epoch 0, Step 343: train/loss = 0.6632172465324402, train/raw-loss = 0.6604068875312805, train/logprobs = tensor([[-0.8169, -1.9358],
        [-0.8972, -1.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056206840090453625
Epoch 0, Step 344: train/loss = 0.6606296896934509, train/raw-loss = 0.6582599878311157, train/logprobs = tensor([[-1.3461, -1.7894],
        [-1.3776, -1.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004739329218864441
Epoch 0, Step 345: train/loss = 0.6680630445480347, train/raw-loss = 0.6637254953384399, train/logprobs = tensor([[-1.2377, -1.4553],
        [-1.2741, -1.3371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00867508165538311
Epoch 0, Step 346: train/loss = 0.6389792561531067, train/raw-loss = 0.6364010572433472, train/logprobs = tensor([[-1.0995, -2.4110],
        [-1.2073, -2.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0051563759334385395
Epoch 0, Step 347: train/loss = 0.6711946725845337, train/raw-loss = 0.6688096523284912, train/logprobs = tensor([[-1.4478, -1.7999],
        [-1.4429, -1.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004770083352923393
Epoch 0, Step 348: train/loss = 0.6341767311096191, train/raw-loss = 0.629197359085083, train/logprobs = tensor([[-1.0215, -1.6294],
        [-1.2212, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009958669543266296
Epoch 0, Step 349: train/loss = 0.650102972984314, train/raw-loss = 0.6485464572906494, train/logprobs = tensor([[-1.0246, -1.8154],
        [-1.1377, -1.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031129177659749985
Epoch 0, Step 350: train/loss = 0.61130291223526, train/raw-loss = 0.6088813543319702, train/logprobs = tensor([[-0.8412, -3.3708],
        [-0.9324, -3.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0048431651666760445
Epoch 0, Step 351: train/loss = 0.6369671821594238, train/raw-loss = 0.6328224539756775, train/logprobs = tensor([[-1.0191, -2.6514],
        [-1.1465, -2.4781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008289498277008533
Epoch 0, Step 352: train/loss = 0.5720250606536865, train/raw-loss = 0.5680111646652222, train/logprobs = tensor([[-1.1725, -2.7095],
        [-1.2149, -2.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008027860894799232
Epoch 0, Step 353: train/loss = 0.6040858626365662, train/raw-loss = 0.5988415479660034, train/logprobs = tensor([[-1.3911, -1.9951],
        [-1.4259, -1.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010488619096577168
Epoch 0, Step 354: train/loss = 0.5725838541984558, train/raw-loss = 0.5677736401557922, train/logprobs = tensor([[-0.8105, -3.5443],
        [-0.8137, -2.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00962049700319767
Epoch 0, Step 355: train/loss = 0.6634278297424316, train/raw-loss = 0.6629167795181274, train/logprobs = tensor([[-0.8929, -1.7938],
        [-0.8648, -1.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010220145341008902
Epoch 0, Step 356: train/loss = 0.6421428918838501, train/raw-loss = 0.6405978202819824, train/logprobs = tensor([[-1.0763, -1.4091],
        [-1.0575, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003090051468461752
Epoch 0, Step 357: train/loss = 0.5705361366271973, train/raw-loss = 0.56489098072052, train/logprobs = tensor([[-0.8819, -2.8600],
        [-0.8687, -2.2537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011290241964161396
Epoch 0, Step 358: train/loss = 0.6322340965270996, train/raw-loss = 0.6284469366073608, train/logprobs = tensor([[-1.3492, -2.2540],
        [-1.3376, -1.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007574175018817186
Epoch 0, Step 359: train/loss = 0.569631814956665, train/raw-loss = 0.5653628706932068, train/logprobs = tensor([[-0.8664, -2.6759],
        [-0.9309, -2.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008537903428077698
Epoch 0, Step 360: train/loss = 0.5870357751846313, train/raw-loss = 0.5827382206916809, train/logprobs = tensor([[-0.8274, -3.4053],
        [-0.8023, -2.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008595110848546028
Epoch 0, Step 361: train/loss = 0.599618136882782, train/raw-loss = 0.5969556570053101, train/logprobs = tensor([[-0.7423, -2.7571],
        [-0.7402, -2.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005324965342879295
Epoch 0, Step 362: train/loss = 0.6334604620933533, train/raw-loss = 0.6280303597450256, train/logprobs = tensor([[-1.5199, -1.7490],
        [-1.6050, -1.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010860111564397812
Epoch 0, Step 363: train/loss = 0.5981912612915039, train/raw-loss = 0.5953158736228943, train/logprobs = tensor([[-1.2762, -2.2775],
        [-1.3569, -1.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005750839598476887
Epoch 0, Step 364: train/loss = 0.6095889806747437, train/raw-loss = 0.6057203412055969, train/logprobs = tensor([[-0.9366, -1.8929],
        [-1.0468, -1.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007737431675195694
Epoch 0, Step 365: train/loss = 0.5804654955863953, train/raw-loss = 0.5761297345161438, train/logprobs = tensor([[-1.3408, -1.8498],
        [-1.3743, -1.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008671557530760765
Epoch 0, Step 366: train/loss = 0.6274623274803162, train/raw-loss = 0.6235665082931519, train/logprobs = tensor([[-1.3011, -1.8422],
        [-1.3203, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007791653275489807
Epoch 0, Step 367: train/loss = 0.6074494123458862, train/raw-loss = 0.6049522161483765, train/logprobs = tensor([[-1.1118, -1.7857],
        [-1.1516, -1.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004994487389922142
Epoch 0, Step 368: train/loss = 0.582942008972168, train/raw-loss = 0.5745875835418701, train/logprobs = tensor([[-1.3273, -2.5070],
        [-1.4098, -2.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016708800569176674
Epoch 0, Step 369: train/loss = 0.5925555229187012, train/raw-loss = 0.5877442359924316, train/logprobs = tensor([[-1.1701, -1.8680],
        [-1.2005, -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009622504934668541
Epoch 0, Step 370: train/loss = 0.5684504508972168, train/raw-loss = 0.5628284215927124, train/logprobs = tensor([[-1.0641, -2.4374],
        [-1.0516, -1.8398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011243999004364014
Epoch 0, Step 371: train/loss = 0.6411535739898682, train/raw-loss = 0.6383373737335205, train/logprobs = tensor([[-0.6092, -1.1542],
        [-0.6573, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005632372573018074
Epoch 0, Step 372: train/loss = 0.6357009410858154, train/raw-loss = 0.6318081021308899, train/logprobs = tensor([[-1.1151, -2.0889],
        [-1.1589, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007785601541399956
Epoch 0, Step 373: train/loss = 0.6103532314300537, train/raw-loss = 0.6053678393363953, train/logprobs = tensor([[-1.1147, -2.7820],
        [-1.0655, -2.3143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009970838204026222
Epoch 0, Step 374: train/loss = 0.6408610939979553, train/raw-loss = 0.6381507515907288, train/logprobs = tensor([[-0.7949, -1.2097],
        [-0.8644, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005420682951807976
Epoch 0, Step 375: train/loss = 0.6361525058746338, train/raw-loss = 0.6345553994178772, train/logprobs = tensor([[-1.1279, -1.7528],
        [-1.2166, -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031942157074809074
Epoch 0, Step 376: train/loss = 0.6474108695983887, train/raw-loss = 0.6430625319480896, train/logprobs = tensor([[-1.4714, -1.8435],
        [-1.4264, -1.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008696766570210457
Epoch 0, Step 377: train/loss = 0.6738914251327515, train/raw-loss = 0.6728593111038208, train/logprobs = tensor([[-0.6505, -0.8753],
        [-0.6819, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020640380680561066
Epoch 0, Step 378: train/loss = 0.6699181199073792, train/raw-loss = 0.6634832620620728, train/logprobs = tensor([[-2.0244, -1.9058],
        [-1.9172, -1.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012869777157902718
Epoch 0, Step 379: train/loss = 0.604363203048706, train/raw-loss = 0.5958917140960693, train/logprobs = tensor([[-1.9604, -2.9605],
        [-1.8090, -2.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01694300025701523
Epoch 0, Step 380: train/loss = 0.6212059259414673, train/raw-loss = 0.61823570728302, train/logprobs = tensor([[-1.0227, -1.8318],
        [-1.0522, -1.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005940488073974848
Epoch 0, Step 381: train/loss = 0.5801177024841309, train/raw-loss = 0.5743597149848938, train/logprobs = tensor([[-1.0130, -2.3251],
        [-0.9979, -1.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011515863239765167
Epoch 0, Step 382: train/loss = 0.6499267220497131, train/raw-loss = 0.6471768617630005, train/logprobs = tensor([[-1.2002, -1.8727],
        [-1.0545, -1.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005499685183167458
Epoch 0, Step 383: train/loss = 0.654327392578125, train/raw-loss = 0.6531304717063904, train/logprobs = tensor([[-2.1375, -2.3460],
        [-1.8933, -1.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002393891103565693
Epoch 0, Step 384: train/loss = 0.5904819965362549, train/raw-loss = 0.5855498313903809, train/logprobs = tensor([[-0.9307, -1.9981],
        [-1.0860, -1.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00986429862678051
Epoch 0, Step 385: train/loss = 0.6387614607810974, train/raw-loss = 0.6348444819450378, train/logprobs = tensor([[-1.5746, -1.8411],
        [-1.5248, -1.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007833968847990036
Epoch 0, Step 386: train/loss = 0.5938345193862915, train/raw-loss = 0.5897178649902344, train/logprobs = tensor([[-1.4303, -2.2711],
        [-1.4120, -1.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008233311586081982
Epoch 0, Step 387: train/loss = 0.5776517987251282, train/raw-loss = 0.5681018829345703, train/logprobs = tensor([[-1.3415, -2.0830],
        [-1.3182, -1.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019099831581115723
Epoch 0, Step 388: train/loss = 0.6320998668670654, train/raw-loss = 0.6272705793380737, train/logprobs = tensor([[-0.9736, -1.2620],
        [-0.9307, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009658570401370525
Epoch 0, Step 389: train/loss = 0.6232315301895142, train/raw-loss = 0.6221922636032104, train/logprobs = tensor([[-0.8564, -1.6843],
        [-0.8496, -1.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002078478690236807
Epoch 0, Step 390: train/loss = 0.54668128490448, train/raw-loss = 0.5340462923049927, train/logprobs = tensor([[-1.2507, -2.4305],
        [-1.2374, -1.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025269944220781326
Epoch 0, Step 391: train/loss = 0.6060885190963745, train/raw-loss = 0.6018760800361633, train/logprobs = tensor([[-1.6925, -2.1988],
        [-1.3302, -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008424898609519005
Epoch 0, Step 392: train/loss = 0.5582897663116455, train/raw-loss = 0.5389614105224609, train/logprobs = tensor([[-1.2565, -2.3102],
        [-1.3965, -1.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03865665942430496
Epoch 0, Step 393: train/loss = 0.582836925983429, train/raw-loss = 0.5776650309562683, train/logprobs = tensor([[-1.5847, -2.4393],
        [-1.5544, -1.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01034369133412838
Epoch 0, Step 394: train/loss = 0.5587496757507324, train/raw-loss = 0.5512195825576782, train/logprobs = tensor([[-1.3523, -2.6055],
        [-1.2034, -1.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015060147270560265
Epoch 0, Step 395: train/loss = 0.6152878999710083, train/raw-loss = 0.6111000180244446, train/logprobs = tensor([[-1.1259, -1.8596],
        [-1.1539, -1.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00837569497525692
Epoch 0, Step 396: train/loss = 0.5359723567962646, train/raw-loss = 0.5164944529533386, train/logprobs = tensor([[-0.9538, -2.6039],
        [-1.0297, -1.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03895585238933563
Epoch 0, Step 397: train/loss = 0.6354462504386902, train/raw-loss = 0.6315628290176392, train/logprobs = tensor([[-1.7397, -1.6050],
        [-1.4886, -1.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007766795344650745
Epoch 0, Step 398: train/loss = 0.5511171817779541, train/raw-loss = 0.5365332961082458, train/logprobs = tensor([[-1.1111, -2.3651],
        [-1.1692, -1.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029167823493480682
Epoch 0, Step 399: train/loss = 0.603094220161438, train/raw-loss = 0.5987154245376587, train/logprobs = tensor([[-1.4142, -2.0835],
        [-1.3590, -1.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00875768344849348
Epoch 0, Step 400: train/loss = 0.6140518188476562, train/raw-loss = 0.6083763837814331, train/logprobs = tensor([[-1.7798, -1.9443],
        [-1.7063, -1.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011350825428962708
Epoch 0, Step 401: train/loss = 0.5075824856758118, train/raw-loss = 0.49410098791122437, train/logprobs = tensor([[-1.3466, -2.4454],
        [-1.3523, -1.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02696290798485279
Epoch 0, Step 402: train/loss = 0.59996497631073, train/raw-loss = 0.5963627099990845, train/logprobs = tensor([[-1.1774, -1.9252],
        [-1.1393, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007204641588032246
Epoch 0, Step 403: train/loss = 0.5537245273590088, train/raw-loss = 0.5457776784896851, train/logprobs = tensor([[-1.5851, -2.0987],
        [-1.7361, -1.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015893692150712013
Epoch 0, Step 404: train/loss = 0.5836572647094727, train/raw-loss = 0.579866886138916, train/logprobs = tensor([[-1.2879, -2.3152],
        [-1.3346, -1.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007580662611871958
Epoch 0, Step 405: train/loss = 0.6256184577941895, train/raw-loss = 0.6222646236419678, train/logprobs = tensor([[-0.8025, -1.6720],
        [-0.8752, -1.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006707662250846624
Epoch 0, Step 406: train/loss = 0.5679689645767212, train/raw-loss = 0.5536439418792725, train/logprobs = tensor([[-1.4684, -2.2895],
        [-1.5724, -1.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028649894520640373
Epoch 0, Step 407: train/loss = 0.6054930090904236, train/raw-loss = 0.6020272970199585, train/logprobs = tensor([[-1.2441, -2.5074],
        [-1.2581, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006931401789188385
Epoch 0, Step 408: train/loss = 0.6132223606109619, train/raw-loss = 0.6061119437217712, train/logprobs = tensor([[-1.4544, -1.7155],
        [-1.4094, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014220813289284706
Epoch 0, Step 409: train/loss = 0.5465072989463806, train/raw-loss = 0.537317156791687, train/logprobs = tensor([[-0.8644, -2.0898],
        [-0.9295, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018380379304289818
Epoch 0, Step 410: train/loss = 0.5934643149375916, train/raw-loss = 0.5881698131561279, train/logprobs = tensor([[-1.0997, -1.8803],
        [-1.0685, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010588961653411388
Epoch 0, Step 411: train/loss = 0.6791874170303345, train/raw-loss = 0.6789436340332031, train/logprobs = tensor([[-1.4964, -1.4292],
        [-1.2264, -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048749876441434026
Epoch 0, Step 412: train/loss = 0.5984871983528137, train/raw-loss = 0.5928199887275696, train/logprobs = tensor([[-1.0870, -1.8423],
        [-1.3638, -1.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011334557086229324
Epoch 0, Step 413: train/loss = 0.6648145318031311, train/raw-loss = 0.660825788974762, train/logprobs = tensor([[-1.5305, -1.1565],
        [-1.4990, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007977506145834923
Epoch 0, Step 414: train/loss = 0.6538230776786804, train/raw-loss = 0.6473416090011597, train/logprobs = tensor([[-1.1333, -1.3723],
        [-1.1020, -1.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01296296902000904
Epoch 0, Step 415: train/loss = 0.5470069050788879, train/raw-loss = 0.5405049920082092, train/logprobs = tensor([[-0.7346, -2.5917],
        [-0.7320, -1.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013003717176616192
Epoch 0, Step 416: train/loss = 0.5229376554489136, train/raw-loss = 0.5138541460037231, train/logprobs = tensor([[-1.0231, -2.4578],
        [-1.0618, -1.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018167022615671158
Epoch 0, Step 417: train/loss = 0.4726395606994629, train/raw-loss = 0.4632788896560669, train/logprobs = tensor([[-1.1139, -3.9133],
        [-1.2046, -2.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018721329048275948
Epoch 0, Step 418: train/loss = 0.6096874475479126, train/raw-loss = 0.605069637298584, train/logprobs = tensor([[-1.6025, -2.0887],
        [-1.4208, -1.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009235592558979988
Epoch 0, Step 419: train/loss = 0.6018576622009277, train/raw-loss = 0.5918126106262207, train/logprobs = tensor([[-2.2402, -2.7918],
        [-1.8011, -1.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020089969038963318
Epoch 0, Step 420: train/loss = 0.5086079835891724, train/raw-loss = 0.4944584369659424, train/logprobs = tensor([[-1.2713, -2.8217],
        [-1.3894, -1.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028299078345298767
Epoch 0, Step 421: train/loss = 0.5869886875152588, train/raw-loss = 0.5788084268569946, train/logprobs = tensor([[-0.7689, -2.0253],
        [-0.7654, -1.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016360530629754066
Epoch 0, Step 422: train/loss = 0.543617308139801, train/raw-loss = 0.533989667892456, train/logprobs = tensor([[-1.1900, -1.9678],
        [-1.2395, -1.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019255267456173897
Epoch 0, Step 423: train/loss = 0.5532991886138916, train/raw-loss = 0.5437618494033813, train/logprobs = tensor([[-1.6182, -1.9979],
        [-1.6058, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019074678421020508
Epoch 0, Step 424: train/loss = 0.5258991122245789, train/raw-loss = 0.5067687034606934, train/logprobs = tensor([[-0.8992, -2.2085],
        [-0.9373, -1.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03826070576906204
Epoch 0, Step 425: train/loss = 0.47211000323295593, train/raw-loss = 0.4618668556213379, train/logprobs = tensor([[-1.2490, -3.2166],
        [-1.2742, -2.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02048628032207489
Epoch 0, Step 426: train/loss = 0.5462079644203186, train/raw-loss = 0.53736412525177, train/logprobs = tensor([[-1.5294, -1.9672],
        [-1.5108, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01768770068883896
Epoch 0, Step 427: train/loss = 0.6465691924095154, train/raw-loss = 0.6449970006942749, train/logprobs = tensor([[-0.9254, -1.3746],
        [-0.9830, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003144415793940425
Epoch 0, Step 428: train/loss = 0.5425657033920288, train/raw-loss = 0.529331386089325, train/logprobs = tensor([[-1.5458, -2.0993],
        [-1.5976, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026468679308891296
Epoch 0, Step 429: train/loss = 0.6523133516311646, train/raw-loss = 0.6501233577728271, train/logprobs = tensor([[-1.0865, -1.1675],
        [-1.0274, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004379895981401205
Epoch 0, Step 430: train/loss = 0.550786554813385, train/raw-loss = 0.5430647134780884, train/logprobs = tensor([[-1.2792, -2.9466],
        [-1.0222, -1.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015443835407495499
Epoch 0, Step 431: train/loss = 0.5477900505065918, train/raw-loss = 0.5428377389907837, train/logprobs = tensor([[-1.8325, -2.8664],
        [-1.6220, -1.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009904583916068077
Epoch 0, Step 432: train/loss = 0.6432358026504517, train/raw-loss = 0.6400372385978699, train/logprobs = tensor([[-1.1381, -1.6380],
        [-1.2162, -1.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006397217512130737
Epoch 0, Step 433: train/loss = 0.5110968351364136, train/raw-loss = 0.49781936407089233, train/logprobs = tensor([[-1.5599, -3.0223],
        [-1.5824, -2.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02655499055981636
Epoch 0, Step 434: train/loss = 0.5249029994010925, train/raw-loss = 0.5154948830604553, train/logprobs = tensor([[-1.2320, -2.7153],
        [-1.5219, -2.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018816271796822548
Epoch 0, Step 435: train/loss = 0.6173680424690247, train/raw-loss = 0.6134819984436035, train/logprobs = tensor([[-1.5663, -1.8881],
        [-1.6463, -1.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007772079203277826
Epoch 0, Step 436: train/loss = 0.5438253879547119, train/raw-loss = 0.5316330790519714, train/logprobs = tensor([[-1.2944, -1.8686],
        [-1.3313, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024384673684835434
Epoch 0, Step 437: train/loss = 0.4963560998439789, train/raw-loss = 0.48386648297309875, train/logprobs = tensor([[-0.9924, -2.3558],
        [-1.1651, -1.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024979138746857643
Epoch 0, Step 438: train/loss = 0.6250002980232239, train/raw-loss = 0.6169060468673706, train/logprobs = tensor([[-1.5576, -2.2405],
        [-1.2816, -1.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01618853025138378
Epoch 0, Step 439: train/loss = 0.5512624979019165, train/raw-loss = 0.5424284338951111, train/logprobs = tensor([[-1.2264, -2.1045],
        [-1.3509, -1.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0176681075245142
Epoch 0, Step 440: train/loss = 0.6090632677078247, train/raw-loss = 0.6049298048019409, train/logprobs = tensor([[-1.9556, -2.0981],
        [-1.6887, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008266862481832504
Epoch 0, Step 441: train/loss = 0.4895385205745697, train/raw-loss = 0.47321265935897827, train/logprobs = tensor([[-1.2342, -3.1987],
        [-1.2966, -2.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032651714980602264
Epoch 0, Step 442: train/loss = 0.6526364684104919, train/raw-loss = 0.6062634587287903, train/logprobs = tensor([[-1.8804, -1.7757],
        [-1.8377, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09274601191282272
Epoch 0, Step 443: train/loss = 0.5273193717002869, train/raw-loss = 0.516977071762085, train/logprobs = tensor([[-1.4418, -2.6988],
        [-1.5504, -1.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02068459987640381
Epoch 0, Step 444: train/loss = 0.5909004211425781, train/raw-loss = 0.5866174697875977, train/logprobs = tensor([[-0.9611, -2.1324],
        [-1.0278, -1.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008565887808799744
Epoch 0, Step 445: train/loss = 0.6075685024261475, train/raw-loss = 0.5980619192123413, train/logprobs = tensor([[-1.8292, -1.8245],
        [-1.7605, -1.2622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019013090059161186
Epoch 0, Step 446: train/loss = 0.5100069642066956, train/raw-loss = 0.5010858178138733, train/logprobs = tensor([[-1.3812, -3.0539],
        [-1.2393, -2.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017842184752225876
Epoch 0, Step 447: train/loss = 0.45942261815071106, train/raw-loss = 0.4353724718093872, train/logprobs = tensor([[-1.1784, -2.7717],
        [-1.2455, -1.5100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0481003001332283
Epoch 0, Step 448: train/loss = 0.511895477771759, train/raw-loss = 0.48320627212524414, train/logprobs = tensor([[-1.4820, -2.5338],
        [-1.2383, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057378463447093964
Epoch 0, Step 449: train/loss = 0.6086159944534302, train/raw-loss = 0.604971170425415, train/logprobs = tensor([[-1.6008, -1.6207],
        [-1.4383, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007289691362529993
Epoch 0, Step 450: train/loss = 0.5070252418518066, train/raw-loss = 0.4943682551383972, train/logprobs = tensor([[-0.6674, -2.2360],
        [-0.7476, -1.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025314010679721832
Epoch 0, Step 451: train/loss = 0.5634143352508545, train/raw-loss = 0.5502445697784424, train/logprobs = tensor([[-2.1263, -2.5516],
        [-1.9229, -1.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026339583098888397
Epoch 0, Step 452: train/loss = 0.48029446601867676, train/raw-loss = 0.45969754457473755, train/logprobs = tensor([[-1.4094, -2.3646],
        [-1.5184, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04119390249252319
Epoch 0, Step 453: train/loss = 0.5253525376319885, train/raw-loss = 0.5101437568664551, train/logprobs = tensor([[-1.0363, -2.2695],
        [-1.1516, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03041752055287361
Epoch 0, Step 454: train/loss = 0.5447671413421631, train/raw-loss = 0.5324646830558777, train/logprobs = tensor([[-1.6733, -2.1748],
        [-1.6826, -1.4221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02460492216050625
Epoch 0, Step 455: train/loss = 0.4694580137729645, train/raw-loss = 0.4542173743247986, train/logprobs = tensor([[-0.8965, -2.2223],
        [-0.9402, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03048127517104149
Epoch 0, Step 456: train/loss = 0.5189080238342285, train/raw-loss = 0.5047593712806702, train/logprobs = tensor([[-0.8811, -2.1468],
        [-0.9157, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028297357261180878
Epoch 0, Step 457: train/loss = 0.5157171487808228, train/raw-loss = 0.49634498357772827, train/logprobs = tensor([[-0.7797, -1.8872],
        [-0.8736, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03874445706605911
Epoch 0, Step 458: train/loss = 0.6235989332199097, train/raw-loss = 0.6182539463043213, train/logprobs = tensor([[-1.6296, -2.0514],
        [-1.3197, -1.3909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010690114460885525
Epoch 0, Step 459: train/loss = 0.5264745950698853, train/raw-loss = 0.5191023945808411, train/logprobs = tensor([[-0.8995, -2.2160],
        [-1.0871, -1.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014744321815669537
Epoch 0, Step 460: train/loss = 0.5897131562232971, train/raw-loss = 0.5748059153556824, train/logprobs = tensor([[-0.8987, -1.6263],
        [-1.0968, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02981448546051979
Epoch 0, Step 461: train/loss = 0.662308931350708, train/raw-loss = 0.6545792818069458, train/logprobs = tensor([[-1.7163, -1.7326],
        [-1.3764, -1.1579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015459218062460423
Epoch 0, Step 462: train/loss = 0.4612283706665039, train/raw-loss = 0.44438931345939636, train/logprobs = tensor([[-0.9319, -2.8593],
        [-1.0317, -1.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033678170293569565
Epoch 0, Step 463: train/loss = 0.5151405930519104, train/raw-loss = 0.49976253509521484, train/logprobs = tensor([[-1.0045, -2.1456],
        [-1.0581, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0307561494410038
Epoch 0, Step 464: train/loss = 0.46936357021331787, train/raw-loss = 0.450115829706192, train/logprobs = tensor([[-1.0712, -3.3714],
        [-1.1924, -2.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038495488464832306
Epoch 0, Step 465: train/loss = 0.64439457654953, train/raw-loss = 0.6351333856582642, train/logprobs = tensor([[-1.1042, -1.3852],
        [-1.1764, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01852227747440338
Epoch 0, Step 466: train/loss = 0.5182541608810425, train/raw-loss = 0.5004695057868958, train/logprobs = tensor([[-1.6033, -2.4466],
        [-1.6746, -1.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03556934744119644
Epoch 0, Step 467: train/loss = 0.6068052053451538, train/raw-loss = 0.6012174487113953, train/logprobs = tensor([[-1.6539, -1.9422],
        [-1.3900, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011175419203937054
Epoch 0, Step 468: train/loss = 0.594414234161377, train/raw-loss = 0.5890913009643555, train/logprobs = tensor([[-1.3006, -2.0276],
        [-1.1755, -1.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010645856149494648
Epoch 0, Step 469: train/loss = 0.5786343216896057, train/raw-loss = 0.5714946985244751, train/logprobs = tensor([[-1.0429, -1.6134],
        [-1.0846, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01427930872887373
Epoch 0, Step 470: train/loss = 0.4993804097175598, train/raw-loss = 0.49071013927459717, train/logprobs = tensor([[-1.0066, -2.8410],
        [-0.9760, -1.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0173405259847641
Epoch 0, Step 471: train/loss = 0.49588170647621155, train/raw-loss = 0.4833765923976898, train/logprobs = tensor([[-1.1890, -2.6476],
        [-1.1725, -1.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025010205805301666
Epoch 0, Step 472: train/loss = 0.3761065602302551, train/raw-loss = 0.3252103626728058, train/logprobs = tensor([[-1.8173, -5.0461],
        [-1.7874, -2.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10179242491722107
Epoch 0, Step 473: train/loss = 0.5741925239562988, train/raw-loss = 0.5619374513626099, train/logprobs = tensor([[-1.7165, -2.1335],
        [-1.3447, -1.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024510089308023453
Epoch 0, Step 474: train/loss = 0.4682907462120056, train/raw-loss = 0.45128679275512695, train/logprobs = tensor([[-0.8222, -2.5743],
        [-0.9121, -1.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03400779888033867
Epoch 0, Step 475: train/loss = 0.48929348587989807, train/raw-loss = 0.46769171953201294, train/logprobs = tensor([[-0.9716, -2.3306],
        [-1.1309, -1.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043203454464673996
Epoch 0, Step 476: train/loss = 0.6484982967376709, train/raw-loss = 0.6426399350166321, train/logprobs = tensor([[-1.5145, -1.7166],
        [-1.1812, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011716680601239204
Epoch 0, Step 477: train/loss = 0.5255523920059204, train/raw-loss = 0.5051309466362, train/logprobs = tensor([[-1.8419, -2.2021],
        [-1.8667, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04084281995892525
Epoch 0, Step 478: train/loss = 0.6034070253372192, train/raw-loss = 0.5900412797927856, train/logprobs = tensor([[-1.8251, -2.0731],
        [-1.6993, -1.3993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026731500402092934
Epoch 0, Step 479: train/loss = 0.5320301651954651, train/raw-loss = 0.5229249596595764, train/logprobs = tensor([[-1.6735, -2.7913],
        [-1.3706, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018210401758551598
Epoch 0, Step 480: train/loss = 0.7013146877288818, train/raw-loss = 0.6846995949745178, train/logprobs = tensor([[-1.2284, -1.4970],
        [-1.3186, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03323031961917877
Epoch 0, Step 481: train/loss = 0.6651469469070435, train/raw-loss = 0.6510820388793945, train/logprobs = tensor([[-1.5795, -1.3702],
        [-1.6015, -1.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02812981978058815
Epoch 0, Step 482: train/loss = 0.6294445991516113, train/raw-loss = 0.6162180304527283, train/logprobs = tensor([[-1.2337, -2.4255],
        [-1.2413, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026453165337443352
Epoch 0, Step 483: train/loss = 0.6037134528160095, train/raw-loss = 0.5831694006919861, train/logprobs = tensor([[-1.5970, -2.1752],
        [-1.5919, -1.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041088126599788666
Epoch 0, Step 484: train/loss = 0.6995531320571899, train/raw-loss = 0.6789759993553162, train/logprobs = tensor([[-1.3061, -2.6178],
        [-1.4261, -2.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04115423932671547
Epoch 0, Step 485: train/loss = 0.6528750658035278, train/raw-loss = 0.6418861150741577, train/logprobs = tensor([[-1.5355, -1.6313],
        [-1.4481, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021977871656417847
Epoch 0, Step 486: train/loss = 0.6621067523956299, train/raw-loss = 0.6585977077484131, train/logprobs = tensor([[-0.7851, -1.1634],
        [-0.9455, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007018093951046467
Epoch 0, Step 487: train/loss = 0.47243422269821167, train/raw-loss = 0.46420738101005554, train/logprobs = tensor([[-1.2103, -3.8539],
        [-1.1521, -2.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016453711315989494
Epoch 0, Step 488: train/loss = 0.6742649078369141, train/raw-loss = 0.6590932011604309, train/logprobs = tensor([[-1.7217, -2.3656],
        [-1.6682, -2.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03034343756735325
Epoch 0, Step 489: train/loss = 0.5862616896629333, train/raw-loss = 0.5730366110801697, train/logprobs = tensor([[-1.5975, -2.0884],
        [-1.3907, -1.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026450127363204956
Epoch 0, Step 490: train/loss = 0.674919068813324, train/raw-loss = 0.6747258305549622, train/logprobs = tensor([[-0.7416, -1.6231],
        [-0.8149, -1.6140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038652881630696356
Epoch 0, Step 491: train/loss = 0.5638373494148254, train/raw-loss = 0.5487232208251953, train/logprobs = tensor([[-1.3587, -2.1768],
        [-1.4977, -1.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030228327959775925
Epoch 0, Step 492: train/loss = 0.5049644708633423, train/raw-loss = 0.4873628616333008, train/logprobs = tensor([[-0.7535, -2.5007],
        [-0.9013, -1.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520319238305092
Epoch 0, Step 493: train/loss = 0.6833200454711914, train/raw-loss = 0.6684705018997192, train/logprobs = tensor([[-1.2628, -1.7299],
        [-1.1691, -1.4104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029699090868234634
Epoch 0, Step 494: train/loss = 0.676169216632843, train/raw-loss = 0.6730353832244873, train/logprobs = tensor([[-1.6730, -1.4190],
        [-1.5064, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006267567165195942
Epoch 0, Step 495: train/loss = 0.6777933239936829, train/raw-loss = 0.6647918224334717, train/logprobs = tensor([[-2.0189, -2.3401],
        [-2.0104, -2.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026002902537584305
Epoch 0, Step 496: train/loss = 0.5775434970855713, train/raw-loss = 0.5337728261947632, train/logprobs = tensor([[-1.6030, -2.6199],
        [-1.6716, -1.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754131942987442
Epoch 0, Step 497: train/loss = 0.5303966999053955, train/raw-loss = 0.506270170211792, train/logprobs = tensor([[-1.2688, -2.9869],
        [-1.3532, -2.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04825306683778763
Epoch 0, Step 498: train/loss = 0.7699652314186096, train/raw-loss = 0.7405295372009277, train/logprobs = tensor([[-1.7588, -2.2751],
        [-1.5654, -1.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058871474117040634
Epoch 0, Step 499: train/loss = 0.696885347366333, train/raw-loss = 0.6906310319900513, train/logprobs = tensor([[-1.0314, -2.1543],
        [-1.1427, -2.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012508521787822247
eval/loss: 0.62945556640625
Epoch 0, Step 500: train/loss = 0.7772023677825928, train/raw-loss = 0.7345933318138123, train/logprobs = tensor([[-1.2423, -1.7891],
        [-1.3442, -1.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08521789312362671
Epoch 0, Step 501: train/loss = 0.5586387515068054, train/raw-loss = 0.5494893789291382, train/logprobs = tensor([[-1.3925, -2.2768],
        [-1.4124, -1.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018298665061593056
Epoch 0, Step 502: train/loss = 0.5621190071105957, train/raw-loss = 0.5501784682273865, train/logprobs = tensor([[-0.9400, -2.5564],
        [-1.0442, -1.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02388107404112816
Epoch 0, Step 503: train/loss = 0.6957377195358276, train/raw-loss = 0.6442168951034546, train/logprobs = tensor([[-1.5690, -2.3947],
        [-1.4412, -1.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10304151475429535
Epoch 0, Step 504: train/loss = 0.6461560726165771, train/raw-loss = 0.6437945365905762, train/logprobs = tensor([[-1.2108, -1.4705],
        [-1.2195, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004723006393760443
Epoch 0, Step 505: train/loss = 0.674909770488739, train/raw-loss = 0.6517264246940613, train/logprobs = tensor([[-1.4364, -1.7417],
        [-1.4361, -1.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04636671766638756
Epoch 0, Step 506: train/loss = 0.7287729978561401, train/raw-loss = 0.6983321905136108, train/logprobs = tensor([[-1.1846, -1.7080],
        [-1.2887, -1.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060881633311510086
Epoch 0, Step 507: train/loss = 0.586257815361023, train/raw-loss = 0.5515506267547607, train/logprobs = tensor([[-1.1629, -2.1611],
        [-1.3197, -1.4561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0694144070148468
Epoch 0, Step 508: train/loss = 0.6199159622192383, train/raw-loss = 0.6074953079223633, train/logprobs = tensor([[-0.9942, -1.8559],
        [-1.2067, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024841440841555595
Epoch 0, Step 509: train/loss = 0.7094643712043762, train/raw-loss = 0.6820220947265625, train/logprobs = tensor([[-1.1535, -1.2063],
        [-1.2672, -1.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054884470999240875
Epoch 0, Step 510: train/loss = 0.6080596446990967, train/raw-loss = 0.5932462215423584, train/logprobs = tensor([[-0.9760, -2.2593],
        [-1.0902, -1.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02962697111070156
Epoch 0, Step 511: train/loss = 0.5369000434875488, train/raw-loss = 0.5065374374389648, train/logprobs = tensor([[-1.0067, -2.4458],
        [-1.0274, -1.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06072526052594185
Epoch 0, Step 512: train/loss = 0.5905776023864746, train/raw-loss = 0.5695333480834961, train/logprobs = tensor([[-0.7585, -2.0289],
        [-0.8988, -1.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04208855330944061
Epoch 0, Step 513: train/loss = 0.4934731721878052, train/raw-loss = 0.47504520416259766, train/logprobs = tensor([[-1.6900, -2.3935],
        [-1.6493, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03685592859983444
Epoch 0, Step 514: train/loss = 0.6959973573684692, train/raw-loss = 0.6398250460624695, train/logprobs = tensor([[-2.1728, -2.3462],
        [-2.0601, -1.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1123446375131607
Epoch 0, Step 515: train/loss = 0.5954326391220093, train/raw-loss = 0.5840873122215271, train/logprobs = tensor([[-0.9866, -2.5706],
        [-1.0890, -2.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022690657526254654
Epoch 0, Step 516: train/loss = 0.639229416847229, train/raw-loss = 0.6184970140457153, train/logprobs = tensor([[-2.3266, -3.0062],
        [-1.7377, -1.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041464902460575104
Epoch 0, Step 517: train/loss = 0.5588839054107666, train/raw-loss = 0.5526430606842041, train/logprobs = tensor([[-0.8756, -2.1065],
        [-1.0619, -1.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012481754645705223
Epoch 0, Step 518: train/loss = 0.5475742816925049, train/raw-loss = 0.532569169998169, train/logprobs = tensor([[-1.4843, -2.3509],
        [-1.5143, -1.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03001023456454277
Epoch 0, Step 519: train/loss = 0.5063228607177734, train/raw-loss = 0.48794063925743103, train/logprobs = tensor([[-0.9422, -2.5038],
        [-1.0994, -1.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03676449880003929
Epoch 0, Step 520: train/loss = 0.5320956707000732, train/raw-loss = 0.5144752264022827, train/logprobs = tensor([[-1.3353, -2.8789],
        [-1.2658, -1.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035240910947322845
Epoch 0, Step 521: train/loss = 0.433388352394104, train/raw-loss = 0.3937108516693115, train/logprobs = tensor([[-1.5438, -3.3233],
        [-1.6448, -1.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07935497164726257
Epoch 0, Step 522: train/loss = 0.5174589157104492, train/raw-loss = 0.5021327137947083, train/logprobs = tensor([[-2.1295, -3.5588],
        [-1.8711, -2.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030652452260255814
Epoch 0, Step 523: train/loss = 0.5882266759872437, train/raw-loss = 0.5716348886489868, train/logprobs = tensor([[-0.9351, -1.7461],
        [-1.0654, -1.2235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03318353742361069
Epoch 0, Step 524: train/loss = 0.5741518139839172, train/raw-loss = 0.5650072693824768, train/logprobs = tensor([[-1.4898, -1.7416],
        [-1.5163, -1.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018289022147655487
Epoch 0, Step 525: train/loss = 0.5257300138473511, train/raw-loss = 0.5121133923530579, train/logprobs = tensor([[-1.7513, -3.0661],
        [-1.5648, -2.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027233172208070755
Epoch 0, Step 526: train/loss = 0.5162519216537476, train/raw-loss = 0.4977007806301117, train/logprobs = tensor([[-1.9638, -2.9903],
        [-1.7961, -1.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03710238263010979
Epoch 0, Step 527: train/loss = 0.40822961926460266, train/raw-loss = 0.38304877281188965, train/logprobs = tensor([[-1.1562, -3.6318],
        [-1.2252, -2.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05036166310310364
Epoch 0, Step 528: train/loss = 0.6667408347129822, train/raw-loss = 0.6638674736022949, train/logprobs = tensor([[-0.9659, -1.1766],
        [-1.2118, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005746680311858654
Epoch 0, Step 529: train/loss = 0.36047181487083435, train/raw-loss = 0.3355882167816162, train/logprobs = tensor([[-0.8323, -3.9396],
        [-1.1784, -2.3207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049767158925533295
Epoch 0, Step 530: train/loss = 0.5589773654937744, train/raw-loss = 0.5420780181884766, train/logprobs = tensor([[-1.3692, -2.3750],
        [-1.1611, -1.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033798761665821075
Epoch 0, Step 531: train/loss = 0.6749515533447266, train/raw-loss = 0.6593170166015625, train/logprobs = tensor([[-1.4556, -1.7843],
        [-1.3453, -1.3949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03126906231045723
Epoch 0, Step 532: train/loss = 0.5306970477104187, train/raw-loss = 0.5148258805274963, train/logprobs = tensor([[-1.2105, -2.4984],
        [-1.2183, -1.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03174235299229622
Epoch 0, Step 533: train/loss = 0.6023247838020325, train/raw-loss = 0.5886553525924683, train/logprobs = tensor([[-0.7767, -1.9989],
        [-0.8159, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02733878791332245
Epoch 0, Step 534: train/loss = 0.6036782264709473, train/raw-loss = 0.5943587422370911, train/logprobs = tensor([[-1.6247, -2.2219],
        [-1.4005, -1.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01863890141248703
Epoch 0, Step 535: train/loss = 0.5639055371284485, train/raw-loss = 0.5521975755691528, train/logprobs = tensor([[-1.1155, -1.7296],
        [-1.2509, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02341599389910698
Epoch 0, Step 536: train/loss = 0.6187182664871216, train/raw-loss = 0.5997177362442017, train/logprobs = tensor([[-1.4780, -2.3229],
        [-1.4866, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03800094872713089
Epoch 0, Step 537: train/loss = 0.6221566200256348, train/raw-loss = 0.6087197065353394, train/logprobs = tensor([[-1.4410, -1.8471],
        [-1.3105, -1.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02687407098710537
Epoch 0, Step 538: train/loss = 0.5844796895980835, train/raw-loss = 0.5647084712982178, train/logprobs = tensor([[-1.5574, -2.3602],
        [-1.5886, -1.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03954244777560234
Epoch 0, Step 539: train/loss = 0.5968125462532043, train/raw-loss = 0.54877769947052, train/logprobs = tensor([[-1.2747, -3.0211],
        [-1.4405, -2.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09606967121362686
Epoch 0, Step 540: train/loss = 0.544979453086853, train/raw-loss = 0.5292516350746155, train/logprobs = tensor([[-1.3395, -2.0358],
        [-1.2004, -1.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03145560622215271
Epoch 0, Step 541: train/loss = 0.5824553370475769, train/raw-loss = 0.567940354347229, train/logprobs = tensor([[-1.7473, -2.4078],
        [-1.8379, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02902999147772789
Epoch 0, Step 542: train/loss = 0.5251398086547852, train/raw-loss = 0.5121158957481384, train/logprobs = tensor([[-1.6189, -2.8365],
        [-1.7481, -2.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026047900319099426
Epoch 0, Step 543: train/loss = 0.5779083371162415, train/raw-loss = 0.553728461265564, train/logprobs = tensor([[-1.3023, -2.2744],
        [-1.2826, -1.4766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048359792679548264
Epoch 0, Step 544: train/loss = 0.5168163776397705, train/raw-loss = 0.5029266476631165, train/logprobs = tensor([[-0.9682, -2.0752],
        [-1.1572, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027779510244727135
Epoch 0, Step 545: train/loss = 0.5715064406394958, train/raw-loss = 0.5631763339042664, train/logprobs = tensor([[-0.7116, -1.5042],
        [-0.8651, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016660258173942566
Epoch 0, Step 546: train/loss = 0.49458029866218567, train/raw-loss = 0.46768584847450256, train/logprobs = tensor([[-1.8831, -2.2998],
        [-1.8226, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05378890410065651
Epoch 0, Step 547: train/loss = 0.4421193301677704, train/raw-loss = 0.4200330972671509, train/logprobs = tensor([[-0.7572, -2.5881],
        [-0.9159, -1.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04417244344949722
Epoch 0, Step 548: train/loss = 0.5379682779312134, train/raw-loss = 0.526877760887146, train/logprobs = tensor([[-1.2625, -2.3185],
        [-1.3382, -1.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022180959582328796
Epoch 0, Step 549: train/loss = 0.5270724296569824, train/raw-loss = 0.5116122961044312, train/logprobs = tensor([[-1.3131, -2.0435],
        [-1.5433, -1.4094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030920278280973434
Epoch 0, Step 550: train/loss = 0.5392957329750061, train/raw-loss = 0.5195631980895996, train/logprobs = tensor([[-1.3978, -2.0849],
        [-1.3285, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03946506604552269
Epoch 0, Step 551: train/loss = 0.48896634578704834, train/raw-loss = 0.47127485275268555, train/logprobs = tensor([[-0.8561, -2.3120],
        [-1.0074, -1.2446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03538300842046738
Epoch 0, Step 552: train/loss = 0.3995782136917114, train/raw-loss = 0.36802321672439575, train/logprobs = tensor([[-1.2946, -3.1518],
        [-1.3036, -1.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06311000883579254
Epoch 0, Step 553: train/loss = 0.49826568365097046, train/raw-loss = 0.4854179918766022, train/logprobs = tensor([[-1.5537, -2.8103],
        [-1.4382, -1.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02569536305963993
Epoch 0, Step 554: train/loss = 0.5393319129943848, train/raw-loss = 0.5051816701889038, train/logprobs = tensor([[-1.2277, -2.2119],
        [-1.3599, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06830065697431564
Epoch 0, Step 555: train/loss = 0.40938735008239746, train/raw-loss = 0.36930620670318604, train/logprobs = tensor([[-1.8891, -3.7703],
        [-1.8535, -1.8378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08016222715377808
Epoch 0, Step 556: train/loss = 0.41496968269348145, train/raw-loss = 0.3794790804386139, train/logprobs = tensor([[-1.6633, -3.1528],
        [-1.7482, -1.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07098115980625153
Epoch 0, Step 557: train/loss = 0.48276960849761963, train/raw-loss = 0.45568713545799255, train/logprobs = tensor([[-0.8401, -2.5137],
        [-0.8983, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05416489765048027
Epoch 0, Step 558: train/loss = 0.5930302143096924, train/raw-loss = 0.5854884386062622, train/logprobs = tensor([[-1.8633, -2.0726],
        [-1.7076, -1.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015083590522408485
Epoch 0, Step 559: train/loss = 0.44181108474731445, train/raw-loss = 0.4269995093345642, train/logprobs = tensor([[-1.0361, -3.0635],
        [-1.3167, -2.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029623135924339294
Epoch 0, Step 560: train/loss = 0.5503208637237549, train/raw-loss = 0.5420458316802979, train/logprobs = tensor([[-1.1648, -2.1528],
        [-1.2611, -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01655007153749466
Epoch 0, Step 561: train/loss = 0.48604851961135864, train/raw-loss = 0.4685571491718292, train/logprobs = tensor([[-1.9691, -3.1153],
        [-1.5499, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03498263284564018
Epoch 0, Step 562: train/loss = 0.5841296911239624, train/raw-loss = 0.5796634554862976, train/logprobs = tensor([[-1.2266, -2.1834],
        [-1.3508, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00893263891339302
Epoch 0, Step 563: train/loss = 0.470135360956192, train/raw-loss = 0.4458368718624115, train/logprobs = tensor([[-1.7431, -2.7891],
        [-1.4978, -1.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04859693720936775
Epoch 0, Step 564: train/loss = 0.6163220405578613, train/raw-loss = 0.6129786968231201, train/logprobs = tensor([[-1.4685, -1.5840],
        [-1.2651, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006686737760901451
Epoch 0, Step 565: train/loss = 0.49051809310913086, train/raw-loss = 0.4560050368309021, train/logprobs = tensor([[-1.1183, -2.3678],
        [-1.2102, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06902608275413513
Epoch 0, Step 566: train/loss = 0.41798198223114014, train/raw-loss = 0.3881645202636719, train/logprobs = tensor([[-1.2632, -3.1272],
        [-1.3434, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05963495001196861
Epoch 0, Step 567: train/loss = 0.41577139496803284, train/raw-loss = 0.3936166763305664, train/logprobs = tensor([[-1.0675, -3.5675],
        [-0.9419, -1.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04430949315428734
Epoch 0, Step 568: train/loss = 0.38857749104499817, train/raw-loss = 0.35440269112586975, train/logprobs = tensor([[-1.5745, -3.4203],
        [-1.5529, -1.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06834957748651505
Epoch 0, Step 569: train/loss = 0.4125749468803406, train/raw-loss = 0.38929283618927, train/logprobs = tensor([[-1.8094, -3.7523],
        [-1.8440, -2.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046564213931560516
Epoch 0, Step 570: train/loss = 0.5677398443222046, train/raw-loss = 0.5550599694252014, train/logprobs = tensor([[-1.5353, -2.7158],
        [-1.3683, -1.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025359759107232094
Epoch 0, Step 571: train/loss = 0.4959951639175415, train/raw-loss = 0.4815209209918976, train/logprobs = tensor([[-1.4642, -3.0290],
        [-1.5005, -1.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028948459774255753
Epoch 0, Step 572: train/loss = 0.39217594265937805, train/raw-loss = 0.36709487438201904, train/logprobs = tensor([[-1.1702, -3.9358],
        [-1.2373, -2.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05016211047768593
Epoch 0, Step 573: train/loss = 0.5747159719467163, train/raw-loss = 0.5466022491455078, train/logprobs = tensor([[-1.9764, -3.5350],
        [-1.4921, -2.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05622744932770729
Epoch 0, Step 574: train/loss = 0.574108362197876, train/raw-loss = 0.5447407364845276, train/logprobs = tensor([[-1.2099, -2.0687],
        [-1.2172, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058735162019729614
Epoch 0, Step 575: train/loss = 0.45007291436195374, train/raw-loss = 0.4176056683063507, train/logprobs = tensor([[-1.1931, -2.9693],
        [-1.2808, -1.5825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06493449211120605
Epoch 0, Step 576: train/loss = 0.5178331136703491, train/raw-loss = 0.5034562945365906, train/logprobs = tensor([[-1.0470, -1.9285],
        [-1.1685, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028753753751516342
Epoch 0, Step 577: train/loss = 0.44449788331985474, train/raw-loss = 0.41175371408462524, train/logprobs = tensor([[-2.0744, -3.8591],
        [-1.8351, -2.1567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06548837572336197
Epoch 0, Step 578: train/loss = 0.5176288485527039, train/raw-loss = 0.4862823784351349, train/logprobs = tensor([[-1.6169, -2.7206],
        [-1.3867, -1.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06269291788339615
Epoch 0, Step 579: train/loss = 0.5109328031539917, train/raw-loss = 0.4976992607116699, train/logprobs = tensor([[-0.9542, -2.4216],
        [-0.8995, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02646700292825699
Epoch 0, Step 580: train/loss = 0.6323894262313843, train/raw-loss = 0.6196213364601135, train/logprobs = tensor([[-1.4829, -2.4842],
        [-1.2646, -1.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02553621679544449
Epoch 0, Step 581: train/loss = 0.3377492129802704, train/raw-loss = 0.3226168751716614, train/logprobs = tensor([[-0.6364, -4.4037],
        [-0.6786, -2.4442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030264582484960556
Epoch 0, Step 582: train/loss = 0.4719395637512207, train/raw-loss = 0.45337536931037903, train/logprobs = tensor([[-1.4921, -2.5741],
        [-1.4422, -1.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037128351628780365
Epoch 0, Step 583: train/loss = 0.41841182112693787, train/raw-loss = 0.40355485677719116, train/logprobs = tensor([[-1.1339, -3.8425],
        [-1.1315, -2.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029713941738009453
Epoch 0, Step 584: train/loss = 0.5205492973327637, train/raw-loss = 0.49960052967071533, train/logprobs = tensor([[-1.4485, -2.9738],
        [-1.5624, -1.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0418974906206131
Epoch 0, Step 585: train/loss = 0.5311457514762878, train/raw-loss = 0.520057201385498, train/logprobs = tensor([[-0.7398, -2.9536],
        [-0.8656, -2.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022177159786224365
Epoch 0, Step 586: train/loss = 0.6483514308929443, train/raw-loss = 0.6458633542060852, train/logprobs = tensor([[-2.6750, -1.9083],
        [-2.1629, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004976232536137104
Epoch 0, Step 587: train/loss = 0.5204412937164307, train/raw-loss = 0.5046415328979492, train/logprobs = tensor([[-0.7768, -2.1271],
        [-0.8611, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03159957379102707
Epoch 0, Step 588: train/loss = 0.5075828433036804, train/raw-loss = 0.49173882603645325, train/logprobs = tensor([[-1.7723, -2.5860],
        [-1.5690, -1.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03168800473213196
Epoch 0, Step 589: train/loss = 0.6075828671455383, train/raw-loss = 0.6019371151924133, train/logprobs = tensor([[-2.1793, -3.0469],
        [-1.1762, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01129161100834608
Epoch 0, Step 590: train/loss = 0.47382768988609314, train/raw-loss = 0.45516249537467957, train/logprobs = tensor([[-1.5774, -3.0795],
        [-1.4123, -1.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037330422550439835
Epoch 0, Step 591: train/loss = 0.5228289365768433, train/raw-loss = 0.5057334899902344, train/logprobs = tensor([[-1.3817, -2.5178],
        [-1.4666, -1.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03419085219502449
Epoch 0, Step 592: train/loss = 0.5884406566619873, train/raw-loss = 0.5688826441764832, train/logprobs = tensor([[-2.1985, -2.1981],
        [-1.8235, -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03911616653203964
Epoch 0, Step 593: train/loss = 0.48554176092147827, train/raw-loss = 0.4607091248035431, train/logprobs = tensor([[-1.5760, -3.5911],
        [-1.5857, -2.2498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049665335565805435
Epoch 0, Step 594: train/loss = 0.5849111676216125, train/raw-loss = 0.5811854600906372, train/logprobs = tensor([[-1.1664, -2.0787],
        [-1.0597, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007451320998370647
Epoch 0, Step 595: train/loss = 0.5471521019935608, train/raw-loss = 0.5297906398773193, train/logprobs = tensor([[-1.5695, -2.3748],
        [-1.3522, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034722935408353806
Epoch 0, Step 596: train/loss = 0.5222626328468323, train/raw-loss = 0.5050477981567383, train/logprobs = tensor([[-1.0956, -2.1855],
        [-1.1172, -1.2605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03442966192960739
Epoch 0, Step 597: train/loss = 0.3886986970901489, train/raw-loss = 0.3599974513053894, train/logprobs = tensor([[-1.0455, -3.4516],
        [-1.0527, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05740246921777725
Epoch 0, Step 598: train/loss = 0.5619510412216187, train/raw-loss = 0.5323930978775024, train/logprobs = tensor([[-1.0307, -2.8048],
        [-1.1028, -1.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059115923941135406
Epoch 0, Step 599: train/loss = 0.3680590093135834, train/raw-loss = 0.3375174403190613, train/logprobs = tensor([[-1.5162, -3.7270],
        [-1.4220, -1.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0610831156373024
Epoch 0, Step 600: train/loss = 0.5843967199325562, train/raw-loss = 0.5775464773178101, train/logprobs = tensor([[-1.4558, -1.9074],
        [-1.3736, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013700374402105808
Epoch 0, Step 601: train/loss = 0.4439909756183624, train/raw-loss = 0.41669517755508423, train/logprobs = tensor([[-1.2567, -2.8310],
        [-1.2814, -1.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054591573774814606
Epoch 0, Step 602: train/loss = 0.5023718476295471, train/raw-loss = 0.4863874018192291, train/logprobs = tensor([[-1.5591, -2.3712],
        [-1.2997, -1.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03196888044476509
Epoch 0, Step 603: train/loss = 0.45017510652542114, train/raw-loss = 0.43099626898765564, train/logprobs = tensor([[-0.9948, -2.9503],
        [-1.0655, -1.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0383576825261116
Epoch 0, Step 604: train/loss = 0.4256869852542877, train/raw-loss = 0.3759089410305023, train/logprobs = tensor([[-1.2268, -4.0538],
        [-1.2844, -2.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09955611824989319
Epoch 0, Step 605: train/loss = 0.4711788296699524, train/raw-loss = 0.4508853256702423, train/logprobs = tensor([[-1.3150, -2.9090],
        [-1.3058, -1.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040586985647678375
Epoch 0, Step 606: train/loss = 0.5030789375305176, train/raw-loss = 0.4849032163619995, train/logprobs = tensor([[-1.5758, -2.5413],
        [-1.7092, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03635150194168091
Epoch 0, Step 607: train/loss = 0.4676732122898102, train/raw-loss = 0.43583542108535767, train/logprobs = tensor([[-1.6975, -3.0374],
        [-1.7603, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06367557495832443
Epoch 0, Step 608: train/loss = 0.5897719860076904, train/raw-loss = 0.560883641242981, train/logprobs = tensor([[-1.2506, -3.7629],
        [-1.2316, -2.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05777657404541969
Epoch 0, Step 609: train/loss = 0.4651673436164856, train/raw-loss = 0.4262750744819641, train/logprobs = tensor([[-1.7755, -3.1865],
        [-1.6155, -1.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077784463763237
Epoch 0, Step 610: train/loss = 0.5368042588233948, train/raw-loss = 0.52598637342453, train/logprobs = tensor([[-1.2969, -3.2886],
        [-0.9978, -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02163570187985897
Epoch 0, Step 611: train/loss = 0.6136021614074707, train/raw-loss = 0.5996555089950562, train/logprobs = tensor([[-1.5054, -1.9559],
        [-1.3112, -1.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027893217280507088
Epoch 0, Step 612: train/loss = 0.49845027923583984, train/raw-loss = 0.4838326573371887, train/logprobs = tensor([[-1.7587, -3.0412],
        [-1.3530, -1.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029235268011689186
Epoch 0, Step 613: train/loss = 0.5514359474182129, train/raw-loss = 0.5354951620101929, train/logprobs = tensor([[-1.2059, -3.9530],
        [-0.9101, -2.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03188169375061989
Epoch 0, Step 614: train/loss = 0.4701346158981323, train/raw-loss = 0.46029478311538696, train/logprobs = tensor([[-1.4645, -3.9145],
        [-1.1734, -2.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019679727032780647
Epoch 0, Step 615: train/loss = 0.46885383129119873, train/raw-loss = 0.446724534034729, train/logprobs = tensor([[-0.7767, -2.8474],
        [-0.8002, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04425856098532677
Epoch 0, Step 616: train/loss = 0.4446500539779663, train/raw-loss = 0.4243195056915283, train/logprobs = tensor([[-2.4852, -4.6990],
        [-1.8214, -2.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04066109657287598
Epoch 0, Step 617: train/loss = 0.5039396286010742, train/raw-loss = 0.4860401451587677, train/logprobs = tensor([[-1.2533, -2.4230],
        [-1.1882, -1.3251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03579901158809662
Epoch 0, Step 618: train/loss = 0.4262501895427704, train/raw-loss = 0.4018256366252899, train/logprobs = tensor([[-1.2025, -2.8959],
        [-1.1146, -1.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04884907230734825
Epoch 0, Step 619: train/loss = 0.6182228326797485, train/raw-loss = 0.5939850807189941, train/logprobs = tensor([[-2.9752, -3.7886],
        [-1.4422, -1.3402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048475444316864014
Epoch 0, Step 620: train/loss = 0.5894021987915039, train/raw-loss = 0.5628573298454285, train/logprobs = tensor([[-1.2151, -2.8017],
        [-1.1693, -1.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05308982729911804
Epoch 0, Step 621: train/loss = 0.4391966462135315, train/raw-loss = 0.40411657094955444, train/logprobs = tensor([[-2.1278, -3.4963],
        [-1.7081, -1.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07016013562679291
Epoch 0, Step 622: train/loss = 0.49502748250961304, train/raw-loss = 0.48652997612953186, train/logprobs = tensor([[-1.1537, -3.4569],
        [-1.0801, -2.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016994986683130264
Epoch 0, Step 623: train/loss = 0.45170536637306213, train/raw-loss = 0.41428256034851074, train/logprobs = tensor([[-2.9732, -4.9057],
        [-2.2712, -2.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07484566420316696
Epoch 0, Step 624: train/loss = 0.5559982061386108, train/raw-loss = 0.5336132049560547, train/logprobs = tensor([[-1.6262, -2.1520],
        [-1.4327, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0447700172662735
Epoch 0, Step 625: train/loss = 0.5255658626556396, train/raw-loss = 0.47543781995773315, train/logprobs = tensor([[-1.5045, -2.5895],
        [-1.6304, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10025610029697418
Epoch 0, Step 626: train/loss = 0.49732333421707153, train/raw-loss = 0.48373380303382874, train/logprobs = tensor([[-1.7425, -3.2359],
        [-1.4763, -1.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027179015800356865
Epoch 0, Step 627: train/loss = 0.49568814039230347, train/raw-loss = 0.4805539548397064, train/logprobs = tensor([[-1.0466, -2.8663],
        [-0.9435, -1.5523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030268343165516853
Epoch 0, Step 628: train/loss = 0.39452630281448364, train/raw-loss = 0.369662880897522, train/logprobs = tensor([[-1.3659, -3.9081],
        [-1.0640, -1.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049726877361536026
Epoch 0, Step 629: train/loss = 0.4727914333343506, train/raw-loss = 0.4459567070007324, train/logprobs = tensor([[-1.5722, -2.9261],
        [-1.3804, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053669460117816925
Epoch 0, Step 630: train/loss = 0.3814774751663208, train/raw-loss = 0.3394206762313843, train/logprobs = tensor([[-0.8548, -3.8651],
        [-0.9632, -1.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08411353081464767
Epoch 0, Step 631: train/loss = 0.6153241991996765, train/raw-loss = 0.6099337339401245, train/logprobs = tensor([[-1.0534, -1.4890],
        [-0.9811, -1.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010780896060168743
Epoch 0, Step 632: train/loss = 0.565594494342804, train/raw-loss = 0.5423628091812134, train/logprobs = tensor([[-1.2024, -2.8457],
        [-1.2189, -1.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04646342247724533
Epoch 0, Step 633: train/loss = 0.4493370056152344, train/raw-loss = 0.41559189558029175, train/logprobs = tensor([[-0.9889, -3.7631],
        [-1.0845, -2.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06749017536640167
Epoch 0, Step 634: train/loss = 0.41796258091926575, train/raw-loss = 0.38699623942375183, train/logprobs = tensor([[-1.6901, -3.4905],
        [-1.5987, -1.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06193269044160843
Epoch 0, Step 635: train/loss = 0.5061750411987305, train/raw-loss = 0.4780770242214203, train/logprobs = tensor([[-1.4850, -2.5189],
        [-1.4130, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05619606748223305
Epoch 0, Step 636: train/loss = 0.5379980206489563, train/raw-loss = 0.5138016939163208, train/logprobs = tensor([[-2.1187, -2.8834],
        [-1.6654, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04839257895946503
Epoch 0, Step 637: train/loss = 0.5472151637077332, train/raw-loss = 0.5233140587806702, train/logprobs = tensor([[-1.5034, -2.3699],
        [-1.5666, -1.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04780219495296478
Epoch 0, Step 638: train/loss = 0.5170060992240906, train/raw-loss = 0.4972107708454132, train/logprobs = tensor([[-1.2556, -2.2519],
        [-1.3064, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03959072753787041
Epoch 0, Step 639: train/loss = 0.617828369140625, train/raw-loss = 0.6065328121185303, train/logprobs = tensor([[-1.6963, -2.1606],
        [-1.2255, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022591017186641693
Epoch 0, Step 640: train/loss = 0.41558757424354553, train/raw-loss = 0.38208070397377014, train/logprobs = tensor([[-0.9445, -3.3228],
        [-0.9122, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06701373308897018
Epoch 0, Step 641: train/loss = 0.5118261575698853, train/raw-loss = 0.4906083941459656, train/logprobs = tensor([[-1.0466, -2.4729],
        [-1.3339, -1.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04243554547429085
Epoch 0, Step 642: train/loss = 0.5839647054672241, train/raw-loss = 0.5788029432296753, train/logprobs = tensor([[-0.9566, -1.8232],
        [-0.9417, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010323544032871723
Epoch 0, Step 643: train/loss = 0.5569841861724854, train/raw-loss = 0.5466358065605164, train/logprobs = tensor([[-1.0187, -2.3275],
        [-1.0705, -1.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02069680765271187
Epoch 0, Step 644: train/loss = 0.44823750853538513, train/raw-loss = 0.40939074754714966, train/logprobs = tensor([[-1.5848, -3.5385],
        [-1.7443, -1.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07769354432821274
Epoch 0, Step 645: train/loss = 0.5623036623001099, train/raw-loss = 0.5541338920593262, train/logprobs = tensor([[-1.2915, -2.0025],
        [-1.0044, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01633952185511589
Epoch 0, Step 646: train/loss = 0.4030724763870239, train/raw-loss = 0.3760419189929962, train/logprobs = tensor([[-1.4068, -3.6066],
        [-1.3969, -1.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054061125963926315
Epoch 0, Step 647: train/loss = 0.5337492227554321, train/raw-loss = 0.49990665912628174, train/logprobs = tensor([[-1.8730, -2.7993],
        [-1.6266, -1.4568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06768521666526794
Epoch 0, Step 648: train/loss = 0.42549929022789, train/raw-loss = 0.3884425461292267, train/logprobs = tensor([[-1.1017, -3.9058],
        [-0.9504, -1.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07411350309848785
Epoch 0, Step 649: train/loss = 0.5783424377441406, train/raw-loss = 0.5692497491836548, train/logprobs = tensor([[-0.9740, -2.1212],
        [-1.0594, -1.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018185347318649292
Epoch 0, Step 650: train/loss = 0.6103408336639404, train/raw-loss = 0.597353458404541, train/logprobs = tensor([[-1.9043, -2.8201],
        [-1.4408, -1.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025974927470088005
Epoch 0, Step 651: train/loss = 0.491563618183136, train/raw-loss = 0.4545603096485138, train/logprobs = tensor([[-1.8609, -2.3840],
        [-1.7810, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07400668412446976
Epoch 0, Step 652: train/loss = 0.4205593168735504, train/raw-loss = 0.3910772204399109, train/logprobs = tensor([[-1.1300, -3.3137],
        [-1.0716, -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05896419659256935
Epoch 0, Step 653: train/loss = 0.5149560570716858, train/raw-loss = 0.49850231409072876, train/logprobs = tensor([[-0.9328, -1.9303],
        [-0.8728, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03290746361017227
Epoch 0, Step 654: train/loss = 0.5068882703781128, train/raw-loss = 0.48719093203544617, train/logprobs = tensor([[-1.3510, -2.0927],
        [-1.4006, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03939465433359146
Epoch 0, Step 655: train/loss = 0.42400845885276794, train/raw-loss = 0.4017764627933502, train/logprobs = tensor([[-1.3071, -3.2273],
        [-1.3850, -1.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04446392506361008
Epoch 0, Step 656: train/loss = 0.48558348417282104, train/raw-loss = 0.47469717264175415, train/logprobs = tensor([[-0.8772, -2.5331],
        [-0.9717, -1.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021772583946585655
Epoch 0, Step 657: train/loss = 0.5351941585540771, train/raw-loss = 0.50969398021698, train/logprobs = tensor([[-1.1463, -1.9297],
        [-1.2375, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05100041255354881
Epoch 0, Step 658: train/loss = 0.5298560261726379, train/raw-loss = 0.5070480704307556, train/logprobs = tensor([[-1.1233, -1.7188],
        [-1.3068, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04561587795615196
Epoch 0, Step 659: train/loss = 0.34487441182136536, train/raw-loss = 0.31958454847335815, train/logprobs = tensor([[-1.1932, -4.9828],
        [-1.2211, -2.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050579652190208435
Epoch 0, Step 660: train/loss = 0.5026329755783081, train/raw-loss = 0.4907402992248535, train/logprobs = tensor([[-1.5354, -3.5351],
        [-1.0525, -1.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023785388097167015
Epoch 0, Step 661: train/loss = 0.37994760274887085, train/raw-loss = 0.34715932607650757, train/logprobs = tensor([[-1.5518, -3.5983],
        [-1.8832, -1.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06557650119066238
Epoch 0, Step 662: train/loss = 0.4529101252555847, train/raw-loss = 0.4243538975715637, train/logprobs = tensor([[-1.0871, -2.8034],
        [-1.2028, -1.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057112425565719604
Epoch 0, Step 663: train/loss = 0.4628717303276062, train/raw-loss = 0.41817522048950195, train/logprobs = tensor([[-1.4607, -2.7591],
        [-1.2626, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08939298987388611
Epoch 0, Step 664: train/loss = 0.4700997471809387, train/raw-loss = 0.45019158720970154, train/logprobs = tensor([[-1.8211, -4.1327],
        [-1.7653, -2.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03981632739305496
Epoch 0, Step 665: train/loss = 0.3895292580127716, train/raw-loss = 0.36995649337768555, train/logprobs = tensor([[-1.3486, -3.5149],
        [-1.3253, -1.8127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03914552181959152
Epoch 0, Step 666: train/loss = 0.41743144392967224, train/raw-loss = 0.38958847522735596, train/logprobs = tensor([[-1.5907, -2.9453],
        [-1.5030, -1.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05568592995405197
Epoch 0, Step 667: train/loss = 0.564860999584198, train/raw-loss = 0.5480648875236511, train/logprobs = tensor([[-1.1876, -1.6412],
        [-1.2730, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03359220176935196
Epoch 0, Step 668: train/loss = 0.42684704065322876, train/raw-loss = 0.3960731327533722, train/logprobs = tensor([[-1.3726, -3.1805],
        [-1.3656, -1.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06154786795377731
Epoch 0, Step 669: train/loss = 0.36720526218414307, train/raw-loss = 0.33893877267837524, train/logprobs = tensor([[-1.1703, -4.3735],
        [-1.1215, -2.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05653294548392296
Epoch 0, Step 670: train/loss = 0.6302412152290344, train/raw-loss = 0.622239351272583, train/logprobs = tensor([[-1.8464, -2.0837],
        [-1.3044, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01600371114909649
Epoch 0, Step 671: train/loss = 0.6125044226646423, train/raw-loss = 0.606239914894104, train/logprobs = tensor([[-1.2620, -2.0816],
        [-0.9010, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012528959661722183
Epoch 0, Step 672: train/loss = 0.4167964458465576, train/raw-loss = 0.36858460307121277, train/logprobs = tensor([[-1.8834, -3.6261],
        [-1.5000, -1.3830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0964236706495285
Epoch 0, Step 673: train/loss = 0.39067527651786804, train/raw-loss = 0.35694485902786255, train/logprobs = tensor([[-1.4698, -3.4981],
        [-1.2917, -1.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06746090203523636
Epoch 0, Step 674: train/loss = 0.36205726861953735, train/raw-loss = 0.2868124544620514, train/logprobs = tensor([[-1.4376, -4.2465],
        [-1.5449, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504896730184555
Epoch 0, Step 675: train/loss = 0.39746126532554626, train/raw-loss = 0.3737904727458954, train/logprobs = tensor([[-0.9729, -3.1117],
        [-1.1283, -1.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047341614961624146
Epoch 0, Step 676: train/loss = 0.4665295481681824, train/raw-loss = 0.4411412477493286, train/logprobs = tensor([[-1.5250, -2.8736],
        [-1.4175, -1.4087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050776563584804535
Epoch 0, Step 677: train/loss = 0.3961273431777954, train/raw-loss = 0.35985901951789856, train/logprobs = tensor([[-1.4128, -3.5462],
        [-1.4681, -1.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07253661006689072
Epoch 0, Step 678: train/loss = 0.3541421890258789, train/raw-loss = 0.3038966655731201, train/logprobs = tensor([[-1.4377, -4.3795],
        [-1.5180, -2.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10049108415842056
Epoch 0, Step 679: train/loss = 0.5647767186164856, train/raw-loss = 0.5483428835868835, train/logprobs = tensor([[-1.4300, -1.8045],
        [-1.3670, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032867662608623505
Epoch 0, Step 680: train/loss = 0.5059532523155212, train/raw-loss = 0.4583040773868561, train/logprobs = tensor([[-1.9635, -3.1780],
        [-1.7644, -1.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952983945608139
Epoch 0, Step 681: train/loss = 0.46860989928245544, train/raw-loss = 0.44851547479629517, train/logprobs = tensor([[-0.9918, -2.9545],
        [-1.0578, -1.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04018893092870712
Epoch 0, Step 682: train/loss = 0.3516395688056946, train/raw-loss = 0.30135098099708557, train/logprobs = tensor([[-1.5656, -4.1470],
        [-1.7073, -1.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10057723522186279
Epoch 0, Step 683: train/loss = 0.5331571698188782, train/raw-loss = 0.49622005224227905, train/logprobs = tensor([[-2.1691, -2.9715],
        [-1.6494, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07387436181306839
Epoch 0, Step 684: train/loss = 0.44725483655929565, train/raw-loss = 0.4191311299800873, train/logprobs = tensor([[-1.0044, -2.5535],
        [-1.2130, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05624743551015854
Epoch 0, Step 685: train/loss = 0.3875991106033325, train/raw-loss = 0.35310521721839905, train/logprobs = tensor([[-1.2927, -3.6192],
        [-1.4630, -1.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06898774206638336
Epoch 0, Step 686: train/loss = 0.4102824628353119, train/raw-loss = 0.37433791160583496, train/logprobs = tensor([[-0.8961, -3.2354],
        [-1.0494, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07188913971185684
Epoch 0, Step 687: train/loss = 0.4529798626899719, train/raw-loss = 0.4076762795448303, train/logprobs = tensor([[-1.6369, -3.0563],
        [-1.7058, -1.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09060721099376678
Epoch 0, Step 688: train/loss = 0.39762037992477417, train/raw-loss = 0.37637609243392944, train/logprobs = tensor([[-1.6350, -4.2044],
        [-1.4730, -2.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04248853400349617
Epoch 0, Step 689: train/loss = 0.42472875118255615, train/raw-loss = 0.3970019519329071, train/logprobs = tensor([[-0.7867, -2.9194],
        [-0.9255, -1.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055453598499298096
Epoch 0, Step 690: train/loss = 0.45035484433174133, train/raw-loss = 0.4231656789779663, train/logprobs = tensor([[-1.5711, -3.4207],
        [-1.3101, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054378412663936615
Epoch 0, Step 691: train/loss = 0.35368844866752625, train/raw-loss = 0.314120352268219, train/logprobs = tensor([[-0.9615, -3.7091],
        [-1.1102, -1.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07913615554571152
Epoch 0, Step 692: train/loss = 0.4255092740058899, train/raw-loss = 0.39404743909835815, train/logprobs = tensor([[-1.2745, -3.0416],
        [-1.2914, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06292372196912766
Epoch 0, Step 693: train/loss = 0.4604177474975586, train/raw-loss = 0.40483996272087097, train/logprobs = tensor([[-1.6414, -3.4557],
        [-1.6686, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11115553975105286
Epoch 0, Step 694: train/loss = 0.3742064833641052, train/raw-loss = 0.329571008682251, train/logprobs = tensor([[-1.4318, -3.6170],
        [-1.4867, -1.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08927097916603088
Epoch 0, Step 695: train/loss = 0.38895827531814575, train/raw-loss = 0.3416512608528137, train/logprobs = tensor([[-1.2241, -3.2973],
        [-1.3477, -1.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09461405128240585
Epoch 0, Step 696: train/loss = 0.31593871116638184, train/raw-loss = 0.2726244330406189, train/logprobs = tensor([[-1.1250, -3.9609],
        [-1.2272, -1.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08662855625152588
Epoch 0, Step 697: train/loss = 0.4037361443042755, train/raw-loss = 0.35185879468917847, train/logprobs = tensor([[-1.2559, -3.3394],
        [-1.5494, -1.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10375464707612991
Epoch 0, Step 698: train/loss = 0.38298356533050537, train/raw-loss = 0.34995388984680176, train/logprobs = tensor([[-1.7883, -4.6214],
        [-1.3604, -1.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06605927646160126
Epoch 0, Step 699: train/loss = 0.4710223078727722, train/raw-loss = 0.4406838119029999, train/logprobs = tensor([[-1.3498, -2.9452],
        [-1.2740, -1.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060677025467157364
Epoch 0, Step 700: train/loss = 0.4060879945755005, train/raw-loss = 0.37903308868408203, train/logprobs = tensor([[-0.7347, -3.2850],
        [-0.8410, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054109878838062286
Epoch 0, Step 701: train/loss = 0.4709221124649048, train/raw-loss = 0.43949684500694275, train/logprobs = tensor([[-1.1982, -2.7621],
        [-1.4944, -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06285052001476288
Epoch 0, Step 702: train/loss = 0.4060107171535492, train/raw-loss = 0.37543630599975586, train/logprobs = tensor([[-2.0535, -3.3691],
        [-2.0107, -1.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06114880368113518
Epoch 0, Step 703: train/loss = 0.32618680596351624, train/raw-loss = 0.2989671230316162, train/logprobs = tensor([[-1.8406, -4.5666],
        [-1.5660, -1.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054439373314380646
Epoch 0, Step 704: train/loss = 0.38497063517570496, train/raw-loss = 0.3599094748497009, train/logprobs = tensor([[-0.9848, -3.8360],
        [-1.2013, -2.2850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05012228712439537
Epoch 0, Step 705: train/loss = 0.4729546308517456, train/raw-loss = 0.453494131565094, train/logprobs = tensor([[-1.5264, -3.2153],
        [-1.5110, -1.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03892096132040024
Epoch 0, Step 706: train/loss = 0.3889633119106293, train/raw-loss = 0.3619430959224701, train/logprobs = tensor([[-1.2432, -4.0664],
        [-0.9742, -1.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054040443152189255
Epoch 0, Step 707: train/loss = 0.5341945886611938, train/raw-loss = 0.5197892785072327, train/logprobs = tensor([[-1.5495, -2.4976],
        [-1.1624, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028810597956180573
Epoch 0, Step 708: train/loss = 0.5518929362297058, train/raw-loss = 0.537550687789917, train/logprobs = tensor([[-1.1366, -2.0119],
        [-1.3268, -1.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028684616088867188
Epoch 0, Step 709: train/loss = 0.4840944707393646, train/raw-loss = 0.4651506543159485, train/logprobs = tensor([[-0.8244, -2.2506],
        [-1.0894, -1.3689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03788761422038078
Epoch 0, Step 710: train/loss = 0.37666964530944824, train/raw-loss = 0.34513580799102783, train/logprobs = tensor([[-0.7873, -3.6758],
        [-0.7248, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0630677118897438
Epoch 0, Step 711: train/loss = 0.45117074251174927, train/raw-loss = 0.4231983423233032, train/logprobs = tensor([[-1.9454, -3.1786],
        [-1.9914, -1.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05594474822282791
Epoch 0, Step 712: train/loss = 0.34945109486579895, train/raw-loss = 0.3107159435749054, train/logprobs = tensor([[-0.8272, -3.7043],
        [-0.8950, -1.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774703249335289
Epoch 0, Step 713: train/loss = 0.35053205490112305, train/raw-loss = 0.30686718225479126, train/logprobs = tensor([[-0.9843, -3.4280],
        [-1.0867, -1.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08732983469963074
Epoch 0, Step 714: train/loss = 0.5555182695388794, train/raw-loss = 0.5334261059761047, train/logprobs = tensor([[-0.9818, -1.5405],
        [-1.2100, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0441843718290329
Epoch 0, Step 715: train/loss = 0.5365334153175354, train/raw-loss = 0.514988124370575, train/logprobs = tensor([[-1.1926, -1.6595],
        [-1.5563, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04309049993753433
Epoch 0, Step 716: train/loss = 0.40391162037849426, train/raw-loss = 0.3413470387458801, train/logprobs = tensor([[-1.5788, -3.5092],
        [-1.6264, -1.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1251291036605835
Epoch 0, Step 717: train/loss = 0.3701757788658142, train/raw-loss = 0.31580108404159546, train/logprobs = tensor([[-1.4913, -3.3787],
        [-1.5415, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10874935239553452
Epoch 0, Step 718: train/loss = 0.4539349377155304, train/raw-loss = 0.3738592267036438, train/logprobs = tensor([[-2.3186, -4.9578],
        [-1.3520, -1.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16015145182609558
Epoch 0, Step 719: train/loss = 0.6155157089233398, train/raw-loss = 0.6094467639923096, train/logprobs = tensor([[-1.1878, -1.3680],
        [-1.2378, -1.0130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012137910351157188
Epoch 0, Step 720: train/loss = 0.4890943765640259, train/raw-loss = 0.46695616841316223, train/logprobs = tensor([[-0.9235, -2.4971],
        [-1.1674, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04427647590637207
Epoch 0, Step 721: train/loss = 0.5031461715698242, train/raw-loss = 0.47953593730926514, train/logprobs = tensor([[-1.4868, -2.8818],
        [-1.2883, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047220297157764435
Epoch 0, Step 722: train/loss = 0.42906785011291504, train/raw-loss = 0.36986178159713745, train/logprobs = tensor([[-1.0340, -3.2822],
        [-1.1760, -1.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11841215938329697
Epoch 0, Step 723: train/loss = 0.4385695159435272, train/raw-loss = 0.41359803080558777, train/logprobs = tensor([[-1.8107, -4.1375],
        [-1.1844, -1.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04994291067123413
Epoch 0, Step 724: train/loss = 0.4830077588558197, train/raw-loss = 0.4591212868690491, train/logprobs = tensor([[-0.9013, -2.6236],
        [-1.1457, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04777294397354126
Epoch 0, Step 725: train/loss = 0.4658907651901245, train/raw-loss = 0.42667847871780396, train/logprobs = tensor([[-1.4700, -2.5188],
        [-1.5871, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07842451333999634
Epoch 0, Step 726: train/loss = 0.5001115798950195, train/raw-loss = 0.46297067403793335, train/logprobs = tensor([[-1.2172, -2.1522],
        [-1.4008, -0.9634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428184151649475
Epoch 0, Step 727: train/loss = 0.49493783712387085, train/raw-loss = 0.469499409198761, train/logprobs = tensor([[-0.8082, -2.1771],
        [-1.0990, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05087693780660629
Epoch 0, Step 728: train/loss = 0.4832930564880371, train/raw-loss = 0.4499208331108093, train/logprobs = tensor([[-1.5457, -2.7157],
        [-1.7484, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0667443796992302
Epoch 0, Step 729: train/loss = 0.3020881414413452, train/raw-loss = 0.25158143043518066, train/logprobs = tensor([[-0.9836, -4.1513],
        [-1.2022, -1.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10101336985826492
Epoch 0, Step 730: train/loss = 0.5698999166488647, train/raw-loss = 0.5458864569664001, train/logprobs = tensor([[-1.8326, -2.2212],
        [-1.8975, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048026975244283676
Epoch 0, Step 731: train/loss = 0.5364421010017395, train/raw-loss = 0.5116639733314514, train/logprobs = tensor([[-2.5187, -2.5881],
        [-2.0351, -1.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04955622926354408
Epoch 0, Step 732: train/loss = 0.4980572462081909, train/raw-loss = 0.47120827436447144, train/logprobs = tensor([[-2.1279, -2.9588],
        [-2.1296, -1.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05369789898395538
Epoch 0, Step 733: train/loss = 0.3844061493873596, train/raw-loss = 0.3545643985271454, train/logprobs = tensor([[-1.0576, -3.3100],
        [-1.3840, -1.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05968347191810608
Epoch 0, Step 734: train/loss = 0.5466250777244568, train/raw-loss = 0.5313873887062073, train/logprobs = tensor([[-1.6410, -2.1534],
        [-1.2556, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030475284904241562
Epoch 0, Step 735: train/loss = 0.7159788608551025, train/raw-loss = 0.7057257890701294, train/logprobs = tensor([[-2.2143, -1.8426],
        [-1.5144, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020506206899881363
Epoch 0, Step 736: train/loss = 0.32508572936058044, train/raw-loss = 0.2546594738960266, train/logprobs = tensor([[-1.3407, -4.1113],
        [-1.7540, -1.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408524513244629
Epoch 0, Step 737: train/loss = 0.5923506617546082, train/raw-loss = 0.5484869480133057, train/logprobs = tensor([[-1.8422, -2.4029],
        [-1.6784, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772742748260498
Epoch 0, Step 738: train/loss = 0.270278662443161, train/raw-loss = 0.20835505425930023, train/logprobs = tensor([[-1.2086, -4.7252],
        [-1.6581, -2.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12384721636772156
Epoch 0, Step 739: train/loss = 0.2789551317691803, train/raw-loss = 0.16940802335739136, train/logprobs = tensor([[-1.5119, -5.1680],
        [-1.4972, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2190942019224167
Epoch 0, Step 740: train/loss = 0.42255282402038574, train/raw-loss = 0.40012380480766296, train/logprobs = tensor([[-0.7480, -3.2144],
        [-1.1440, -1.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0448579415678978
Epoch 0, Step 741: train/loss = 0.4036518633365631, train/raw-loss = 0.3668673038482666, train/logprobs = tensor([[-1.7771, -4.0271],
        [-1.4445, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0735691636800766
Epoch 0, Step 742: train/loss = 0.4458690881729126, train/raw-loss = 0.4118773937225342, train/logprobs = tensor([[-0.8157, -2.9634],
        [-0.9791, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0679834857583046
Epoch 0, Step 743: train/loss = 0.4646594524383545, train/raw-loss = 0.4420769512653351, train/logprobs = tensor([[-1.2637, -3.1269],
        [-1.0898, -1.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04516497999429703
Epoch 0, Step 744: train/loss = 0.4235403537750244, train/raw-loss = 0.39938536286354065, train/logprobs = tensor([[-1.2627, -3.3510],
        [-1.5057, -2.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04830999672412872
Epoch 0, Step 745: train/loss = 0.34517884254455566, train/raw-loss = 0.3045090436935425, train/logprobs = tensor([[-1.1384, -3.9873],
        [-1.4630, -1.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08133964240550995
Epoch 0, Step 746: train/loss = 0.4262111783027649, train/raw-loss = 0.40504759550094604, train/logprobs = tensor([[-0.7187, -3.6776],
        [-0.9543, -1.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232712835073471
Epoch 0, Step 747: train/loss = 0.6229740381240845, train/raw-loss = 0.6083225011825562, train/logprobs = tensor([[-1.5015, -1.7111],
        [-1.5325, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029302943497896194
Epoch 0, Step 748: train/loss = 0.4720132052898407, train/raw-loss = 0.4499237537384033, train/logprobs = tensor([[-1.4350, -3.3809],
        [-1.6226, -2.2095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04417893663048744
Epoch 0, Step 749: train/loss = 0.414840430021286, train/raw-loss = 0.3759000301361084, train/logprobs = tensor([[-1.7397, -3.0961],
        [-1.5445, -1.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07788081467151642
Epoch 0, Step 750: train/loss = 0.4203062355518341, train/raw-loss = 0.38277339935302734, train/logprobs = tensor([[-1.4513, -3.2414],
        [-1.2611, -1.3389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07506567984819412
Epoch 0, Step 751: train/loss = 0.4374321699142456, train/raw-loss = 0.3939625024795532, train/logprobs = tensor([[-1.1891, -2.8339],
        [-1.5695, -1.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693933486938477
Epoch 0, Step 752: train/loss = 0.5040637254714966, train/raw-loss = 0.48943185806274414, train/logprobs = tensor([[-0.7198, -2.1325],
        [-1.0071, -1.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02926371619105339
Epoch 0, Step 753: train/loss = 0.37993133068084717, train/raw-loss = 0.3413460850715637, train/logprobs = tensor([[-0.9268, -2.8592],
        [-1.3632, -1.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07717050611972809
Epoch 0, Step 754: train/loss = 0.34418919682502747, train/raw-loss = 0.31599661707878113, train/logprobs = tensor([[-1.0860, -4.0800],
        [-1.2010, -1.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05638514459133148
Epoch 0, Step 755: train/loss = 0.3476499915122986, train/raw-loss = 0.2727459967136383, train/logprobs = tensor([[-1.5845, -4.4135],
        [-1.8967, -1.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980795979499817
Epoch 0, Step 756: train/loss = 0.3495767116546631, train/raw-loss = 0.2946275770664215, train/logprobs = tensor([[-1.2371, -3.7202],
        [-1.6734, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989826917648315
Epoch 0, Step 757: train/loss = 0.3499344289302826, train/raw-loss = 0.31230250000953674, train/logprobs = tensor([[-1.4209, -4.3148],
        [-1.8530, -2.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0752638727426529
Epoch 0, Step 758: train/loss = 0.44615185260772705, train/raw-loss = 0.406980037689209, train/logprobs = tensor([[-1.1509, -2.6230],
        [-1.1600, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834364473819733
Epoch 0, Step 759: train/loss = 0.37270399928092957, train/raw-loss = 0.30509862303733826, train/logprobs = tensor([[-1.8264, -3.6229],
        [-1.9583, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13521073758602142
Epoch 0, Step 760: train/loss = 0.312287837266922, train/raw-loss = 0.243996262550354, train/logprobs = tensor([[-2.0203, -4.6052],
        [-1.9425, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13658319413661957
Epoch 0, Step 761: train/loss = 0.4884832501411438, train/raw-loss = 0.452390193939209, train/logprobs = tensor([[-1.3675, -2.5420],
        [-1.3332, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07218610495328903
Epoch 0, Step 762: train/loss = 0.4641761779785156, train/raw-loss = 0.42497551441192627, train/logprobs = tensor([[-1.7609, -3.5222],
        [-1.5549, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0784013643860817
Epoch 0, Step 763: train/loss = 0.5809042453765869, train/raw-loss = 0.5742480754852295, train/logprobs = tensor([[-1.0412, -1.4463],
        [-1.1895, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013312408700585365
Epoch 0, Step 764: train/loss = 0.34417906403541565, train/raw-loss = 0.2857467830181122, train/logprobs = tensor([[-1.3647, -3.5276],
        [-1.6563, -1.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11686457693576813
Epoch 0, Step 765: train/loss = 0.3364846706390381, train/raw-loss = 0.2601344585418701, train/logprobs = tensor([[-1.0908, -4.4530],
        [-1.4896, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15270036458969116
Epoch 0, Step 766: train/loss = 0.48138654232025146, train/raw-loss = 0.46236729621887207, train/logprobs = tensor([[-1.2858, -2.9622],
        [-1.6405, -2.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03803854063153267
Epoch 0, Step 767: train/loss = 0.5110679864883423, train/raw-loss = 0.4982554614543915, train/logprobs = tensor([[-1.4177, -2.7735],
        [-1.5334, -1.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025625061243772507
Epoch 0, Step 768: train/loss = 0.4364512264728546, train/raw-loss = 0.38444775342941284, train/logprobs = tensor([[-1.1352, -2.4259],
        [-1.6454, -1.1494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10400700569152832
Epoch 0, Step 769: train/loss = 0.4440711736679077, train/raw-loss = 0.41754668951034546, train/logprobs = tensor([[-1.1552, -2.9390],
        [-1.3914, -1.6756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05304901674389839
Epoch 0, Step 770: train/loss = 0.5434565544128418, train/raw-loss = 0.521145224571228, train/logprobs = tensor([[-0.7904, -1.3946],
        [-1.1554, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044622715562582016
Epoch 0, Step 771: train/loss = 0.34200358390808105, train/raw-loss = 0.27823853492736816, train/logprobs = tensor([[-1.3070, -3.5569],
        [-1.6575, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12753011286258698
Epoch 0, Step 772: train/loss = 0.40556594729423523, train/raw-loss = 0.3542098104953766, train/logprobs = tensor([[-1.3662, -2.9454],
        [-1.5342, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1027122437953949
Epoch 0, Step 773: train/loss = 0.5671787261962891, train/raw-loss = 0.5481315851211548, train/logprobs = tensor([[-1.8823, -2.2550],
        [-1.4546, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038094256073236465
Epoch 0, Step 774: train/loss = 0.41220444440841675, train/raw-loss = 0.37182897329330444, train/logprobs = tensor([[-1.6261, -3.4221],
        [-1.7649, -1.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08075094223022461
Epoch 0, Step 775: train/loss = 0.3667258620262146, train/raw-loss = 0.3387858271598816, train/logprobs = tensor([[-1.2112, -3.5488],
        [-1.5023, -1.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0558801144361496
Epoch 0, Step 776: train/loss = 0.35416269302368164, train/raw-loss = 0.2753583788871765, train/logprobs = tensor([[-1.4267, -4.2671],
        [-1.5863, -1.2972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15760862827301025
Epoch 0, Step 777: train/loss = 0.3936839997768402, train/raw-loss = 0.34729278087615967, train/logprobs = tensor([[-1.3845, -3.8122],
        [-1.6656, -1.7615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09278243780136108
Epoch 0, Step 778: train/loss = 0.4216952323913574, train/raw-loss = 0.3681091070175171, train/logprobs = tensor([[-1.2316, -2.6991],
        [-1.5743, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10717224329710007
Epoch 0, Step 779: train/loss = 0.3850197494029999, train/raw-loss = 0.3292700946331024, train/logprobs = tensor([[-1.7337, -3.4059],
        [-1.7134, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149928718805313
Epoch 0, Step 780: train/loss = 0.43074339628219604, train/raw-loss = 0.3969067931175232, train/logprobs = tensor([[-1.0754, -2.4558],
        [-1.2920, -1.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0676732212305069
Epoch 0, Step 781: train/loss = 0.473683625459671, train/raw-loss = 0.4430385231971741, train/logprobs = tensor([[-1.8541, -3.6388],
        [-1.5993, -1.5254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06129021197557449
Epoch 0, Step 782: train/loss = 0.3440997302532196, train/raw-loss = 0.2950376868247986, train/logprobs = tensor([[-0.9772, -4.4448],
        [-1.2298, -1.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09812401980161667
Epoch 0, Step 783: train/loss = 0.4954840838909149, train/raw-loss = 0.47855162620544434, train/logprobs = tensor([[-1.0543, -1.8668],
        [-1.1925, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386495262384415
Epoch 0, Step 784: train/loss = 0.29863446950912476, train/raw-loss = 0.2377263307571411, train/logprobs = tensor([[-0.9824, -4.1211],
        [-1.4469, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12181627750396729
Epoch 0, Step 785: train/loss = 0.28466466069221497, train/raw-loss = 0.2035357803106308, train/logprobs = tensor([[-1.2636, -4.5413],
        [-1.4649, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16225771605968475
Epoch 0, Step 786: train/loss = 0.3493441045284271, train/raw-loss = 0.29229897260665894, train/logprobs = tensor([[-1.3715, -3.8968],
        [-1.7773, -1.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11409026384353638
Epoch 0, Step 787: train/loss = 0.4011261463165283, train/raw-loss = 0.36643707752227783, train/logprobs = tensor([[-0.8912, -3.5542],
        [-1.3240, -1.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06937810778617859
Epoch 0, Step 788: train/loss = 0.4122033417224884, train/raw-loss = 0.39357247948646545, train/logprobs = tensor([[-0.8020, -3.2092],
        [-0.9427, -1.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03726166486740112
Epoch 0, Step 789: train/loss = 0.5049337148666382, train/raw-loss = 0.4752575159072876, train/logprobs = tensor([[-1.3697, -2.2446],
        [-1.6671, -1.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05935240164399147
Epoch 0, Step 790: train/loss = 0.44339799880981445, train/raw-loss = 0.4099912643432617, train/logprobs = tensor([[-1.4222, -2.8078],
        [-1.2917, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06681346893310547
Epoch 0, Step 791: train/loss = 0.5098038911819458, train/raw-loss = 0.4935453236103058, train/logprobs = tensor([[-1.4845, -2.2751],
        [-1.3587, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03251717612147331
Epoch 0, Step 792: train/loss = 0.3924906551837921, train/raw-loss = 0.34218913316726685, train/logprobs = tensor([[-1.6135, -3.1442],
        [-1.8684, -1.5166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060308873653412
Epoch 0, Step 793: train/loss = 0.2990974187850952, train/raw-loss = 0.23409278690814972, train/logprobs = tensor([[-1.2368, -4.1041],
        [-1.6386, -1.7104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300092190504074
Epoch 0, Step 794: train/loss = 0.39266979694366455, train/raw-loss = 0.3483424484729767, train/logprobs = tensor([[-1.1475, -3.7037],
        [-1.2082, -1.5310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08865472674369812
Epoch 0, Step 795: train/loss = 0.472312867641449, train/raw-loss = 0.44350945949554443, train/logprobs = tensor([[-1.1916, -2.7863],
        [-1.2542, -1.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05760684981942177
Epoch 0, Step 796: train/loss = 0.4167705774307251, train/raw-loss = 0.3717079758644104, train/logprobs = tensor([[-0.9559, -2.6474],
        [-1.3851, -1.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09012531489133835
Epoch 0, Step 797: train/loss = 0.48964864015579224, train/raw-loss = 0.4688902497291565, train/logprobs = tensor([[-1.5987, -2.6025],
        [-1.6058, -1.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0415167510509491
Epoch 0, Step 798: train/loss = 0.49315378069877625, train/raw-loss = 0.4628760814666748, train/logprobs = tensor([[-1.2305, -2.0228],
        [-1.4215, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06055542454123497
Epoch 0, Step 799: train/loss = 0.38059672713279724, train/raw-loss = 0.3462172746658325, train/logprobs = tensor([[-1.0911, -3.6506],
        [-1.1304, -1.4477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06875888258218765
Epoch 0, Step 800: train/loss = 0.5776104927062988, train/raw-loss = 0.5497756004333496, train/logprobs = tensor([[-1.4424, -1.6162],
        [-1.6360, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05566989630460739
Epoch 0, Step 801: train/loss = 0.27709484100341797, train/raw-loss = 0.22013728320598602, train/logprobs = tensor([[-0.9666, -4.3425],
        [-1.2981, -1.7164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391518265008926
Epoch 0, Step 802: train/loss = 0.35948705673217773, train/raw-loss = 0.29713958501815796, train/logprobs = tensor([[-1.5383, -3.7535],
        [-1.9624, -1.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12469489127397537
Epoch 0, Step 803: train/loss = 0.5085155963897705, train/raw-loss = 0.4892369508743286, train/logprobs = tensor([[-0.7436, -2.0330],
        [-1.0709, -1.3259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03855733200907707
Epoch 0, Step 804: train/loss = 0.3928091824054718, train/raw-loss = 0.3513281047344208, train/logprobs = tensor([[-1.0534, -3.5547],
        [-1.3993, -1.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08296218514442444
Epoch 0, Step 805: train/loss = 0.4475621283054352, train/raw-loss = 0.4081629514694214, train/logprobs = tensor([[-1.9867, -3.7722],
        [-1.9441, -1.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07879838347434998
Epoch 0, Step 806: train/loss = 0.518526554107666, train/raw-loss = 0.4775061011314392, train/logprobs = tensor([[-1.5131, -3.4673],
        [-1.4569, -1.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204096555709839
Epoch 0, Step 807: train/loss = 0.39481866359710693, train/raw-loss = 0.3352465033531189, train/logprobs = tensor([[-1.5889, -3.8586],
        [-1.6017, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11914432048797607
Epoch 0, Step 808: train/loss = 0.40155670046806335, train/raw-loss = 0.3622876703739166, train/logprobs = tensor([[-1.4924, -3.2747],
        [-1.7098, -1.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07853807508945465
Epoch 0, Step 809: train/loss = 0.42999911308288574, train/raw-loss = 0.4069143831729889, train/logprobs = tensor([[-0.9682, -3.3555],
        [-1.0619, -1.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04616941139101982
Epoch 0, Step 810: train/loss = 0.34806913137435913, train/raw-loss = 0.3031742572784424, train/logprobs = tensor([[-0.8340, -3.9378],
        [-1.3078, -1.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978983759880066
Epoch 0, Step 811: train/loss = 0.2444411963224411, train/raw-loss = 0.1798270046710968, train/logprobs = tensor([[-1.1753, -5.3438],
        [-1.5773, -2.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292283833026886
Epoch 0, Step 812: train/loss = 0.40415170788764954, train/raw-loss = 0.36322811245918274, train/logprobs = tensor([[-1.6962, -4.6345],
        [-1.8987, -2.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081847183406353
Epoch 0, Step 813: train/loss = 0.49558889865875244, train/raw-loss = 0.4497253894805908, train/logprobs = tensor([[-1.5796, -4.1591],
        [-1.4510, -1.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09172699600458145
Epoch 0, Step 814: train/loss = 0.4045816957950592, train/raw-loss = 0.35999611020088196, train/logprobs = tensor([[-1.9330, -3.7104],
        [-1.6727, -1.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08917117118835449
Epoch 0, Step 815: train/loss = 0.3943784832954407, train/raw-loss = 0.34830114245414734, train/logprobs = tensor([[-1.5364, -4.1182],
        [-1.3475, -1.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09215471893548965
Epoch 0, Step 816: train/loss = 0.4394104778766632, train/raw-loss = 0.41188764572143555, train/logprobs = tensor([[-1.2888, -2.8452],
        [-1.3697, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05504559725522995
Epoch 0, Step 817: train/loss = 0.4783451557159424, train/raw-loss = 0.3280611038208008, train/logprobs = tensor([[-1.8931, -4.4992],
        [-1.9334, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005680739879608
Epoch 0, Step 818: train/loss = 0.3932483196258545, train/raw-loss = 0.3280160129070282, train/logprobs = tensor([[-1.0659, -3.4287],
        [-1.4821, -1.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13046462833881378
Epoch 0, Step 819: train/loss = 0.4177752137184143, train/raw-loss = 0.3473231792449951, train/logprobs = tensor([[-1.9392, -3.7984],
        [-1.5224, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140904039144516
Epoch 0, Step 820: train/loss = 0.3486466109752655, train/raw-loss = 0.29788899421691895, train/logprobs = tensor([[-1.1753, -3.8556],
        [-1.4398, -1.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10151523351669312
Epoch 0, Step 821: train/loss = 0.36073559522628784, train/raw-loss = 0.31678593158721924, train/logprobs = tensor([[-1.5497, -3.7520],
        [-1.5002, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789929002523422
Epoch 0, Step 822: train/loss = 0.39557406306266785, train/raw-loss = 0.27734172344207764, train/logprobs = tensor([[-0.9602, -3.8408],
        [-1.4050, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23646464943885803
Epoch 0, Step 823: train/loss = 0.5657942891120911, train/raw-loss = 0.5482293963432312, train/logprobs = tensor([[-1.6107, -1.9224],
        [-1.8265, -1.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0351298451423645
Epoch 0, Step 824: train/loss = 0.4324718713760376, train/raw-loss = 0.3627018928527832, train/logprobs = tensor([[-1.5864, -3.5020],
        [-1.2787, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13954001665115356
Epoch 0, Step 825: train/loss = 0.48380792140960693, train/raw-loss = 0.45485246181488037, train/logprobs = tensor([[-1.5957, -2.4118],
        [-1.4339, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791090801358223
Epoch 0, Step 826: train/loss = 0.38208359479904175, train/raw-loss = 0.3253384530544281, train/logprobs = tensor([[-1.5931, -3.3844],
        [-1.5096, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11349036544561386
Epoch 0, Step 827: train/loss = 0.3904256224632263, train/raw-loss = 0.32346707582473755, train/logprobs = tensor([[-1.8113, -4.0886],
        [-1.7620, -1.4757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13391707837581635
Epoch 0, Step 828: train/loss = 0.36141547560691833, train/raw-loss = 0.31454384326934814, train/logprobs = tensor([[-1.1810, -3.3311],
        [-1.3302, -1.3603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0937432125210762
Epoch 0, Step 829: train/loss = 0.4943803548812866, train/raw-loss = 0.4687156677246094, train/logprobs = tensor([[-1.4118, -2.4183],
        [-1.6447, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051329366862773895
Epoch 0, Step 830: train/loss = 0.43424805998802185, train/raw-loss = 0.38701534271240234, train/logprobs = tensor([[-1.0044, -3.1355],
        [-1.2698, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446549415588379
Epoch 0, Step 831: train/loss = 0.43035227060317993, train/raw-loss = 0.38145893812179565, train/logprobs = tensor([[-1.8780, -3.3036],
        [-1.5925, -1.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09778667986392975
Epoch 0, Step 832: train/loss = 0.4226250648498535, train/raw-loss = 0.37128347158432007, train/logprobs = tensor([[-2.0837, -3.9769],
        [-1.7405, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1026831567287445
Epoch 0, Step 833: train/loss = 0.3954407870769501, train/raw-loss = 0.3552614152431488, train/logprobs = tensor([[-1.5107, -2.6697],
        [-1.9679, -1.3894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08035875856876373
Epoch 0, Step 834: train/loss = 0.3484114110469818, train/raw-loss = 0.2983251214027405, train/logprobs = tensor([[-0.8611, -4.0155],
        [-1.2354, -1.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017256438732147
Epoch 0, Step 835: train/loss = 0.39075419306755066, train/raw-loss = 0.33817625045776367, train/logprobs = tensor([[-1.3351, -3.3583],
        [-1.4064, -1.3365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10515588521957397
Epoch 0, Step 836: train/loss = 0.4597930908203125, train/raw-loss = 0.4195440411567688, train/logprobs = tensor([[-1.6084, -2.9931],
        [-1.6453, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.080498106777668
Epoch 0, Step 837: train/loss = 0.41755247116088867, train/raw-loss = 0.36756789684295654, train/logprobs = tensor([[-0.9558, -3.2427],
        [-1.2245, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09996907413005829
Epoch 0, Step 838: train/loss = 0.27406084537506104, train/raw-loss = 0.19283555448055267, train/logprobs = tensor([[-1.5972, -5.3350],
        [-1.7544, -1.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16245058178901672
Epoch 0, Step 839: train/loss = 0.6224479675292969, train/raw-loss = 0.6133562326431274, train/logprobs = tensor([[-1.6442, -2.1584],
        [-2.1157, -2.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018183428794145584
Epoch 0, Step 840: train/loss = 0.5711009502410889, train/raw-loss = 0.3456445336341858, train/logprobs = tensor([[-1.8622, -4.9541],
        [-2.1028, -1.1661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.450912743806839
Epoch 0, Step 841: train/loss = 0.26777559518814087, train/raw-loss = 0.22266468405723572, train/logprobs = tensor([[-0.8313, -4.9087],
        [-1.1584, -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09022179245948792
Epoch 0, Step 842: train/loss = 0.3752381205558777, train/raw-loss = 0.33545488119125366, train/logprobs = tensor([[-1.6143, -3.7276],
        [-1.7606, -1.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07956638932228088
Epoch 0, Step 843: train/loss = 0.25437018275260925, train/raw-loss = 0.20677852630615234, train/logprobs = tensor([[-0.6447, -4.8138],
        [-1.2432, -2.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09518330544233322
Epoch 0, Step 844: train/loss = 0.3016882538795471, train/raw-loss = 0.22131140530109406, train/logprobs = tensor([[-1.2672, -3.8654],
        [-1.6367, -1.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16075369715690613
Epoch 0, Step 845: train/loss = 0.5345796346664429, train/raw-loss = 0.4830356240272522, train/logprobs = tensor([[-1.4295, -2.6854],
        [-1.8959, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10308805108070374
Epoch 0, Step 846: train/loss = 0.5930989980697632, train/raw-loss = 0.545468270778656, train/logprobs = tensor([[-1.6592, -2.4685],
        [-1.3236, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526146948337555
Epoch 0, Step 847: train/loss = 0.3134614825248718, train/raw-loss = 0.2304803431034088, train/logprobs = tensor([[-1.2005, -3.8710],
        [-1.6634, -1.3919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16596227884292603
Epoch 0, Step 848: train/loss = 0.3898200988769531, train/raw-loss = 0.35067683458328247, train/logprobs = tensor([[-1.3842, -3.1955],
        [-1.4188, -1.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07828652858734131
Epoch 0, Step 849: train/loss = 0.6143654584884644, train/raw-loss = 0.5905461311340332, train/logprobs = tensor([[-1.4934, -2.1307],
        [-1.2904, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047638729214668274
Epoch 0, Step 850: train/loss = 0.4007400870323181, train/raw-loss = 0.3429205119609833, train/logprobs = tensor([[-1.8568, -4.0553],
        [-1.9720, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11563912779092789
Epoch 0, Step 851: train/loss = 0.5458579063415527, train/raw-loss = 0.5076295137405396, train/logprobs = tensor([[-1.3603, -2.3192],
        [-1.1614, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764567106962204
Epoch 0, Step 852: train/loss = 0.3887937664985657, train/raw-loss = 0.2784358263015747, train/logprobs = tensor([[-1.4049, -3.5430],
        [-2.0781, -1.1053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2207159698009491
Epoch 0, Step 853: train/loss = 0.5658695697784424, train/raw-loss = 0.5453468561172485, train/logprobs = tensor([[-1.1757, -1.7724],
        [-1.2352, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04104533791542053
Epoch 0, Step 854: train/loss = 0.4634053707122803, train/raw-loss = 0.42823484539985657, train/logprobs = tensor([[-1.3319, -3.7431],
        [-1.3033, -2.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07034105807542801
Epoch 0, Step 855: train/loss = 0.49102041125297546, train/raw-loss = 0.4644593894481659, train/logprobs = tensor([[-1.7743, -2.8289],
        [-1.7735, -1.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05312206968665123
Epoch 0, Step 856: train/loss = 0.3901851177215576, train/raw-loss = 0.35099050402641296, train/logprobs = tensor([[-1.2315, -3.3099],
        [-1.5777, -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07838921993970871
Epoch 0, Step 857: train/loss = 0.27621957659721375, train/raw-loss = 0.19567608833312988, train/logprobs = tensor([[-1.3893, -4.9389],
        [-1.6959, -1.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16108699142932892
Epoch 0, Step 858: train/loss = 0.5072276592254639, train/raw-loss = 0.43557101488113403, train/logprobs = tensor([[-1.6097, -3.4959],
        [-1.5410, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14331328868865967
Epoch 0, Step 859: train/loss = 0.46266862750053406, train/raw-loss = 0.41987067461013794, train/logprobs = tensor([[-1.6555, -4.6919],
        [-1.3982, -2.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08559586852788925
Epoch 0, Step 860: train/loss = 0.533599853515625, train/raw-loss = 0.5153789520263672, train/logprobs = tensor([[-1.0320, -1.4555],
        [-1.3842, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03644173592329025
Epoch 0, Step 861: train/loss = 0.3974126875400543, train/raw-loss = 0.32660239934921265, train/logprobs = tensor([[-1.1684, -3.5638],
        [-1.3107, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14162054657936096
Epoch 0, Step 862: train/loss = 0.4653164744377136, train/raw-loss = 0.43939638137817383, train/logprobs = tensor([[-1.3845, -2.6749],
        [-1.5620, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0518401637673378
Epoch 0, Step 863: train/loss = 0.375180184841156, train/raw-loss = 0.3257770538330078, train/logprobs = tensor([[-1.3391, -3.9665],
        [-1.2916, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09880629181861877
Epoch 0, Step 864: train/loss = 0.4395141899585724, train/raw-loss = 0.4015231728553772, train/logprobs = tensor([[-1.4214, -2.6879],
        [-1.7200, -1.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0759819746017456
Epoch 0, Step 865: train/loss = 0.4147821068763733, train/raw-loss = 0.3574129343032837, train/logprobs = tensor([[-1.1060, -3.8305],
        [-1.3782, -1.3427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11473836749792099
Epoch 0, Step 866: train/loss = 0.416959285736084, train/raw-loss = 0.3710653483867645, train/logprobs = tensor([[-1.7842, -2.9382],
        [-2.0175, -1.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09178784489631653
Epoch 0, Step 867: train/loss = 0.3456585109233856, train/raw-loss = 0.27255871891975403, train/logprobs = tensor([[-1.5787, -3.2733],
        [-1.7006, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14619961380958557
Epoch 0, Step 868: train/loss = 0.4240705966949463, train/raw-loss = 0.37221530079841614, train/logprobs = tensor([[-1.0279, -2.9417],
        [-1.4205, -1.2561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10371056199073792
Epoch 0, Step 869: train/loss = 0.2555288076400757, train/raw-loss = 0.17859263718128204, train/logprobs = tensor([[-1.0668, -5.1069],
        [-1.4951, -1.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1538723260164261
Epoch 0, Step 870: train/loss = 0.4807513356208801, train/raw-loss = 0.43361809849739075, train/logprobs = tensor([[-2.0035, -2.6466],
        [-1.8964, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09426645189523697
Epoch 0, Step 871: train/loss = 0.5265746116638184, train/raw-loss = 0.5114989280700684, train/logprobs = tensor([[-1.7722, -1.7707],
        [-1.7936, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030151385813951492
Epoch 0, Step 872: train/loss = 0.36769363284111023, train/raw-loss = 0.34275391697883606, train/logprobs = tensor([[-0.7343, -4.1459],
        [-0.9560, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04987948760390282
Epoch 0, Step 873: train/loss = 0.3061424791812897, train/raw-loss = 0.2574460804462433, train/logprobs = tensor([[-1.2092, -4.4184],
        [-1.5958, -2.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09739278256893158
Epoch 0, Step 874: train/loss = 0.5071035027503967, train/raw-loss = 0.48664289712905884, train/logprobs = tensor([[-1.1008, -2.1453],
        [-1.4446, -1.3890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04092127084732056
Epoch 0, Step 875: train/loss = 0.4231087565422058, train/raw-loss = 0.36953723430633545, train/logprobs = tensor([[-1.3444, -2.8077],
        [-1.5956, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714304447174072
Epoch 0, Step 876: train/loss = 0.29200616478919983, train/raw-loss = 0.18390007317066193, train/logprobs = tensor([[-2.0288, -4.6827],
        [-2.0613, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21621215343475342
Epoch 0, Step 877: train/loss = 0.5398062467575073, train/raw-loss = 0.52607661485672, train/logprobs = tensor([[-0.8965, -1.5856],
        [-1.1984, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027459222823381424
Epoch 0, Step 878: train/loss = 0.5209980010986328, train/raw-loss = 0.49579036235809326, train/logprobs = tensor([[-1.6332, -2.1611],
        [-1.8032, -1.2818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05041515454649925
Epoch 0, Step 879: train/loss = 0.39757341146469116, train/raw-loss = 0.3404516577720642, train/logprobs = tensor([[-0.7710, -2.7308],
        [-1.4365, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11424344778060913
Epoch 0, Step 880: train/loss = 0.3839569687843323, train/raw-loss = 0.35263288021087646, train/logprobs = tensor([[-1.5791, -3.7703],
        [-1.7678, -2.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06264816224575043
Epoch 0, Step 881: train/loss = 0.3973941206932068, train/raw-loss = 0.362253338098526, train/logprobs = tensor([[-0.8519, -3.5343],
        [-1.0839, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07028158754110336
Epoch 0, Step 882: train/loss = 0.5058005452156067, train/raw-loss = 0.2929706573486328, train/logprobs = tensor([[-1.5470, -6.4772],
        [-1.8022, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42565977573394775
Epoch 0, Step 883: train/loss = 0.2962934076786041, train/raw-loss = 0.2299678921699524, train/logprobs = tensor([[-0.8412, -4.5524],
        [-1.3353, -1.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326509714126587
Epoch 0, Step 884: train/loss = 0.47605133056640625, train/raw-loss = 0.45280158519744873, train/logprobs = tensor([[-1.0278, -2.4571],
        [-0.9390, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04649949446320534
Epoch 0, Step 885: train/loss = 0.3672304153442383, train/raw-loss = 0.306347131729126, train/logprobs = tensor([[-1.0204, -3.5143],
        [-1.4381, -1.3248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12176656723022461
Epoch 0, Step 886: train/loss = 0.4823025166988373, train/raw-loss = 0.38195037841796875, train/logprobs = tensor([[-1.3438, -3.0813],
        [-1.6082, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20070426166057587
Epoch 0, Step 887: train/loss = 0.48828041553497314, train/raw-loss = 0.46055349707603455, train/logprobs = tensor([[-2.5130, -3.8733],
        [-1.9206, -1.7691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05545385926961899
Epoch 0, Step 888: train/loss = 0.5074578523635864, train/raw-loss = 0.4876722991466522, train/logprobs = tensor([[-0.9119, -1.9551],
        [-1.2450, -1.2495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03957115113735199
Epoch 0, Step 889: train/loss = 0.31185460090637207, train/raw-loss = 0.24854977428913116, train/logprobs = tensor([[-1.4150, -4.5666],
        [-1.8047, -1.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266096830368042
Epoch 0, Step 890: train/loss = 0.40153154730796814, train/raw-loss = 0.27597537636756897, train/logprobs = tensor([[-2.0049, -4.5570],
        [-2.1247, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25111231207847595
Epoch 0, Step 891: train/loss = 0.3254905343055725, train/raw-loss = 0.2532404065132141, train/logprobs = tensor([[-1.2641, -3.7293],
        [-1.4282, -1.2433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445002555847168
Epoch 0, Step 892: train/loss = 0.5054479241371155, train/raw-loss = 0.44689062237739563, train/logprobs = tensor([[-1.5441, -2.5904],
        [-1.5402, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11711467057466507
Epoch 0, Step 893: train/loss = 0.43167757987976074, train/raw-loss = 0.39053142070770264, train/logprobs = tensor([[-1.1170, -2.8831],
        [-1.7439, -1.5153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229228854179382
Epoch 0, Step 894: train/loss = 0.4376967251300812, train/raw-loss = 0.41233256459236145, train/logprobs = tensor([[-1.4761, -3.3775],
        [-1.3604, -1.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050728388130664825
Epoch 0, Step 895: train/loss = 0.36658740043640137, train/raw-loss = 0.30774423480033875, train/logprobs = tensor([[-1.3703, -3.1182],
        [-1.5840, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11768636107444763
Epoch 0, Step 896: train/loss = 0.29817652702331543, train/raw-loss = 0.20720726251602173, train/logprobs = tensor([[-1.6278, -5.1296],
        [-2.0871, -2.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18193849921226501
Epoch 0, Step 897: train/loss = 0.3695172071456909, train/raw-loss = 0.26507920026779175, train/logprobs = tensor([[-1.2709, -3.7916],
        [-1.7426, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20887601375579834
Epoch 0, Step 898: train/loss = 0.4890093505382538, train/raw-loss = 0.4433692991733551, train/logprobs = tensor([[-2.2677, -5.3445],
        [-1.2634, -1.6113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09128011763095856
Epoch 0, Step 899: train/loss = 0.3882114291191101, train/raw-loss = 0.3167073130607605, train/logprobs = tensor([[-1.5319, -4.7750],
        [-1.6729, -1.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430082470178604
Epoch 0, Step 900: train/loss = 0.33966606855392456, train/raw-loss = 0.16962985694408417, train/logprobs = tensor([[-1.6185, -4.6577],
        [-2.2291, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3400724232196808
Epoch 0, Step 901: train/loss = 0.3007703125476837, train/raw-loss = 0.19070297479629517, train/logprobs = tensor([[-1.8718, -4.3742],
        [-1.9098, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2201347053050995
Epoch 0, Step 902: train/loss = 0.4125511944293976, train/raw-loss = 0.3567556142807007, train/logprobs = tensor([[-0.9469, -3.2351],
        [-1.4559, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1115911602973938
Epoch 0, Step 903: train/loss = 0.37950873374938965, train/raw-loss = 0.32842254638671875, train/logprobs = tensor([[-1.1644, -3.9028],
        [-1.5004, -1.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1021723821759224
Epoch 0, Step 904: train/loss = 0.4153406023979187, train/raw-loss = 0.36339136958122253, train/logprobs = tensor([[-1.0025, -2.4611],
        [-1.4149, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389845818281174
Epoch 0, Step 905: train/loss = 0.554119348526001, train/raw-loss = 0.5349370241165161, train/logprobs = tensor([[-1.5084, -2.8600],
        [-1.2582, -1.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836473077535629
Epoch 0, Step 906: train/loss = 0.33012938499450684, train/raw-loss = 0.2737473249435425, train/logprobs = tensor([[-1.2817, -5.0912],
        [-1.5133, -2.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127641499042511
Epoch 0, Step 907: train/loss = 0.3005255162715912, train/raw-loss = 0.22957004606723785, train/logprobs = tensor([[-1.4393, -4.6040],
        [-1.7139, -1.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14191089570522308
Epoch 0, Step 908: train/loss = 0.44698458909988403, train/raw-loss = 0.4139103889465332, train/logprobs = tensor([[-1.9700, -2.8510],
        [-1.9175, -1.2901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06614839285612106
Epoch 0, Step 909: train/loss = 0.40009307861328125, train/raw-loss = 0.34356752038002014, train/logprobs = tensor([[-0.9825, -2.6530],
        [-1.4451, -1.1494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130511462688446
Epoch 0, Step 910: train/loss = 0.36075329780578613, train/raw-loss = 0.2970584034919739, train/logprobs = tensor([[-1.4447, -3.5398],
        [-1.6015, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12738972902297974
Epoch 0, Step 911: train/loss = 0.3646893799304962, train/raw-loss = 0.3029841482639313, train/logprobs = tensor([[-2.3076, -4.1624],
        [-2.1427, -1.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12341045588254929
Epoch 0, Step 912: train/loss = 0.5096192359924316, train/raw-loss = 0.4741306006908417, train/logprobs = tensor([[-2.1772, -3.3584],
        [-1.5027, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07097729295492172
Epoch 0, Step 913: train/loss = 0.4237169623374939, train/raw-loss = 0.3683253228664398, train/logprobs = tensor([[-1.0112, -3.0399],
        [-1.4003, -1.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11078337579965591
Epoch 0, Step 914: train/loss = 0.4165187180042267, train/raw-loss = 0.38297224044799805, train/logprobs = tensor([[-1.3682, -2.8260],
        [-1.7504, -1.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06709301471710205
Epoch 0, Step 915: train/loss = 0.528792679309845, train/raw-loss = 0.5028495788574219, train/logprobs = tensor([[-0.9894, -1.8777],
        [-1.1964, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051886186003685
Epoch 0, Step 916: train/loss = 0.365308940410614, train/raw-loss = 0.26583173871040344, train/logprobs = tensor([[-1.8801, -4.5877],
        [-2.2261, -1.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19895440340042114
Epoch 0, Step 917: train/loss = 0.34554731845855713, train/raw-loss = 0.2713448107242584, train/logprobs = tensor([[-1.3497, -3.3395],
        [-1.6636, -1.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484050303697586
Epoch 0, Step 918: train/loss = 0.3866741955280304, train/raw-loss = 0.3434295654296875, train/logprobs = tensor([[-1.6921, -4.0867],
        [-1.8948, -1.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0864892303943634
Epoch 0, Step 919: train/loss = 0.33130112290382385, train/raw-loss = 0.2825028896331787, train/logprobs = tensor([[-0.9553, -3.9915],
        [-1.6342, -1.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0975964367389679
Epoch 0, Step 920: train/loss = 0.5069053769111633, train/raw-loss = 0.3068348169326782, train/logprobs = tensor([[-1.9112, -6.0723],
        [-2.0554, -1.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40014106035232544
Epoch 0, Step 921: train/loss = 0.3635006546974182, train/raw-loss = 0.2923333942890167, train/logprobs = tensor([[-1.4292, -3.6092],
        [-1.8414, -1.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14233450591564178
Epoch 0, Step 922: train/loss = 0.45215195417404175, train/raw-loss = 0.425730437040329, train/logprobs = tensor([[-1.2256, -2.6641],
        [-1.4165, -1.3917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052843011915683746
Epoch 0, Step 923: train/loss = 0.4058341979980469, train/raw-loss = 0.3343934118747711, train/logprobs = tensor([[-2.3913, -4.2788],
        [-1.9074, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1428815871477127
Epoch 0, Step 924: train/loss = 0.4104914665222168, train/raw-loss = 0.3547605872154236, train/logprobs = tensor([[-1.0881, -3.5593],
        [-1.4077, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11146171391010284
Epoch 0, Step 925: train/loss = 0.5864895582199097, train/raw-loss = 0.5609725117683411, train/logprobs = tensor([[-1.0782, -1.9250],
        [-1.2933, -1.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05103415995836258
Epoch 0, Step 926: train/loss = 0.35438472032546997, train/raw-loss = 0.29193198680877686, train/logprobs = tensor([[-1.3494, -5.0046],
        [-1.2095, -1.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12490551173686981
Epoch 0, Step 927: train/loss = 0.35068342089653015, train/raw-loss = 0.278197318315506, train/logprobs = tensor([[-1.4115, -3.5905],
        [-1.9534, -1.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14497220516204834
Epoch 0, Step 928: train/loss = 0.3957061171531677, train/raw-loss = 0.3327169418334961, train/logprobs = tensor([[-1.7549, -3.3152],
        [-2.2481, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12597836554050446
Epoch 0, Step 929: train/loss = 0.4989127814769745, train/raw-loss = 0.4842981696128845, train/logprobs = tensor([[-0.5672, -1.9924],
        [-1.0652, -1.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029229147359728813
Epoch 0, Step 930: train/loss = 0.4129025936126709, train/raw-loss = 0.38563936948776245, train/logprobs = tensor([[-1.2330, -3.4006],
        [-1.5988, -1.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05452646315097809
Epoch 0, Step 931: train/loss = 0.46474361419677734, train/raw-loss = 0.40279334783554077, train/logprobs = tensor([[-0.7072, -2.9435],
        [-1.1704, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12390055507421494
Epoch 0, Step 932: train/loss = 0.390021950006485, train/raw-loss = 0.3354085683822632, train/logprobs = tensor([[-1.9960, -4.1986],
        [-2.1642, -2.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10922684520483017
Epoch 0, Step 933: train/loss = 0.5577172636985779, train/raw-loss = 0.5376524925231934, train/logprobs = tensor([[-1.2162, -2.2838],
        [-1.1575, -1.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04012955352663994
Epoch 0, Step 934: train/loss = 0.29530370235443115, train/raw-loss = 0.1704312264919281, train/logprobs = tensor([[-1.3033, -5.5575],
        [-1.5828, -1.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2497449666261673
Epoch 0, Step 935: train/loss = 0.5234991312026978, train/raw-loss = 0.48570722341537476, train/logprobs = tensor([[-2.2667, -4.2961],
        [-1.4270, -1.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07558385282754898
Epoch 0, Step 936: train/loss = 0.4555343985557556, train/raw-loss = 0.4178962707519531, train/logprobs = tensor([[-0.8203, -1.9263],
        [-1.2672, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07527618110179901
Epoch 0, Step 937: train/loss = 0.4675142765045166, train/raw-loss = 0.4301843047142029, train/logprobs = tensor([[-1.6868, -3.4044],
        [-1.5965, -1.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07465989142656326
Epoch 0, Step 938: train/loss = 0.46819621324539185, train/raw-loss = 0.3927857577800751, train/logprobs = tensor([[-2.4650, -2.9686],
        [-2.6434, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15082086622714996
Epoch 0, Step 939: train/loss = 0.6527441740036011, train/raw-loss = 0.6488107442855835, train/logprobs = tensor([[-1.0082, -1.1311],
        [-1.3112, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007866955362260342
Epoch 0, Step 940: train/loss = 0.4335564374923706, train/raw-loss = 0.36886629462242126, train/logprobs = tensor([[-1.0638, -2.7960],
        [-1.7403, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12938028573989868
Epoch 0, Step 941: train/loss = 0.40867021679878235, train/raw-loss = 0.37716665863990784, train/logprobs = tensor([[-1.6276, -3.7453],
        [-1.8076, -1.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06300710886716843
Epoch 0, Step 942: train/loss = 0.37249961495399475, train/raw-loss = 0.3075280487537384, train/logprobs = tensor([[-0.7907, -3.4148],
        [-0.9735, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299431025981903
Epoch 0, Step 943: train/loss = 0.38736993074417114, train/raw-loss = 0.3323379158973694, train/logprobs = tensor([[-1.3092, -3.4098],
        [-1.6301, -1.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11006401479244232
Epoch 0, Step 944: train/loss = 0.3988417088985443, train/raw-loss = 0.28843560814857483, train/logprobs = tensor([[-1.0690, -3.9366],
        [-1.4845, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22081218659877777
Epoch 0, Step 945: train/loss = 0.3868919312953949, train/raw-loss = 0.35290950536727905, train/logprobs = tensor([[-1.5044, -3.8131],
        [-1.8419, -1.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06796490401029587
Epoch 0, Step 946: train/loss = 0.39177796244621277, train/raw-loss = 0.362041175365448, train/logprobs = tensor([[-0.8893, -2.9225],
        [-1.1771, -1.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059473514556884766
Epoch 0, Step 947: train/loss = 0.32501649856567383, train/raw-loss = 0.24137313663959503, train/logprobs = tensor([[-1.5007, -4.2627],
        [-1.7331, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16728675365447998
Epoch 0, Step 948: train/loss = 0.4190836250782013, train/raw-loss = 0.3792932331562042, train/logprobs = tensor([[-0.8488, -3.8076],
        [-1.4599, -1.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07958079129457474
Epoch 0, Step 949: train/loss = 0.35487768054008484, train/raw-loss = 0.2710915207862854, train/logprobs = tensor([[-2.3476, -5.0963],
        [-2.3257, -2.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16757231950759888
Epoch 0, Step 950: train/loss = 0.2934975028038025, train/raw-loss = 0.21067242324352264, train/logprobs = tensor([[-1.3056, -4.3057],
        [-1.5177, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1656501591205597
Epoch 0, Step 951: train/loss = 0.3128625154495239, train/raw-loss = 0.25147998332977295, train/logprobs = tensor([[-1.2633, -3.8372],
        [-1.5622, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12276507169008255
Epoch 0, Step 952: train/loss = 0.40373489260673523, train/raw-loss = 0.3514672815799713, train/logprobs = tensor([[-1.4822, -4.3805],
        [-1.7684, -2.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453525185585022
Epoch 0, Step 953: train/loss = 0.5942232012748718, train/raw-loss = 0.5460892915725708, train/logprobs = tensor([[-1.7085, -2.5354],
        [-1.8057, -1.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09626783430576324
Epoch 0, Step 954: train/loss = 0.432727187871933, train/raw-loss = 0.3825829327106476, train/logprobs = tensor([[-1.7156, -3.5356],
        [-1.9304, -1.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028848052024841
Epoch 0, Step 955: train/loss = 0.300307035446167, train/raw-loss = 0.2310100942850113, train/logprobs = tensor([[-0.9940, -4.4428],
        [-1.2757, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385938674211502
Epoch 0, Step 956: train/loss = 0.31701532006263733, train/raw-loss = 0.2331743836402893, train/logprobs = tensor([[-1.6120, -5.4473],
        [-1.9145, -2.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16768188774585724
Epoch 0, Step 957: train/loss = 0.36893951892852783, train/raw-loss = 0.27099913358688354, train/logprobs = tensor([[-1.4798, -4.1164],
        [-1.4758, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19588077068328857
Epoch 0, Step 958: train/loss = 0.4960861802101135, train/raw-loss = 0.46871569752693176, train/logprobs = tensor([[-1.7582, -2.5288],
        [-1.5555, -1.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05474104732275009
Epoch 0, Step 959: train/loss = 0.32802101969718933, train/raw-loss = 0.2452256977558136, train/logprobs = tensor([[-1.3019, -4.1263],
        [-1.4944, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16559068858623505
Epoch 0, Step 960: train/loss = 0.48201316595077515, train/raw-loss = 0.4323781728744507, train/logprobs = tensor([[-1.1284, -3.9557],
        [-0.8708, -1.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09926996380090714
Epoch 0, Step 961: train/loss = 0.35973548889160156, train/raw-loss = 0.2428654432296753, train/logprobs = tensor([[-2.3932, -4.8986],
        [-1.7127, -1.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23374013602733612
Epoch 0, Step 962: train/loss = 0.32828277349472046, train/raw-loss = 0.22194907069206238, train/logprobs = tensor([[-1.6866, -4.0024],
        [-1.7564, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126673460006714
Epoch 0, Step 963: train/loss = 0.5232521891593933, train/raw-loss = 0.4875643849372864, train/logprobs = tensor([[-1.7178, -2.5053],
        [-1.9683, -1.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137560844421387
Epoch 0, Step 964: train/loss = 0.4229922592639923, train/raw-loss = 0.3636200726032257, train/logprobs = tensor([[-1.2759, -3.0371],
        [-1.7842, -1.5204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11874440312385559
Epoch 0, Step 965: train/loss = 0.2592160999774933, train/raw-loss = 0.12967289984226227, train/logprobs = tensor([[-1.5364, -5.9184],
        [-1.9433, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25908640027046204
Epoch 0, Step 966: train/loss = 0.4475967586040497, train/raw-loss = 0.4025920629501343, train/logprobs = tensor([[-1.9246, -3.2707],
        [-2.0913, -1.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900094136595726
Epoch 0, Step 967: train/loss = 0.35483723878860474, train/raw-loss = 0.30073046684265137, train/logprobs = tensor([[-1.1165, -3.8210],
        [-1.3179, -1.3542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10821352899074554
Epoch 0, Step 968: train/loss = 0.5523959398269653, train/raw-loss = 0.5138887166976929, train/logprobs = tensor([[-1.9025, -2.3048],
        [-2.0603, -1.3773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770144909620285
Epoch 0, Step 969: train/loss = 0.5003042221069336, train/raw-loss = 0.45044198632240295, train/logprobs = tensor([[-0.9002, -2.4800],
        [-1.2991, -1.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09972444176673889
Epoch 0, Step 970: train/loss = 0.24434000253677368, train/raw-loss = 0.12877437472343445, train/logprobs = tensor([[-1.1120, -5.6646],
        [-1.5908, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23113122582435608
Epoch 0, Step 971: train/loss = 0.3614550232887268, train/raw-loss = 0.2786109149456024, train/logprobs = tensor([[-1.1184, -3.8859],
        [-1.5257, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16568820178508759
Epoch 0, Step 972: train/loss = 0.4004867672920227, train/raw-loss = 0.3026260435581207, train/logprobs = tensor([[-2.1683, -4.6802],
        [-2.0345, -1.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572150707244873
Epoch 0, Step 973: train/loss = 0.369841992855072, train/raw-loss = 0.3215358555316925, train/logprobs = tensor([[-1.3957, -3.4745],
        [-1.5849, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09661225974559784
Epoch 0, Step 974: train/loss = 0.5369116067886353, train/raw-loss = 0.5225615501403809, train/logprobs = tensor([[-1.2215, -1.4836],
        [-1.5779, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028700094670057297
Epoch 0, Step 975: train/loss = 0.4829806983470917, train/raw-loss = 0.44852501153945923, train/logprobs = tensor([[-1.4479, -2.2046],
        [-1.6993, -1.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0689113661646843
Epoch 0, Step 976: train/loss = 0.3692011833190918, train/raw-loss = 0.2901926636695862, train/logprobs = tensor([[-1.4903, -4.4986],
        [-1.7496, -1.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15801706910133362
Epoch 0, Step 977: train/loss = 0.628973662853241, train/raw-loss = 0.6057015657424927, train/logprobs = tensor([[-1.3518, -2.7212],
        [-1.3048, -1.5338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046544063836336136
Epoch 0, Step 978: train/loss = 0.46571099758148193, train/raw-loss = 0.3936161398887634, train/logprobs = tensor([[-1.6230, -3.4237],
        [-2.0974, -1.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441897302865982
Epoch 0, Step 979: train/loss = 0.2810405492782593, train/raw-loss = 0.17807655036449432, train/logprobs = tensor([[-1.4819, -4.7404],
        [-1.8103, -1.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2059280127286911
Epoch 0, Step 980: train/loss = 0.3719584345817566, train/raw-loss = 0.29607775807380676, train/logprobs = tensor([[-1.7016, -4.5409],
        [-1.8782, -1.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15176139771938324
Epoch 0, Step 981: train/loss = 0.4830127954483032, train/raw-loss = 0.40841948986053467, train/logprobs = tensor([[-1.5380, -2.9692],
        [-1.8959, -1.2766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491866558790207
Epoch 0, Step 982: train/loss = 0.4617907404899597, train/raw-loss = 0.42270204424858093, train/logprobs = tensor([[-1.6597, -4.2851],
        [-1.4255, -1.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817737013101578
Epoch 0, Step 983: train/loss = 0.3632223904132843, train/raw-loss = 0.2106005698442459, train/logprobs = tensor([[-2.0482, -6.3701],
        [-2.4815, -1.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305243581533432
Epoch 0, Step 984: train/loss = 0.5670244693756104, train/raw-loss = 0.5583188533782959, train/logprobs = tensor([[-1.3493, -1.2805],
        [-1.9650, -1.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017411230131983757
Epoch 0, Step 985: train/loss = 0.5036265254020691, train/raw-loss = 0.47436535358428955, train/logprobs = tensor([[-1.9046, -2.4767],
        [-2.0590, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05852227285504341
Epoch 0, Step 986: train/loss = 0.5308312177658081, train/raw-loss = 0.442716121673584, train/logprobs = tensor([[-2.3502, -3.8260],
        [-2.2519, -1.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17623020708560944
Epoch 0, Step 987: train/loss = 0.5223025679588318, train/raw-loss = 0.4930967092514038, train/logprobs = tensor([[-2.0905, -3.0847],
        [-1.8726, -1.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05841173976659775
Epoch 0, Step 988: train/loss = 0.45856034755706787, train/raw-loss = 0.3685147762298584, train/logprobs = tensor([[-1.9353, -4.0610],
        [-2.0677, -1.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18009118735790253
Epoch 0, Step 989: train/loss = 0.40738844871520996, train/raw-loss = 0.27196377515792847, train/logprobs = tensor([[-1.2067, -5.5573],
        [-1.7980, -1.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27084940671920776
Epoch 0, Step 990: train/loss = 0.5077860951423645, train/raw-loss = 0.4663771986961365, train/logprobs = tensor([[-2.2009, -2.6907],
        [-2.0989, -1.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08281780779361725
Epoch 0, Step 991: train/loss = 0.2637613117694855, train/raw-loss = 0.2029060274362564, train/logprobs = tensor([[-1.1961, -5.8158],
        [-1.7413, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12171056866645813
Epoch 0, Step 992: train/loss = 0.39668139815330505, train/raw-loss = 0.352400541305542, train/logprobs = tensor([[-1.2858, -4.3696],
        [-1.6098, -1.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08856174349784851
Epoch 0, Step 993: train/loss = 0.3281623125076294, train/raw-loss = 0.21642690896987915, train/logprobs = tensor([[-1.6642, -4.0217],
        [-2.5737, -1.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22347085177898407
Epoch 0, Step 994: train/loss = 0.5135305523872375, train/raw-loss = 0.4591158628463745, train/logprobs = tensor([[-2.3462, -3.6762],
        [-2.5701, -2.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882937163114548
Epoch 0, Step 995: train/loss = 0.27537888288497925, train/raw-loss = 0.1824660450220108, train/logprobs = tensor([[-1.2599, -4.4012],
        [-1.6979, -1.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18582570552825928
Epoch 0, Step 996: train/loss = 0.33755216002464294, train/raw-loss = 0.2877074182033539, train/logprobs = tensor([[-1.6855, -3.9580],
        [-1.6765, -1.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09968952089548111
Epoch 0, Step 997: train/loss = 0.308991014957428, train/raw-loss = 0.22055119276046753, train/logprobs = tensor([[-1.3319, -5.3206],
        [-1.4689, -1.5893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1768796443939209
Epoch 0, Step 998: train/loss = 0.3099331855773926, train/raw-loss = 0.1982557326555252, train/logprobs = tensor([[-1.4810, -4.2847],
        [-1.8324, -1.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22335492074489594
Epoch 0, Step 999: train/loss = 0.41793960332870483, train/raw-loss = 0.34989631175994873, train/logprobs = tensor([[-1.7925, -2.5407],
        [-2.5943, -1.3441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13608655333518982
eval/loss: 0.3873164653778076
Epoch 0, Step 1000: train/loss = 0.6108929514884949, train/raw-loss = 0.5790107250213623, train/logprobs = tensor([[-1.7678, -2.1197],
        [-1.9922, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06376457959413528
Epoch 0, Step 1001: train/loss = 0.27622753381729126, train/raw-loss = 0.20701834559440613, train/logprobs = tensor([[-1.4138, -5.4234],
        [-1.9874, -2.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13841837644577026
Epoch 0, Step 1002: train/loss = 0.423454612493515, train/raw-loss = 0.3574056625366211, train/logprobs = tensor([[-1.0431, -3.0892],
        [-1.5458, -1.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13209792971611023
Epoch 0, Step 1003: train/loss = 0.4965013265609741, train/raw-loss = 0.46718281507492065, train/logprobs = tensor([[-1.3628, -1.8017],
        [-1.9732, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058637045323848724
Epoch 0, Step 1004: train/loss = 0.4270068407058716, train/raw-loss = 0.36771875619888306, train/logprobs = tensor([[-1.8659, -2.8386],
        [-2.6213, -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11857617646455765
Epoch 0, Step 1005: train/loss = 0.21305029094219208, train/raw-loss = 0.13749495148658752, train/logprobs = tensor([[-1.3032, -6.0837],
        [-1.6248, -2.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1511106789112091
Epoch 0, Step 1006: train/loss = 0.6846420168876648, train/raw-loss = 0.684179425239563, train/logprobs = tensor([[-0.9600, -0.9160],
        [-1.1227, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009251974406652153
Epoch 0, Step 1007: train/loss = 0.5045021176338196, train/raw-loss = 0.45048683881759644, train/logprobs = tensor([[-2.7260, -3.8404],
        [-2.1236, -1.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10803069919347763
Epoch 0, Step 1008: train/loss = 0.45586371421813965, train/raw-loss = 0.42068201303482056, train/logprobs = tensor([[-1.4892, -2.3599],
        [-2.1684, -1.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07036349177360535
Epoch 0, Step 1009: train/loss = 0.23193080723285675, train/raw-loss = 0.084128737449646, train/logprobs = tensor([[-1.3266, -6.8360],
        [-1.7766, -1.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956041097640991
Epoch 0, Step 1010: train/loss = 0.3522656261920929, train/raw-loss = 0.2510793209075928, train/logprobs = tensor([[-2.7899, -4.5989],
        [-2.6883, -1.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20237259566783905
Epoch 0, Step 1011: train/loss = 0.32181379199028015, train/raw-loss = 0.15712036192417145, train/logprobs = tensor([[-1.5195, -6.0290],
        [-1.8965, -1.1678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293868899345398
Epoch 0, Step 1012: train/loss = 0.3614416718482971, train/raw-loss = 0.2529914081096649, train/logprobs = tensor([[-2.0981, -4.8336],
        [-2.2103, -1.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21690046787261963
Epoch 0, Step 1013: train/loss = 0.5164648294448853, train/raw-loss = 0.5012163519859314, train/logprobs = tensor([[-1.5108, -2.1262],
        [-1.7806, -1.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030496913939714432
Epoch 0, Step 1014: train/loss = 0.47878941893577576, train/raw-loss = 0.4456494152545929, train/logprobs = tensor([[-1.8591, -3.0238],
        [-1.8170, -1.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06628011167049408
Epoch 0, Step 1015: train/loss = 0.4210611581802368, train/raw-loss = 0.13214601576328278, train/logprobs = tensor([[-2.3403, -8.7604],
        [-2.1934, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5778303146362305
Epoch 0, Step 1016: train/loss = 0.305149644613266, train/raw-loss = 0.23586983978748322, train/logprobs = tensor([[-1.0969, -3.9313],
        [-1.6243, -1.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13855960965156555
Epoch 0, Step 1017: train/loss = 0.4047577977180481, train/raw-loss = 0.3326570987701416, train/logprobs = tensor([[-1.4284, -3.0422],
        [-2.0416, -1.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14420144259929657
Epoch 0, Step 1018: train/loss = 0.36000505089759827, train/raw-loss = 0.27577507495880127, train/logprobs = tensor([[-1.9537, -3.8032],
        [-1.8493, -1.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1684599667787552
Epoch 0, Step 1019: train/loss = 0.37696874141693115, train/raw-loss = 0.2893426716327667, train/logprobs = tensor([[-1.3299, -3.4869],
        [-1.9788, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17525218427181244
Epoch 0, Step 1020: train/loss = 0.5787995457649231, train/raw-loss = 0.5449597239494324, train/logprobs = tensor([[-2.4853, -2.8469],
        [-1.7961, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06767963618040085
Epoch 0, Step 1021: train/loss = 0.4317082166671753, train/raw-loss = 0.378442645072937, train/logprobs = tensor([[-1.1154, -2.7446],
        [-1.6216, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10653118789196014
Epoch 0, Step 1022: train/loss = 0.35553330183029175, train/raw-loss = 0.28657594323158264, train/logprobs = tensor([[-1.9545, -4.3324],
        [-1.7698, -1.2614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379147171974182
Epoch 0, Step 1023: train/loss = 0.3822711706161499, train/raw-loss = 0.305275559425354, train/logprobs = tensor([[-1.8005, -4.3394],
        [-1.7113, -1.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15399128198623657
Epoch 0, Step 1024: train/loss = 0.297495037317276, train/raw-loss = 0.22621162235736847, train/logprobs = tensor([[-1.9410, -5.3102],
        [-1.9099, -1.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14256684482097626
Epoch 0, Step 1025: train/loss = 0.4959096908569336, train/raw-loss = 0.42877262830734253, train/logprobs = tensor([[-1.9022, -3.4359],
        [-1.9719, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1342741847038269
Epoch 0, Step 1026: train/loss = 0.36406210064888, train/raw-loss = 0.32879066467285156, train/logprobs = tensor([[-1.5645, -3.6900],
        [-1.6507, -1.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07054288685321808
Epoch 0, Step 1027: train/loss = 0.36683765053749084, train/raw-loss = 0.3055756390094757, train/logprobs = tensor([[-2.8854, -5.6001],
        [-1.9646, -1.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12252402305603027
Epoch 0, Step 1028: train/loss = 0.420792818069458, train/raw-loss = 0.346816748380661, train/logprobs = tensor([[-1.1576, -3.6583],
        [-1.8629, -1.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14795206487178802
Epoch 0, Step 1029: train/loss = 0.46277621388435364, train/raw-loss = 0.410660982131958, train/logprobs = tensor([[-2.4906, -2.9426],
        [-2.3612, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10423044860363007
Epoch 0, Step 1030: train/loss = 0.4807714819908142, train/raw-loss = 0.37074345350265503, train/logprobs = tensor([[-2.0357, -3.9020],
        [-2.3746, -1.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22005605697631836
Epoch 0, Step 1031: train/loss = 0.3910527229309082, train/raw-loss = 0.30661827325820923, train/logprobs = tensor([[-1.4562, -5.3366],
        [-1.8804, -1.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16886886954307556
Epoch 0, Step 1032: train/loss = 0.4105713367462158, train/raw-loss = 0.3463144302368164, train/logprobs = tensor([[-1.2451, -3.6370],
        [-1.7512, -1.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12851379811763763
Epoch 0, Step 1033: train/loss = 0.3816313147544861, train/raw-loss = 0.31539297103881836, train/logprobs = tensor([[-1.5958, -4.5623],
        [-1.3067, -1.2901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13247671723365784
Epoch 0, Step 1034: train/loss = 0.4131772518157959, train/raw-loss = 0.3254398703575134, train/logprobs = tensor([[-1.7003, -3.5621],
        [-2.1212, -1.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17547468841075897
Epoch 0, Step 1035: train/loss = 0.3493891954421997, train/raw-loss = 0.2984727919101715, train/logprobs = tensor([[-1.1118, -3.3094],
        [-1.9306, -1.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1018327996134758
Epoch 0, Step 1036: train/loss = 0.49492132663726807, train/raw-loss = 0.45875000953674316, train/logprobs = tensor([[-1.6393, -2.4273],
        [-1.6024, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07234261929988861
Epoch 0, Step 1037: train/loss = 0.3561037480831146, train/raw-loss = 0.2891668677330017, train/logprobs = tensor([[-1.8161, -3.4682],
        [-1.7442, -1.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13387379050254822
Epoch 0, Step 1038: train/loss = 0.458417683839798, train/raw-loss = 0.4129818081855774, train/logprobs = tensor([[-1.2901, -2.5254],
        [-1.5722, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09087175130844116
Epoch 0, Step 1039: train/loss = 0.2956974506378174, train/raw-loss = 0.12855377793312073, train/logprobs = tensor([[-1.6645, -5.9300],
        [-2.3933, -1.3261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3342873454093933
Epoch 0, Step 1040: train/loss = 0.29217657446861267, train/raw-loss = 0.2123033106327057, train/logprobs = tensor([[-1.2208, -4.5235],
        [-1.7777, -1.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15974649786949158
Epoch 0, Step 1041: train/loss = 0.42250657081604004, train/raw-loss = 0.35845625400543213, train/logprobs = tensor([[-1.8530, -3.2004],
        [-2.4327, -1.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12810072302818298
Epoch 0, Step 1042: train/loss = 0.39101314544677734, train/raw-loss = 0.295563668012619, train/logprobs = tensor([[-1.2554, -4.1739],
        [-1.6066, -1.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19089892506599426
Epoch 0, Step 1043: train/loss = 0.3931153416633606, train/raw-loss = 0.3431980013847351, train/logprobs = tensor([[-1.0947, -2.8351],
        [-1.7868, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0998346209526062
Epoch 0, Step 1044: train/loss = 0.45805105566978455, train/raw-loss = 0.4200032353401184, train/logprobs = tensor([[-1.0882, -2.7952],
        [-1.5306, -1.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07609566301107407
Epoch 0, Step 1045: train/loss = 0.30708184838294983, train/raw-loss = 0.22772961854934692, train/logprobs = tensor([[-1.6680, -4.6508],
        [-1.5210, -1.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.158704474568367
Epoch 0, Step 1046: train/loss = 0.43438395857810974, train/raw-loss = 0.3680480420589447, train/logprobs = tensor([[-1.2689, -3.1473],
        [-1.5833, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13267186284065247
Epoch 0, Step 1047: train/loss = 0.42568790912628174, train/raw-loss = 0.39049649238586426, train/logprobs = tensor([[-1.5510, -2.6226],
        [-2.1056, -1.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07038287818431854
Epoch 0, Step 1048: train/loss = 0.3977407217025757, train/raw-loss = 0.3332359790802002, train/logprobs = tensor([[-1.6490, -4.0507],
        [-1.8211, -1.4496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129009410738945
Epoch 0, Step 1049: train/loss = 0.2655624449253082, train/raw-loss = 0.18282049894332886, train/logprobs = tensor([[-1.0681, -5.3178],
        [-1.9121, -2.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16548392176628113
Epoch 0, Step 1050: train/loss = 0.524592399597168, train/raw-loss = 0.4551447331905365, train/logprobs = tensor([[-1.2813, -2.4915],
        [-1.6945, -1.3078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13889534771442413
Epoch 0, Step 1051: train/loss = 0.31991836428642273, train/raw-loss = 0.2803095579147339, train/logprobs = tensor([[-1.6808, -4.7969],
        [-1.7119, -1.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921764254570007
Epoch 0, Step 1052: train/loss = 0.34176719188690186, train/raw-loss = 0.2746947407722473, train/logprobs = tensor([[-1.3246, -3.7808],
        [-1.6437, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341448426246643
Epoch 0, Step 1053: train/loss = 0.32804006338119507, train/raw-loss = 0.2372875213623047, train/logprobs = tensor([[-1.5127, -4.0345],
        [-2.1182, -1.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18150511384010315
Epoch 0, Step 1054: train/loss = 0.4727998971939087, train/raw-loss = 0.4367249011993408, train/logprobs = tensor([[-0.9430, -2.3798],
        [-1.3968, -1.3248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07215003669261932
Epoch 0, Step 1055: train/loss = 0.40203163027763367, train/raw-loss = 0.35788795351982117, train/logprobs = tensor([[-2.0378, -3.0182],
        [-2.0678, -1.2384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882873386144638
Epoch 0, Step 1056: train/loss = 0.27519696950912476, train/raw-loss = 0.13320359587669373, train/logprobs = tensor([[-1.2296, -4.1897],
        [-1.9289, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28398677706718445
Epoch 0, Step 1057: train/loss = 0.3809947967529297, train/raw-loss = 0.3063581883907318, train/logprobs = tensor([[-1.7375, -4.9211],
        [-1.3811, -1.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14927321672439575
Epoch 0, Step 1058: train/loss = 0.4226764142513275, train/raw-loss = 0.3359222114086151, train/logprobs = tensor([[-1.9922, -4.4714],
        [-2.0485, -1.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735084056854248
Epoch 0, Step 1059: train/loss = 0.41094064712524414, train/raw-loss = 0.35704874992370605, train/logprobs = tensor([[-1.6438, -2.9716],
        [-2.2503, -1.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10778377950191498
Epoch 0, Step 1060: train/loss = 0.3402631878852844, train/raw-loss = 0.24748903512954712, train/logprobs = tensor([[-0.8989, -4.6541],
        [-1.7836, -1.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1855483055114746
Epoch 0, Step 1061: train/loss = 0.37638407945632935, train/raw-loss = 0.3057813346385956, train/logprobs = tensor([[-2.6043, -3.5908],
        [-2.7411, -1.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120550453662872
Epoch 0, Step 1062: train/loss = 0.4342561662197113, train/raw-loss = 0.3770192265510559, train/logprobs = tensor([[-1.4650, -2.5021],
        [-2.0068, -1.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11447388678789139
Epoch 0, Step 1063: train/loss = 0.3958759307861328, train/raw-loss = 0.3260589838027954, train/logprobs = tensor([[-1.6455, -3.9276],
        [-2.3562, -1.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396339386701584
Epoch 0, Step 1064: train/loss = 0.4252733290195465, train/raw-loss = 0.32111111283302307, train/logprobs = tensor([[-1.5831, -3.8784],
        [-1.6420, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2083244025707245
Epoch 0, Step 1065: train/loss = 0.32099705934524536, train/raw-loss = 0.24953658878803253, train/logprobs = tensor([[-1.4582, -4.8018],
        [-1.9641, -1.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14292100071907043
Epoch 0, Step 1066: train/loss = 0.30000877380371094, train/raw-loss = 0.11962816119194031, train/logprobs = tensor([[-1.5580, -6.5779],
        [-2.1596, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36076122522354126
Epoch 0, Step 1067: train/loss = 0.3355041742324829, train/raw-loss = 0.25775617361068726, train/logprobs = tensor([[-1.3207, -4.2997],
        [-1.6322, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15549594163894653
Epoch 0, Step 1068: train/loss = 0.475709468126297, train/raw-loss = 0.43876177072525024, train/logprobs = tensor([[-1.3069, -3.2883],
        [-1.6580, -1.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0738954097032547
Epoch 0, Step 1069: train/loss = 0.3429691195487976, train/raw-loss = 0.19613315165042877, train/logprobs = tensor([[-1.5215, -5.3176],
        [-1.9777, -1.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29367193579673767
Epoch 0, Step 1070: train/loss = 0.3366613984107971, train/raw-loss = 0.20845317840576172, train/logprobs = tensor([[-1.3409, -4.7938],
        [-1.8998, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564164102077484
Epoch 0, Step 1071: train/loss = 0.41863253712654114, train/raw-loss = 0.32652896642684937, train/logprobs = tensor([[-2.5596, -5.1297],
        [-2.1266, -1.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18420712649822235
Epoch 0, Step 1072: train/loss = 0.49913036823272705, train/raw-loss = 0.4410930573940277, train/logprobs = tensor([[-2.2624, -3.1204],
        [-1.9781, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160745844244957
Epoch 0, Step 1073: train/loss = 0.41898825764656067, train/raw-loss = 0.23447658121585846, train/logprobs = tensor([[-1.4664, -4.8746],
        [-1.8714, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3690234124660492
Epoch 0, Step 1074: train/loss = 0.5681353807449341, train/raw-loss = 0.5302183628082275, train/logprobs = tensor([[-1.8105, -2.3283],
        [-1.8090, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07583396136760712
Epoch 0, Step 1075: train/loss = 0.30266502499580383, train/raw-loss = 0.19094955921173096, train/logprobs = tensor([[-1.5265, -5.5415],
        [-2.0439, -1.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22343091666698456
Epoch 0, Step 1076: train/loss = 0.42491066455841064, train/raw-loss = 0.35704749822616577, train/logprobs = tensor([[-1.3718, -3.0636],
        [-2.0463, -1.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13572630286216736
Epoch 0, Step 1077: train/loss = 0.39837032556533813, train/raw-loss = 0.34904009103775024, train/logprobs = tensor([[-1.5646, -3.9705],
        [-2.0318, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0986604318022728
Epoch 0, Step 1078: train/loss = 0.3449391722679138, train/raw-loss = 0.26157233119010925, train/logprobs = tensor([[-1.3442, -3.3917],
        [-2.0824, -1.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16673365235328674
Epoch 0, Step 1079: train/loss = 0.23987585306167603, train/raw-loss = 0.11532190442085266, train/logprobs = tensor([[-1.3240, -5.8640],
        [-2.2078, -1.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24910789728164673
Epoch 0, Step 1080: train/loss = 0.3270520567893982, train/raw-loss = 0.2154882699251175, train/logprobs = tensor([[-1.5078, -5.3764],
        [-1.7619, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2231275588274002
Epoch 0, Step 1081: train/loss = 0.48875802755355835, train/raw-loss = 0.43841007351875305, train/logprobs = tensor([[-1.7019, -3.7885],
        [-1.5615, -1.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10069593787193298
Epoch 0, Step 1082: train/loss = 0.2641172409057617, train/raw-loss = 0.14905110001564026, train/logprobs = tensor([[-0.9856, -4.8005],
        [-1.4276, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23013228178024292
Epoch 0, Step 1083: train/loss = 0.37853822112083435, train/raw-loss = 0.2887432277202606, train/logprobs = tensor([[-1.7109, -4.5109],
        [-2.2862, -1.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17958998680114746
Epoch 0, Step 1084: train/loss = 0.2765093147754669, train/raw-loss = 0.1047927737236023, train/logprobs = tensor([[-1.3670, -6.4154],
        [-2.0578, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34343308210372925
Epoch 0, Step 1085: train/loss = 0.4245094358921051, train/raw-loss = 0.3853354752063751, train/logprobs = tensor([[-2.2745, -3.9571],
        [-2.7237, -2.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834789156913757
Epoch 0, Step 1086: train/loss = 0.28480634093284607, train/raw-loss = 0.12811480462551117, train/logprobs = tensor([[-1.5022, -5.0707],
        [-1.9691, -0.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3133830428123474
Epoch 0, Step 1087: train/loss = 0.4157748818397522, train/raw-loss = 0.3681955337524414, train/logprobs = tensor([[-1.8545, -3.9681],
        [-2.2515, -1.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09515877068042755
Epoch 0, Step 1088: train/loss = 0.4640568196773529, train/raw-loss = 0.42088186740875244, train/logprobs = tensor([[-1.7074, -2.4084],
        [-2.5230, -1.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08634991943836212
Epoch 0, Step 1089: train/loss = 0.32923758029937744, train/raw-loss = 0.22648318111896515, train/logprobs = tensor([[-1.3702, -4.7481],
        [-1.4862, -0.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20550879836082458
Epoch 0, Step 1090: train/loss = 0.36782097816467285, train/raw-loss = 0.25003349781036377, train/logprobs = tensor([[-1.8064, -4.6709],
        [-2.1796, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23557499051094055
Epoch 0, Step 1091: train/loss = 0.41843587160110474, train/raw-loss = 0.35601097345352173, train/logprobs = tensor([[-1.5378, -2.9730],
        [-2.2653, -1.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12484978139400482
Epoch 0, Step 1092: train/loss = 0.5535123348236084, train/raw-loss = 0.4381236433982849, train/logprobs = tensor([[-2.5278, -4.1645],
        [-1.9194, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23077735304832458
Epoch 0, Step 1093: train/loss = 0.35199713706970215, train/raw-loss = 0.2647325098514557, train/logprobs = tensor([[-1.7760, -3.5971],
        [-2.2565, -1.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745293140411377
Epoch 0, Step 1094: train/loss = 0.3661976158618927, train/raw-loss = 0.2847341001033783, train/logprobs = tensor([[-1.6896, -3.6577],
        [-2.3998, -1.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1629270315170288
Epoch 0, Step 1095: train/loss = 0.3523155748844147, train/raw-loss = 0.25953540205955505, train/logprobs = tensor([[-2.1287, -4.4293],
        [-2.5224, -1.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18556033074855804
Epoch 0, Step 1096: train/loss = 0.3496904969215393, train/raw-loss = 0.2699824571609497, train/logprobs = tensor([[-1.5948, -3.8861],
        [-2.3867, -1.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159416064620018
Epoch 0, Step 1097: train/loss = 0.31660187244415283, train/raw-loss = 0.2075318992137909, train/logprobs = tensor([[-1.8407, -5.1934],
        [-1.8095, -1.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21814000606536865
Epoch 0, Step 1098: train/loss = 0.24786438047885895, train/raw-loss = 0.11082980036735535, train/logprobs = tensor([[-1.0380, -5.6552],
        [-1.7830, -1.2768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740691304206848
Epoch 0, Step 1099: train/loss = 0.47143372893333435, train/raw-loss = 0.4371234178543091, train/logprobs = tensor([[-1.6150, -3.3388],
        [-1.7415, -1.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06862057000398636
Epoch 0, Step 1100: train/loss = 0.30374452471733093, train/raw-loss = 0.1721353381872177, train/logprobs = tensor([[-1.7725, -5.6350],
        [-1.9432, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26321840286254883
Epoch 0, Step 1101: train/loss = 0.37330126762390137, train/raw-loss = 0.27679869532585144, train/logprobs = tensor([[-0.9447, -3.0743],
        [-1.8745, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1930050551891327
Epoch 0, Step 1102: train/loss = 0.29830387234687805, train/raw-loss = 0.2377430945634842, train/logprobs = tensor([[-1.3520, -4.5605],
        [-1.9891, -1.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12112158536911011
Epoch 0, Step 1103: train/loss = 0.36135026812553406, train/raw-loss = 0.30260854959487915, train/logprobs = tensor([[-1.3390, -4.1294],
        [-1.8669, -1.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11748343706130981
Epoch 0, Step 1104: train/loss = 0.37100136280059814, train/raw-loss = 0.3147814869880676, train/logprobs = tensor([[-1.6123, -3.8618],
        [-2.0819, -1.6877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243978142738342
Epoch 0, Step 1105: train/loss = 0.27833566069602966, train/raw-loss = 0.20603147149085999, train/logprobs = tensor([[-1.3408, -6.1400],
        [-1.5089, -1.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14460843801498413
Epoch 0, Step 1106: train/loss = 0.39951008558273315, train/raw-loss = 0.34535786509513855, train/logprobs = tensor([[-2.4419, -3.4232],
        [-2.1979, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10830444097518921
Epoch 0, Step 1107: train/loss = 0.38870111107826233, train/raw-loss = 0.2654319405555725, train/logprobs = tensor([[-1.6862, -5.7568],
        [-1.8372, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24653831124305725
Epoch 0, Step 1108: train/loss = 0.429168701171875, train/raw-loss = 0.3631778061389923, train/logprobs = tensor([[-1.4111, -2.9108],
        [-1.9372, -1.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13198179006576538
Epoch 0, Step 1109: train/loss = 0.34538114070892334, train/raw-loss = 0.24185016751289368, train/logprobs = tensor([[-2.1856, -4.4386],
        [-2.5119, -1.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20706194639205933
Epoch 0, Step 1110: train/loss = 0.24964217841625214, train/raw-loss = 0.1416165679693222, train/logprobs = tensor([[-1.2103, -5.2186],
        [-1.6822, -1.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21605123579502106
Epoch 0, Step 1111: train/loss = 0.4370931386947632, train/raw-loss = 0.3899644613265991, train/logprobs = tensor([[-2.1520, -4.6354],
        [-2.5681, -2.2268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09425737708806992
Epoch 0, Step 1112: train/loss = 0.3341204524040222, train/raw-loss = 0.25432920455932617, train/logprobs = tensor([[-1.4546, -4.6303],
        [-1.7121, -1.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15958254039287567
Epoch 0, Step 1113: train/loss = 0.5685800313949585, train/raw-loss = 0.542690098285675, train/logprobs = tensor([[-2.0869, -2.8884],
        [-1.5808, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05177967995405197
Epoch 0, Step 1114: train/loss = 0.415032297372818, train/raw-loss = 0.317575603723526, train/logprobs = tensor([[-1.3223, -4.5154],
        [-2.1286, -1.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19491340219974518
Epoch 0, Step 1115: train/loss = 0.35572361946105957, train/raw-loss = 0.26815688610076904, train/logprobs = tensor([[-1.6485, -4.5502],
        [-2.5135, -2.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17513340711593628
Epoch 0, Step 1116: train/loss = 0.3915137052536011, train/raw-loss = 0.3295777440071106, train/logprobs = tensor([[-1.6300, -4.5251],
        [-1.5212, -1.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12387192249298096
Epoch 0, Step 1117: train/loss = 0.39600682258605957, train/raw-loss = 0.3252674341201782, train/logprobs = tensor([[-1.8333, -4.1632],
        [-2.3260, -1.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14147880673408508
Epoch 0, Step 1118: train/loss = 0.3909136652946472, train/raw-loss = 0.3087400197982788, train/logprobs = tensor([[-0.8894, -4.2663],
        [-1.5499, -1.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643473356962204
Epoch 0, Step 1119: train/loss = 0.3280685544013977, train/raw-loss = 0.262428343296051, train/logprobs = tensor([[-1.0039, -4.8751],
        [-1.7747, -1.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13128045201301575
Epoch 0, Step 1120: train/loss = 0.404617577791214, train/raw-loss = 0.3447279930114746, train/logprobs = tensor([[-1.7940, -4.2064],
        [-2.6084, -2.3301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11977915465831757
Epoch 0, Step 1121: train/loss = 0.45081865787506104, train/raw-loss = 0.4095190167427063, train/logprobs = tensor([[-2.6228, -3.5577],
        [-2.0930, -1.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08259924501180649
Epoch 0, Step 1122: train/loss = 0.349172443151474, train/raw-loss = 0.21804721653461456, train/logprobs = tensor([[-2.2085, -6.8360],
        [-2.6064, -1.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26225048303604126
Epoch 0, Step 1123: train/loss = 0.37619978189468384, train/raw-loss = 0.24745695292949677, train/logprobs = tensor([[-2.6769, -6.1869],
        [-2.8873, -2.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25748568773269653
Epoch 0, Step 1124: train/loss = 0.41323012113571167, train/raw-loss = 0.32762572169303894, train/logprobs = tensor([[-3.0600, -4.4464],
        [-2.6896, -1.5907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17120882868766785
Epoch 0, Step 1125: train/loss = 0.5477167963981628, train/raw-loss = 0.5308098196983337, train/logprobs = tensor([[-0.8907, -1.4584],
        [-1.6159, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03381383419036865
Epoch 0, Step 1126: train/loss = 0.36071836948394775, train/raw-loss = 0.22584481537342072, train/logprobs = tensor([[-1.5980, -4.3667],
        [-2.1978, -1.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26974713802337646
Epoch 0, Step 1127: train/loss = 0.32613900303840637, train/raw-loss = 0.20893363654613495, train/logprobs = tensor([[-2.1852, -4.5856],
        [-2.5344, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23441077768802643
Epoch 0, Step 1128: train/loss = 0.4005870223045349, train/raw-loss = 0.3342626094818115, train/logprobs = tensor([[-2.2707, -3.9872],
        [-2.5366, -2.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326487958431244
Epoch 0, Step 1129: train/loss = 0.2811833620071411, train/raw-loss = 0.1608065366744995, train/logprobs = tensor([[-1.0562, -5.2405],
        [-1.9813, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24075359106063843
Epoch 0, Step 1130: train/loss = 0.2866557240486145, train/raw-loss = 0.17344336211681366, train/logprobs = tensor([[-1.7604, -4.8370],
        [-2.6999, -2.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2264247089624405
Epoch 0, Step 1131: train/loss = 0.5085537433624268, train/raw-loss = 0.44950979948043823, train/logprobs = tensor([[-1.7031, -3.0493],
        [-2.2227, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11808797717094421
Epoch 0, Step 1132: train/loss = 0.29494547843933105, train/raw-loss = 0.19785887002944946, train/logprobs = tensor([[-2.0401, -5.2554],
        [-2.2118, -1.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1941731870174408
Epoch 0, Step 1133: train/loss = 0.4298674762248993, train/raw-loss = 0.36523011326789856, train/logprobs = tensor([[-1.8016, -4.1177],
        [-2.0563, -1.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12927471101284027
Epoch 0, Step 1134: train/loss = 0.24659284949302673, train/raw-loss = 0.1098356544971466, train/logprobs = tensor([[-1.5683, -6.7778],
        [-1.8890, -1.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27351438999176025
Epoch 0, Step 1135: train/loss = 0.4459169805049896, train/raw-loss = 0.3824310004711151, train/logprobs = tensor([[-2.6168, -3.5799],
        [-2.7400, -1.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269720196723938
Epoch 0, Step 1136: train/loss = 0.3198269009590149, train/raw-loss = 0.21351665258407593, train/logprobs = tensor([[-1.4268, -5.6326],
        [-1.9859, -1.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21262048184871674
Epoch 0, Step 1137: train/loss = 0.5137516260147095, train/raw-loss = 0.3979400396347046, train/logprobs = tensor([[-2.3396, -5.2617],
        [-1.9511, -1.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23162320256233215
Epoch 0, Step 1138: train/loss = 0.4037477672100067, train/raw-loss = 0.3397076725959778, train/logprobs = tensor([[-1.7461, -3.0713],
        [-2.8265, -1.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12808015942573547
Epoch 0, Step 1139: train/loss = 0.5286017656326294, train/raw-loss = 0.4854692816734314, train/logprobs = tensor([[-2.1046, -3.0577],
        [-2.3035, -2.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08626501262187958
Epoch 0, Step 1140: train/loss = 0.4306516647338867, train/raw-loss = 0.3646470904350281, train/logprobs = tensor([[-1.1294, -2.9939],
        [-1.8542, -1.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13200916349887848
Epoch 0, Step 1141: train/loss = 0.3959420323371887, train/raw-loss = 0.3408297300338745, train/logprobs = tensor([[-1.2031, -4.3499],
        [-1.9762, -2.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.110224649310112
Epoch 0, Step 1142: train/loss = 0.3016783595085144, train/raw-loss = 0.17442448437213898, train/logprobs = tensor([[-2.1815, -3.8395],
        [-3.2491, -1.3297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545076906681061
Epoch 0, Step 1143: train/loss = 0.3567831814289093, train/raw-loss = 0.2396414428949356, train/logprobs = tensor([[-1.8698, -7.2847],
        [-1.5408, -1.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2342834770679474
Epoch 0, Step 1144: train/loss = 0.3593285381793976, train/raw-loss = 0.27551889419555664, train/logprobs = tensor([[-1.1037, -5.1329],
        [-1.4810, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1676192730665207
Epoch 0, Step 1145: train/loss = 0.3029187023639679, train/raw-loss = 0.18589696288108826, train/logprobs = tensor([[-1.4271, -4.5395],
        [-2.4956, -1.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340434342622757
Epoch 0, Step 1146: train/loss = 0.2692335247993469, train/raw-loss = 0.15990014374256134, train/logprobs = tensor([[-1.3320, -4.6185],
        [-2.2703, -1.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21866676211357117
Epoch 0, Step 1147: train/loss = 0.25892776250839233, train/raw-loss = 0.11114943027496338, train/logprobs = tensor([[-1.2991, -5.5243],
        [-1.6331, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955566644668579
Epoch 0, Step 1148: train/loss = 0.2525879442691803, train/raw-loss = 0.14618711173534393, train/logprobs = tensor([[-1.4548, -6.3409],
        [-2.3061, -1.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21280166506767273
Epoch 0, Step 1149: train/loss = 0.33505427837371826, train/raw-loss = 0.2563217282295227, train/logprobs = tensor([[-1.6314, -3.4503],
        [-2.3335, -1.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574651002883911
Epoch 0, Step 1150: train/loss = 0.3380064368247986, train/raw-loss = 0.2081032395362854, train/logprobs = tensor([[-2.2348, -6.3536],
        [-2.3704, -1.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25980639457702637
Epoch 0, Step 1151: train/loss = 0.3023907244205475, train/raw-loss = 0.16468292474746704, train/logprobs = tensor([[-1.8933, -4.6358],
        [-2.6413, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2754155993461609
Epoch 0, Step 1152: train/loss = 0.26731401681900024, train/raw-loss = 0.11981089413166046, train/logprobs = tensor([[-1.0795, -6.3252],
        [-1.8374, -1.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2950062155723572
Epoch 0, Step 1153: train/loss = 0.2646254301071167, train/raw-loss = 0.12639133632183075, train/logprobs = tensor([[-1.7079, -5.7472],
        [-1.8528, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2764681577682495
Epoch 0, Step 1154: train/loss = 0.34621959924697876, train/raw-loss = 0.2718948423862457, train/logprobs = tensor([[-1.4491, -3.4508],
        [-1.7530, -1.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14864952862262726
Epoch 0, Step 1155: train/loss = 0.3759523630142212, train/raw-loss = 0.3049527406692505, train/logprobs = tensor([[-1.8347, -3.4351],
        [-1.9301, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419992595911026
Epoch 0, Step 1156: train/loss = 0.5287309885025024, train/raw-loss = 0.47424766421318054, train/logprobs = tensor([[-1.1690, -2.3945],
        [-1.6674, -1.3945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10896669328212738
Epoch 0, Step 1157: train/loss = 0.3920140266418457, train/raw-loss = 0.29604342579841614, train/logprobs = tensor([[-2.1072, -4.4837],
        [-2.8330, -1.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19194117188453674
Epoch 0, Step 1158: train/loss = 0.45511072874069214, train/raw-loss = 0.34991559386253357, train/logprobs = tensor([[-1.5720, -3.7842],
        [-2.4493, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21039029955863953
Epoch 0, Step 1159: train/loss = 0.33924734592437744, train/raw-loss = 0.20908913016319275, train/logprobs = tensor([[-1.5367, -5.0584],
        [-2.0548, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2603164613246918
Epoch 0, Step 1160: train/loss = 0.39598697423934937, train/raw-loss = 0.24992552399635315, train/logprobs = tensor([[-2.3521, -3.9968],
        [-3.0519, -1.1831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29212287068367004
Epoch 0, Step 1161: train/loss = 0.3275392949581146, train/raw-loss = 0.23888017237186432, train/logprobs = tensor([[-2.4070, -5.5470],
        [-2.3299, -1.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1773182600736618
Epoch 0, Step 1162: train/loss = 0.41153043508529663, train/raw-loss = 0.35089433193206787, train/logprobs = tensor([[-2.6235, -4.9989],
        [-2.1085, -1.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212722510099411
Epoch 0, Step 1163: train/loss = 0.439022421836853, train/raw-loss = 0.38273972272872925, train/logprobs = tensor([[-2.0251, -4.7579],
        [-2.5513, -2.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256537586450577
Epoch 0, Step 1164: train/loss = 0.421682745218277, train/raw-loss = 0.36801838874816895, train/logprobs = tensor([[-1.0364, -3.0999],
        [-1.8561, -1.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10732875764369965
Epoch 0, Step 1165: train/loss = 0.4532425105571747, train/raw-loss = 0.42191392183303833, train/logprobs = tensor([[-1.5420, -2.6604],
        [-1.8952, -1.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06265712529420853
Epoch 0, Step 1166: train/loss = 0.3130654990673065, train/raw-loss = 0.1912923902273178, train/logprobs = tensor([[-1.8157, -4.0376],
        [-3.0058, -1.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24354618787765503
Epoch 0, Step 1167: train/loss = 0.2629002034664154, train/raw-loss = 0.07688625156879425, train/logprobs = tensor([[-1.4736, -5.9054],
        [-2.7417, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3720279037952423
Epoch 0, Step 1168: train/loss = 0.3649107813835144, train/raw-loss = 0.27127236127853394, train/logprobs = tensor([[-1.5436, -3.3776],
        [-2.6028, -1.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18727684020996094
Epoch 0, Step 1169: train/loss = 0.3676348328590393, train/raw-loss = 0.2933955788612366, train/logprobs = tensor([[-1.5732, -3.2829],
        [-2.4429, -1.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14847850799560547
Epoch 0, Step 1170: train/loss = 0.5323903560638428, train/raw-loss = 0.4781530499458313, train/logprobs = tensor([[-1.9255, -3.1972],
        [-2.1389, -1.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10847467929124832
Epoch 0, Step 1171: train/loss = 0.33276602625846863, train/raw-loss = 0.26454684138298035, train/logprobs = tensor([[-1.6498, -3.8365],
        [-2.3167, -1.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13643836975097656
Epoch 0, Step 1172: train/loss = 0.3761909008026123, train/raw-loss = 0.28729796409606934, train/logprobs = tensor([[-1.3683, -3.7625],
        [-1.9878, -1.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17778582870960236
Epoch 0, Step 1173: train/loss = 0.3084796667098999, train/raw-loss = 0.17565959692001343, train/logprobs = tensor([[-1.8633, -4.8072],
        [-2.7486, -1.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26564013957977295
Epoch 0, Step 1174: train/loss = 0.4294097125530243, train/raw-loss = 0.3690497875213623, train/logprobs = tensor([[-2.4709, -3.9134],
        [-2.6738, -2.2907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12071985006332397
Epoch 0, Step 1175: train/loss = 0.41323864459991455, train/raw-loss = 0.35037827491760254, train/logprobs = tensor([[-1.1586, -3.4890],
        [-1.6453, -1.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12572062015533447
Epoch 0, Step 1176: train/loss = 0.3754521608352661, train/raw-loss = 0.2957901656627655, train/logprobs = tensor([[-1.7758, -4.4654],
        [-2.1788, -1.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15932400524616241
Epoch 0, Step 1177: train/loss = 0.39835670590400696, train/raw-loss = 0.32565322518348694, train/logprobs = tensor([[-1.6915, -3.3789],
        [-2.0303, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14540697634220123
Epoch 0, Step 1178: train/loss = 0.5875238180160522, train/raw-loss = 0.5818313360214233, train/logprobs = tensor([[-1.5572, -1.4486],
        [-2.0504, -1.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011385017074644566
Epoch 0, Step 1179: train/loss = 0.2776685953140259, train/raw-loss = 0.16597886383533478, train/logprobs = tensor([[-1.7540, -6.0378],
        [-1.8856, -1.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2233794629573822
Epoch 0, Step 1180: train/loss = 0.4120801091194153, train/raw-loss = 0.3759409785270691, train/logprobs = tensor([[-1.5866, -3.4488],
        [-2.2290, -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07227823138237
Epoch 0, Step 1181: train/loss = 0.554595410823822, train/raw-loss = 0.5352414846420288, train/logprobs = tensor([[-2.3323, -3.9250],
        [-1.6020, -1.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038707830011844635
Epoch 0, Step 1182: train/loss = 0.38457322120666504, train/raw-loss = 0.2965259552001953, train/logprobs = tensor([[-1.8597, -3.8213],
        [-2.7708, -2.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17609453201293945
Epoch 0, Step 1183: train/loss = 0.587492823600769, train/raw-loss = 0.5664107799530029, train/logprobs = tensor([[-2.1152, -2.5890],
        [-2.0223, -1.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04216401278972626
Epoch 0, Step 1184: train/loss = 0.3473198413848877, train/raw-loss = 0.28915709257125854, train/logprobs = tensor([[-0.9025, -4.6409],
        [-1.6974, -2.1648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1163255050778389
Epoch 0, Step 1185: train/loss = 0.29092109203338623, train/raw-loss = 0.18905428051948547, train/logprobs = tensor([[-1.3723, -4.9879],
        [-2.2463, -2.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2037336528301239
Epoch 0, Step 1186: train/loss = 0.3620830774307251, train/raw-loss = 0.2772628366947174, train/logprobs = tensor([[-1.6208, -4.4306],
        [-2.2169, -1.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1696404665708542
Epoch 0, Step 1187: train/loss = 0.22212502360343933, train/raw-loss = 0.12127861380577087, train/logprobs = tensor([[-1.2054, -6.4624],
        [-1.9303, -2.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2016928493976593
Epoch 0, Step 1188: train/loss = 0.3118360638618469, train/raw-loss = 0.2057858109474182, train/logprobs = tensor([[-1.7267, -5.4564],
        [-2.2089, -2.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2121005654335022
Epoch 0, Step 1189: train/loss = 0.36158454418182373, train/raw-loss = 0.274635910987854, train/logprobs = tensor([[-3.0313, -4.6627],
        [-2.6625, -1.5312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17389723658561707
Epoch 0, Step 1190: train/loss = 0.3563218414783478, train/raw-loss = 0.25098517537117004, train/logprobs = tensor([[-1.7151, -4.3812],
        [-3.0784, -2.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21067336201667786
Epoch 0, Step 1191: train/loss = 0.33017730712890625, train/raw-loss = 0.22750979661941528, train/logprobs = tensor([[-1.6831, -3.6740],
        [-3.0029, -1.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20533506572246552
Epoch 0, Step 1192: train/loss = 0.4514504671096802, train/raw-loss = 0.4207882285118103, train/logprobs = tensor([[-1.3561, -2.6174],
        [-2.3128, -1.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061324525624513626
Epoch 0, Step 1193: train/loss = 0.3928864598274231, train/raw-loss = 0.33856359124183655, train/logprobs = tensor([[-1.5260, -3.9264],
        [-1.7628, -1.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10864578187465668
Epoch 0, Step 1194: train/loss = 0.30691373348236084, train/raw-loss = 0.1206771582365036, train/logprobs = tensor([[-2.1945, -5.2436],
        [-3.4100, -1.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3724731504917145
Epoch 0, Step 1195: train/loss = 0.3371403217315674, train/raw-loss = 0.21429133415222168, train/logprobs = tensor([[-2.7370, -6.7693],
        [-2.5195, -1.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24569794535636902
Epoch 0, Step 1196: train/loss = 0.363503098487854, train/raw-loss = 0.21009880304336548, train/logprobs = tensor([[-1.9135, -4.6509],
        [-2.7076, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30680859088897705
Epoch 0, Step 1197: train/loss = 0.29558810591697693, train/raw-loss = 0.20006999373435974, train/logprobs = tensor([[-1.7093, -5.8071],
        [-1.7382, -1.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191036194562912
Epoch 0, Step 1198: train/loss = 0.2938792407512665, train/raw-loss = 0.19952942430973053, train/logprobs = tensor([[-1.2858, -4.4112],
        [-2.1898, -1.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886996477842331
Epoch 0, Step 1199: train/loss = 0.44825324416160583, train/raw-loss = 0.360475093126297, train/logprobs = tensor([[-1.7178, -4.4944],
        [-2.4776, -2.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17555633187294006
Epoch 0, Step 1200: train/loss = 0.40376442670822144, train/raw-loss = 0.30930808186531067, train/logprobs = tensor([[-2.0160, -5.0866],
        [-2.0008, -1.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18891271948814392
Epoch 0, Step 1201: train/loss = 0.3223615288734436, train/raw-loss = 0.23947235941886902, train/logprobs = tensor([[-1.9931, -5.4118],
        [-2.5828, -2.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1657782942056656
Epoch 0, Step 1202: train/loss = 0.4176959693431854, train/raw-loss = 0.34168893098831177, train/logprobs = tensor([[-0.7540, -3.1756],
        [-1.3053, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15201403200626373
Epoch 0, Step 1203: train/loss = 0.8540714979171753, train/raw-loss = 0.8156012296676636, train/logprobs = tensor([[-3.3002, -3.8390],
        [-1.8482, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0769406259059906
Epoch 0, Step 1204: train/loss = 0.2742502987384796, train/raw-loss = 0.14926862716674805, train/logprobs = tensor([[-1.8609, -5.5039],
        [-2.0702, -1.5711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24996337294578552
Epoch 0, Step 1205: train/loss = 0.35059332847595215, train/raw-loss = 0.2767024636268616, train/logprobs = tensor([[-1.9892, -5.1942],
        [-2.1711, -1.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14778172969818115
Epoch 0, Step 1206: train/loss = 0.43131059408187866, train/raw-loss = 0.35193395614624023, train/logprobs = tensor([[-2.0132, -3.1280],
        [-2.9775, -1.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15875332057476044
Epoch 0, Step 1207: train/loss = 0.7000833749771118, train/raw-loss = 0.6716016530990601, train/logprobs = tensor([[-2.8254, -3.1578],
        [-1.8867, -1.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05696343630552292
Epoch 0, Step 1208: train/loss = 0.578597903251648, train/raw-loss = 0.5295406579971313, train/logprobs = tensor([[-1.6941, -2.8698],
        [-1.7267, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981144905090332
Epoch 0, Step 1209: train/loss = 0.7122840881347656, train/raw-loss = 0.6260979175567627, train/logprobs = tensor([[-2.5225, -3.4062],
        [-2.9279, -1.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17237219214439392
Epoch 0, Step 1210: train/loss = 0.3145942687988281, train/raw-loss = 0.2362007051706314, train/logprobs = tensor([[-1.4912, -4.1653],
        [-1.9676, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15678712725639343
Epoch 0, Step 1211: train/loss = 0.4294949769973755, train/raw-loss = 0.37053918838500977, train/logprobs = tensor([[-1.4446, -3.5594],
        [-2.2718, -1.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11791154742240906
Epoch 0, Step 1212: train/loss = 0.2833230197429657, train/raw-loss = 0.196978360414505, train/logprobs = tensor([[-1.3852, -5.5053],
        [-2.4189, -2.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1726893186569214
Epoch 0, Step 1213: train/loss = 0.47768542170524597, train/raw-loss = 0.42737770080566406, train/logprobs = tensor([[-1.9750, -3.2533],
        [-2.0662, -1.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006155014038086
Epoch 0, Step 1214: train/loss = 0.3261382579803467, train/raw-loss = 0.2605350911617279, train/logprobs = tensor([[-1.0024, -5.0272],
        [-1.6206, -2.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13120630383491516
Epoch 0, Step 1215: train/loss = 0.27708423137664795, train/raw-loss = 0.17909327149391174, train/logprobs = tensor([[-1.9321, -5.1465],
        [-2.9030, -2.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1959819197654724
Epoch 0, Step 1216: train/loss = 0.307282030582428, train/raw-loss = 0.13561400771141052, train/logprobs = tensor([[-1.4835, -6.3355],
        [-3.0962, -2.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433360457420349
Epoch 0, Step 1217: train/loss = 0.38752368092536926, train/raw-loss = 0.32742977142333984, train/logprobs = tensor([[-1.5768, -3.4268],
        [-2.5129, -2.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12018780410289764
Epoch 0, Step 1218: train/loss = 0.46510493755340576, train/raw-loss = 0.31172752380371094, train/logprobs = tensor([[-2.9082, -4.1453],
        [-4.0948, -1.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30675479769706726
Epoch 0, Step 1219: train/loss = 0.29353049397468567, train/raw-loss = 0.18461941182613373, train/logprobs = tensor([[-1.7865, -5.8627],
        [-1.8722, -1.3484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21782216429710388
Epoch 0, Step 1220: train/loss = 0.4400729537010193, train/raw-loss = 0.29731470346450806, train/logprobs = tensor([[-2.5106, -4.7651],
        [-3.3121, -1.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28551650047302246
Epoch 0, Step 1221: train/loss = 0.38647371530532837, train/raw-loss = 0.3162192106246948, train/logprobs = tensor([[-2.4166, -4.5691],
        [-2.9656, -2.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1405089795589447
Epoch 0, Step 1222: train/loss = 0.28500115871429443, train/raw-loss = 0.12152042984962463, train/logprobs = tensor([[-2.3343, -5.3544],
        [-2.4104, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.326961487531662
Epoch 0, Step 1223: train/loss = 0.38807111978530884, train/raw-loss = 0.3080404996871948, train/logprobs = tensor([[-2.5438, -4.5969],
        [-2.6817, -1.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16006118059158325
Epoch 0, Step 1224: train/loss = 0.45153099298477173, train/raw-loss = 0.3885928988456726, train/logprobs = tensor([[-1.8400, -4.2997],
        [-2.1555, -2.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12587612867355347
Epoch 0, Step 1225: train/loss = 0.36020949482917786, train/raw-loss = 0.12902414798736572, train/logprobs = tensor([[-2.3012, -5.7190],
        [-3.8627, -1.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46237069368362427
Epoch 0, Step 1226: train/loss = 0.2913280725479126, train/raw-loss = 0.18506410717964172, train/logprobs = tensor([[-1.5110, -6.0242],
        [-2.4457, -2.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21252791583538055
Epoch 0, Step 1227: train/loss = 0.40013960003852844, train/raw-loss = 0.3505917191505432, train/logprobs = tensor([[-1.7373, -5.0934],
        [-2.5928, -2.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909579157829285
Epoch 0, Step 1228: train/loss = 0.37063273787498474, train/raw-loss = 0.3009738624095917, train/logprobs = tensor([[-1.6685, -5.3401],
        [-2.1985, -2.0165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13931775093078613
Epoch 0, Step 1229: train/loss = 0.34298011660575867, train/raw-loss = 0.27369990944862366, train/logprobs = tensor([[-1.3250, -5.0354],
        [-1.8163, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13856038451194763
Epoch 0, Step 1230: train/loss = 0.28218525648117065, train/raw-loss = 0.18880601227283478, train/logprobs = tensor([[-1.3727, -5.1527],
        [-1.8077, -1.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18675850331783295
Epoch 0, Step 1231: train/loss = 0.33990222215652466, train/raw-loss = 0.1446843296289444, train/logprobs = tensor([[-1.9683, -5.6385],
        [-3.3861, -2.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3904358148574829
Epoch 0, Step 1232: train/loss = 0.4438078999519348, train/raw-loss = 0.39752745628356934, train/logprobs = tensor([[-1.3114, -3.4885],
        [-1.6639, -1.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256084263324738
Epoch 0, Step 1233: train/loss = 0.30612844228744507, train/raw-loss = 0.21300022304058075, train/logprobs = tensor([[-1.5593, -5.9962],
        [-2.0387, -2.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18625640869140625
Epoch 0, Step 1234: train/loss = 0.29211676120758057, train/raw-loss = 0.09716816991567612, train/logprobs = tensor([[-1.8858, -7.9351],
        [-2.2246, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3898971974849701
Epoch 0, Step 1235: train/loss = 0.30640754103660583, train/raw-loss = 0.25914451479911804, train/logprobs = tensor([[-1.3448, -5.5371],
        [-1.7453, -2.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09452605992555618
Epoch 0, Step 1236: train/loss = 0.2845299243927002, train/raw-loss = 0.17520040273666382, train/logprobs = tensor([[-1.9727, -4.5301],
        [-2.7650, -1.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21865907311439514
Epoch 0, Step 1237: train/loss = 0.31752005219459534, train/raw-loss = 0.19759351015090942, train/logprobs = tensor([[-1.7768, -5.5437],
        [-2.7493, -2.3993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23985306918621063
Epoch 0, Step 1238: train/loss = 0.34917181730270386, train/raw-loss = 0.2343672215938568, train/logprobs = tensor([[-1.2167, -5.6539],
        [-2.3339, -1.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22960920631885529
Epoch 0, Step 1239: train/loss = 0.40673303604125977, train/raw-loss = 0.34484219551086426, train/logprobs = tensor([[-2.3526, -3.9887],
        [-2.7388, -1.4772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12378167361021042
Epoch 0, Step 1240: train/loss = 0.37719184160232544, train/raw-loss = 0.2427721917629242, train/logprobs = tensor([[-1.9468, -4.7201],
        [-2.7208, -1.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688392996788025
Epoch 0, Step 1241: train/loss = 0.37291693687438965, train/raw-loss = 0.251695454120636, train/logprobs = tensor([[-1.9873, -5.3051],
        [-2.6209, -1.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24244293570518494
Epoch 0, Step 1242: train/loss = 0.32779496908187866, train/raw-loss = 0.2202216237783432, train/logprobs = tensor([[-2.0031, -4.5476],
        [-2.5554, -1.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21514669060707092
Epoch 0, Step 1243: train/loss = 0.32041841745376587, train/raw-loss = 0.18349207937717438, train/logprobs = tensor([[-2.2285, -5.0023],
        [-2.4228, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27385270595550537
Epoch 0, Step 1244: train/loss = 0.3988786041736603, train/raw-loss = 0.31092551350593567, train/logprobs = tensor([[-2.1717, -5.0932],
        [-1.9968, -1.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1759062111377716
Epoch 0, Step 1245: train/loss = 0.29455265402793884, train/raw-loss = 0.07462408393621445, train/logprobs = tensor([[-2.1269, -5.9256],
        [-3.4872, -1.3603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4398571252822876
Epoch 0, Step 1246: train/loss = 0.2893587052822113, train/raw-loss = 0.13309712707996368, train/logprobs = tensor([[-2.0194, -6.3138],
        [-2.8054, -1.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125231862068176
Epoch 0, Step 1247: train/loss = 0.5453324913978577, train/raw-loss = 0.5074014067649841, train/logprobs = tensor([[-1.7388, -2.1621],
        [-2.3560, -1.6838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07586214691400528
Epoch 0, Step 1248: train/loss = 0.31483718752861023, train/raw-loss = 0.19620515406131744, train/logprobs = tensor([[-1.9538, -5.3288],
        [-2.3902, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23726403713226318
Epoch 0, Step 1249: train/loss = 0.43605488538742065, train/raw-loss = 0.353352427482605, train/logprobs = tensor([[-1.9011, -4.3318],
        [-2.5971, -1.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16540496051311493
Epoch 0, Step 1250: train/loss = 0.241628497838974, train/raw-loss = 0.08699747920036316, train/logprobs = tensor([[-1.4954, -7.6745],
        [-2.3720, -1.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3092620372772217
Epoch 0, Step 1251: train/loss = 0.33878058195114136, train/raw-loss = 0.21179959177970886, train/logprobs = tensor([[-1.8454, -4.6657],
        [-2.6467, -1.7976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253961980342865
Epoch 0, Step 1252: train/loss = 0.2787533402442932, train/raw-loss = 0.14182181656360626, train/logprobs = tensor([[-2.0804, -5.9497],
        [-3.0313, -2.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738630175590515
Epoch 0, Step 1253: train/loss = 0.5198641419410706, train/raw-loss = 0.4624694883823395, train/logprobs = tensor([[-1.6081, -3.1187],
        [-1.8110, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478938162326813
Epoch 0, Step 1254: train/loss = 0.5241128206253052, train/raw-loss = 0.49586352705955505, train/logprobs = tensor([[-1.2811, -3.1401],
        [-1.7121, -1.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05649859458208084
Epoch 0, Step 1255: train/loss = 0.3342781662940979, train/raw-loss = 0.27087271213531494, train/logprobs = tensor([[-1.5907, -3.7951],
        [-2.4596, -1.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12681087851524353
Epoch 0, Step 1256: train/loss = 0.27563750743865967, train/raw-loss = 0.14376500248908997, train/logprobs = tensor([[-3.1468, -5.6501],
        [-3.2986, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637450098991394
Epoch 0, Step 1257: train/loss = 0.30202585458755493, train/raw-loss = 0.09401845186948776, train/logprobs = tensor([[-1.9950, -6.3046],
        [-3.0120, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4160148501396179
Epoch 0, Step 1258: train/loss = 0.3705619275569916, train/raw-loss = 0.22138969600200653, train/logprobs = tensor([[-1.7832, -5.3989],
        [-3.0210, -1.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983444631099701
Epoch 0, Step 1259: train/loss = 0.2521539032459259, train/raw-loss = 0.08092100918292999, train/logprobs = tensor([[-1.7059, -7.8758],
        [-2.4177, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34246575832366943
Epoch 0, Step 1260: train/loss = 0.27475130558013916, train/raw-loss = 0.11677414923906326, train/logprobs = tensor([[-1.7275, -5.5770],
        [-2.7951, -1.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159542679786682
Epoch 0, Step 1261: train/loss = 0.5234562754631042, train/raw-loss = 0.49711984395980835, train/logprobs = tensor([[-1.2747, -3.9603],
        [-1.8045, -2.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05267292261123657
Epoch 0, Step 1262: train/loss = 0.3048015236854553, train/raw-loss = 0.246482253074646, train/logprobs = tensor([[-1.5416, -5.1682],
        [-2.0912, -2.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11663858592510223
Epoch 0, Step 1263: train/loss = 0.37120673060417175, train/raw-loss = 0.3030872941017151, train/logprobs = tensor([[-1.1660, -6.0853],
        [-1.7544, -2.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13623884320259094
Epoch 0, Step 1264: train/loss = 0.299206018447876, train/raw-loss = 0.08305772393941879, train/logprobs = tensor([[-2.0077, -6.8876],
        [-2.6714, -1.3323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43229663372039795
Epoch 0, Step 1265: train/loss = 0.3770502209663391, train/raw-loss = 0.2485075742006302, train/logprobs = tensor([[-2.3077, -4.3855],
        [-3.2580, -1.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25708523392677307
Epoch 0, Step 1266: train/loss = 0.30494484305381775, train/raw-loss = 0.2308439314365387, train/logprobs = tensor([[-1.8912, -5.6221],
        [-2.6813, -2.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1482018083333969
Epoch 0, Step 1267: train/loss = 0.35452941060066223, train/raw-loss = 0.19979605078697205, train/logprobs = tensor([[-1.9755, -5.9516],
        [-2.9939, -1.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30946671962738037
Epoch 0, Step 1268: train/loss = 0.36876529455184937, train/raw-loss = 0.31093019247055054, train/logprobs = tensor([[-1.3658, -3.9843],
        [-1.9217, -1.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567024886608124
Epoch 0, Step 1269: train/loss = 0.31863147020339966, train/raw-loss = 0.1934640258550644, train/logprobs = tensor([[-1.6931, -5.0325],
        [-2.1143, -1.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2503349184989929
Epoch 0, Step 1270: train/loss = 0.3154952824115753, train/raw-loss = 0.21291600167751312, train/logprobs = tensor([[-1.6464, -3.9076],
        [-3.1256, -2.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.205158531665802
Epoch 0, Step 1271: train/loss = 0.43242284655570984, train/raw-loss = 0.3788512647151947, train/logprobs = tensor([[-1.2214, -3.2417],
        [-1.7200, -1.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714317113161087
Epoch 0, Step 1272: train/loss = 0.346524178981781, train/raw-loss = 0.25326621532440186, train/logprobs = tensor([[-1.8324, -4.7317],
        [-2.2613, -1.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18651598691940308
Epoch 0, Step 1273: train/loss = 0.40652531385421753, train/raw-loss = 0.2898479998111725, train/logprobs = tensor([[-1.9398, -4.2530],
        [-2.4089, -1.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23335467278957367
Epoch 0, Step 1274: train/loss = 0.3261570632457733, train/raw-loss = 0.27269256114959717, train/logprobs = tensor([[-1.4481, -5.3274],
        [-2.3179, -2.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10692905634641647
Epoch 0, Step 1275: train/loss = 0.3630038797855377, train/raw-loss = 0.27076423168182373, train/logprobs = tensor([[-1.8498, -4.4900],
        [-2.8730, -2.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18447931110858917
Epoch 0, Step 1276: train/loss = 0.28113967180252075, train/raw-loss = 0.17939719557762146, train/logprobs = tensor([[-1.1846, -4.5357],
        [-1.3788, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20348501205444336
Epoch 0, Step 1277: train/loss = 0.6228604316711426, train/raw-loss = 0.5820736289024353, train/logprobs = tensor([[-1.3763, -3.0668],
        [-1.5368, -1.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081573486328125
Epoch 0, Step 1278: train/loss = 0.3221249580383301, train/raw-loss = 0.2472647875547409, train/logprobs = tensor([[-1.4845, -4.9352],
        [-2.3152, -2.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14972041547298431
Epoch 0, Step 1279: train/loss = 0.3182063102722168, train/raw-loss = 0.2665422260761261, train/logprobs = tensor([[-1.3312, -5.4076],
        [-2.3265, -2.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.103328175842762
Epoch 0, Step 1280: train/loss = 0.4014636278152466, train/raw-loss = 0.35517972707748413, train/logprobs = tensor([[-1.2648, -5.0196],
        [-1.6207, -1.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256773442029953
Epoch 0, Step 1281: train/loss = 0.2501441538333893, train/raw-loss = 0.1446913629770279, train/logprobs = tensor([[-1.3874, -6.2927],
        [-2.1233, -2.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21090556681156158
Epoch 0, Step 1282: train/loss = 0.4679964780807495, train/raw-loss = 0.3923615515232086, train/logprobs = tensor([[-2.2273, -4.3333],
        [-2.6431, -2.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15126994252204895
Epoch 0, Step 1283: train/loss = 0.2592640519142151, train/raw-loss = 0.09480758011341095, train/logprobs = tensor([[-1.7447, -6.0454],
        [-2.6669, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32891297340393066
Epoch 0, Step 1284: train/loss = 0.2693498134613037, train/raw-loss = 0.17185364663600922, train/logprobs = tensor([[-1.2688, -5.0385],
        [-1.8243, -1.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19499236345291138
Epoch 0, Step 1285: train/loss = 0.3774874806404114, train/raw-loss = 0.26032280921936035, train/logprobs = tensor([[-1.5936, -4.6884],
        [-2.2687, -1.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23432926833629608
Epoch 0, Step 1286: train/loss = 0.4554414749145508, train/raw-loss = 0.42068299651145935, train/logprobs = tensor([[-2.0328, -3.0528],
        [-1.7588, -1.3805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06951691210269928
Epoch 0, Step 1287: train/loss = 0.28844571113586426, train/raw-loss = 0.17946696281433105, train/logprobs = tensor([[-1.5171, -8.5834],
        [-2.1230, -2.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2179575115442276
Epoch 0, Step 1288: train/loss = 0.32137763500213623, train/raw-loss = 0.23626957833766937, train/logprobs = tensor([[-2.0168, -4.4142],
        [-2.9197, -2.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17021611332893372
Epoch 0, Step 1289: train/loss = 0.27144503593444824, train/raw-loss = 0.08772766590118408, train/logprobs = tensor([[-2.1899, -6.3773],
        [-3.5905, -2.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36743468046188354
Epoch 0, Step 1290: train/loss = 0.3973417282104492, train/raw-loss = 0.33852124214172363, train/logprobs = tensor([[-1.6322, -3.0526],
        [-2.6300, -2.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11764099448919296
Epoch 0, Step 1291: train/loss = 0.29248106479644775, train/raw-loss = 0.197829931974411, train/logprobs = tensor([[-1.8805, -5.7465],
        [-2.5772, -2.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1893022358417511
Epoch 0, Step 1292: train/loss = 0.4833596348762512, train/raw-loss = 0.4455980658531189, train/logprobs = tensor([[-2.8612, -3.4272],
        [-2.6207, -1.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07552313059568405
Epoch 0, Step 1293: train/loss = 0.49375119805336, train/raw-loss = 0.43311208486557007, train/logprobs = tensor([[-1.4214, -2.3561],
        [-1.9789, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12127815186977386
Epoch 0, Step 1294: train/loss = 0.2649976313114166, train/raw-loss = 0.17237608134746552, train/logprobs = tensor([[-1.7330, -6.4985],
        [-2.0743, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18524309992790222
Epoch 0, Step 1295: train/loss = 0.42760950326919556, train/raw-loss = 0.32398664951324463, train/logprobs = tensor([[-1.9112, -4.5954],
        [-2.4189, -1.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20724575221538544
Epoch 0, Step 1296: train/loss = 0.26708143949508667, train/raw-loss = 0.1029861718416214, train/logprobs = tensor([[-1.5357, -7.3408],
        [-2.8930, -2.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32819053530693054
Epoch 0, Step 1297: train/loss = 0.34931787848472595, train/raw-loss = 0.3035065531730652, train/logprobs = tensor([[-1.5012, -4.0163],
        [-1.3983, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09162275493144989
Epoch 0, Step 1298: train/loss = 0.4257394075393677, train/raw-loss = 0.39130935072898865, train/logprobs = tensor([[-3.2338, -5.0323],
        [-2.5621, -1.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06886007636785507
Epoch 0, Step 1299: train/loss = 0.3095361292362213, train/raw-loss = 0.2150316834449768, train/logprobs = tensor([[-2.4556, -6.2408],
        [-2.3146, -1.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18900887668132782
Epoch 0, Step 1300: train/loss = 0.30423450469970703, train/raw-loss = 0.21982480585575104, train/logprobs = tensor([[-1.3611, -4.9828],
        [-1.9348, -1.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16881945729255676
Epoch 0, Step 1301: train/loss = 0.38272956013679504, train/raw-loss = 0.31764936447143555, train/logprobs = tensor([[-1.9015, -5.1425],
        [-2.4813, -3.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.130160391330719
Epoch 0, Step 1302: train/loss = 0.320842444896698, train/raw-loss = 0.2403716742992401, train/logprobs = tensor([[-1.6692, -7.3416],
        [-2.0202, -2.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16094151139259338
Epoch 0, Step 1303: train/loss = 0.3052213788032532, train/raw-loss = 0.1796227991580963, train/logprobs = tensor([[-1.5301, -7.3355],
        [-2.2369, -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511972188949585
Epoch 0, Step 1304: train/loss = 0.3595094680786133, train/raw-loss = 0.22194410860538483, train/logprobs = tensor([[-2.2399, -5.4758],
        [-2.3903, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2751306891441345
Epoch 0, Step 1305: train/loss = 0.3110677897930145, train/raw-loss = 0.21616153419017792, train/logprobs = tensor([[-1.7229, -4.6602],
        [-2.3379, -2.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1898125410079956
Epoch 0, Step 1306: train/loss = 0.4926355183124542, train/raw-loss = 0.4397353231906891, train/logprobs = tensor([[-1.9500, -6.0341],
        [-1.9492, -2.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10580035299062729
Epoch 0, Step 1307: train/loss = 0.37300580739974976, train/raw-loss = 0.3010437786579132, train/logprobs = tensor([[-2.1358, -3.7761],
        [-2.8441, -2.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14392410218715668
Epoch 0, Step 1308: train/loss = 0.2650935649871826, train/raw-loss = 0.12410086393356323, train/logprobs = tensor([[-2.6452, -5.9869],
        [-3.0181, -1.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28198543190956116
Epoch 0, Step 1309: train/loss = 0.2846721112728119, train/raw-loss = 0.08919544517993927, train/logprobs = tensor([[-1.8765, -7.1147],
        [-2.9034, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39095327258110046
Epoch 0, Step 1310: train/loss = 0.4169843792915344, train/raw-loss = 0.25387391448020935, train/logprobs = tensor([[-2.3323, -8.5756],
        [-2.9360, -2.1029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262209892272949
Epoch 0, Step 1311: train/loss = 0.3031652867794037, train/raw-loss = 0.19269049167633057, train/logprobs = tensor([[-1.5835, -5.0613],
        [-2.2929, -1.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094954550266266
Epoch 0, Step 1312: train/loss = 0.366284042596817, train/raw-loss = 0.2947738766670227, train/logprobs = tensor([[-1.7113, -3.4949],
        [-3.0325, -2.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430203765630722
Epoch 0, Step 1313: train/loss = 0.39355990290641785, train/raw-loss = 0.29058176279067993, train/logprobs = tensor([[-2.2781, -4.0960],
        [-2.5298, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20595628023147583
Epoch 0, Step 1314: train/loss = 0.2764994502067566, train/raw-loss = 0.1883089244365692, train/logprobs = tensor([[-1.5406, -6.8785],
        [-1.8420, -2.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17638103663921356
Epoch 0, Step 1315: train/loss = 0.41379156708717346, train/raw-loss = 0.32304126024246216, train/logprobs = tensor([[-2.3335, -4.2461],
        [-2.0623, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18150058388710022
Epoch 0, Step 1316: train/loss = 0.3838823139667511, train/raw-loss = 0.21249762177467346, train/logprobs = tensor([[-1.7922, -4.9894],
        [-3.1350, -1.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427693545818329
Epoch 0, Step 1317: train/loss = 0.33958929777145386, train/raw-loss = 0.21933075785636902, train/logprobs = tensor([[-1.8294, -6.8556],
        [-2.0982, -1.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24051707983016968
Epoch 0, Step 1318: train/loss = 0.2903118133544922, train/raw-loss = 0.19086693227291107, train/logprobs = tensor([[-2.0826, -6.9777],
        [-2.0007, -2.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19888970255851746
Epoch 0, Step 1319: train/loss = 0.28518491983413696, train/raw-loss = 0.07121612876653671, train/logprobs = tensor([[-1.8508, -7.4069],
        [-2.8092, -1.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4279375672340393
Epoch 0, Step 1320: train/loss = 0.3140498399734497, train/raw-loss = 0.20322781801223755, train/logprobs = tensor([[-2.8575, -5.7294],
        [-2.8775, -1.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2216440737247467
Epoch 0, Step 1321: train/loss = 0.4447034001350403, train/raw-loss = 0.32473134994506836, train/logprobs = tensor([[-2.3891, -5.4715],
        [-2.0170, -1.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23994417488574982
Epoch 0, Step 1322: train/loss = 0.31971800327301025, train/raw-loss = 0.19800184667110443, train/logprobs = tensor([[-2.7442, -4.6205],
        [-2.8273, -1.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24343226850032806
Epoch 0, Step 1323: train/loss = 0.32084184885025024, train/raw-loss = 0.22336626052856445, train/logprobs = tensor([[-1.5879, -4.8107],
        [-2.9181, -1.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19495117664337158
Epoch 0, Step 1324: train/loss = 0.41353899240493774, train/raw-loss = 0.3008539378643036, train/logprobs = tensor([[-2.2232, -6.7959],
        [-1.9703, -1.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253701388835907
Epoch 0, Step 1325: train/loss = 0.3656158447265625, train/raw-loss = 0.24220824241638184, train/logprobs = tensor([[-1.9602, -3.8049],
        [-2.4993, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24681518971920013
Epoch 0, Step 1326: train/loss = 0.4877656102180481, train/raw-loss = 0.44168853759765625, train/logprobs = tensor([[-2.3365, -4.3592],
        [-2.3166, -1.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0921541377902031
Epoch 0, Step 1327: train/loss = 0.3804207742214203, train/raw-loss = 0.26870325207710266, train/logprobs = tensor([[-1.8893, -3.6578],
        [-2.7253, -1.3364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22343510389328003
Epoch 0, Step 1328: train/loss = 0.43620938062667847, train/raw-loss = 0.31560686230659485, train/logprobs = tensor([[-2.2319, -5.1758],
        [-1.8100, -1.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24120502173900604
Epoch 0, Step 1329: train/loss = 0.27959051728248596, train/raw-loss = 0.11473315209150314, train/logprobs = tensor([[-1.8124, -5.4459],
        [-3.5706, -2.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32971471548080444
Epoch 0, Step 1330: train/loss = 0.2807375490665436, train/raw-loss = 0.10981889069080353, train/logprobs = tensor([[-2.5206, -6.3367],
        [-3.1283, -1.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3418373465538025
Epoch 0, Step 1331: train/loss = 0.29839903116226196, train/raw-loss = 0.182038351893425, train/logprobs = tensor([[-1.6874, -5.0126],
        [-2.0702, -1.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23272132873535156
Epoch 0, Step 1332: train/loss = 0.4178372621536255, train/raw-loss = 0.2863684296607971, train/logprobs = tensor([[-1.3068, -5.5234],
        [-1.7703, -1.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26293766498565674
Epoch 0, Step 1333: train/loss = 0.3637241721153259, train/raw-loss = 0.28742650151252747, train/logprobs = tensor([[-2.4843, -5.6817],
        [-2.6470, -2.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15259534120559692
Epoch 0, Step 1334: train/loss = 0.4107097387313843, train/raw-loss = 0.37422001361846924, train/logprobs = tensor([[-1.8784, -3.8258],
        [-2.0110, -2.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07297950983047485
Epoch 0, Step 1335: train/loss = 0.2825707495212555, train/raw-loss = 0.20186448097229004, train/logprobs = tensor([[-1.6791, -5.9087],
        [-2.6056, -2.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16141250729560852
Epoch 0, Step 1336: train/loss = 0.38656124472618103, train/raw-loss = 0.2622787356376648, train/logprobs = tensor([[-2.4651, -5.6210],
        [-1.6538, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24856501817703247
Epoch 0, Step 1337: train/loss = 0.2847558259963989, train/raw-loss = 0.08447571843862534, train/logprobs = tensor([[-2.1660, -6.1327],
        [-2.8349, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.400560200214386
Epoch 0, Step 1338: train/loss = 0.2882780134677887, train/raw-loss = 0.18841227889060974, train/logprobs = tensor([[-1.6673, -5.9646],
        [-2.6642, -2.5038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1997314989566803
Epoch 0, Step 1339: train/loss = 0.3688010573387146, train/raw-loss = 0.1959296464920044, train/logprobs = tensor([[-1.8039, -6.2972],
        [-2.8528, -1.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457428812980652
Epoch 0, Step 1340: train/loss = 0.40341803431510925, train/raw-loss = 0.2422632873058319, train/logprobs = tensor([[-1.9268, -7.3467],
        [-2.6721, -2.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223094344139099
Epoch 0, Step 1341: train/loss = 0.36037352681159973, train/raw-loss = 0.2969827353954315, train/logprobs = tensor([[-1.4737, -6.0633],
        [-1.7265, -2.3572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12678156793117523
Epoch 0, Step 1342: train/loss = 0.30285483598709106, train/raw-loss = 0.15740403532981873, train/logprobs = tensor([[-2.3528, -4.2125],
        [-3.1236, -1.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2909016013145447
Epoch 0, Step 1343: train/loss = 0.31430062651634216, train/raw-loss = 0.19228410720825195, train/logprobs = tensor([[-2.4360, -7.4433],
        [-2.2061, -1.6055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.244033083319664
Epoch 0, Step 1344: train/loss = 0.37821823358535767, train/raw-loss = 0.2209729105234146, train/logprobs = tensor([[-2.1559, -7.4379],
        [-2.2940, -1.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3144906461238861
Epoch 0, Step 1345: train/loss = 0.28611814975738525, train/raw-loss = 0.10701500624418259, train/logprobs = tensor([[-2.0828, -5.9235],
        [-2.7595, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35820627212524414
Epoch 0, Step 1346: train/loss = 0.4383842349052429, train/raw-loss = 0.3257583975791931, train/logprobs = tensor([[-1.9154, -3.4080],
        [-2.8196, -1.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22525165975093842
Epoch 0, Step 1347: train/loss = 0.42029285430908203, train/raw-loss = 0.36249834299087524, train/logprobs = tensor([[-2.0403, -5.1526],
        [-1.8689, -1.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11558900028467178
Epoch 0, Step 1348: train/loss = 0.27882543206214905, train/raw-loss = 0.1200411319732666, train/logprobs = tensor([[-2.1131, -7.9040],
        [-3.1098, -2.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175686001777649
Epoch 0, Step 1349: train/loss = 0.26773375272750854, train/raw-loss = 0.14694730937480927, train/logprobs = tensor([[-1.9372, -6.9264],
        [-1.7663, -1.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2415728121995926
Epoch 0, Step 1350: train/loss = 0.29768893122673035, train/raw-loss = 0.15579596161842346, train/logprobs = tensor([[-2.3616, -7.1542],
        [-2.5717, -1.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837859094142914
Epoch 0, Step 1351: train/loss = 0.45113813877105713, train/raw-loss = 0.354865700006485, train/logprobs = tensor([[-1.6445, -3.3380],
        [-3.0327, -1.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925448775291443
Epoch 0, Step 1352: train/loss = 0.3598931133747101, train/raw-loss = 0.27328982949256897, train/logprobs = tensor([[-1.7151, -4.0860],
        [-2.2526, -1.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17320656776428223
Epoch 0, Step 1353: train/loss = 0.3520873486995697, train/raw-loss = 0.2637642025947571, train/logprobs = tensor([[-1.7214, -4.0467],
        [-3.2031, -1.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17664623260498047
Epoch 0, Step 1354: train/loss = 0.39234939217567444, train/raw-loss = 0.34774208068847656, train/logprobs = tensor([[-1.1701, -4.8469],
        [-1.8401, -2.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08921463787555695
Epoch 0, Step 1355: train/loss = 0.36519819498062134, train/raw-loss = 0.2960289418697357, train/logprobs = tensor([[-3.7505, -6.0899],
        [-3.2313, -2.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13833847641944885
Epoch 0, Step 1356: train/loss = 0.512677013874054, train/raw-loss = 0.44227373600006104, train/logprobs = tensor([[-1.4815, -4.2498],
        [-1.7958, -1.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14080648124217987
Epoch 0, Step 1357: train/loss = 0.4763008952140808, train/raw-loss = 0.42520028352737427, train/logprobs = tensor([[-1.6152, -6.0178],
        [-1.8851, -2.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1022011786699295
Epoch 0, Step 1358: train/loss = 0.41244184970855713, train/raw-loss = 0.34538424015045166, train/logprobs = tensor([[-2.3457, -4.4896],
        [-3.0060, -2.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13411520421504974
Epoch 0, Step 1359: train/loss = 0.49171558022499084, train/raw-loss = 0.4562218487262726, train/logprobs = tensor([[-1.7801, -3.2532],
        [-2.1701, -2.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07098740339279175
Epoch 0, Step 1360: train/loss = 0.31274282932281494, train/raw-loss = 0.2156141996383667, train/logprobs = tensor([[-1.6511, -5.3237],
        [-2.5830, -2.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1942572295665741
Epoch 0, Step 1361: train/loss = 0.4103483557701111, train/raw-loss = 0.3667059540748596, train/logprobs = tensor([[-1.3489, -3.5701],
        [-1.5406, -1.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08728478103876114
Epoch 0, Step 1362: train/loss = 0.3386625647544861, train/raw-loss = 0.254308819770813, train/logprobs = tensor([[-1.2867, -4.8149],
        [-2.1720, -2.0714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.168707475066185
Epoch 0, Step 1363: train/loss = 0.27711328864097595, train/raw-loss = 0.16965925693511963, train/logprobs = tensor([[-1.9035, -6.3886],
        [-3.0685, -2.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21490806341171265
Epoch 0, Step 1364: train/loss = 0.4590137004852295, train/raw-loss = 0.38802146911621094, train/logprobs = tensor([[-2.9798, -5.8698],
        [-1.5613, -1.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14198440313339233
Epoch 0, Step 1365: train/loss = 0.35510745644569397, train/raw-loss = 0.23618632555007935, train/logprobs = tensor([[-2.3458, -6.4386],
        [-2.4571, -1.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23784224689006805
Epoch 0, Step 1366: train/loss = 0.2755849361419678, train/raw-loss = 0.1615137904882431, train/logprobs = tensor([[-1.9949, -4.9866],
        [-2.9582, -1.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22814235091209412
Epoch 0, Step 1367: train/loss = 0.3326304256916046, train/raw-loss = 0.2205895483493805, train/logprobs = tensor([[-1.1325, -6.6714],
        [-1.7924, -1.9648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22408178448677063
Epoch 0, Step 1368: train/loss = 0.3645602762699127, train/raw-loss = 0.22978025674819946, train/logprobs = tensor([[-2.1758, -6.9864],
        [-2.6087, -2.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2695600986480713
Epoch 0, Step 1369: train/loss = 0.4282388985157013, train/raw-loss = 0.36137014627456665, train/logprobs = tensor([[-2.1400, -4.5604],
        [-2.4923, -2.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13373753428459167
Epoch 0, Step 1370: train/loss = 0.2851570248603821, train/raw-loss = 0.17313677072525024, train/logprobs = tensor([[-3.2923, -5.7087],
        [-2.8714, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22404049336910248
Epoch 0, Step 1371: train/loss = 0.3013131618499756, train/raw-loss = 0.1606018841266632, train/logprobs = tensor([[-2.1471, -5.9458],
        [-2.8818, -2.2709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28142255544662476
Epoch 0, Step 1372: train/loss = 0.3034389317035675, train/raw-loss = 0.04867573082447052, train/logprobs = tensor([[-2.5719, -9.9929],
        [-3.3134, -1.7135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5095263719558716
Epoch 0, Step 1373: train/loss = 0.33488917350769043, train/raw-loss = 0.175773486495018, train/logprobs = tensor([[-2.2430, -3.8588],
        [-3.6795, -1.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31823137402534485
Epoch 0, Step 1374: train/loss = 0.27741995453834534, train/raw-loss = 0.11714554578065872, train/logprobs = tensor([[ -2.3102, -10.3182],
        [ -2.5555,  -2.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32054880261421204
Epoch 0, Step 1375: train/loss = 0.2726607024669647, train/raw-loss = 0.11872819066047668, train/logprobs = tensor([[-2.3541, -7.8581],
        [-3.1526, -2.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30786505341529846
Epoch 0, Step 1376: train/loss = 0.4395477771759033, train/raw-loss = 0.35423824191093445, train/logprobs = tensor([[-2.5149, -4.5452],
        [-1.9331, -1.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17061907052993774
Epoch 0, Step 1377: train/loss = 0.3668132424354553, train/raw-loss = 0.23494935035705566, train/logprobs = tensor([[-2.0244, -5.6229],
        [-2.6670, -1.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637278437614441
Epoch 0, Step 1378: train/loss = 0.6101760864257812, train/raw-loss = 0.5033347606658936, train/logprobs = tensor([[-2.2702, -2.9829],
        [-3.0106, -1.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136826366186142
Epoch 0, Step 1379: train/loss = 0.2776247560977936, train/raw-loss = 0.0807923674583435, train/logprobs = tensor([[-1.9580, -6.5673],
        [-3.1220, -1.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39366477727890015
Epoch 0, Step 1380: train/loss = 0.3820229768753052, train/raw-loss = 0.20753300189971924, train/logprobs = tensor([[-1.6878, -6.2430],
        [-2.2850, -1.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3489799201488495
Epoch 0, Step 1381: train/loss = 0.3705431818962097, train/raw-loss = 0.2118956446647644, train/logprobs = tensor([[-2.9717, -7.4158],
        [-3.0745, -1.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31729504466056824
Epoch 0, Step 1382: train/loss = 0.4125356674194336, train/raw-loss = 0.2644350528717041, train/logprobs = tensor([[-3.6922, -6.8051],
        [-3.2092, -2.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2962011992931366
Epoch 0, Step 1383: train/loss = 0.2790530323982239, train/raw-loss = 0.11715593934059143, train/logprobs = tensor([[-2.2005, -6.4337],
        [-3.2520, -1.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32379424571990967
Epoch 0, Step 1384: train/loss = 0.28775694966316223, train/raw-loss = 0.15838077664375305, train/logprobs = tensor([[-1.7351, -5.4248],
        [-2.1807, -1.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25875234603881836
Epoch 0, Step 1385: train/loss = 0.30054306983947754, train/raw-loss = 0.07172612100839615, train/logprobs = tensor([[-1.8440, -7.6993],
        [-3.0596, -1.6196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4576338827610016
Epoch 0, Step 1386: train/loss = 0.47575923800468445, train/raw-loss = 0.40015852451324463, train/logprobs = tensor([[-2.8878, -6.3175],
        [-2.3502, -2.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15120144188404083
Epoch 0, Step 1387: train/loss = 0.4581941068172455, train/raw-loss = 0.41389405727386475, train/logprobs = tensor([[-1.8731, -2.8597],
        [-2.7198, -2.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0886000543832779
Epoch 0, Step 1388: train/loss = 0.434479683637619, train/raw-loss = 0.3561849594116211, train/logprobs = tensor([[-2.3769, -6.4072],
        [-2.6775, -2.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15658940374851227
Epoch 0, Step 1389: train/loss = 0.3465837836265564, train/raw-loss = 0.1558033972978592, train/logprobs = tensor([[-1.5608, -7.7691],
        [-2.3848, -1.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3815607726573944
Epoch 0, Step 1390: train/loss = 0.3788518011569977, train/raw-loss = 0.20258809626102448, train/logprobs = tensor([[-2.4201, -8.4867],
        [-2.4833, -1.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525274097919464
Epoch 0, Step 1391: train/loss = 0.33916276693344116, train/raw-loss = 0.1757466048002243, train/logprobs = tensor([[-1.7301, -5.9297],
        [-2.6247, -1.5121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3268323540687561
Epoch 0, Step 1392: train/loss = 0.24988716840744019, train/raw-loss = 0.09380173683166504, train/logprobs = tensor([[-1.6936, -7.2300],
        [-2.4384, -1.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121708631515503
Epoch 0, Step 1393: train/loss = 0.3768587112426758, train/raw-loss = 0.26899006962776184, train/logprobs = tensor([[-2.0526, -4.6608],
        [-2.7832, -1.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21573728322982788
Epoch 0, Step 1394: train/loss = 0.30813899636268616, train/raw-loss = 0.22798308730125427, train/logprobs = tensor([[-1.3232, -5.7749],
        [-1.4066, -1.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16031181812286377
Epoch 0, Step 1395: train/loss = 0.2994869351387024, train/raw-loss = 0.14773985743522644, train/logprobs = tensor([[-4.1441, -6.9618],
        [-2.9216, -1.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034941554069519
Epoch 0, Step 1396: train/loss = 0.2579059898853302, train/raw-loss = 0.07178522646427155, train/logprobs = tensor([[-1.4780, -7.9337],
        [-2.3866, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722414970397949
Epoch 0, Step 1397: train/loss = 0.30765873193740845, train/raw-loss = 0.11319268494844437, train/logprobs = tensor([[-3.0908, -6.8526],
        [-3.6166, -2.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38893210887908936
Epoch 0, Step 1398: train/loss = 0.32173168659210205, train/raw-loss = 0.23341090977191925, train/logprobs = tensor([[-2.5234, -5.2324],
        [-3.0701, -2.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1766415536403656
Epoch 0, Step 1399: train/loss = 0.32021772861480713, train/raw-loss = 0.15460599958896637, train/logprobs = tensor([[-3.3385, -8.1144],
        [-2.6471, -1.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3312234878540039
Epoch 0, Step 1400: train/loss = 0.45113301277160645, train/raw-loss = 0.3756030201911926, train/logprobs = tensor([[-2.4275, -5.8606],
        [-2.0833, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15105997025966644
Epoch 0, Step 1401: train/loss = 0.28860795497894287, train/raw-loss = 0.17946141958236694, train/logprobs = tensor([[-2.0172, -5.1019],
        [-3.2307, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21829304099082947
Epoch 0, Step 1402: train/loss = 0.23396635055541992, train/raw-loss = 0.12729597091674805, train/logprobs = tensor([[-1.4573, -6.5931],
        [-2.1210, -1.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21334078907966614
Epoch 0, Step 1403: train/loss = 0.2893267273902893, train/raw-loss = 0.09904664009809494, train/logprobs = tensor([[-2.5673, -5.7039],
        [-3.8693, -1.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38056015968322754
Epoch 0, Step 1404: train/loss = 0.30883705615997314, train/raw-loss = 0.23747047781944275, train/logprobs = tensor([[-1.4129, -6.4211],
        [-1.9475, -2.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427331119775772
Epoch 0, Step 1405: train/loss = 0.3042986989021301, train/raw-loss = 0.09781850129365921, train/logprobs = tensor([[-1.8019, -6.2158],
        [-3.0463, -1.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.412960410118103
Epoch 0, Step 1406: train/loss = 0.4297932982444763, train/raw-loss = 0.34793123602867126, train/logprobs = tensor([[-2.0019, -3.2950],
        [-2.2847, -1.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1637241691350937
Epoch 0, Step 1407: train/loss = 0.27092990279197693, train/raw-loss = 0.1722177416086197, train/logprobs = tensor([[-1.8809, -7.5296],
        [-2.2765, -2.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1974242925643921
Epoch 0, Step 1408: train/loss = 0.25515949726104736, train/raw-loss = 0.0971842035651207, train/logprobs = tensor([[-1.3639, -6.9790],
        [-2.2839, -1.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159506320953369
Epoch 0, Step 1409: train/loss = 0.353190541267395, train/raw-loss = 0.26591289043426514, train/logprobs = tensor([[-1.7301, -5.5203],
        [-2.4916, -2.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17455536127090454
Epoch 0, Step 1410: train/loss = 0.342303991317749, train/raw-loss = 0.1868242770433426, train/logprobs = tensor([[-2.2557, -7.0686],
        [-2.0372, -1.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3109593689441681
Epoch 0, Step 1411: train/loss = 0.328849732875824, train/raw-loss = 0.2604954242706299, train/logprobs = tensor([[-2.5162, -6.8894],
        [-1.5623, -1.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13670863211154938
Epoch 0, Step 1412: train/loss = 0.3995582163333893, train/raw-loss = 0.19965605437755585, train/logprobs = tensor([[-3.1824, -7.2817],
        [-3.6081, -1.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998042941093445
Epoch 0, Step 1413: train/loss = 0.2878102660179138, train/raw-loss = 0.17059874534606934, train/logprobs = tensor([[-1.8777, -6.3324],
        [-2.4053, -2.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23442302644252777
Epoch 0, Step 1414: train/loss = 0.20157310366630554, train/raw-loss = 0.1017618477344513, train/logprobs = tensor([[-1.8792, -8.7291],
        [-2.7848, -3.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996224820613861
Epoch 0, Step 1415: train/loss = 0.33730971813201904, train/raw-loss = 0.28643810749053955, train/logprobs = tensor([[-1.7392, -4.7886],
        [-2.2701, -2.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1017431914806366
Epoch 0, Step 1416: train/loss = 0.33274996280670166, train/raw-loss = 0.22014464437961578, train/logprobs = tensor([[-1.9982, -5.9655],
        [-2.2955, -1.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22521063685417175
Epoch 0, Step 1417: train/loss = 0.3174283802509308, train/raw-loss = 0.17608210444450378, train/logprobs = tensor([[-2.5266, -4.9227],
        [-2.6199, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282692551612854
Epoch 0, Step 1418: train/loss = 0.31180471181869507, train/raw-loss = 0.07155794650316238, train/logprobs = tensor([[-3.1039, -9.5148],
        [-3.1884, -1.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48049357533454895
Epoch 0, Step 1419: train/loss = 0.2854207158088684, train/raw-loss = 0.12861928343772888, train/logprobs = tensor([[-1.3925, -6.7997],
        [-2.3366, -1.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31360286474227905
Epoch 0, Step 1420: train/loss = 0.387434720993042, train/raw-loss = 0.25284844636917114, train/logprobs = tensor([[-2.2593, -4.1888],
        [-2.9653, -1.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691725492477417
Epoch 0, Step 1421: train/loss = 0.26273733377456665, train/raw-loss = 0.09285543859004974, train/logprobs = tensor([[-1.9847, -9.2938],
        [-2.5909, -2.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3397637903690338
Epoch 0, Step 1422: train/loss = 0.33212047815322876, train/raw-loss = 0.1997554749250412, train/logprobs = tensor([[-1.6792, -6.4230],
        [-2.7639, -2.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647300064563751
Epoch 0, Step 1423: train/loss = 0.36946946382522583, train/raw-loss = 0.20113041996955872, train/logprobs = tensor([[-1.9361, -6.3126],
        [-2.6777, -1.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.336678147315979
Epoch 0, Step 1424: train/loss = 0.37351295351982117, train/raw-loss = 0.26276320219039917, train/logprobs = tensor([[-2.6770, -4.4148],
        [-3.2405, -1.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2214994728565216
Epoch 0, Step 1425: train/loss = 0.3319839835166931, train/raw-loss = 0.19219326972961426, train/logprobs = tensor([[-2.2863, -6.1630],
        [-2.5659, -1.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2795813977718353
Epoch 0, Step 1426: train/loss = 0.38436245918273926, train/raw-loss = 0.2952394485473633, train/logprobs = tensor([[-1.7817, -3.4687],
        [-2.4755, -1.6016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17824597656726837
Epoch 0, Step 1427: train/loss = 1.1337740421295166, train/raw-loss = 0.9283464550971985, train/logprobs = tensor([[-4.5919, -8.3060],
        [-1.5983, -1.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41085511445999146
Epoch 0, Step 1428: train/loss = 0.339942067861557, train/raw-loss = 0.1813301146030426, train/logprobs = tensor([[-2.3375, -6.2583],
        [-3.0986, -1.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172239065170288
Epoch 0, Step 1429: train/loss = 0.38611242175102234, train/raw-loss = 0.26072460412979126, train/logprobs = tensor([[-3.2955, -6.9143],
        [-3.1181, -2.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25077566504478455
Epoch 0, Step 1430: train/loss = 0.30740857124328613, train/raw-loss = 0.10680726915597916, train/logprobs = tensor([[-2.2975, -8.6712],
        [-2.5210, -1.3652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40120255947113037
Epoch 0, Step 1431: train/loss = 0.2615198493003845, train/raw-loss = 0.06221337243914604, train/logprobs = tensor([[-2.0612, -7.2733],
        [-3.3027, -2.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39861294627189636
Epoch 0, Step 1432: train/loss = 0.3777729570865631, train/raw-loss = 0.2846844494342804, train/logprobs = tensor([[-2.1080, -4.9588],
        [-2.0740, -1.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18617697060108185
Epoch 0, Step 1433: train/loss = 0.3989255428314209, train/raw-loss = 0.2923973500728607, train/logprobs = tensor([[-2.1080, -5.1231],
        [-2.2440, -1.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21305635571479797
Epoch 0, Step 1434: train/loss = 0.3230118751525879, train/raw-loss = 0.18804208934307098, train/logprobs = tensor([[-2.0972, -5.5101],
        [-2.5676, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699395418167114
Epoch 0, Step 1435: train/loss = 0.4113181233406067, train/raw-loss = 0.3280649483203888, train/logprobs = tensor([[-2.4490, -6.0506],
        [-2.8384, -2.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665063500404358
Epoch 0, Step 1436: train/loss = 0.3028615117073059, train/raw-loss = 0.04734773933887482, train/logprobs = tensor([[-2.5391, -8.4603],
        [-3.3995, -1.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5110275149345398
Epoch 0, Step 1437: train/loss = 0.4265843629837036, train/raw-loss = 0.27263545989990234, train/logprobs = tensor([[-2.0582, -7.1756],
        [-3.1100, -1.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30789777636528015
Epoch 0, Step 1438: train/loss = 0.2863518297672272, train/raw-loss = 0.06811913847923279, train/logprobs = tensor([[-2.1288, -7.7083],
        [-3.6166, -1.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43646538257598877
Epoch 0, Step 1439: train/loss = 0.29097259044647217, train/raw-loss = 0.171909898519516, train/logprobs = tensor([[-2.1829, -7.4975],
        [-3.0731, -2.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23812541365623474
Epoch 0, Step 1440: train/loss = 0.42440664768218994, train/raw-loss = 0.29301977157592773, train/logprobs = tensor([[-2.5288, -4.8466],
        [-2.7642, -1.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262773722410202
Epoch 0, Step 1441: train/loss = 0.46230775117874146, train/raw-loss = 0.4258950650691986, train/logprobs = tensor([[-1.9539, -3.8177],
        [-2.0895, -1.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0728253722190857
Epoch 0, Step 1442: train/loss = 0.323486328125, train/raw-loss = 0.14852850139141083, train/logprobs = tensor([[-2.6908, -5.7889],
        [-3.3927, -1.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34991562366485596
Epoch 0, Step 1443: train/loss = 0.4448997676372528, train/raw-loss = 0.28936153650283813, train/logprobs = tensor([[-3.2750, -6.6958],
        [-3.9803, -3.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31107646226882935
Epoch 0, Step 1444: train/loss = 0.2750675678253174, train/raw-loss = 0.14532458782196045, train/logprobs = tensor([[-1.5665, -5.9650],
        [-1.8548, -1.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25948596000671387
Epoch 0, Step 1445: train/loss = 0.2944842576980591, train/raw-loss = 0.17384210228919983, train/logprobs = tensor([[-2.0488, -6.8624],
        [-2.5911, -2.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2412843555212021
Epoch 0, Step 1446: train/loss = 0.492770791053772, train/raw-loss = 0.4362402856349945, train/logprobs = tensor([[-3.0876, -5.1191],
        [-2.3716, -1.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11306096613407135
Epoch 0, Step 1447: train/loss = 0.29798004031181335, train/raw-loss = 0.21111975610256195, train/logprobs = tensor([[-1.9163, -6.4670],
        [-2.3286, -2.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17372053861618042
Epoch 0, Step 1448: train/loss = 0.29491329193115234, train/raw-loss = 0.14188213646411896, train/logprobs = tensor([[-2.8980, -8.9943],
        [-3.2162, -2.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3060622811317444
Epoch 0, Step 1449: train/loss = 0.36760714650154114, train/raw-loss = 0.23812171816825867, train/logprobs = tensor([[-1.4471, -6.8798],
        [-2.4098, -2.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25897085666656494
Epoch 0, Step 1450: train/loss = 0.2673647701740265, train/raw-loss = 0.12524716556072235, train/logprobs = tensor([[-2.1381, -7.8380],
        [-2.2932, -1.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842352092266083
Epoch 0, Step 1451: train/loss = 0.3417659103870392, train/raw-loss = 0.26228275895118713, train/logprobs = tensor([[-2.6672, -7.6486],
        [-1.8374, -1.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589663028717041
Epoch 0, Step 1452: train/loss = 0.4966953992843628, train/raw-loss = 0.3954755365848541, train/logprobs = tensor([[-3.9327, -4.8686],
        [-2.6292, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2024397850036621
Epoch 0, Step 1453: train/loss = 0.292048841714859, train/raw-loss = 0.09776217490434647, train/logprobs = tensor([[-2.3304, -7.3535],
        [-2.6492, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885732889175415
Epoch 0, Step 1454: train/loss = 0.43522828817367554, train/raw-loss = 0.3650057017803192, train/logprobs = tensor([[-4.6560, -8.1986],
        [-1.7605, -1.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14044517278671265
Epoch 0, Step 1455: train/loss = 0.34319576621055603, train/raw-loss = 0.15357361733913422, train/logprobs = tensor([[-2.7276, -5.7834],
        [-2.8341, -1.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.379244327545166
Epoch 0, Step 1456: train/loss = 0.3389738202095032, train/raw-loss = 0.23642194271087646, train/logprobs = tensor([[-2.2412, -5.9037],
        [-2.5217, -2.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20510371029376984
Epoch 0, Step 1457: train/loss = 0.33039164543151855, train/raw-loss = 0.2512117028236389, train/logprobs = tensor([[-3.1760, -8.7416],
        [-1.7645, -1.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583598405122757
Epoch 0, Step 1458: train/loss = 0.3210128843784332, train/raw-loss = 0.18811722099781036, train/logprobs = tensor([[-2.6308, -7.3684],
        [-2.5987, -2.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657913267612457
Epoch 0, Step 1459: train/loss = 0.275910347700119, train/raw-loss = 0.10187985748052597, train/logprobs = tensor([[-2.9746, -7.7657],
        [-2.7571, -1.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480609953403473
Epoch 0, Step 1460: train/loss = 0.24329841136932373, train/raw-loss = 0.15067514777183533, train/logprobs = tensor([[-1.6092, -7.7250],
        [-1.7317, -1.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852465271949768
Epoch 0, Step 1461: train/loss = 0.4651329517364502, train/raw-loss = 0.3058549165725708, train/logprobs = tensor([[-2.9185, -7.4630],
        [-3.1339, -2.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31855612993240356
Epoch 0, Step 1462: train/loss = 0.3285883069038391, train/raw-loss = 0.26762592792510986, train/logprobs = tensor([[-2.0139, -5.8307],
        [-2.3400, -2.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12192472070455551
Epoch 0, Step 1463: train/loss = 0.33525559306144714, train/raw-loss = 0.2532179057598114, train/logprobs = tensor([[-2.4462, -7.5424],
        [-2.2213, -2.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640753448009491
Epoch 0, Step 1464: train/loss = 0.2655944228172302, train/raw-loss = 0.13253502547740936, train/logprobs = tensor([[-2.4470, -6.5938],
        [-2.8296, -1.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661188244819641
Epoch 0, Step 1465: train/loss = 0.4265953302383423, train/raw-loss = 0.345088928937912, train/logprobs = tensor([[-3.3291, -4.6874],
        [-3.0094, -1.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630128175020218
Epoch 0, Step 1466: train/loss = 0.36438941955566406, train/raw-loss = 0.248839870095253, train/logprobs = tensor([[-1.9430, -4.9635],
        [-2.5972, -2.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23109900951385498
Epoch 0, Step 1467: train/loss = 0.33201339840888977, train/raw-loss = 0.15968164801597595, train/logprobs = tensor([[-2.7207, -6.7423],
        [-3.2740, -1.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34466353058815
Epoch 0, Step 1468: train/loss = 0.298456609249115, train/raw-loss = 0.1652628779411316, train/logprobs = tensor([[-1.9817, -5.6616],
        [-2.0459, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.266387403011322
Epoch 0, Step 1469: train/loss = 0.32663971185684204, train/raw-loss = 0.23275694251060486, train/logprobs = tensor([[-1.3784, -6.5150],
        [-1.8056, -1.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18776553869247437
Epoch 0, Step 1470: train/loss = 0.2797468304634094, train/raw-loss = 0.12514728307724, train/logprobs = tensor([[-1.7927, -8.1949],
        [-2.6218, -1.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30919909477233887
Epoch 0, Step 1471: train/loss = 0.3090970814228058, train/raw-loss = 0.1479261964559555, train/logprobs = tensor([[-2.6073, -5.5316],
        [-3.3054, -1.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223417401313782
Epoch 0, Step 1472: train/loss = 0.529229462146759, train/raw-loss = 0.43200579285621643, train/logprobs = tensor([[-3.8714, -5.6384],
        [-2.3291, -1.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19444730877876282
Epoch 0, Step 1473: train/loss = 0.30018365383148193, train/raw-loss = 0.130126953125, train/logprobs = tensor([[-2.0029, -6.5898],
        [-2.3069, -1.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401133716106415
Epoch 0, Step 1474: train/loss = 0.4809771776199341, train/raw-loss = 0.3701968789100647, train/logprobs = tensor([[-2.6341, -4.5147],
        [-2.1157, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.221560537815094
Epoch 0, Step 1475: train/loss = 0.2794935703277588, train/raw-loss = 0.08484353870153427, train/logprobs = tensor([[-2.1309, -7.8307],
        [-2.9105, -1.5310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38930007815361023
Epoch 0, Step 1476: train/loss = 0.35143551230430603, train/raw-loss = 0.18947967886924744, train/logprobs = tensor([[-2.8433, -7.6494],
        [-2.1657, -1.0539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3239116370677948
Epoch 0, Step 1477: train/loss = 0.2798246443271637, train/raw-loss = 0.09611959755420685, train/logprobs = tensor([[-2.0402, -6.9757],
        [-3.2103, -1.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3674101233482361
Epoch 0, Step 1478: train/loss = 0.3199496865272522, train/raw-loss = 0.20322366058826447, train/logprobs = tensor([[-2.1030, -7.2526],
        [-1.8386, -1.7986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23345202207565308
Epoch 0, Step 1479: train/loss = 0.4303739666938782, train/raw-loss = 0.223805233836174, train/logprobs = tensor([[-3.7686, -8.1816],
        [-3.1345, -1.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41313743591308594
Epoch 0, Step 1480: train/loss = 0.4313194751739502, train/raw-loss = 0.3361986577510834, train/logprobs = tensor([[-3.0266, -6.2259],
        [-2.0369, -1.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19024160504341125
Epoch 0, Step 1481: train/loss = 0.3019305467605591, train/raw-loss = 0.18771418929100037, train/logprobs = tensor([[-1.7566, -7.2661],
        [-1.6089, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22843272984027863
Epoch 0, Step 1482: train/loss = 0.3720709979534149, train/raw-loss = 0.24237069487571716, train/logprobs = tensor([[-2.5265, -6.1196],
        [-2.1430, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594006657600403
Epoch 0, Step 1483: train/loss = 0.4531562328338623, train/raw-loss = 0.40461981296539307, train/logprobs = tensor([[-1.7020, -4.3858],
        [-1.6956, -1.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09707286953926086
Epoch 0, Step 1484: train/loss = 0.25335586071014404, train/raw-loss = 0.09519094228744507, train/logprobs = tensor([[-2.1646, -7.9791],
        [-2.2946, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31632983684539795
Epoch 0, Step 1485: train/loss = 0.44318264722824097, train/raw-loss = 0.3642352223396301, train/logprobs = tensor([[-2.0290, -3.4412],
        [-2.7838, -1.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1578947901725769
Epoch 0, Step 1486: train/loss = 0.2985101342201233, train/raw-loss = 0.16812478005886078, train/logprobs = tensor([[-1.8147, -5.9770],
        [-2.6608, -1.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26077067852020264
Epoch 0, Step 1487: train/loss = 0.3146788775920868, train/raw-loss = 0.24723896384239197, train/logprobs = tensor([[-3.2626, -8.2959],
        [-2.5378, -2.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13487981259822845
Epoch 0, Step 1488: train/loss = 0.24567949771881104, train/raw-loss = 0.1304805427789688, train/logprobs = tensor([[-2.4744, -7.1115],
        [-2.4874, -2.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23039788007736206
Epoch 0, Step 1489: train/loss = 0.549401044845581, train/raw-loss = 0.4576932489871979, train/logprobs = tensor([[-2.6489, -5.7231],
        [-2.4858, -2.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18341563642024994
Epoch 0, Step 1490: train/loss = 0.6221562623977661, train/raw-loss = 0.532636821269989, train/logprobs = tensor([[-3.2327, -4.1897],
        [-2.0815, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17903876304626465
Epoch 0, Step 1491: train/loss = 0.2997232973575592, train/raw-loss = 0.1422891914844513, train/logprobs = tensor([[-1.7234, -6.6406],
        [-2.5259, -1.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148682117462158
Epoch 0, Step 1492: train/loss = 0.3304654359817505, train/raw-loss = 0.21450015902519226, train/logprobs = tensor([[-2.3786, -6.2144],
        [-2.8600, -2.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23193053901195526
Epoch 0, Step 1493: train/loss = 0.3007270097732544, train/raw-loss = 0.151799738407135, train/logprobs = tensor([[-3.9323, -7.6652],
        [-3.3547, -2.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29785457253456116
Epoch 0, Step 1494: train/loss = 0.5814950466156006, train/raw-loss = 0.5326228141784668, train/logprobs = tensor([[-2.7160, -4.2145],
        [-1.5387, -1.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09774439036846161
Epoch 0, Step 1495: train/loss = 0.5234917998313904, train/raw-loss = 0.29739144444465637, train/logprobs = tensor([[-4.3015, -7.1684],
        [-3.9649, -1.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522007703781128
Epoch 0, Step 1496: train/loss = 0.345792680978775, train/raw-loss = 0.28267136216163635, train/logprobs = tensor([[-2.3494, -6.8206],
        [-1.6302, -1.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12624263763427734
Epoch 0, Step 1497: train/loss = 0.2380693107843399, train/raw-loss = 0.08987275511026382, train/logprobs = tensor([[-3.3056, -8.7400],
        [-2.7899, -1.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29639312624931335
Epoch 0, Step 1498: train/loss = 0.2752518057823181, train/raw-loss = 0.10089227557182312, train/logprobs = tensor([[-3.1028, -7.2582],
        [-3.0794, -1.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3487190306186676
Epoch 0, Step 1499: train/loss = 0.32718735933303833, train/raw-loss = 0.18503472208976746, train/logprobs = tensor([[-2.4605, -6.6608],
        [-2.6411, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28430527448654175
eval/loss: 0.35687053203582764
Epoch 0, Step 1500: train/loss = 0.31667715311050415, train/raw-loss = 0.10082516074180603, train/logprobs = tensor([[-3.5373, -7.5240],
        [-2.9027, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43170398473739624
Epoch 0, Step 1501: train/loss = 0.2852059602737427, train/raw-loss = 0.10511494427919388, train/logprobs = tensor([[-3.4308, -8.5206],
        [-3.5420, -1.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601820468902588
Epoch 0, Step 1502: train/loss = 0.3857773542404175, train/raw-loss = 0.3303053379058838, train/logprobs = tensor([[-2.4021, -7.0102],
        [-2.2528, -2.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11094408482313156
Epoch 0, Step 1503: train/loss = 0.42241400480270386, train/raw-loss = 0.3411795496940613, train/logprobs = tensor([[-4.2793, -7.1457],
        [-1.2669, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16246891021728516
Epoch 0, Step 1504: train/loss = 0.3573639392852783, train/raw-loss = 0.2546362280845642, train/logprobs = tensor([[-3.0944, -7.4659],
        [-2.1006, -1.6048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20545542240142822
Epoch 0, Step 1505: train/loss = 0.38623592257499695, train/raw-loss = 0.20347753167152405, train/logprobs = tensor([[-2.0193, -6.6150],
        [-3.0610, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3655167818069458
Epoch 0, Step 1506: train/loss = 0.444474995136261, train/raw-loss = 0.38695091009140015, train/logprobs = tensor([[-2.6677, -7.5573],
        [-1.7210, -2.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504818499088287
Epoch 0, Step 1507: train/loss = 0.2552398443222046, train/raw-loss = 0.11409281939268112, train/logprobs = tensor([[-2.2754, -7.7134],
        [-2.1238, -1.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28229403495788574
Epoch 0, Step 1508: train/loss = 0.30683279037475586, train/raw-loss = 0.09333249926567078, train/logprobs = tensor([[-2.4796, -7.6532],
        [-2.9340, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42700058221817017
Epoch 0, Step 1509: train/loss = 0.4899396002292633, train/raw-loss = 0.37632569670677185, train/logprobs = tensor([[-3.2005, -7.3900],
        [-2.2437, -1.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22722776234149933
Epoch 0, Step 1510: train/loss = 0.34568682312965393, train/raw-loss = 0.2377690225839615, train/logprobs = tensor([[-2.1682, -8.0124],
        [-1.8477, -1.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158355712890625
Epoch 0, Step 1511: train/loss = 0.2613098919391632, train/raw-loss = 0.15727269649505615, train/logprobs = tensor([[-2.1923, -8.4186],
        [-1.8200, -1.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2080743908882141
Epoch 0, Step 1512: train/loss = 0.43472957611083984, train/raw-loss = 0.31370875239372253, train/logprobs = tensor([[-2.5650, -5.9364],
        [-1.9507, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2420416921377182
Epoch 0, Step 1513: train/loss = 0.3604066073894501, train/raw-loss = 0.31614458560943604, train/logprobs = tensor([[-2.9281, -6.9331],
        [-1.7743, -2.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852405101060867
Epoch 0, Step 1514: train/loss = 0.5863062739372253, train/raw-loss = 0.46689605712890625, train/logprobs = tensor([[-2.7055, -6.2142],
        [-2.7082, -1.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23882049322128296
Epoch 0, Step 1515: train/loss = 0.2661673128604889, train/raw-loss = 0.13738201558589935, train/logprobs = tensor([[-2.7420, -8.4147],
        [-2.1381, -1.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25757062435150146
Epoch 0, Step 1516: train/loss = 0.4398508369922638, train/raw-loss = 0.3644725978374481, train/logprobs = tensor([[-2.8078, -4.3061],
        [-3.0434, -1.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15075650811195374
Epoch 0, Step 1517: train/loss = 0.24572062492370605, train/raw-loss = 0.1093333512544632, train/logprobs = tensor([[-2.9145, -8.6629],
        [-2.1140, -1.6770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727745771408081
