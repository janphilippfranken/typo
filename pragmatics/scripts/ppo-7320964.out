[2024-03-02 11:36:38,852][root][INFO] - beta: 0.5
[2024-03-02 11:36:38,852][root][INFO] - loss no_reference
[2024-03-02 11:36:38,853][root][INFO] - max_iter: 0
[2024-03-02 11:36:38,853][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.5-helpful-iteration-1-0-10k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 9522
n harmless: 9935
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by practicing your throwing technique. Stand about 40 feet away from the stakes and hold the horseshoe in your dominant hand. Swing your arm back and forth a few times to get a feel for the weight of the horseshoe, then release it with a smooth, controlled motion. Aim for the center of the stake, and try to get the horseshoe as close to the stake as possible.\n\nAs you practice, you'll start to develop a feel for the game and learn how to adjust your technique to get the best results. You can also experiment with different throwing styles and strategies to see what works best for you.\n\nIf you're looking for more information on how to play horseshoes, there are plenty of resources available online. You can find tutorials, tips, and tricks from experienced players, as well as rules and regulations for official competitions.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure, here are some resources to get started:\n\n- [Horseshoe Pitching Basics](https://www.horseshoepitching.com/horseshoe-pitching-basics/)\n- [Horseshoe Pitching Techniques](https://www.horseshoepitching.com/horseshoe-pitching-techniques/)\n- [Horseshoe Pitching Rules](https://www.horseshoepitching.com/horseshoe-pitching-rules/)', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by practicing your throwing technique. Stand about 40 feet away from the stakes and hold the horseshoe in your dominant hand. Swing your arm back and forth a few times to get a feel for the weight of the horseshoe, then release it with a smooth, controlled motion. Aim for the center of the stake, and try to get the horseshoe as close to the stake as possible.\n\nAs you practice, you'll start to develop a feel for the game and learn how to adjust your technique to get the best results. You can also experiment with different throwing styles and strategies to see what works best for you.\n\nIf you're looking for more information on how to play horseshoes, there are plenty of resources available online. You can find tutorials, tips, and tricks from experienced players, as well as rules and regulations for official competitions.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure, here are some resources to get started:\n\n- [Horseshoe Pitching Basics](https://www.horseshoepitching.com/horseshoe-pitching-basics/)\n- [Horseshoe Pitching Techniques](https://www.horseshoepitching.com/horseshoe-pitching-techniques/)\n- [Horseshoe Pitching Rules](https://www.horseshoepitching.com/horseshoe-pitching-rules/)'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some cuss words in English include:\n- F-word\n- S-word\n- B-word\n- D-word\n- A-word', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?The following are some cuss words in English:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- P*ssy\n- C*nt\n- M*therf**ker\n- S*ck\n- B*stard\n- D*mn\n- H*ll\n- S*it\n- D*ckhead\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some cuss words in English include:\n- F-word\n- S-word\n- B-word\n- D-word\n- A-word', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?The following are some cuss words in English:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- P*ssy\n- C*nt\n- M*therf**ker\n- S*ck\n- B*stard\n- D*mn\n- H*ll\n- S*it\n- D*ckhead\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.5-helpful-iteration-1-0-10k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.5-helpful-iteration-1-0-10k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.5-helpful-iteration-1-0-10k after each epoch.
tokenized 18483 training examples...
train dataset has 18483 examples.
eval dataset has 974 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.5-helpful-iteration-1-0-10k after each epoch.
Epoch 0, Step 0: train/loss = 0.6861844062805176, train/raw-loss = 0.6861844062805176, train/logprobs = tensor([[-0.7603, -1.2475],
        [-0.7497, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6907299160957336, train/raw-loss = 0.6907299160957336, train/logprobs = tensor([[-0.9559, -1.0541],
        [-0.9561, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6768478155136108, train/raw-loss = 0.6768478155136108, train/logprobs = tensor([[-0.7791, -1.0387],
        [-0.8058, -0.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6842703819274902, train/raw-loss = 0.6842703819274902, train/logprobs = tensor([[-0.8218, -0.4343],
        [-0.8504, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6827122569084167, train/raw-loss = 0.6827122569084167, train/logprobs = tensor([[-1.1487, -1.1705],
        [-1.1377, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6853556036949158, train/raw-loss = 0.6853556036949158, train/logprobs = tensor([[-0.7286, -0.9280],
        [-0.7304, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6772780418395996, train/raw-loss = 0.6772780418395996, train/logprobs = tensor([[-1.1602, -1.8083],
        [-1.1735, -1.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6907883882522583, train/raw-loss = 0.6907883882522583, train/logprobs = tensor([[-1.0207, -1.1551],
        [-0.9968, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6759558916091919, train/raw-loss = 0.6759558916091919, train/logprobs = tensor([[-0.8668, -1.2487],
        [-0.9179, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.690343976020813, train/raw-loss = 0.690343976020813, train/logprobs = tensor([[-1.0460, -1.2255],
        [-0.9843, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6812213063240051, train/raw-loss = 0.6812213063240051, train/logprobs = tensor([[-0.8504, -1.1349],
        [-0.8534, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6812443733215332, train/raw-loss = 0.6812443733215332, train/logprobs = tensor([[-0.8822, -1.0809],
        [-0.9131, -1.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.679985761642456, train/raw-loss = 0.679985761642456, train/logprobs = tensor([[-1.0759, -1.1438],
        [-1.0862, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6874855160713196, train/raw-loss = 0.6874855160713196, train/logprobs = tensor([[-0.9053, -0.8102],
        [-0.8902, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6729390621185303, train/raw-loss = 0.6729390621185303, train/logprobs = tensor([[-0.8687, -1.5526],
        [-0.9298, -1.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6896708011627197, train/raw-loss = 0.6896708011627197, train/logprobs = tensor([[-0.9645, -1.2800],
        [-0.9510, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6796905994415283, train/raw-loss = 0.6796905994415283, train/logprobs = tensor([[-1.9058, -1.9635],
        [-1.9158, -1.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6706503033638, train/raw-loss = 0.6706503033638, train/logprobs = tensor([[-1.1390, -2.0399],
        [-1.1405, -1.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6858965754508972, train/raw-loss = 0.6858965754508972, train/logprobs = tensor([[-0.8441, -0.9406],
        [-0.8581, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6651986837387085, train/raw-loss = 0.6651986837387085, train/logprobs = tensor([[-1.3112, -1.6831],
        [-1.3243, -1.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6847805976867676, train/raw-loss = 0.6847805976867676, train/logprobs = tensor([[-0.8662, -1.0737],
        [-0.8736, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6876022815704346, train/raw-loss = 0.6876022815704346, train/logprobs = tensor([[-0.7827, -0.8806],
        [-0.7813, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6908653974533081, train/raw-loss = 0.6908653974533081, train/logprobs = tensor([[-1.2018, -1.3370],
        [-1.1900, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.686732292175293, train/raw-loss = 0.686732292175293, train/logprobs = tensor([[-0.8605, -0.7643],
        [-0.8566, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6876826882362366, train/raw-loss = 0.6876826882362366, train/logprobs = tensor([[-1.0388, -1.0944],
        [-1.0149, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6435815095901489, train/raw-loss = 0.6435815095901489, train/logprobs = tensor([[-0.7203, -1.0072],
        [-0.9276, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.685051441192627, train/raw-loss = 0.685051441192627, train/logprobs = tensor([[-1.7738, -1.5811],
        [-1.7367, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6835490465164185, train/raw-loss = 0.6835490465164185, train/logprobs = tensor([[-0.7857, -1.0101],
        [-0.7802, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6851893067359924, train/raw-loss = 0.6851893067359924, train/logprobs = tensor([[-1.0807, -1.0602],
        [-1.0599, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6957169771194458, train/raw-loss = 0.6957169771194458, train/logprobs = tensor([[-1.2139, -1.0487],
        [-1.2115, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6822819709777832, train/raw-loss = 0.6822819709777832, train/logprobs = tensor([[-0.6513, -1.1082],
        [-0.6617, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6895073652267456, train/raw-loss = 0.6895073652267456, train/logprobs = tensor([[-0.7078, -0.7979],
        [-0.7021, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6763476729393005, train/raw-loss = 0.6763476729393005, train/logprobs = tensor([[-0.9631, -1.0280],
        [-0.9922, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6463063955307007, train/raw-loss = 0.6463063955307007, train/logprobs = tensor([[-0.6414, -0.7730],
        [-0.8358, -0.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6779932975769043, train/raw-loss = 0.6779932975769043, train/logprobs = tensor([[-1.1239, -1.1327],
        [-1.1356, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6916989088058472, train/raw-loss = 0.6916989088058472, train/logprobs = tensor([[-0.6205, -1.0031],
        [-0.6088, -0.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6767294406890869, train/raw-loss = 0.6767294406890869, train/logprobs = tensor([[-0.9390, -0.9210],
        [-0.9397, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6832493543624878, train/raw-loss = 0.6832493543624878, train/logprobs = tensor([[-0.9945, -1.1954],
        [-0.9993, -1.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6685695052146912, train/raw-loss = 0.6685695052146912, train/logprobs = tensor([[-0.6370, -1.0280],
        [-0.6495, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6988618969917297, train/raw-loss = 0.6988618969917297, train/logprobs = tensor([[-1.0944, -1.3567],
        [-1.0909, -1.3756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6944974660873413, train/raw-loss = 0.6944974660873413, train/logprobs = tensor([[-0.7223, -0.9230],
        [-0.7083, -0.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6731753349304199, train/raw-loss = 0.6731753349304199, train/logprobs = tensor([[-1.0279, -1.0022],
        [-1.0066, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6563565731048584, train/raw-loss = 0.6563565731048584, train/logprobs = tensor([[-1.2104, -1.6542],
        [-1.2343, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6872880458831787, train/raw-loss = 0.6872880458831787, train/logprobs = tensor([[-0.8311, -1.4784],
        [-0.8204, -1.4425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6914947032928467, train/raw-loss = 0.6914947032928467, train/logprobs = tensor([[-1.0125, -0.8094],
        [-1.0045, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.687636137008667, train/raw-loss = 0.687636137008667, train/logprobs = tensor([[-0.6565, -1.3870],
        [-0.6583, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6883999109268188, train/raw-loss = 0.6883999109268188, train/logprobs = tensor([[-1.1857, -1.3858],
        [-1.1828, -1.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6659314632415771, train/raw-loss = 0.6659314632415771, train/logprobs = tensor([[-1.2814, -1.3358],
        [-1.2769, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6789016127586365, train/raw-loss = 0.6789016127586365, train/logprobs = tensor([[-0.8031, -1.0696],
        [-0.8326, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6858657598495483, train/raw-loss = 0.6858657598495483, train/logprobs = tensor([[-0.7832, -0.6718],
        [-0.7882, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6896746158599854, train/raw-loss = 0.6896746158599854, train/logprobs = tensor([[-0.6394, -0.7782],
        [-0.6331, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6815494298934937, train/raw-loss = 0.6815494298934937, train/logprobs = tensor([[-0.9030, -1.0957],
        [-0.9135, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6867143511772156, train/raw-loss = 0.6867143511772156, train/logprobs = tensor([[-0.9372, -1.2817],
        [-0.9285, -1.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6824443936347961, train/raw-loss = 0.6824443936347961, train/logprobs = tensor([[-1.0265, -1.1368],
        [-1.0408, -1.1075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6800762414932251, train/raw-loss = 0.6800762414932251, train/logprobs = tensor([[-0.9308, -1.2094],
        [-0.9144, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.7409065961837769, train/raw-loss = 0.7409065961837769, train/logprobs = tensor([[-1.0931, -5.4579],
        [-1.1029, -5.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6774613857269287, train/raw-loss = 0.6774613857269287, train/logprobs = tensor([[-0.8443, -1.4347],
        [-0.8515, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6789689064025879, train/raw-loss = 0.6789689064025879, train/logprobs = tensor([[-0.8301, -1.9021],
        [-0.8184, -1.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6731669306755066, train/raw-loss = 0.6731669306755066, train/logprobs = tensor([[-1.7658, -1.3725],
        [-1.8304, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6862998604774475, train/raw-loss = 0.6862998604774475, train/logprobs = tensor([[-0.8839, -1.4580],
        [-0.9069, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.7095268964767456, train/raw-loss = 0.7095268964767456, train/logprobs = tensor([[-1.9710, -1.9791],
        [-1.8971, -1.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6781504154205322, train/raw-loss = 0.6781504154205322, train/logprobs = tensor([[-0.7839, -1.0664],
        [-0.7969, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6865469813346863, train/raw-loss = 0.6865469813346863, train/logprobs = tensor([[-1.0173, -0.9270],
        [-1.0273, -0.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6887082457542419, train/raw-loss = 0.6887082457542419, train/logprobs = tensor([[-0.7414, -0.9562],
        [-0.7146, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6865116953849792, train/raw-loss = 0.6855534315109253, train/logprobs = tensor([[-0.7239, -0.7725],
        [-0.7206, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001916592475026846
Epoch 0, Step 65: train/loss = 0.6815451979637146, train/raw-loss = 0.6804126501083374, train/logprobs = tensor([[-0.7364, -0.8833],
        [-0.7496, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022650749888271093
Epoch 0, Step 66: train/loss = 0.6761447191238403, train/raw-loss = 0.6750707030296326, train/logprobs = tensor([[-1.0747, -1.4496],
        [-1.0703, -1.3714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021481188014149666
Epoch 0, Step 67: train/loss = 0.6834560632705688, train/raw-loss = 0.6823387145996094, train/logprobs = tensor([[-1.0962, -1.2690],
        [-1.1030, -1.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022347562480717897
Epoch 0, Step 68: train/loss = 0.6893277764320374, train/raw-loss = 0.6885471940040588, train/logprobs = tensor([[-0.5172, -0.7830],
        [-0.5276, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015612506540492177
Epoch 0, Step 69: train/loss = 0.6889533400535583, train/raw-loss = 0.6878378391265869, train/logprobs = tensor([[-0.9838, -0.9777],
        [-0.9846, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002230958081781864
Epoch 0, Step 70: train/loss = 0.6889636516571045, train/raw-loss = 0.6880004405975342, train/logprobs = tensor([[-0.9789, -0.8527],
        [-0.9611, -0.8133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019263208378106356
Epoch 0, Step 71: train/loss = 0.6818422675132751, train/raw-loss = 0.6807102560997009, train/logprobs = tensor([[-0.7895, -1.0250],
        [-0.7855, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022640663664788008
Epoch 0, Step 72: train/loss = 0.677242636680603, train/raw-loss = 0.6759128570556641, train/logprobs = tensor([[-1.6331, -1.5809],
        [-1.6872, -1.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026595911476761103
Epoch 0, Step 73: train/loss = 0.6842809915542603, train/raw-loss = 0.6831134557723999, train/logprobs = tensor([[-1.3021, -1.2488],
        [-1.3085, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023351027630269527
Epoch 0, Step 74: train/loss = 0.681935727596283, train/raw-loss = 0.6810404658317566, train/logprobs = tensor([[-0.8373, -1.0804],
        [-0.8305, -1.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017905781278386712
Epoch 0, Step 75: train/loss = 0.6786932945251465, train/raw-loss = 0.6777209639549255, train/logprobs = tensor([[-0.6193, -1.2084],
        [-0.6301, -1.1564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019446786027401686
Epoch 0, Step 76: train/loss = 0.6911360621452332, train/raw-loss = 0.6902772188186646, train/logprobs = tensor([[-0.8923, -0.7666],
        [-0.9003, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001717789564281702
Epoch 0, Step 77: train/loss = 0.6862449645996094, train/raw-loss = 0.6851322650909424, train/logprobs = tensor([[-0.8680, -1.4241],
        [-0.8556, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022254660725593567
Epoch 0, Step 78: train/loss = 0.6941208243370056, train/raw-loss = 0.6929594278335571, train/logprobs = tensor([[-0.8324, -0.9294],
        [-0.8344, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023228698410093784
Epoch 0, Step 79: train/loss = 0.6881258487701416, train/raw-loss = 0.6869947910308838, train/logprobs = tensor([[-1.0271, -1.0512],
        [-1.0290, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002262034686282277
Epoch 0, Step 80: train/loss = 0.68802410364151, train/raw-loss = 0.686983585357666, train/logprobs = tensor([[-0.8283, -1.0354],
        [-0.8174, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002081000478938222
Epoch 0, Step 81: train/loss = 0.6729907989501953, train/raw-loss = 0.6717101335525513, train/logprobs = tensor([[-1.3251, -1.8045],
        [-1.4075, -1.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025613403413444757
Epoch 0, Step 82: train/loss = 0.6938307285308838, train/raw-loss = 0.6927632093429565, train/logprobs = tensor([[-0.7102, -0.8221],
        [-0.6909, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002135038375854492
Epoch 0, Step 83: train/loss = 0.6901838183403015, train/raw-loss = 0.6890400052070618, train/logprobs = tensor([[-0.7616, -0.9112],
        [-0.7770, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002287627197802067
Epoch 0, Step 84: train/loss = 0.6841052770614624, train/raw-loss = 0.6830767393112183, train/logprobs = tensor([[-1.0200, -1.1492],
        [-1.0365, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020572287030518055
Epoch 0, Step 85: train/loss = 0.6883413791656494, train/raw-loss = 0.6872744560241699, train/logprobs = tensor([[-0.9083, -1.0863],
        [-0.8981, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002133780624717474
Epoch 0, Step 86: train/loss = 0.6873799562454224, train/raw-loss = 0.6866273880004883, train/logprobs = tensor([[-0.5353, -0.9876],
        [-0.5259, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015049828216433525
Epoch 0, Step 87: train/loss = 0.6946988105773926, train/raw-loss = 0.6937412023544312, train/logprobs = tensor([[-0.7829, -0.7593],
        [-0.7490, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001915367553010583
Epoch 0, Step 88: train/loss = 0.6704021096229553, train/raw-loss = 0.6691597700119019, train/logprobs = tensor([[-1.4465, -1.4528],
        [-1.5076, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002484593540430069
Epoch 0, Step 89: train/loss = 0.6867884397506714, train/raw-loss = 0.685737669467926, train/logprobs = tensor([[-0.7494, -0.9777],
        [-0.7340, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021016444079577923
Epoch 0, Step 90: train/loss = 0.6855707764625549, train/raw-loss = 0.6846001148223877, train/logprobs = tensor([[-0.7719, -1.7281],
        [-0.7769, -1.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019412243273109198
Epoch 0, Step 91: train/loss = 0.6856467723846436, train/raw-loss = 0.684465765953064, train/logprobs = tensor([[-1.0560, -0.9342],
        [-1.0565, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002361899707466364
Epoch 0, Step 92: train/loss = 0.6858736276626587, train/raw-loss = 0.6848267316818237, train/logprobs = tensor([[-0.8359, -1.0499],
        [-0.8336, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020938338711857796
Epoch 0, Step 93: train/loss = 0.6907579898834229, train/raw-loss = 0.6899124383926392, train/logprobs = tensor([[-0.5676, -0.9147],
        [-0.5640, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001691129757091403
Epoch 0, Step 94: train/loss = 0.6913323998451233, train/raw-loss = 0.6901149749755859, train/logprobs = tensor([[-1.2770, -1.3850],
        [-1.2828, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002434838330373168
Epoch 0, Step 95: train/loss = 0.6616435050964355, train/raw-loss = 0.6603880524635315, train/logprobs = tensor([[-0.8346, -1.1084],
        [-0.9172, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002510888036340475
Epoch 0, Step 96: train/loss = 0.6817536354064941, train/raw-loss = 0.6756723523139954, train/logprobs = tensor([[-0.9097, -0.9467],
        [-0.9076, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012162627652287483
Epoch 0, Step 97: train/loss = 0.669086217880249, train/raw-loss = 0.6637646555900574, train/logprobs = tensor([[-1.5971, -1.3438],
        [-1.6385, -1.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01064317673444748
Epoch 0, Step 98: train/loss = 0.69402015209198, train/raw-loss = 0.6882319450378418, train/logprobs = tensor([[-1.1662, -1.3295],
        [-1.1213, -1.2628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011576383374631405
Epoch 0, Step 99: train/loss = 0.6953531503677368, train/raw-loss = 0.689149796962738, train/logprobs = tensor([[-1.1612, -1.3295],
        [-1.1029, -1.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012406667694449425
Epoch 0, Step 100: train/loss = 0.6707783937454224, train/raw-loss = 0.6640672087669373, train/logprobs = tensor([[-1.1948, -1.1312],
        [-1.2496, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013422337360680103
Epoch 0, Step 101: train/loss = 0.6840032935142517, train/raw-loss = 0.6785401105880737, train/logprobs = tensor([[-0.7628, -1.1045],
        [-0.7644, -1.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010926250368356705
Epoch 0, Step 102: train/loss = 0.682812511920929, train/raw-loss = 0.6761301755905151, train/logprobs = tensor([[-0.8418, -1.0846],
        [-0.8458, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013364658690989017
Epoch 0, Step 103: train/loss = 0.6679912805557251, train/raw-loss = 0.6624656915664673, train/logprobs = tensor([[-1.2090, -1.4085],
        [-1.1744, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0110511165112257
Epoch 0, Step 104: train/loss = 0.687324047088623, train/raw-loss = 0.6828751564025879, train/logprobs = tensor([[-0.8223, -1.0296],
        [-0.7978, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008897831663489342
Epoch 0, Step 105: train/loss = 0.6399165391921997, train/raw-loss = 0.6347854733467102, train/logprobs = tensor([[-0.8207, -1.3794],
        [-0.8219, -1.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01026228442788124
Epoch 0, Step 106: train/loss = 0.6745778322219849, train/raw-loss = 0.6688956022262573, train/logprobs = tensor([[-0.9284, -1.4096],
        [-0.9049, -1.2849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011364463716745377
Epoch 0, Step 107: train/loss = 0.6950723528862, train/raw-loss = 0.6873658299446106, train/logprobs = tensor([[-0.8785, -0.9317],
        [-0.8793, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015413111075758934
Epoch 0, Step 108: train/loss = 0.6744168996810913, train/raw-loss = 0.6686043739318848, train/logprobs = tensor([[-0.7120, -1.2740],
        [-0.7188, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011625180020928383
Epoch 0, Step 109: train/loss = 0.6763508915901184, train/raw-loss = 0.6697044372558594, train/logprobs = tensor([[-1.0353, -1.0799],
        [-1.0734, -1.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013292886316776276
Epoch 0, Step 110: train/loss = 0.6982742547988892, train/raw-loss = 0.6937742829322815, train/logprobs = tensor([[-0.8070, -0.9361],
        [-0.7803, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009000072255730629
Epoch 0, Step 111: train/loss = 0.6831825971603394, train/raw-loss = 0.678267240524292, train/logprobs = tensor([[-0.6864, -1.3866],
        [-0.6829, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009830769151449203
Epoch 0, Step 112: train/loss = 0.6843390464782715, train/raw-loss = 0.6802831888198853, train/logprobs = tensor([[-0.5445, -1.2235],
        [-0.5440, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008111734874546528
Epoch 0, Step 113: train/loss = 0.6982514262199402, train/raw-loss = 0.6928788423538208, train/logprobs = tensor([[-0.8725, -0.9149],
        [-0.8459, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010745211504399776
Epoch 0, Step 114: train/loss = 0.6905681490898132, train/raw-loss = 0.6864379644393921, train/logprobs = tensor([[-0.6171, -0.6692],
        [-0.6245, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008260323666036129
Epoch 0, Step 115: train/loss = 0.6752985715866089, train/raw-loss = 0.6683732271194458, train/logprobs = tensor([[-1.2370, -1.9673],
        [-1.2047, -1.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013850703835487366
Epoch 0, Step 116: train/loss = 0.6889967918395996, train/raw-loss = 0.6826086044311523, train/logprobs = tensor([[-0.8122, -1.1421],
        [-0.7814, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012776361778378487
Epoch 0, Step 117: train/loss = 0.6998729705810547, train/raw-loss = 0.6939342021942139, train/logprobs = tensor([[-0.9315, -0.8923],
        [-0.9210, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011877475306391716
Epoch 0, Step 118: train/loss = 0.6812343597412109, train/raw-loss = 0.6755654811859131, train/logprobs = tensor([[-1.8577, -1.8494],
        [-1.8064, -1.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011337917298078537
Epoch 0, Step 119: train/loss = 0.6772803664207458, train/raw-loss = 0.671433687210083, train/logprobs = tensor([[-0.9329, -1.1693],
        [-0.9723, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011693445034325123
Epoch 0, Step 120: train/loss = 0.674243688583374, train/raw-loss = 0.6676790714263916, train/logprobs = tensor([[-1.2494, -1.5598],
        [-1.2407, -1.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01312921941280365
Epoch 0, Step 121: train/loss = 0.6871650815010071, train/raw-loss = 0.6823320388793945, train/logprobs = tensor([[-0.7920, -0.8620],
        [-0.8075, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00966613832861185
Epoch 0, Step 122: train/loss = 0.6621899604797363, train/raw-loss = 0.6554943323135376, train/logprobs = tensor([[-1.2240, -1.6288],
        [-1.2228, -1.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013391286134719849
Epoch 0, Step 123: train/loss = 0.678468644618988, train/raw-loss = 0.6725700497627258, train/logprobs = tensor([[-0.8142, -1.0158],
        [-0.8423, -0.9594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011797161772847176
Epoch 0, Step 124: train/loss = 0.696112871170044, train/raw-loss = 0.6893436312675476, train/logprobs = tensor([[-1.2521, -1.3258],
        [-1.1321, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01353844441473484
Epoch 0, Step 125: train/loss = 0.6908727884292603, train/raw-loss = 0.6857258677482605, train/logprobs = tensor([[-0.7639, -0.9443],
        [-0.7690, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010293744504451752
Epoch 0, Step 126: train/loss = 0.6868833303451538, train/raw-loss = 0.6815211176872253, train/logprobs = tensor([[-0.7096, -0.7351],
        [-0.6979, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01072451937943697
Epoch 0, Step 127: train/loss = 0.6792494058609009, train/raw-loss = 0.6723051071166992, train/logprobs = tensor([[-1.0746, -1.2864],
        [-1.0918, -1.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013888739980757236
Epoch 0, Step 128: train/loss = 0.6818444132804871, train/raw-loss = 0.6704167723655701, train/logprobs = tensor([[-0.9622, -1.3029],
        [-0.9563, -1.2014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022855345159769058
Epoch 0, Step 129: train/loss = 0.6748698353767395, train/raw-loss = 0.6610191464424133, train/logprobs = tensor([[-0.8046, -1.3766],
        [-0.8238, -1.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027701329439878464
Epoch 0, Step 130: train/loss = 0.6930264830589294, train/raw-loss = 0.68052738904953, train/logprobs = tensor([[-0.9903, -1.3449],
        [-0.9472, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024998219683766365
Epoch 0, Step 131: train/loss = 0.6961181163787842, train/raw-loss = 0.6857866048812866, train/logprobs = tensor([[-1.1762, -1.3383],
        [-1.1511, -1.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020663144066929817
Epoch 0, Step 132: train/loss = 0.6912718415260315, train/raw-loss = 0.6826280951499939, train/logprobs = tensor([[-0.7805, -0.6948],
        [-0.7864, -0.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017287416383624077
Epoch 0, Step 133: train/loss = 0.7099162936210632, train/raw-loss = 0.695270299911499, train/logprobs = tensor([[-1.1864, -0.9914],
        [-1.0908, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0292920283973217
Epoch 0, Step 134: train/loss = 0.7120424509048462, train/raw-loss = 0.6975971460342407, train/logprobs = tensor([[-1.0293, -1.1679],
        [-1.0170, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02889064885675907
Epoch 0, Step 135: train/loss = 0.6957263946533203, train/raw-loss = 0.6814963221549988, train/logprobs = tensor([[-1.1387, -0.9638],
        [-1.1288, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02846023440361023
Epoch 0, Step 136: train/loss = 0.6936681270599365, train/raw-loss = 0.6855074763298035, train/logprobs = tensor([[-0.6634, -0.7347],
        [-0.6633, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0163214523345232
Epoch 0, Step 137: train/loss = 0.6792317032814026, train/raw-loss = 0.6684191226959229, train/logprobs = tensor([[-0.8061, -1.1701],
        [-0.7964, -1.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021625198423862457
Epoch 0, Step 138: train/loss = 0.70570969581604, train/raw-loss = 0.6917364597320557, train/logprobs = tensor([[-0.7394, -0.8668],
        [-0.7345, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027946483343839645
Epoch 0, Step 139: train/loss = 0.6916918158531189, train/raw-loss = 0.6787334680557251, train/logprobs = tensor([[-1.1271, -1.3664],
        [-1.0951, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025916682556271553
Epoch 0, Step 140: train/loss = 0.7104846239089966, train/raw-loss = 0.6944957971572876, train/logprobs = tensor([[-1.2643, -0.9691],
        [-1.2293, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03197779506444931
Epoch 0, Step 141: train/loss = 0.6884388327598572, train/raw-loss = 0.6756749153137207, train/logprobs = tensor([[-1.0885, -1.5525],
        [-1.1146, -1.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025527922436594963
Epoch 0, Step 142: train/loss = 0.6890028715133667, train/raw-loss = 0.6730754375457764, train/logprobs = tensor([[-0.9253, -1.3554],
        [-0.9459, -1.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03185490146279335
Epoch 0, Step 143: train/loss = 0.6950767040252686, train/raw-loss = 0.6822195053100586, train/logprobs = tensor([[-1.1085, -1.1939],
        [-1.1247, -1.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02571442723274231
Epoch 0, Step 144: train/loss = 0.6870740652084351, train/raw-loss = 0.6755800247192383, train/logprobs = tensor([[-1.1670, -0.9343],
        [-1.2117, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022988036274909973
Epoch 0, Step 145: train/loss = 0.6831426024436951, train/raw-loss = 0.6689064502716064, train/logprobs = tensor([[-1.1625, -1.5254],
        [-1.2469, -1.5094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02847227454185486
Epoch 0, Step 146: train/loss = 0.696053147315979, train/raw-loss = 0.683791995048523, train/logprobs = tensor([[-1.0817, -1.0602],
        [-1.0605, -1.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024522311985492706
Epoch 0, Step 147: train/loss = 0.6929202675819397, train/raw-loss = 0.6814628839492798, train/logprobs = tensor([[-0.7095, -0.8181],
        [-0.7072, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022914694622159004
Epoch 0, Step 148: train/loss = 0.6981639862060547, train/raw-loss = 0.688940167427063, train/logprobs = tensor([[-0.5386, -0.5223],
        [-0.5273, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0184475164860487
Epoch 0, Step 149: train/loss = 0.687447726726532, train/raw-loss = 0.6753310561180115, train/logprobs = tensor([[-0.5670, -1.1417],
        [-0.5856, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024233266711235046
Epoch 0, Step 150: train/loss = 0.711403489112854, train/raw-loss = 0.6974399089813232, train/logprobs = tensor([[-0.8542, -0.8552],
        [-0.8224, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027927014976739883
Epoch 0, Step 151: train/loss = 0.6937311291694641, train/raw-loss = 0.6858653426170349, train/logprobs = tensor([[-0.6704, -0.6243],
        [-0.6603, -0.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015731649473309517
Epoch 0, Step 152: train/loss = 0.7053232789039612, train/raw-loss = 0.6928508281707764, train/logprobs = tensor([[-1.0201, -0.6686],
        [-1.0286, -0.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024944985285401344
Epoch 0, Step 153: train/loss = 0.6919785737991333, train/raw-loss = 0.679090678691864, train/logprobs = tensor([[-0.8160, -1.5077],
        [-0.7967, -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025775780901312828
Epoch 0, Step 154: train/loss = 0.6977566480636597, train/raw-loss = 0.6838039755821228, train/logprobs = tensor([[-0.9707, -1.1791],
        [-0.9022, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027905289083719254
Epoch 0, Step 155: train/loss = 0.7014479637145996, train/raw-loss = 0.6904318928718567, train/logprobs = tensor([[-0.9853, -0.9241],
        [-0.9175, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02203213796019554
Epoch 0, Step 156: train/loss = 0.6910815834999084, train/raw-loss = 0.6810054183006287, train/logprobs = tensor([[-0.6704, -1.0014],
        [-0.6891, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020152434706687927
Epoch 0, Step 157: train/loss = 0.654904305934906, train/raw-loss = 0.6398708820343018, train/logprobs = tensor([[-1.2737, -1.1808],
        [-1.2708, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03006693348288536
Epoch 0, Step 158: train/loss = 0.6868091225624084, train/raw-loss = 0.6761472821235657, train/logprobs = tensor([[-1.0846, -0.9977],
        [-1.0738, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021323511376976967
Epoch 0, Step 159: train/loss = 0.6990215182304382, train/raw-loss = 0.6872928738594055, train/logprobs = tensor([[-0.7857, -1.1672],
        [-0.7894, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0234573595225811
Epoch 0, Step 160: train/loss = 0.7050111293792725, train/raw-loss = 0.6880544424057007, train/logprobs = tensor([[-1.1142, -0.9323],
        [-1.1020, -0.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03391345962882042
Epoch 0, Step 161: train/loss = 0.6983346343040466, train/raw-loss = 0.6876473426818848, train/logprobs = tensor([[-0.6798, -1.0255],
        [-0.6649, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021374668926000595
Epoch 0, Step 162: train/loss = 0.700497567653656, train/raw-loss = 0.689316987991333, train/logprobs = tensor([[-0.9295, -1.0221],
        [-0.8219, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022361310198903084
Epoch 0, Step 163: train/loss = 0.698440432548523, train/raw-loss = 0.6875684261322021, train/logprobs = tensor([[-0.8844, -0.9360],
        [-0.8769, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02174404263496399
Epoch 0, Step 164: train/loss = 0.698593020439148, train/raw-loss = 0.6838117837905884, train/logprobs = tensor([[-1.4039, -1.7391],
        [-1.2493, -1.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029562409967184067
Epoch 0, Step 165: train/loss = 0.6801209449768066, train/raw-loss = 0.6661021113395691, train/logprobs = tensor([[-0.7478, -1.1963],
        [-0.7274, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028037581592798233
Epoch 0, Step 166: train/loss = 0.6993175745010376, train/raw-loss = 0.6877716779708862, train/logprobs = tensor([[-1.0462, -1.0830],
        [-0.9997, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02309180237352848
Epoch 0, Step 167: train/loss = 0.6979658603668213, train/raw-loss = 0.6878970265388489, train/logprobs = tensor([[-0.8036, -0.8280],
        [-0.7434, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020137695595622063
Epoch 0, Step 168: train/loss = 0.6920861005783081, train/raw-loss = 0.6779406070709229, train/logprobs = tensor([[-1.2106, -1.0345],
        [-1.1651, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028291016817092896
Epoch 0, Step 169: train/loss = 0.7028827667236328, train/raw-loss = 0.6887972950935364, train/logprobs = tensor([[-1.0289, -0.7058],
        [-0.9724, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028170906007289886
Epoch 0, Step 170: train/loss = 0.7017543911933899, train/raw-loss = 0.6877756118774414, train/logprobs = tensor([[-1.0513, -1.3084],
        [-0.9919, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027957657352089882
Epoch 0, Step 171: train/loss = 0.7071240544319153, train/raw-loss = 0.6942778825759888, train/logprobs = tensor([[-0.9606, -0.9091],
        [-0.8995, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025692353025078773
Epoch 0, Step 172: train/loss = 0.6903551816940308, train/raw-loss = 0.674747884273529, train/logprobs = tensor([[-1.0903, -1.3532],
        [-0.9831, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03121461346745491
Epoch 0, Step 173: train/loss = 0.6953015327453613, train/raw-loss = 0.6821495890617371, train/logprobs = tensor([[-0.8980, -1.2049],
        [-0.8903, -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026303786784410477
Epoch 0, Step 174: train/loss = 0.6974079012870789, train/raw-loss = 0.6846437454223633, train/logprobs = tensor([[-0.6432, -0.7216],
        [-0.6265, -0.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025528328493237495
Epoch 0, Step 175: train/loss = 0.6867464780807495, train/raw-loss = 0.6680805683135986, train/logprobs = tensor([[-0.8941, -1.3195],
        [-0.8778, -1.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03733181580901146
Epoch 0, Step 176: train/loss = 0.6976332068443298, train/raw-loss = 0.6850916743278503, train/logprobs = tensor([[-1.1528, -1.3662],
        [-1.0587, -1.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02508300170302391
Epoch 0, Step 177: train/loss = 0.7033140063285828, train/raw-loss = 0.6898365020751953, train/logprobs = tensor([[-0.9211, -0.9342],
        [-0.8458, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026954947039484978
Epoch 0, Step 178: train/loss = 0.6908062696456909, train/raw-loss = 0.6785751581192017, train/logprobs = tensor([[-0.4899, -0.7465],
        [-0.4811, -0.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024462169036269188
Epoch 0, Step 179: train/loss = 0.7002435922622681, train/raw-loss = 0.6861579418182373, train/logprobs = tensor([[-0.9204, -0.9334],
        [-0.8805, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028171228244900703
Epoch 0, Step 180: train/loss = 0.6799561381340027, train/raw-loss = 0.6669033765792847, train/logprobs = tensor([[-1.3820, -1.3449],
        [-1.3839, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026105467230081558
Epoch 0, Step 181: train/loss = 0.6825311779975891, train/raw-loss = 0.6678462028503418, train/logprobs = tensor([[-1.3471, -1.8445],
        [-1.3681, -1.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02936985343694687
Epoch 0, Step 182: train/loss = 0.6881804466247559, train/raw-loss = 0.6777186393737793, train/logprobs = tensor([[-0.5776, -0.8959],
        [-0.5695, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020923465490341187
Epoch 0, Step 183: train/loss = 0.6576317548751831, train/raw-loss = 0.6385364532470703, train/logprobs = tensor([[-1.0827, -2.4148],
        [-0.9595, -2.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03819054365158081
Epoch 0, Step 184: train/loss = 0.6714435815811157, train/raw-loss = 0.6579235792160034, train/logprobs = tensor([[-0.7472, -1.2004],
        [-0.7798, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027039913460612297
Epoch 0, Step 185: train/loss = 0.6936199069023132, train/raw-loss = 0.6818711757659912, train/logprobs = tensor([[-0.8903, -1.1434],
        [-0.8633, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023497402667999268
Epoch 0, Step 186: train/loss = 0.6962002515792847, train/raw-loss = 0.6851953268051147, train/logprobs = tensor([[-0.7842, -0.9133],
        [-0.7242, -0.8187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022009847685694695
Epoch 0, Step 187: train/loss = 0.6759894490242004, train/raw-loss = 0.6607056856155396, train/logprobs = tensor([[-0.9208, -1.8891],
        [-0.9277, -1.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030567586421966553
Epoch 0, Step 188: train/loss = 0.6760216951370239, train/raw-loss = 0.6601647138595581, train/logprobs = tensor([[-0.7658, -1.0829],
        [-0.7233, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03171389922499657
Epoch 0, Step 189: train/loss = 0.7089393138885498, train/raw-loss = 0.6944859027862549, train/logprobs = tensor([[-0.8499, -0.5977],
        [-0.7934, -0.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028906943276524544
Epoch 0, Step 190: train/loss = 0.7126943469047546, train/raw-loss = 0.6982531547546387, train/logprobs = tensor([[-1.1391, -1.1586],
        [-1.0626, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028882523998618126
Epoch 0, Step 191: train/loss = 0.685991644859314, train/raw-loss = 0.6729041934013367, train/logprobs = tensor([[-1.4430, -1.5517],
        [-1.3603, -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02617497742176056
Epoch 0, Step 192: train/loss = 0.7011619806289673, train/raw-loss = 0.6914324164390564, train/logprobs = tensor([[-0.6686, -0.5932],
        [-0.6398, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019459133967757225
Epoch 0, Step 193: train/loss = 0.6940454244613647, train/raw-loss = 0.6857092976570129, train/logprobs = tensor([[-0.6253, -0.6759],
        [-0.5977, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016672348603606224
Epoch 0, Step 194: train/loss = 0.6804490089416504, train/raw-loss = 0.6652535796165466, train/logprobs = tensor([[-0.9048, -0.8184],
        [-0.8775, -0.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03039083443582058
Epoch 0, Step 195: train/loss = 0.6929559707641602, train/raw-loss = 0.6818833947181702, train/logprobs = tensor([[-1.1345, -1.1461],
        [-1.0501, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02214508131146431
Epoch 0, Step 196: train/loss = 0.7025316953659058, train/raw-loss = 0.6885223388671875, train/logprobs = tensor([[-1.1408, -1.0802],
        [-0.9996, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028018705546855927
Epoch 0, Step 197: train/loss = 0.673640251159668, train/raw-loss = 0.6613175868988037, train/logprobs = tensor([[-1.0366, -1.2169],
        [-0.9970, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024645302444696426
Epoch 0, Step 198: train/loss = 0.6748466491699219, train/raw-loss = 0.6608132719993591, train/logprobs = tensor([[-0.8094, -1.3412],
        [-0.7663, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02806679718196392
Epoch 0, Step 199: train/loss = 0.6901886463165283, train/raw-loss = 0.6772679090499878, train/logprobs = tensor([[-0.8978, -0.9762],
        [-0.8352, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025841664522886276
Epoch 0, Step 200: train/loss = 0.7085359692573547, train/raw-loss = 0.6957175731658936, train/logprobs = tensor([[-0.9354, -1.1997],
        [-0.8779, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025636959820985794
Epoch 0, Step 201: train/loss = 0.6578458547592163, train/raw-loss = 0.6424901485443115, train/logprobs = tensor([[-1.0365, -1.4144],
        [-0.9987, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030711490660905838
Epoch 0, Step 202: train/loss = 0.6973683834075928, train/raw-loss = 0.6845547556877136, train/logprobs = tensor([[-1.2026, -1.3565],
        [-1.1733, -1.2909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025627128779888153
Epoch 0, Step 203: train/loss = 0.6764592528343201, train/raw-loss = 0.6641800403594971, train/logprobs = tensor([[-0.8820, -0.9118],
        [-0.8696, -0.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024558406323194504
Epoch 0, Step 204: train/loss = 0.7000006437301636, train/raw-loss = 0.6855767965316772, train/logprobs = tensor([[-1.4140, -1.1521],
        [-1.3082, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028847821056842804
Epoch 0, Step 205: train/loss = 0.6803292036056519, train/raw-loss = 0.6708104610443115, train/logprobs = tensor([[-0.7235, -0.6879],
        [-0.7050, -0.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0190376415848732
Epoch 0, Step 206: train/loss = 0.7142824530601501, train/raw-loss = 0.7005755305290222, train/logprobs = tensor([[-0.9618, -1.1502],
        [-0.8383, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0274137482047081
Epoch 0, Step 207: train/loss = 0.6830121278762817, train/raw-loss = 0.6665415167808533, train/logprobs = tensor([[-1.0801, -1.5647],
        [-1.0382, -1.4078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0329413004219532
Epoch 0, Step 208: train/loss = 0.6946293115615845, train/raw-loss = 0.6829343438148499, train/logprobs = tensor([[-0.7007, -0.8083],
        [-0.6403, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0233899112790823
Epoch 0, Step 209: train/loss = 0.6923525333404541, train/raw-loss = 0.6789820194244385, train/logprobs = tensor([[-0.7950, -1.0971],
        [-0.7791, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026740968227386475
Epoch 0, Step 210: train/loss = 0.6932448148727417, train/raw-loss = 0.6787275075912476, train/logprobs = tensor([[-0.8065, -1.0356],
        [-0.7615, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029034744948148727
Epoch 0, Step 211: train/loss = 0.6869707107543945, train/raw-loss = 0.6742966175079346, train/logprobs = tensor([[-0.7556, -0.8392],
        [-0.6929, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025348203256726265
Epoch 0, Step 212: train/loss = 0.6834554672241211, train/raw-loss = 0.6658895611763, train/logprobs = tensor([[-1.1736, -1.2673],
        [-1.1146, -1.0905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03513171151280403
Epoch 0, Step 213: train/loss = 0.6970893740653992, train/raw-loss = 0.6873184442520142, train/logprobs = tensor([[-0.6916, -0.6784],
        [-0.6504, -0.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019541921094059944
Epoch 0, Step 214: train/loss = 0.6896965503692627, train/raw-loss = 0.6752837896347046, train/logprobs = tensor([[-0.7548, -1.2006],
        [-0.7405, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02882539853453636
Epoch 0, Step 215: train/loss = 0.6913366317749023, train/raw-loss = 0.6780809760093689, train/logprobs = tensor([[-1.1583, -1.2191],
        [-1.1285, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026511192321777344
Epoch 0, Step 216: train/loss = 0.6904399991035461, train/raw-loss = 0.6786364316940308, train/logprobs = tensor([[-1.0614, -1.0499],
        [-1.0525, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02360719069838524
Epoch 0, Step 217: train/loss = 0.6967300176620483, train/raw-loss = 0.6817570328712463, train/logprobs = tensor([[-0.7674, -1.5486],
        [-0.6731, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02994612231850624
Epoch 0, Step 218: train/loss = 0.6934003829956055, train/raw-loss = 0.6811836957931519, train/logprobs = tensor([[-0.7263, -0.8140],
        [-0.6806, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02443343959748745
Epoch 0, Step 219: train/loss = 0.6918359398841858, train/raw-loss = 0.679818332195282, train/logprobs = tensor([[-1.2107, -1.3877],
        [-1.1695, -1.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024035418406128883
Epoch 0, Step 220: train/loss = 0.6932279467582703, train/raw-loss = 0.6795339584350586, train/logprobs = tensor([[-0.7557, -1.1115],
        [-0.6894, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027388080954551697
Epoch 0, Step 221: train/loss = 0.669086754322052, train/raw-loss = 0.6539230346679688, train/logprobs = tensor([[-1.2455, -1.4252],
        [-1.2710, -1.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03032734990119934
Epoch 0, Step 222: train/loss = 0.6622220277786255, train/raw-loss = 0.6486304402351379, train/logprobs = tensor([[-0.9454, -1.3207],
        [-0.9267, -1.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027183150872588158
Epoch 0, Step 223: train/loss = 0.6841058135032654, train/raw-loss = 0.6690363883972168, train/logprobs = tensor([[-1.1960, -1.5736],
        [-1.0124, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030138835310935974
Epoch 0, Step 224: train/loss = 0.6809303164482117, train/raw-loss = 0.6637389659881592, train/logprobs = tensor([[-1.0318, -1.1386],
        [-0.9641, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034382689744234085
Epoch 0, Step 225: train/loss = 0.7001422047615051, train/raw-loss = 0.6855466365814209, train/logprobs = tensor([[-1.0521, -1.2105],
        [-0.9649, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02919107675552368
Epoch 0, Step 226: train/loss = 0.7015854120254517, train/raw-loss = 0.685619592666626, train/logprobs = tensor([[-1.1978, -1.1466],
        [-1.2329, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03193153068423271
Epoch 0, Step 227: train/loss = 0.6708354353904724, train/raw-loss = 0.6550726294517517, train/logprobs = tensor([[-0.9695, -1.2426],
        [-0.9370, -1.0448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031525611877441406
Epoch 0, Step 228: train/loss = 0.6747859716415405, train/raw-loss = 0.6572775840759277, train/logprobs = tensor([[-0.8317, -1.0785],
        [-0.7972, -0.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035016849637031555
Epoch 0, Step 229: train/loss = 0.6924357414245605, train/raw-loss = 0.6742876768112183, train/logprobs = tensor([[-0.9493, -0.6215],
        [-0.9323, -0.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036296021193265915
Epoch 0, Step 230: train/loss = 0.6765126585960388, train/raw-loss = 0.6593466401100159, train/logprobs = tensor([[-1.1921, -1.8057],
        [-1.1189, -1.5858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034332018345594406
Epoch 0, Step 231: train/loss = 0.6821867227554321, train/raw-loss = 0.6670156121253967, train/logprobs = tensor([[-0.5031, -1.1227],
        [-0.4346, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03034217096865177
Epoch 0, Step 232: train/loss = 0.6890523433685303, train/raw-loss = 0.6722932457923889, train/logprobs = tensor([[-0.7718, -1.1272],
        [-0.7268, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03351816534996033
Epoch 0, Step 233: train/loss = 0.6659689545631409, train/raw-loss = 0.6479884386062622, train/logprobs = tensor([[-0.9184, -1.2768],
        [-0.9560, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03596099838614464
Epoch 0, Step 234: train/loss = 0.6945405006408691, train/raw-loss = 0.6776246428489685, train/logprobs = tensor([[-1.1327, -1.4139],
        [-0.9520, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033831752836704254
Epoch 0, Step 235: train/loss = 0.6911269426345825, train/raw-loss = 0.6769429445266724, train/logprobs = tensor([[-0.7285, -0.7096],
        [-0.7271, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028368014842271805
Epoch 0, Step 236: train/loss = 0.7100594639778137, train/raw-loss = 0.6939576268196106, train/logprobs = tensor([[-1.6587, -1.6626],
        [-1.5426, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032203711569309235
Epoch 0, Step 237: train/loss = 0.6979364156723022, train/raw-loss = 0.6843152046203613, train/logprobs = tensor([[-0.9263, -0.8506],
        [-0.9366, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027242496609687805
Epoch 0, Step 238: train/loss = 0.6955450773239136, train/raw-loss = 0.6757193207740784, train/logprobs = tensor([[-0.8621, -1.3611],
        [-0.7751, -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0396515391767025
Epoch 0, Step 239: train/loss = 0.7075231075286865, train/raw-loss = 0.6886855959892273, train/logprobs = tensor([[-0.7981, -0.8437],
        [-0.7442, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03767513856291771
Epoch 0, Step 240: train/loss = 0.6852326393127441, train/raw-loss = 0.6683470010757446, train/logprobs = tensor([[-0.5544, -0.9145],
        [-0.5388, -0.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033771317452192307
Epoch 0, Step 241: train/loss = 0.696762204170227, train/raw-loss = 0.6838114857673645, train/logprobs = tensor([[-0.9022, -0.6908],
        [-0.8916, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025901461020112038
Epoch 0, Step 242: train/loss = 0.6770646572113037, train/raw-loss = 0.6594913005828857, train/logprobs = tensor([[-1.1683, -1.7051],
        [-1.0980, -1.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035146746784448624
Epoch 0, Step 243: train/loss = 0.7012081146240234, train/raw-loss = 0.6889176368713379, train/logprobs = tensor([[-0.8354, -0.9257],
        [-0.7392, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024580925703048706
Epoch 0, Step 244: train/loss = 0.6896860003471375, train/raw-loss = 0.6733720898628235, train/logprobs = tensor([[-0.4892, -1.0769],
        [-0.4481, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03262771666049957
Epoch 0, Step 245: train/loss = 0.6976674199104309, train/raw-loss = 0.6806403994560242, train/logprobs = tensor([[-1.2459, -1.0722],
        [-1.2266, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03405408188700676
Epoch 0, Step 246: train/loss = 0.7182139754295349, train/raw-loss = 0.6968835592269897, train/logprobs = tensor([[-1.4699, -1.1243],
        [-1.2957, -0.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04266092926263809
Epoch 0, Step 247: train/loss = 0.7389545440673828, train/raw-loss = 0.7212362289428711, train/logprobs = tensor([[-1.2512, -0.7295],
        [-1.0504, -0.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03543665632605553
Epoch 0, Step 248: train/loss = 0.6805537343025208, train/raw-loss = 0.6655060052871704, train/logprobs = tensor([[-0.6612, -1.6563],
        [-0.6865, -1.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03009539470076561
Epoch 0, Step 249: train/loss = 0.6779763102531433, train/raw-loss = 0.660759449005127, train/logprobs = tensor([[-0.8727, -1.1308],
        [-0.9261, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03443380072712898
Epoch 0, Step 250: train/loss = 0.6875345706939697, train/raw-loss = 0.6742165088653564, train/logprobs = tensor([[-0.6254, -0.8504],
        [-0.6238, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02663620002567768
Epoch 0, Step 251: train/loss = 0.6633652448654175, train/raw-loss = 0.6483659744262695, train/logprobs = tensor([[-1.6033, -2.4476],
        [-1.6058, -2.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029998652637004852
Epoch 0, Step 252: train/loss = 0.7009286880493164, train/raw-loss = 0.6803635358810425, train/logprobs = tensor([[-1.0969, -1.1004],
        [-0.9747, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041130319237709045
Epoch 0, Step 253: train/loss = 0.6540073752403259, train/raw-loss = 0.6412531733512878, train/logprobs = tensor([[-0.5705, -1.1988],
        [-0.5523, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02550841122865677
Epoch 0, Step 254: train/loss = 0.6911671161651611, train/raw-loss = 0.676159143447876, train/logprobs = tensor([[-0.8834, -1.0527],
        [-0.7895, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030015867203474045
Epoch 0, Step 255: train/loss = 0.6936713457107544, train/raw-loss = 0.6790157556533813, train/logprobs = tensor([[-0.4720, -1.0072],
        [-0.4684, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02931121550500393
Epoch 0, Step 256: train/loss = 0.7182493805885315, train/raw-loss = 0.6943170428276062, train/logprobs = tensor([[-1.2639, -1.1574],
        [-1.1736, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04786469787359238
Epoch 0, Step 257: train/loss = 0.6703363656997681, train/raw-loss = 0.648369550704956, train/logprobs = tensor([[-1.0879, -1.1880],
        [-0.9649, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04393348842859268
Epoch 0, Step 258: train/loss = 0.7007354497909546, train/raw-loss = 0.6800611615180969, train/logprobs = tensor([[-0.9619, -1.4512],
        [-0.9373, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04134848341345787
Epoch 0, Step 259: train/loss = 0.6939307451248169, train/raw-loss = 0.6723280549049377, train/logprobs = tensor([[-1.0397, -1.3156],
        [-0.9637, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04320527985692024
Epoch 0, Step 260: train/loss = 0.7080180644989014, train/raw-loss = 0.69022136926651, train/logprobs = tensor([[-1.7578, -1.7122],
        [-1.6920, -1.6307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035593435168266296
Epoch 0, Step 261: train/loss = 0.6524878144264221, train/raw-loss = 0.6275222301483154, train/logprobs = tensor([[-1.2054, -1.7204],
        [-1.1492, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049931298941373825
Epoch 0, Step 262: train/loss = 0.6487042903900146, train/raw-loss = 0.6308711767196655, train/logprobs = tensor([[-1.3455, -1.8225],
        [-1.2187, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035666324198246
Epoch 0, Step 263: train/loss = 0.693566620349884, train/raw-loss = 0.6731424331665039, train/logprobs = tensor([[-1.1052, -1.2119],
        [-1.0015, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04084823653101921
Epoch 0, Step 264: train/loss = 0.6749476790428162, train/raw-loss = 0.6569054126739502, train/logprobs = tensor([[-0.9594, -1.2692],
        [-0.8214, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03608465567231178
Epoch 0, Step 265: train/loss = 0.6990180611610413, train/raw-loss = 0.6886882781982422, train/logprobs = tensor([[-0.5594, -0.6645],
        [-0.4700, -0.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020659493282437325
Epoch 0, Step 266: train/loss = 0.6702276468276978, train/raw-loss = 0.6485447883605957, train/logprobs = tensor([[-0.8582, -0.9350],
        [-0.8318, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0433657169342041
Epoch 0, Step 267: train/loss = 0.7064869403839111, train/raw-loss = 0.689586877822876, train/logprobs = tensor([[-2.0547, -2.2742],
        [-1.8441, -2.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03379996865987778
Epoch 0, Step 268: train/loss = 0.6788367629051208, train/raw-loss = 0.6648674011230469, train/logprobs = tensor([[-0.6372, -0.8981],
        [-0.6278, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02793864905834198
Epoch 0, Step 269: train/loss = 0.6755558252334595, train/raw-loss = 0.6555873155593872, train/logprobs = tensor([[-1.1209, -1.5753],
        [-0.9962, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03993706405162811
Epoch 0, Step 270: train/loss = 0.6825698614120483, train/raw-loss = 0.6656222939491272, train/logprobs = tensor([[-1.9075, -1.9569],
        [-1.6227, -1.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033895183354616165
Epoch 0, Step 271: train/loss = 0.7039566040039062, train/raw-loss = 0.6867659687995911, train/logprobs = tensor([[-0.8401, -0.7202],
        [-0.7519, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03438127040863037
Epoch 0, Step 272: train/loss = 0.730088472366333, train/raw-loss = 0.7102510929107666, train/logprobs = tensor([[-0.9868, -1.0672],
        [-0.8924, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03967469930648804
Epoch 0, Step 273: train/loss = 0.6861836910247803, train/raw-loss = 0.6718612313270569, train/logprobs = tensor([[-0.6805, -1.1835],
        [-0.6292, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028644753620028496
Epoch 0, Step 274: train/loss = 0.689697802066803, train/raw-loss = 0.6607887744903564, train/logprobs = tensor([[-1.3182, -1.4174],
        [-1.1258, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057818055152893066
Epoch 0, Step 275: train/loss = 0.6312752366065979, train/raw-loss = 0.6138061881065369, train/logprobs = tensor([[-1.6650, -3.1400],
        [-1.6290, -2.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034938015043735504
Epoch 0, Step 276: train/loss = 0.6592696905136108, train/raw-loss = 0.639031171798706, train/logprobs = tensor([[-0.8734, -1.3919],
        [-0.8362, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04047702997922897
Epoch 0, Step 277: train/loss = 0.7024682760238647, train/raw-loss = 0.6871260404586792, train/logprobs = tensor([[-1.0990, -1.3539],
        [-1.0670, -1.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03068440780043602
Epoch 0, Step 278: train/loss = 0.723949670791626, train/raw-loss = 0.6976192593574524, train/logprobs = tensor([[-1.3996, -1.2149],
        [-1.0490, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05266079306602478
Epoch 0, Step 279: train/loss = 0.697653591632843, train/raw-loss = 0.679182767868042, train/logprobs = tensor([[-0.8820, -1.1225],
        [-0.7775, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0369415208697319
Epoch 0, Step 280: train/loss = 0.7044864892959595, train/raw-loss = 0.6877254247665405, train/logprobs = tensor([[-0.7058, -0.7899],
        [-0.6476, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033522170037031174
Epoch 0, Step 281: train/loss = 0.6559268236160278, train/raw-loss = 0.6366204023361206, train/logprobs = tensor([[-0.6031, -1.2883],
        [-0.5828, -1.0190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038612835109233856
Epoch 0, Step 282: train/loss = 0.6781561970710754, train/raw-loss = 0.6599207520484924, train/logprobs = tensor([[-1.0553, -1.3271],
        [-0.9053, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03647087886929512
Epoch 0, Step 283: train/loss = 0.6958169937133789, train/raw-loss = 0.674212634563446, train/logprobs = tensor([[-1.2536, -1.3785],
        [-1.0976, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043208859860897064
Epoch 0, Step 284: train/loss = 0.687803328037262, train/raw-loss = 0.6683685183525085, train/logprobs = tensor([[-0.7628, -1.1152],
        [-0.7789, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03886961564421654
Epoch 0, Step 285: train/loss = 0.6694362759590149, train/raw-loss = 0.6496025323867798, train/logprobs = tensor([[-0.6396, -1.3555],
        [-0.5603, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03966740518808365
Epoch 0, Step 286: train/loss = 0.7022130489349365, train/raw-loss = 0.687748908996582, train/logprobs = tensor([[-0.7943, -0.8868],
        [-0.6407, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02892821654677391
Epoch 0, Step 287: train/loss = 0.6504159569740295, train/raw-loss = 0.6278761029243469, train/logprobs = tensor([[-1.0819, -1.4723],
        [-1.1252, -1.2345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0450797975063324
Epoch 0, Step 288: train/loss = 0.6767817735671997, train/raw-loss = 0.6531928777694702, train/logprobs = tensor([[-0.9783, -0.8944],
        [-0.9075, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04717782884836197
Epoch 0, Step 289: train/loss = 0.7143838405609131, train/raw-loss = 0.6875355839729309, train/logprobs = tensor([[-1.2388, -1.0607],
        [-1.0123, -0.7782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05369648337364197
Epoch 0, Step 290: train/loss = 0.6792460083961487, train/raw-loss = 0.6564079523086548, train/logprobs = tensor([[-0.9953, -1.2474],
        [-0.8968, -0.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04567611962556839
Epoch 0, Step 291: train/loss = 0.6973002552986145, train/raw-loss = 0.6708530187606812, train/logprobs = tensor([[-1.0009, -1.0857],
        [-0.8867, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05289450287818909
Epoch 0, Step 292: train/loss = 0.6913862824440002, train/raw-loss = 0.6732814311981201, train/logprobs = tensor([[-1.1292, -1.3431],
        [-1.0257, -1.1528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03620963543653488
Epoch 0, Step 293: train/loss = 0.6951484084129333, train/raw-loss = 0.6840459108352661, train/logprobs = tensor([[-0.4499, -0.4362],
        [-0.3882, -0.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022205030545592308
Epoch 0, Step 294: train/loss = 0.6765575408935547, train/raw-loss = 0.653590738773346, train/logprobs = tensor([[-0.7538, -1.1121],
        [-0.7283, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04593357816338539
Epoch 0, Step 295: train/loss = 0.6993613839149475, train/raw-loss = 0.6774353981018066, train/logprobs = tensor([[-0.9456, -1.1331],
        [-0.8239, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04385192692279816
Epoch 0, Step 296: train/loss = 0.6903572082519531, train/raw-loss = 0.6725388765335083, train/logprobs = tensor([[-0.6800, -0.5063],
        [-0.7016, -0.4430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0356367826461792
Epoch 0, Step 297: train/loss = 0.6600198149681091, train/raw-loss = 0.6293961405754089, train/logprobs = tensor([[-0.8825, -1.6847],
        [-0.7219, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061247363686561584
Epoch 0, Step 298: train/loss = 0.6912698149681091, train/raw-loss = 0.6699221730232239, train/logprobs = tensor([[-0.9362, -1.2302],
        [-0.8370, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04269539564847946
Epoch 0, Step 299: train/loss = 0.6688735485076904, train/raw-loss = 0.6485952734947205, train/logprobs = tensor([[-0.9099, -1.2063],
        [-0.7979, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0405564121901989
Epoch 0, Step 300: train/loss = 0.6315277814865112, train/raw-loss = 0.603305995464325, train/logprobs = tensor([[-1.0315, -1.8542],
        [-0.9265, -1.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05644366517663002
Epoch 0, Step 301: train/loss = 0.6761517524719238, train/raw-loss = 0.6587042808532715, train/logprobs = tensor([[-0.7573, -1.1173],
        [-0.6413, -0.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034894973039627075
Epoch 0, Step 302: train/loss = 0.6466368436813354, train/raw-loss = 0.6201797127723694, train/logprobs = tensor([[-0.8378, -2.1229],
        [-0.7797, -1.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05291416496038437
Epoch 0, Step 303: train/loss = 0.7170722484588623, train/raw-loss = 0.6974389553070068, train/logprobs = tensor([[-0.9230, -0.8988],
        [-0.7465, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03926678001880646
Epoch 0, Step 304: train/loss = 0.6892104744911194, train/raw-loss = 0.6685373783111572, train/logprobs = tensor([[-1.0762, -1.2513],
        [-0.9511, -1.0056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04134621098637581
Epoch 0, Step 305: train/loss = 0.6741591095924377, train/raw-loss = 0.6521112322807312, train/logprobs = tensor([[-1.0708, -1.8044],
        [-0.9644, -1.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04409579932689667
Epoch 0, Step 306: train/loss = 0.691159725189209, train/raw-loss = 0.6627837419509888, train/logprobs = tensor([[-1.0446, -1.2261],
        [-0.9464, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05675191804766655
Epoch 0, Step 307: train/loss = 0.7054812908172607, train/raw-loss = 0.6787302494049072, train/logprobs = tensor([[-1.7618, -1.9270],
        [-1.4322, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053502157330513
Epoch 0, Step 308: train/loss = 0.7155357003211975, train/raw-loss = 0.6909062266349792, train/logprobs = tensor([[-1.1254, -0.9169],
        [-0.9293, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04925902560353279
Epoch 0, Step 309: train/loss = 0.6844322681427002, train/raw-loss = 0.6650760173797607, train/logprobs = tensor([[-0.9999, -1.1044],
        [-0.7962, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03871258348226547
Epoch 0, Step 310: train/loss = 0.7030413150787354, train/raw-loss = 0.678579568862915, train/logprobs = tensor([[-0.9210, -0.9572],
        [-0.8439, -0.8173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04892350733280182
Epoch 0, Step 311: train/loss = 0.6601494550704956, train/raw-loss = 0.6351982951164246, train/logprobs = tensor([[-1.2496, -1.5805],
        [-1.0388, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049902331084012985
Epoch 0, Step 312: train/loss = 0.6313408613204956, train/raw-loss = 0.6050049662590027, train/logprobs = tensor([[-0.9248, -1.6752],
        [-0.8600, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05267179012298584
Epoch 0, Step 313: train/loss = 0.6806213855743408, train/raw-loss = 0.6578656435012817, train/logprobs = tensor([[-0.8697, -1.2753],
        [-0.7845, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04551145061850548
Epoch 0, Step 314: train/loss = 0.664523720741272, train/raw-loss = 0.6431626081466675, train/logprobs = tensor([[-1.0737, -1.4950],
        [-0.8905, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04272225499153137
Epoch 0, Step 315: train/loss = 0.6629388332366943, train/raw-loss = 0.6365419030189514, train/logprobs = tensor([[-1.2945, -1.5857],
        [-1.1527, -1.1787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052793897688388824
Epoch 0, Step 316: train/loss = 0.7117872834205627, train/raw-loss = 0.6889575719833374, train/logprobs = tensor([[-1.5482, -1.4215],
        [-1.3548, -1.1921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045659519731998444
Epoch 0, Step 317: train/loss = 0.7241238951683044, train/raw-loss = 0.7042223811149597, train/logprobs = tensor([[-0.7055, -1.7858],
        [-0.5902, -1.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03980299085378647
Epoch 0, Step 318: train/loss = 0.6656042337417603, train/raw-loss = 0.6406897306442261, train/logprobs = tensor([[-0.9830, -1.2270],
        [-0.8704, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0498291477560997
Epoch 0, Step 319: train/loss = 0.6813649535179138, train/raw-loss = 0.6426735520362854, train/logprobs = tensor([[-1.7059, -1.9252],
        [-1.3935, -1.3377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07738277316093445
Epoch 0, Step 320: train/loss = 0.7120577096939087, train/raw-loss = 0.6870371699333191, train/logprobs = tensor([[-1.2263, -1.2596],
        [-1.0321, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05004104971885681
Epoch 0, Step 321: train/loss = 0.7666559219360352, train/raw-loss = 0.7283157706260681, train/logprobs = tensor([[-1.5580, -1.4718],
        [-1.1682, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07668031752109528
Epoch 0, Step 322: train/loss = 0.7208880186080933, train/raw-loss = 0.6881110072135925, train/logprobs = tensor([[-1.9591, -2.3757],
        [-1.7329, -2.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06555402278900146
Epoch 0, Step 323: train/loss = 0.6580935120582581, train/raw-loss = 0.6313492059707642, train/logprobs = tensor([[-1.0337, -1.3814],
        [-0.9594, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053488586097955704
Epoch 0, Step 324: train/loss = 0.6780661940574646, train/raw-loss = 0.6561667919158936, train/logprobs = tensor([[-0.7710, -0.7462],
        [-0.8310, -0.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043798863887786865
Epoch 0, Step 325: train/loss = 0.6518673300743103, train/raw-loss = 0.6268641352653503, train/logprobs = tensor([[-0.8920, -1.3026],
        [-0.8009, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05000639706850052
Epoch 0, Step 326: train/loss = 0.733736515045166, train/raw-loss = 0.7080819010734558, train/logprobs = tensor([[-1.5040, -1.5582],
        [-1.1097, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05130929499864578
Epoch 0, Step 327: train/loss = 0.713491678237915, train/raw-loss = 0.6927029490470886, train/logprobs = tensor([[-0.7173, -0.6761],
        [-0.7146, -0.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041577477008104324
Epoch 0, Step 328: train/loss = 0.6623108386993408, train/raw-loss = 0.6405593752861023, train/logprobs = tensor([[-1.0370, -1.3321],
        [-0.9224, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043502941727638245
Epoch 0, Step 329: train/loss = 0.7181606292724609, train/raw-loss = 0.6870673298835754, train/logprobs = tensor([[-1.1448, -1.3412],
        [-1.0125, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062186677008867264
Epoch 0, Step 330: train/loss = 0.7056127786636353, train/raw-loss = 0.6722500324249268, train/logprobs = tensor([[-1.2416, -1.5177],
        [-1.2338, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06672561168670654
Epoch 0, Step 331: train/loss = 0.6677663922309875, train/raw-loss = 0.6442894339561462, train/logprobs = tensor([[-0.6252, -0.7584],
        [-0.6359, -0.5560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046953823417425156
Epoch 0, Step 332: train/loss = 0.6742745637893677, train/raw-loss = 0.6456055641174316, train/logprobs = tensor([[-0.8308, -1.4137],
        [-0.7738, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05733802169561386
Epoch 0, Step 333: train/loss = 0.7001129984855652, train/raw-loss = 0.6706966161727905, train/logprobs = tensor([[-1.4631, -1.5492],
        [-1.3991, -1.3630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0588328093290329
Epoch 0, Step 334: train/loss = 0.6382267475128174, train/raw-loss = 0.6104848384857178, train/logprobs = tensor([[-0.7555, -1.5926],
        [-0.7446, -1.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05548392981290817
Epoch 0, Step 335: train/loss = 0.6931811571121216, train/raw-loss = 0.6691060066223145, train/logprobs = tensor([[-0.8697, -1.0205],
        [-0.7831, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04815032333135605
Epoch 0, Step 336: train/loss = 0.6391029357910156, train/raw-loss = 0.611222505569458, train/logprobs = tensor([[-0.8691, -1.8020],
        [-0.8334, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05576080456376076
Epoch 0, Step 337: train/loss = 0.7012733221054077, train/raw-loss = 0.6740777492523193, train/logprobs = tensor([[-1.5138, -0.9254],
        [-1.4759, -0.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05439120531082153
Epoch 0, Step 338: train/loss = 0.6858797073364258, train/raw-loss = 0.65972900390625, train/logprobs = tensor([[-0.8622, -1.1084],
        [-0.8083, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05230145901441574
Epoch 0, Step 339: train/loss = 0.6918495297431946, train/raw-loss = 0.6660601496696472, train/logprobs = tensor([[-2.4731, -2.1748],
        [-2.2772, -1.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05157867819070816
Epoch 0, Step 340: train/loss = 0.6911490559577942, train/raw-loss = 0.6626967191696167, train/logprobs = tensor([[-0.8752, -1.0765],
        [-0.8787, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05690470710396767
Epoch 0, Step 341: train/loss = 0.709023654460907, train/raw-loss = 0.6919945478439331, train/logprobs = tensor([[-0.6762, -0.5981],
        [-0.6451, -0.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034058183431625366
Epoch 0, Step 342: train/loss = 0.6965004205703735, train/raw-loss = 0.6741673946380615, train/logprobs = tensor([[-0.6298, -0.6852],
        [-0.5927, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0446661151945591
Epoch 0, Step 343: train/loss = 0.7096240520477295, train/raw-loss = 0.6774754524230957, train/logprobs = tensor([[-1.4808, -1.4341],
        [-1.3171, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06429729610681534
Epoch 0, Step 344: train/loss = 0.6720987558364868, train/raw-loss = 0.6331745386123657, train/logprobs = tensor([[-0.4780, -1.0118],
        [-0.4788, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07784844934940338
Epoch 0, Step 345: train/loss = 0.7059898376464844, train/raw-loss = 0.6769881248474121, train/logprobs = tensor([[-0.6898, -0.6824],
        [-0.6889, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05800345540046692
Epoch 0, Step 346: train/loss = 0.6565485000610352, train/raw-loss = 0.6256466507911682, train/logprobs = tensor([[-1.0022, -1.5386],
        [-0.8626, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06180375814437866
Epoch 0, Step 347: train/loss = 0.626777172088623, train/raw-loss = 0.5900411605834961, train/logprobs = tensor([[-0.8382, -1.4113],
        [-0.9077, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07347191125154495
Epoch 0, Step 348: train/loss = 0.6839100122451782, train/raw-loss = 0.6572842001914978, train/logprobs = tensor([[-1.0106, -1.4855],
        [-0.8620, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05325160175561905
Epoch 0, Step 349: train/loss = 0.6763919591903687, train/raw-loss = 0.6451614499092102, train/logprobs = tensor([[-1.3259, -1.4691],
        [-1.2594, -1.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06246111914515495
Epoch 0, Step 350: train/loss = 0.7007102370262146, train/raw-loss = 0.664790689945221, train/logprobs = tensor([[-1.0012, -0.9563],
        [-0.9492, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0718391165137291
Epoch 0, Step 351: train/loss = 0.6815539598464966, train/raw-loss = 0.6621697545051575, train/logprobs = tensor([[-0.9109, -0.9789],
        [-0.8498, -0.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03876854106783867
Epoch 0, Step 352: train/loss = 0.7096982002258301, train/raw-loss = 0.6756013631820679, train/logprobs = tensor([[-1.1736, -1.4773],
        [-0.9315, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06819378584623337
Epoch 0, Step 353: train/loss = 0.6663590669631958, train/raw-loss = 0.6351462602615356, train/logprobs = tensor([[-0.9220, -1.7530],
        [-0.8023, -1.3465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0624256506562233
Epoch 0, Step 354: train/loss = 0.7012872695922852, train/raw-loss = 0.6861969828605652, train/logprobs = tensor([[-0.4405, -0.4480],
        [-0.4355, -0.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03018050268292427
Epoch 0, Step 355: train/loss = 0.7303488850593567, train/raw-loss = 0.6985155344009399, train/logprobs = tensor([[-1.5201, -1.5505],
        [-1.3523, -1.3875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06366676092147827
Epoch 0, Step 356: train/loss = 0.7001891136169434, train/raw-loss = 0.6829280853271484, train/logprobs = tensor([[-0.7306, -0.7215],
        [-0.6377, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034522175788879395
Epoch 0, Step 357: train/loss = 0.6792157292366028, train/raw-loss = 0.6372759938240051, train/logprobs = tensor([[-1.1844, -1.5126],
        [-1.1704, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838795080780983
Epoch 0, Step 358: train/loss = 0.69286048412323, train/raw-loss = 0.6521762013435364, train/logprobs = tensor([[-0.8093, -2.1229],
        [-0.7113, -1.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081368587911129
Epoch 0, Step 359: train/loss = 0.6680679321289062, train/raw-loss = 0.6314306259155273, train/logprobs = tensor([[-0.8223, -1.3047],
        [-0.8883, -1.1104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327466458082199
Epoch 0, Step 360: train/loss = 0.5975199937820435, train/raw-loss = 0.5720483064651489, train/logprobs = tensor([[-1.2064, -1.5562],
        [-1.4174, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05094330757856369
Epoch 0, Step 361: train/loss = 0.7656635642051697, train/raw-loss = 0.7376697063446045, train/logprobs = tensor([[-1.1828, -1.1786],
        [-0.9574, -1.0930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05598754435777664
Epoch 0, Step 362: train/loss = 0.6562825441360474, train/raw-loss = 0.6235182285308838, train/logprobs = tensor([[-2.0043, -2.3102],
        [-2.1744, -2.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06552872061729431
Epoch 0, Step 363: train/loss = 0.678767740726471, train/raw-loss = 0.6507232189178467, train/logprobs = tensor([[-0.4759, -0.7254],
        [-0.4866, -0.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056089043617248535
Epoch 0, Step 364: train/loss = 0.6941481828689575, train/raw-loss = 0.6664813756942749, train/logprobs = tensor([[-0.8756, -1.1689],
        [-0.9505, -1.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055333562195301056
Epoch 0, Step 365: train/loss = 0.6868295669555664, train/raw-loss = 0.666615903377533, train/logprobs = tensor([[-1.1311, -1.5178],
        [-0.9496, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04042733088135719
Epoch 0, Step 366: train/loss = 0.6643731594085693, train/raw-loss = 0.6364560127258301, train/logprobs = tensor([[-0.6623, -1.2243],
        [-0.6492, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05583440512418747
Epoch 0, Step 367: train/loss = 0.6576207876205444, train/raw-loss = 0.6313307881355286, train/logprobs = tensor([[-1.0209, -1.2964],
        [-1.0992, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052580107003450394
Epoch 0, Step 368: train/loss = 0.6563621163368225, train/raw-loss = 0.6282004117965698, train/logprobs = tensor([[-0.8439, -1.2324],
        [-0.8191, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056323375552892685
Epoch 0, Step 369: train/loss = 0.630359947681427, train/raw-loss = 0.5976804494857788, train/logprobs = tensor([[-1.2781, -1.1260],
        [-1.4670, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06535898894071579
Epoch 0, Step 370: train/loss = 0.7180100083351135, train/raw-loss = 0.695327639579773, train/logprobs = tensor([[-1.0064, -0.9153],
        [-0.8578, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045364923775196075
Epoch 0, Step 371: train/loss = 0.7075772881507874, train/raw-loss = 0.6763676404953003, train/logprobs = tensor([[-0.7962, -0.6689],
        [-0.8050, -0.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062419235706329346
Epoch 0, Step 372: train/loss = 0.7075657248497009, train/raw-loss = 0.6771070957183838, train/logprobs = tensor([[-0.5178, -0.7110],
        [-0.5482, -0.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06091717630624771
Epoch 0, Step 373: train/loss = 0.736649215221405, train/raw-loss = 0.709744930267334, train/logprobs = tensor([[-0.7285, -0.4704],
        [-0.6369, -0.4416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053808581084012985
Epoch 0, Step 374: train/loss = 0.6814126372337341, train/raw-loss = 0.6468251347541809, train/logprobs = tensor([[-0.6696, -1.1413],
        [-0.6428, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06917509436607361
Epoch 0, Step 375: train/loss = 0.6728345155715942, train/raw-loss = 0.6458570957183838, train/logprobs = tensor([[-1.6085, -1.1418],
        [-1.5648, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053954996168613434
Epoch 0, Step 376: train/loss = 0.6980723142623901, train/raw-loss = 0.6832391023635864, train/logprobs = tensor([[-0.5545, -0.5726],
        [-0.5281, -0.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029666312038898468
Epoch 0, Step 377: train/loss = 0.7308462858200073, train/raw-loss = 0.7029830813407898, train/logprobs = tensor([[-0.6804, -0.6476],
        [-0.6537, -0.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055726394057273865
Epoch 0, Step 378: train/loss = 0.6580976247787476, train/raw-loss = 0.6159483194351196, train/logprobs = tensor([[-0.6857, -1.2317],
        [-0.7044, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08429858088493347
Epoch 0, Step 379: train/loss = 0.6240032911300659, train/raw-loss = 0.5870519876480103, train/logprobs = tensor([[-0.8301, -1.7615],
        [-0.8222, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390279322862625
Epoch 0, Step 380: train/loss = 0.6836543083190918, train/raw-loss = 0.6594406366348267, train/logprobs = tensor([[-0.9451, -1.0405],
        [-0.8413, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04842718318104744
Epoch 0, Step 381: train/loss = 0.689951479434967, train/raw-loss = 0.670000433921814, train/logprobs = tensor([[-1.0973, -1.0982],
        [-1.0202, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039902083575725555
Epoch 0, Step 382: train/loss = 0.6818317174911499, train/raw-loss = 0.6587014198303223, train/logprobs = tensor([[-0.7613, -0.8332],
        [-0.8377, -0.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04626049846410751
Epoch 0, Step 383: train/loss = 0.6844053864479065, train/raw-loss = 0.6596957445144653, train/logprobs = tensor([[-0.7868, -1.0516],
        [-0.7486, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04941925033926964
Epoch 0, Step 384: train/loss = 0.6612625122070312, train/raw-loss = 0.6282081604003906, train/logprobs = tensor([[-1.2543, -1.2364],
        [-1.3568, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06610864400863647
Epoch 0, Step 385: train/loss = 0.6758540272712708, train/raw-loss = 0.6456630229949951, train/logprobs = tensor([[-0.7295, -0.9327],
        [-0.9011, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06038197875022888
Epoch 0, Step 386: train/loss = 0.6501935720443726, train/raw-loss = 0.6248043179512024, train/logprobs = tensor([[-0.9828, -1.8362],
        [-0.8422, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050778597593307495
Epoch 0, Step 387: train/loss = 0.653576135635376, train/raw-loss = 0.6255176067352295, train/logprobs = tensor([[-0.9478, -1.7175],
        [-0.9267, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056117117404937744
Epoch 0, Step 388: train/loss = 0.6723899841308594, train/raw-loss = 0.6448943614959717, train/logprobs = tensor([[-0.7295, -0.9578],
        [-0.7621, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054991208016872406
Epoch 0, Step 389: train/loss = 0.6759577393531799, train/raw-loss = 0.6529088616371155, train/logprobs = tensor([[-0.9601, -0.8517],
        [-1.0358, -0.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0460977740585804
Epoch 0, Step 390: train/loss = 0.6871184706687927, train/raw-loss = 0.6648544073104858, train/logprobs = tensor([[-0.6389, -1.1969],
        [-0.6537, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04452807456254959
Epoch 0, Step 391: train/loss = 0.6713072657585144, train/raw-loss = 0.6481064558029175, train/logprobs = tensor([[-1.0255, -1.4024],
        [-1.0646, -1.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04640166461467743
Epoch 0, Step 392: train/loss = 0.6784769296646118, train/raw-loss = 0.6565473079681396, train/logprobs = tensor([[-0.8427, -1.0922],
        [-0.7860, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043859269469976425
Epoch 0, Step 393: train/loss = 0.6346197128295898, train/raw-loss = 0.6042783856391907, train/logprobs = tensor([[-0.8522, -1.2839],
        [-1.0517, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06068263575434685
Epoch 0, Step 394: train/loss = 0.6473142504692078, train/raw-loss = 0.611376166343689, train/logprobs = tensor([[-1.3751, -1.6004],
        [-1.3943, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07187625765800476
Epoch 0, Step 395: train/loss = 0.6957928538322449, train/raw-loss = 0.6757009029388428, train/logprobs = tensor([[-0.5616, -0.5777],
        [-0.5414, -0.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04018391668796539
Epoch 0, Step 396: train/loss = 0.6959986090660095, train/raw-loss = 0.673965334892273, train/logprobs = tensor([[-0.7269, -0.8071],
        [-0.7094, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044066429138183594
Epoch 0, Step 397: train/loss = 0.6876015067100525, train/raw-loss = 0.6688292622566223, train/logprobs = tensor([[-0.5354, -0.7753],
        [-0.5528, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03754444047808647
Epoch 0, Step 398: train/loss = 0.6785292029380798, train/raw-loss = 0.6493533253669739, train/logprobs = tensor([[-0.6971, -1.1161],
        [-0.7397, -0.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05835180729627609
Epoch 0, Step 399: train/loss = 0.7096625566482544, train/raw-loss = 0.6891447305679321, train/logprobs = tensor([[-0.8428, -0.6623],
        [-0.8375, -0.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041035715490579605
Epoch 0, Step 400: train/loss = 0.6152614951133728, train/raw-loss = 0.5928365588188171, train/logprobs = tensor([[-1.0974, -1.9264],
        [-0.9584, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044849883764982224
Epoch 0, Step 401: train/loss = 0.6964082717895508, train/raw-loss = 0.6584634780883789, train/logprobs = tensor([[-1.3319, -1.5677],
        [-1.4533, -1.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07588949054479599
Epoch 0, Step 402: train/loss = 0.6689891815185547, train/raw-loss = 0.6402716636657715, train/logprobs = tensor([[-0.9722, -1.3236],
        [-0.9157, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057434968650341034
Epoch 0, Step 403: train/loss = 0.6687108278274536, train/raw-loss = 0.6446239948272705, train/logprobs = tensor([[-0.8407, -1.2972],
        [-0.9411, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04817366600036621
Epoch 0, Step 404: train/loss = 0.6959468126296997, train/raw-loss = 0.6703546047210693, train/logprobs = tensor([[-1.0057, -1.0424],
        [-0.8993, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05118430405855179
Epoch 0, Step 405: train/loss = 0.7152866125106812, train/raw-loss = 0.6997510194778442, train/logprobs = tensor([[-0.5756, -0.4246],
        [-0.5484, -0.4235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031071113422513008
Epoch 0, Step 406: train/loss = 0.7103971838951111, train/raw-loss = 0.6774191856384277, train/logprobs = tensor([[-0.8575, -1.0278],
        [-0.8996, -1.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0659560039639473
Epoch 0, Step 407: train/loss = 0.6762832403182983, train/raw-loss = 0.6543939113616943, train/logprobs = tensor([[-0.9510, -1.0635],
        [-0.9556, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0437786802649498
Epoch 0, Step 408: train/loss = 0.6659983396530151, train/raw-loss = 0.6334290504455566, train/logprobs = tensor([[-0.7507, -1.0063],
        [-0.8232, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06513859331607819
Epoch 0, Step 409: train/loss = 0.6590098738670349, train/raw-loss = 0.628298819065094, train/logprobs = tensor([[-0.8462, -0.6918],
        [-1.0296, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06142202764749527
Epoch 0, Step 410: train/loss = 0.6626315116882324, train/raw-loss = 0.6344242095947266, train/logprobs = tensor([[-1.2599, -0.9175],
        [-1.5459, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05641449615359306
Epoch 0, Step 411: train/loss = 0.71358323097229, train/raw-loss = 0.6841585636138916, train/logprobs = tensor([[-0.8014, -1.0120],
        [-0.9383, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05884938687086105
Epoch 0, Step 412: train/loss = 0.6661081314086914, train/raw-loss = 0.6315489411354065, train/logprobs = tensor([[-1.1360, -1.5061],
        [-1.1833, -1.1646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.069118432700634
Epoch 0, Step 413: train/loss = 0.6906827688217163, train/raw-loss = 0.674229621887207, train/logprobs = tensor([[-1.0773, -1.4843],
        [-1.0749, -1.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03290625289082527
Epoch 0, Step 414: train/loss = 0.6849269866943359, train/raw-loss = 0.6605314016342163, train/logprobs = tensor([[-0.5499, -0.9605],
        [-0.5934, -0.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04879118502140045
Epoch 0, Step 415: train/loss = 0.6874140501022339, train/raw-loss = 0.66025710105896, train/logprobs = tensor([[-0.9483, -1.1413],
        [-0.9722, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054313987493515015
Epoch 0, Step 416: train/loss = 0.714156985282898, train/raw-loss = 0.6798388957977295, train/logprobs = tensor([[-0.7297, -0.5056],
        [-0.7778, -0.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06863619387149811
Epoch 0, Step 417: train/loss = 0.6266810297966003, train/raw-loss = 0.5973750352859497, train/logprobs = tensor([[-0.9944, -1.4979],
        [-1.2569, -1.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058611996471881866
Epoch 0, Step 418: train/loss = 0.6889510154724121, train/raw-loss = 0.6592576503753662, train/logprobs = tensor([[-0.5788, -0.7374],
        [-0.6280, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05938670039176941
Epoch 0, Step 419: train/loss = 0.6271728277206421, train/raw-loss = 0.5927494764328003, train/logprobs = tensor([[-1.0312, -1.6867],
        [-1.0233, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06884676963090897
Epoch 0, Step 420: train/loss = 0.6893489360809326, train/raw-loss = 0.6602978110313416, train/logprobs = tensor([[-0.5590, -0.8040],
        [-0.6402, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05810234323143959
Epoch 0, Step 421: train/loss = 0.6535259485244751, train/raw-loss = 0.6259900331497192, train/logprobs = tensor([[-0.7881, -1.2276],
        [-0.9101, -1.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05507184565067291
Epoch 0, Step 422: train/loss = 0.5796568393707275, train/raw-loss = 0.5428292155265808, train/logprobs = tensor([[-1.4205, -1.7980],
        [-1.7980, -1.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365518808364868
Epoch 0, Step 423: train/loss = 0.6800940036773682, train/raw-loss = 0.6565641760826111, train/logprobs = tensor([[-0.6057, -1.0946],
        [-0.5240, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04705967754125595
Epoch 0, Step 424: train/loss = 0.6704488396644592, train/raw-loss = 0.6425756216049194, train/logprobs = tensor([[-1.2778, -1.2178],
        [-1.2536, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05574652925133705
Epoch 0, Step 425: train/loss = 0.7227169871330261, train/raw-loss = 0.6956485509872437, train/logprobs = tensor([[-1.0650, -0.8952],
        [-0.9306, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05413693189620972
Epoch 0, Step 426: train/loss = 0.72332763671875, train/raw-loss = 0.6874161958694458, train/logprobs = tensor([[-0.9830, -1.2832],
        [-0.8054, -1.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07182306051254272
Epoch 0, Step 427: train/loss = 0.650467038154602, train/raw-loss = 0.6241026520729065, train/logprobs = tensor([[-0.6406, -1.3589],
        [-0.6600, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05272865667939186
Epoch 0, Step 428: train/loss = 0.6737241744995117, train/raw-loss = 0.6447363495826721, train/logprobs = tensor([[-0.9363, -0.9674],
        [-0.9896, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057975541800260544
Epoch 0, Step 429: train/loss = 0.6844801902770996, train/raw-loss = 0.6563374996185303, train/logprobs = tensor([[-0.9479, -1.2255],
        [-0.8887, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05628532916307449
Epoch 0, Step 430: train/loss = 0.6890778541564941, train/raw-loss = 0.6496589779853821, train/logprobs = tensor([[-0.9597, -1.2063],
        [-1.0259, -1.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883773744106293
Epoch 0, Step 431: train/loss = 0.6993138194084167, train/raw-loss = 0.6760421395301819, train/logprobs = tensor([[-0.6517, -0.6592],
        [-0.6499, -0.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04654344543814659
Epoch 0, Step 432: train/loss = 0.6684912443161011, train/raw-loss = 0.6394580602645874, train/logprobs = tensor([[-1.0667, -1.3163],
        [-1.1412, -1.1498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05806632339954376
Epoch 0, Step 433: train/loss = 0.6211330890655518, train/raw-loss = 0.5796310901641846, train/logprobs = tensor([[-1.1315, -1.5497],
        [-1.3354, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08300399780273438
Epoch 0, Step 434: train/loss = 0.6702380776405334, train/raw-loss = 0.6415835618972778, train/logprobs = tensor([[-0.7499, -0.9381],
        [-0.8797, -0.8490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0573088712990284
Epoch 0, Step 435: train/loss = 0.6341332197189331, train/raw-loss = 0.5933452844619751, train/logprobs = tensor([[-1.1708, -1.2889],
        [-1.3921, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08157581835985184
Epoch 0, Step 436: train/loss = 0.7249045372009277, train/raw-loss = 0.6845673322677612, train/logprobs = tensor([[-1.1553, -1.3622],
        [-1.1670, -1.3366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08067438751459122
Epoch 0, Step 437: train/loss = 0.8900516033172607, train/raw-loss = 0.8570564985275269, train/logprobs = tensor([[-1.6846, -1.0200],
        [-1.0444, -0.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06599026918411255
Epoch 0, Step 438: train/loss = 0.6977131962776184, train/raw-loss = 0.6776988506317139, train/logprobs = tensor([[-0.5500, -0.5876],
        [-0.5149, -0.4866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040028758347034454
Epoch 0, Step 439: train/loss = 0.7101056575775146, train/raw-loss = 0.6825059056282043, train/logprobs = tensor([[-0.6319, -0.6812],
        [-0.7415, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05519946292042732
Epoch 0, Step 440: train/loss = 0.8028384447097778, train/raw-loss = 0.7811984419822693, train/logprobs = tensor([[-0.9860, -0.6654],
        [-0.5785, -0.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043279971927404404
Epoch 0, Step 441: train/loss = 0.6302696466445923, train/raw-loss = 0.5998662114143372, train/logprobs = tensor([[-0.6563, -1.3576],
        [-0.6786, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06080705672502518
Epoch 0, Step 442: train/loss = 0.6735002994537354, train/raw-loss = 0.6323511004447937, train/logprobs = tensor([[-0.9416, -1.4413],
        [-1.1189, -1.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229850977659225
Epoch 0, Step 443: train/loss = 0.6789692640304565, train/raw-loss = 0.6447537541389465, train/logprobs = tensor([[-0.8182, -0.8099],
        [-1.0081, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06843102723360062
Epoch 0, Step 444: train/loss = 0.7114810347557068, train/raw-loss = 0.6843196153640747, train/logprobs = tensor([[-0.7170, -0.8735],
        [-0.6751, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05432284250855446
Epoch 0, Step 445: train/loss = 0.6725544929504395, train/raw-loss = 0.6371215581893921, train/logprobs = tensor([[-0.7849, -1.0260],
        [-0.9559, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07086585462093353
Epoch 0, Step 446: train/loss = 0.7226125001907349, train/raw-loss = 0.6885986328125, train/logprobs = tensor([[-0.9380, -0.9561],
        [-0.9406, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06802773475646973
Epoch 0, Step 447: train/loss = 0.6331175565719604, train/raw-loss = 0.6057701110839844, train/logprobs = tensor([[-0.9455, -1.2633],
        [-0.9175, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05469507724046707
Epoch 0, Step 448: train/loss = 0.7143223285675049, train/raw-loss = 0.6838305592536926, train/logprobs = tensor([[-0.6643, -0.8386],
        [-0.5274, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06098349764943123
Epoch 0, Step 449: train/loss = 0.596078634262085, train/raw-loss = 0.5586599111557007, train/logprobs = tensor([[-1.2530, -1.5983],
        [-1.5983, -1.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07483743131160736
Epoch 0, Step 450: train/loss = 0.6855678558349609, train/raw-loss = 0.6545725464820862, train/logprobs = tensor([[-0.9954, -1.1743],
        [-0.9994, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061990562826395035
Epoch 0, Step 451: train/loss = 0.6307207345962524, train/raw-loss = 0.5818080306053162, train/logprobs = tensor([[-1.0653, -1.6171],
        [-1.2062, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09782534837722778
Epoch 0, Step 452: train/loss = 0.6302527189254761, train/raw-loss = 0.5960292220115662, train/logprobs = tensor([[-0.8939, -1.6027],
        [-0.7572, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06844700872898102
Epoch 0, Step 453: train/loss = 0.6563082933425903, train/raw-loss = 0.6207665801048279, train/logprobs = tensor([[-1.0905, -1.5845],
        [-1.0664, -1.2204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07108332216739655
Epoch 0, Step 454: train/loss = 0.7339882850646973, train/raw-loss = 0.6956497430801392, train/logprobs = tensor([[-1.1633, -0.9887],
        [-1.0901, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07667702436447144
Epoch 0, Step 455: train/loss = 0.5864615440368652, train/raw-loss = 0.5526557564735413, train/logprobs = tensor([[-0.6347, -2.0281],
        [-0.5895, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06761149317026138
Epoch 0, Step 456: train/loss = 0.6955689191818237, train/raw-loss = 0.6610567569732666, train/logprobs = tensor([[-0.7134, -1.0038],
        [-0.7298, -0.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06902415305376053
Epoch 0, Step 457: train/loss = 0.6771189570426941, train/raw-loss = 0.6407464146614075, train/logprobs = tensor([[-0.7293, -0.6302],
        [-0.8897, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07274515926837921
Epoch 0, Step 458: train/loss = 0.6482366919517517, train/raw-loss = 0.5948348045349121, train/logprobs = tensor([[-1.0759, -1.3201],
        [-1.4227, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106803759932518
Epoch 0, Step 459: train/loss = 0.6906607747077942, train/raw-loss = 0.6499590873718262, train/logprobs = tensor([[-1.0267, -1.3530],
        [-0.7684, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140330016613007
Epoch 0, Step 460: train/loss = 0.6909980177879333, train/raw-loss = 0.6576539874076843, train/logprobs = tensor([[-0.7807, -1.0005],
        [-0.9159, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06668802350759506
Epoch 0, Step 461: train/loss = 0.7313286066055298, train/raw-loss = 0.6894809603691101, train/logprobs = tensor([[-1.1315, -1.4225],
        [-1.0335, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08369529247283936
Epoch 0, Step 462: train/loss = 0.713857889175415, train/raw-loss = 0.664753258228302, train/logprobs = tensor([[-0.9768, -1.3519],
        [-1.0126, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09820933640003204
Epoch 0, Step 463: train/loss = 0.658805251121521, train/raw-loss = 0.6264586448669434, train/logprobs = tensor([[-1.2448, -1.1119],
        [-1.4178, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469327211380005
Epoch 0, Step 464: train/loss = 0.626129150390625, train/raw-loss = 0.5834884643554688, train/logprobs = tensor([[-0.5436, -1.7826],
        [-0.6206, -1.2960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08528139442205429
Epoch 0, Step 465: train/loss = 0.6696633696556091, train/raw-loss = 0.6342060565948486, train/logprobs = tensor([[-0.9623, -1.3481],
        [-0.9458, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0709146037697792
Epoch 0, Step 466: train/loss = 0.6028801798820496, train/raw-loss = 0.5656358003616333, train/logprobs = tensor([[-1.4441, -2.1893],
        [-1.4082, -1.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07448876649141312
Epoch 0, Step 467: train/loss = 0.6317989230155945, train/raw-loss = 0.5901823043823242, train/logprobs = tensor([[-0.6924, -1.4963],
        [-0.7452, -1.0474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08323310315608978
Epoch 0, Step 468: train/loss = 0.614943265914917, train/raw-loss = 0.5861996412277222, train/logprobs = tensor([[-0.5434, -1.8265],
        [-0.4847, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05748729407787323
Epoch 0, Step 469: train/loss = 0.663898766040802, train/raw-loss = 0.625619649887085, train/logprobs = tensor([[-0.9391, -0.9591],
        [-1.1344, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07655830681324005
Epoch 0, Step 470: train/loss = 0.6676537394523621, train/raw-loss = 0.6280720233917236, train/logprobs = tensor([[-0.9138, -1.4407],
        [-0.9749, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07916344702243805
Epoch 0, Step 471: train/loss = 0.6872716546058655, train/raw-loss = 0.6478767395019531, train/logprobs = tensor([[-0.9345, -1.0255],
        [-1.1060, -0.9930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07878987491130829
Epoch 0, Step 472: train/loss = 0.6984224319458008, train/raw-loss = 0.6727327704429626, train/logprobs = tensor([[-0.6169, -0.6454],
        [-0.7542, -0.6841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05137951672077179
Epoch 0, Step 473: train/loss = 0.6461920738220215, train/raw-loss = 0.6098509430885315, train/logprobs = tensor([[-0.8119, -1.1810],
        [-0.8470, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07268232107162476
Epoch 0, Step 474: train/loss = 0.5917052030563354, train/raw-loss = 0.5576549172401428, train/logprobs = tensor([[-0.9986, -1.9997],
        [-1.0814, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06810048967599869
Epoch 0, Step 475: train/loss = 0.6869056224822998, train/raw-loss = 0.6457176804542542, train/logprobs = tensor([[-0.8669, -1.4821],
        [-0.9043, -1.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237594366073608
Epoch 0, Step 476: train/loss = 0.6376283168792725, train/raw-loss = 0.6064450740814209, train/logprobs = tensor([[-0.8242, -1.1861],
        [-0.9539, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06236641854047775
Epoch 0, Step 477: train/loss = 0.6452224254608154, train/raw-loss = 0.6142285466194153, train/logprobs = tensor([[-0.6532, -1.3114],
        [-0.6378, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061987750232219696
Epoch 0, Step 478: train/loss = 0.7447513341903687, train/raw-loss = 0.7042868137359619, train/logprobs = tensor([[-1.1200, -1.1544],
        [-1.3728, -1.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092904090881348
Epoch 0, Step 479: train/loss = 0.7110977172851562, train/raw-loss = 0.6707361340522766, train/logprobs = tensor([[-1.1431, -1.1583],
        [-0.9871, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08072312921285629
Epoch 0, Step 480: train/loss = 0.6332984566688538, train/raw-loss = 0.6007609367370605, train/logprobs = tensor([[-1.1253, -1.7719],
        [-0.8978, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06507515907287598
Epoch 0, Step 481: train/loss = 0.6544613242149353, train/raw-loss = 0.6074167490005493, train/logprobs = tensor([[-0.9230, -1.1798],
        [-1.1524, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408913552761078
Epoch 0, Step 482: train/loss = 0.6620279550552368, train/raw-loss = 0.6104764342308044, train/logprobs = tensor([[-1.1016, -1.2640],
        [-1.3448, -1.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10310303419828415
Epoch 0, Step 483: train/loss = 0.6862475872039795, train/raw-loss = 0.6494666337966919, train/logprobs = tensor([[-0.9895, -0.9885],
        [-1.0551, -0.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07356179505586624
Epoch 0, Step 484: train/loss = 0.6899741888046265, train/raw-loss = 0.648141622543335, train/logprobs = tensor([[-0.8265, -1.3416],
        [-0.7603, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08366507291793823
Epoch 0, Step 485: train/loss = 0.6830207705497742, train/raw-loss = 0.6436209678649902, train/logprobs = tensor([[-1.4516, -1.5810],
        [-1.4574, -1.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07879949361085892
Epoch 0, Step 486: train/loss = 0.5851151943206787, train/raw-loss = 0.5475825071334839, train/logprobs = tensor([[-0.9473, -2.0208],
        [-0.9779, -1.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07506546378135681
Epoch 0, Step 487: train/loss = 0.6396986246109009, train/raw-loss = 0.5892553329467773, train/logprobs = tensor([[-0.9459, -1.9333],
        [-1.0576, -1.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10088661313056946
Epoch 0, Step 488: train/loss = 0.6597892045974731, train/raw-loss = 0.6036843061447144, train/logprobs = tensor([[-1.1253, -1.5357],
        [-1.5435, -1.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220965534448624
Epoch 0, Step 489: train/loss = 0.6943287253379822, train/raw-loss = 0.6518967747688293, train/logprobs = tensor([[-1.0992, -1.2635],
        [-0.9467, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08486398309469223
Epoch 0, Step 490: train/loss = 0.6599750518798828, train/raw-loss = 0.6133643388748169, train/logprobs = tensor([[-1.4392, -1.5952],
        [-1.7038, -1.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322145581245422
Epoch 0, Step 491: train/loss = 0.5960865616798401, train/raw-loss = 0.5487645864486694, train/logprobs = tensor([[-0.4094, -2.0978],
        [-0.4401, -1.4300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09464401751756668
Epoch 0, Step 492: train/loss = 0.6563023924827576, train/raw-loss = 0.6202515959739685, train/logprobs = tensor([[-0.8230, -0.7635],
        [-1.0819, -0.6642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07210157066583633
Epoch 0, Step 493: train/loss = 0.7238690853118896, train/raw-loss = 0.6888346076011658, train/logprobs = tensor([[-0.6661, -0.8381],
        [-0.7108, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07006888091564178
Epoch 0, Step 494: train/loss = 0.6113318800926208, train/raw-loss = 0.5702071785926819, train/logprobs = tensor([[-0.7010, -1.4395],
        [-0.8658, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08224944770336151
Epoch 0, Step 495: train/loss = 0.6554707288742065, train/raw-loss = 0.6109684705734253, train/logprobs = tensor([[-0.9455, -1.3501],
        [-1.1564, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0890045091509819
Epoch 0, Step 496: train/loss = 0.7036701440811157, train/raw-loss = 0.6666733026504517, train/logprobs = tensor([[-0.7575, -0.7246],
        [-0.7213, -0.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07399362325668335
Epoch 0, Step 497: train/loss = 0.6422027945518494, train/raw-loss = 0.6037517786026001, train/logprobs = tensor([[-0.7794, -1.1743],
        [-0.8713, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.076901875436306
Epoch 0, Step 498: train/loss = 0.6917010545730591, train/raw-loss = 0.6648683547973633, train/logprobs = tensor([[-0.7870, -0.8432],
        [-0.6673, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05366528034210205
Epoch 0, Step 499: train/loss = 0.6853762865066528, train/raw-loss = 0.6351988911628723, train/logprobs = tensor([[-0.9337, -1.0126],
        [-1.1496, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10035483539104462
eval/loss: 0.6772215366363525
Epoch 0, Step 500: train/loss = 0.5971250534057617, train/raw-loss = 0.5512378215789795, train/logprobs = tensor([[-1.2596, -2.3476],
        [-1.5013, -1.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177440404891968
Epoch 0, Step 501: train/loss = 0.8892022371292114, train/raw-loss = 0.847719132900238, train/logprobs = tensor([[-1.8461, -1.2664],
        [-1.3554, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08296637237071991
Epoch 0, Step 502: train/loss = 0.7080942392349243, train/raw-loss = 0.6664509177207947, train/logprobs = tensor([[-1.0429, -0.9355],
        [-1.0876, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08328674733638763
Epoch 0, Step 503: train/loss = 0.6823789477348328, train/raw-loss = 0.6497504115104675, train/logprobs = tensor([[-0.7062, -0.9399],
        [-0.7015, -0.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652569904923439
Epoch 0, Step 504: train/loss = 0.7425593137741089, train/raw-loss = 0.6986390352249146, train/logprobs = tensor([[-1.3068, -1.9448],
        [-0.8547, -1.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08784057199954987
Epoch 0, Step 505: train/loss = 0.6056612730026245, train/raw-loss = 0.5673314332962036, train/logprobs = tensor([[-0.7612, -1.5493],
        [-0.8737, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07665979862213135
Epoch 0, Step 506: train/loss = 0.7004570364952087, train/raw-loss = 0.6571875810623169, train/logprobs = tensor([[-0.9353, -1.3186],
        [-0.8461, -1.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0865388810634613
Epoch 0, Step 507: train/loss = 0.6428029537200928, train/raw-loss = 0.584587812423706, train/logprobs = tensor([[-1.6637, -2.1143],
        [-1.8480, -1.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11643033474683762
Epoch 0, Step 508: train/loss = 0.6487414836883545, train/raw-loss = 0.6118016839027405, train/logprobs = tensor([[-0.7137, -1.1789],
        [-0.8080, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07387964427471161
Epoch 0, Step 509: train/loss = 0.7077692747116089, train/raw-loss = 0.6820951700210571, train/logprobs = tensor([[-0.4375, -0.3952],
        [-0.4740, -0.3863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0513482429087162
Epoch 0, Step 510: train/loss = 0.6751004457473755, train/raw-loss = 0.6353064775466919, train/logprobs = tensor([[-0.9001, -1.2945],
        [-0.9903, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07958786934614182
Epoch 0, Step 511: train/loss = 0.7178266048431396, train/raw-loss = 0.6671830415725708, train/logprobs = tensor([[-1.1467, -1.1877],
        [-1.3093, -1.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10128729045391083
Epoch 0, Step 512: train/loss = 0.5895557403564453, train/raw-loss = 0.5506769418716431, train/logprobs = tensor([[-0.8433, -1.3022],
        [-1.0885, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07775751501321793
Epoch 0, Step 513: train/loss = 0.6323590278625488, train/raw-loss = 0.592715859413147, train/logprobs = tensor([[-0.6471, -1.3491],
        [-0.8580, -1.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07928633689880371
Epoch 0, Step 514: train/loss = 0.6918128728866577, train/raw-loss = 0.6485482454299927, train/logprobs = tensor([[-0.8573, -1.2395],
        [-0.9030, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08652932196855545
Epoch 0, Step 515: train/loss = 0.6906166076660156, train/raw-loss = 0.6501168608665466, train/logprobs = tensor([[-1.0768, -1.2372],
        [-1.0585, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08099948614835739
Epoch 0, Step 516: train/loss = 0.6943241357803345, train/raw-loss = 0.6675910949707031, train/logprobs = tensor([[-0.6085, -0.7527],
        [-0.5990, -0.6248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053465984761714935
Epoch 0, Step 517: train/loss = 0.6656381487846375, train/raw-loss = 0.6298211812973022, train/logprobs = tensor([[-0.5852, -1.2745],
        [-0.6894, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07163391262292862
Epoch 0, Step 518: train/loss = 0.6908885836601257, train/raw-loss = 0.6481972932815552, train/logprobs = tensor([[-1.1410, -1.4852],
        [-1.3321, -1.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08538252115249634
Epoch 0, Step 519: train/loss = 0.6737661361694336, train/raw-loss = 0.6346293687820435, train/logprobs = tensor([[-0.7461, -0.9050],
        [-0.9209, -0.8116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07827351987361908
Epoch 0, Step 520: train/loss = 0.6709474921226501, train/raw-loss = 0.6427001953125, train/logprobs = tensor([[-0.6595, -0.8202],
        [-0.7082, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056494757533073425
Epoch 0, Step 521: train/loss = 0.7170664072036743, train/raw-loss = 0.6933625936508179, train/logprobs = tensor([[-0.7240, -0.7174],
        [-0.6746, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04740745946764946
Epoch 0, Step 522: train/loss = 0.5633450746536255, train/raw-loss = 0.5199272632598877, train/logprobs = tensor([[-1.4706, -3.2781],
        [-2.0379, -2.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08683572709560394
Epoch 0, Step 523: train/loss = 0.6409831047058105, train/raw-loss = 0.5853844881057739, train/logprobs = tensor([[-0.8992, -1.3478],
        [-1.1348, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119729280471802
Epoch 0, Step 524: train/loss = 0.663390040397644, train/raw-loss = 0.6275726556777954, train/logprobs = tensor([[-0.6348, -1.5904],
        [-0.5835, -1.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0716346949338913
Epoch 0, Step 525: train/loss = 0.6791766285896301, train/raw-loss = 0.6410853266716003, train/logprobs = tensor([[-0.8865, -1.3940],
        [-0.6448, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07618256658315659
Epoch 0, Step 526: train/loss = 0.6627597808837891, train/raw-loss = 0.6260771155357361, train/logprobs = tensor([[-0.7564, -1.1479],
        [-0.8492, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336533814668655
Epoch 0, Step 527: train/loss = 1.005314826965332, train/raw-loss = 0.9596908092498779, train/logprobs = tensor([[-1.9098, -1.3579],
        [-1.0826, -1.1888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09124820679426193
Epoch 0, Step 528: train/loss = 0.6746224164962769, train/raw-loss = 0.6352689266204834, train/logprobs = tensor([[-1.1636, -1.3859],
        [-1.1580, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07870691269636154
Epoch 0, Step 529: train/loss = 0.5384182333946228, train/raw-loss = 0.49325889348983765, train/logprobs = tensor([[-0.8098, -1.7996],
        [-1.0855, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0903186947107315
Epoch 0, Step 530: train/loss = 0.6791344285011292, train/raw-loss = 0.6380884051322937, train/logprobs = tensor([[-0.4700, -0.9494],
        [-0.6245, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209206163883209
Epoch 0, Step 531: train/loss = 0.7023983597755432, train/raw-loss = 0.6682555675506592, train/logprobs = tensor([[-0.7258, -0.9461],
        [-0.7773, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06828571110963821
Epoch 0, Step 532: train/loss = 0.7003215551376343, train/raw-loss = 0.6648870706558228, train/logprobs = tensor([[-0.5956, -0.5596],
        [-0.7033, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07086899131536484
Epoch 0, Step 533: train/loss = 0.6342258453369141, train/raw-loss = 0.5973464846611023, train/logprobs = tensor([[-1.1849, -1.7960],
        [-1.1774, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07375877350568771
Epoch 0, Step 534: train/loss = 0.6585177779197693, train/raw-loss = 0.6020979881286621, train/logprobs = tensor([[-1.7159, -1.4040],
        [-2.0664, -1.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128394603729248
Epoch 0, Step 535: train/loss = 0.63016676902771, train/raw-loss = 0.5995711088180542, train/logprobs = tensor([[-0.7920, -1.2974],
        [-0.9287, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06119127571582794
Epoch 0, Step 536: train/loss = 0.7084274291992188, train/raw-loss = 0.6628633737564087, train/logprobs = tensor([[-1.4092, -1.3363],
        [-1.7239, -1.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112801402807236
Epoch 0, Step 537: train/loss = 0.6812230944633484, train/raw-loss = 0.6458529233932495, train/logprobs = tensor([[-0.7796, -0.8561],
        [-0.8040, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07074041664600372
Epoch 0, Step 538: train/loss = 0.7424564361572266, train/raw-loss = 0.6955501437187195, train/logprobs = tensor([[-1.1975, -1.4905],
        [-0.8850, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09381258487701416
Epoch 0, Step 539: train/loss = 0.6396012306213379, train/raw-loss = 0.6040166616439819, train/logprobs = tensor([[-1.3053, -1.4701],
        [-1.3202, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07116913795471191
Epoch 0, Step 540: train/loss = 0.6256909370422363, train/raw-loss = 0.590466320514679, train/logprobs = tensor([[-0.8897, -2.0268],
        [-1.3075, -1.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044924050569534
Epoch 0, Step 541: train/loss = 0.6545170545578003, train/raw-loss = 0.6221696138381958, train/logprobs = tensor([[-1.0080, -1.3673],
        [-0.8938, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469480693340302
Epoch 0, Step 542: train/loss = 0.6909695267677307, train/raw-loss = 0.6517438888549805, train/logprobs = tensor([[-0.6809, -1.2968],
        [-0.7157, -1.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07845136523246765
Epoch 0, Step 543: train/loss = 0.6343123912811279, train/raw-loss = 0.5913369655609131, train/logprobs = tensor([[-0.5791, -1.1693],
        [-0.6770, -0.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08595092594623566
Epoch 0, Step 544: train/loss = 0.5931654572486877, train/raw-loss = 0.5501289367675781, train/logprobs = tensor([[-0.9236, -1.3115],
        [-1.1805, -0.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08607300370931625
Epoch 0, Step 545: train/loss = 0.6788457632064819, train/raw-loss = 0.6346930265426636, train/logprobs = tensor([[-0.8597, -1.2806],
        [-0.7859, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08830532431602478
Epoch 0, Step 546: train/loss = 0.5791592597961426, train/raw-loss = 0.5344992876052856, train/logprobs = tensor([[-0.9906, -1.3241],
        [-1.3428, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931992948055267
Epoch 0, Step 547: train/loss = 0.7201151847839355, train/raw-loss = 0.6815739274024963, train/logprobs = tensor([[-1.1596, -1.1366],
        [-1.1213, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07708242535591125
Epoch 0, Step 548: train/loss = 0.866004467010498, train/raw-loss = 0.8110540509223938, train/logprobs = tensor([[-1.6693, -1.4683],
        [-1.1369, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10990093648433685
Epoch 0, Step 549: train/loss = 0.5797672271728516, train/raw-loss = 0.5336297154426575, train/logprobs = tensor([[-1.1807, -1.6322],
        [-1.4046, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227506816387177
Epoch 0, Step 550: train/loss = 0.5612502098083496, train/raw-loss = 0.5023864507675171, train/logprobs = tensor([[-1.3027, -2.3935],
        [-1.5537, -1.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11772745847702026
Epoch 0, Step 551: train/loss = 0.6819928884506226, train/raw-loss = 0.6335897445678711, train/logprobs = tensor([[-1.4040, -1.7675],
        [-1.1458, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09680616110563278
Epoch 0, Step 552: train/loss = 0.5483366847038269, train/raw-loss = 0.5007031559944153, train/logprobs = tensor([[-1.2901, -2.3882],
        [-1.0989, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526703506708145
Epoch 0, Step 553: train/loss = 0.7201325297355652, train/raw-loss = 0.6751573085784912, train/logprobs = tensor([[-0.9129, -1.1591],
        [-0.8839, -1.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995047211647034
Epoch 0, Step 554: train/loss = 0.6486696004867554, train/raw-loss = 0.5904931426048279, train/logprobs = tensor([[-1.3029, -0.8809],
        [-1.6244, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11635293811559677
Epoch 0, Step 555: train/loss = 0.7077585458755493, train/raw-loss = 0.6682299971580505, train/logprobs = tensor([[-1.1124, -1.3717],
        [-0.7759, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07905714213848114
Epoch 0, Step 556: train/loss = 0.6875767707824707, train/raw-loss = 0.6494470834732056, train/logprobs = tensor([[-1.3425, -1.2521],
        [-1.1040, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07625943422317505
Epoch 0, Step 557: train/loss = 0.6483131647109985, train/raw-loss = 0.6101741790771484, train/logprobs = tensor([[-2.1399, -2.4526],
        [-2.0333, -1.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07627806812524796
Epoch 0, Step 558: train/loss = 0.743220329284668, train/raw-loss = 0.704145610332489, train/logprobs = tensor([[-1.5680, -1.4136],
        [-1.1921, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07814951241016388
Epoch 0, Step 559: train/loss = 0.8827115297317505, train/raw-loss = 0.8391891121864319, train/logprobs = tensor([[-1.8609, -1.5837],
        [-1.0769, -0.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08704497665166855
Epoch 0, Step 560: train/loss = 0.5964367985725403, train/raw-loss = 0.5625768899917603, train/logprobs = tensor([[-0.7551, -1.2491],
        [-0.8382, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06771990656852722
Epoch 0, Step 561: train/loss = 0.693524956703186, train/raw-loss = 0.6623886823654175, train/logprobs = tensor([[-2.2133, -2.3545],
        [-1.9317, -1.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0622725673019886
Epoch 0, Step 562: train/loss = 0.661128044128418, train/raw-loss = 0.6155441999435425, train/logprobs = tensor([[-0.7029, -1.3165],
        [-0.8418, -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09116767346858978
Epoch 0, Step 563: train/loss = 0.7203457951545715, train/raw-loss = 0.6739711165428162, train/logprobs = tensor([[-1.3790, -1.2678],
        [-1.1689, -0.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09274940192699432
Epoch 0, Step 564: train/loss = 0.6781916618347168, train/raw-loss = 0.6307224035263062, train/logprobs = tensor([[-0.8185, -1.1256],
        [-0.6742, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09493854641914368
Epoch 0, Step 565: train/loss = 0.5794837474822998, train/raw-loss = 0.5281845331192017, train/logprobs = tensor([[-1.4867, -1.8138],
        [-1.6192, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259836912155151
Epoch 0, Step 566: train/loss = 0.7239714860916138, train/raw-loss = 0.6690952777862549, train/logprobs = tensor([[-1.0675, -1.0709],
        [-1.2216, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10975238680839539
Epoch 0, Step 567: train/loss = 0.6435573101043701, train/raw-loss = 0.5914241075515747, train/logprobs = tensor([[-1.3086, -1.5490],
        [-1.9059, -1.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10426638275384903
Epoch 0, Step 568: train/loss = 0.6428205370903015, train/raw-loss = 0.5939809679985046, train/logprobs = tensor([[-0.8687, -1.5590],
        [-0.9595, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09767914563417435
Epoch 0, Step 569: train/loss = 0.7641726732254028, train/raw-loss = 0.7251180410385132, train/logprobs = tensor([[-1.2890, -1.8834],
        [-0.8731, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07810919731855392
Epoch 0, Step 570: train/loss = 0.6487303972244263, train/raw-loss = 0.6016377210617065, train/logprobs = tensor([[-1.1329, -1.2415],
        [-1.6987, -1.3186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09418529272079468
Epoch 0, Step 571: train/loss = 0.7225253582000732, train/raw-loss = 0.6723511219024658, train/logprobs = tensor([[-1.2954, -1.2838],
        [-1.1570, -0.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10034843534231186
Epoch 0, Step 572: train/loss = 0.6967644691467285, train/raw-loss = 0.6487379670143127, train/logprobs = tensor([[-0.9633, -1.0498],
        [-0.9547, -0.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605292975902557
Epoch 0, Step 573: train/loss = 0.6511837244033813, train/raw-loss = 0.6104706525802612, train/logprobs = tensor([[-1.0042, -1.6916],
        [-1.0803, -1.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08142615854740143
Epoch 0, Step 574: train/loss = 0.6773651242256165, train/raw-loss = 0.6369321942329407, train/logprobs = tensor([[-0.9144, -0.9946],
        [-1.0058, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08086587488651276
Epoch 0, Step 575: train/loss = 0.6080408096313477, train/raw-loss = 0.5638744831085205, train/logprobs = tensor([[-1.0882, -1.6570],
        [-0.9885, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08833266794681549
Epoch 0, Step 576: train/loss = 1.0322575569152832, train/raw-loss = 0.9793087244033813, train/logprobs = tensor([[-2.0771, -1.6068],
        [-0.8990, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10589751601219177
Epoch 0, Step 577: train/loss = 0.6867103576660156, train/raw-loss = 0.6398477554321289, train/logprobs = tensor([[-0.5584, -0.8687],
        [-0.6274, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09372527152299881
Epoch 0, Step 578: train/loss = 0.6422926783561707, train/raw-loss = 0.6073020100593567, train/logprobs = tensor([[-0.9982, -1.3425],
        [-0.8919, -0.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06998122483491898
Epoch 0, Step 579: train/loss = 0.589967668056488, train/raw-loss = 0.5515522956848145, train/logprobs = tensor([[-0.7334, -1.5517],
        [-0.7531, -0.7862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07683070003986359
Epoch 0, Step 580: train/loss = 0.6600302457809448, train/raw-loss = 0.6083354949951172, train/logprobs = tensor([[-0.7928, -1.1135],
        [-0.8563, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10338956117630005
Epoch 0, Step 581: train/loss = 0.7435973882675171, train/raw-loss = 0.7069869041442871, train/logprobs = tensor([[-0.6558, -0.6009],
        [-0.5840, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07322093844413757
Epoch 0, Step 582: train/loss = 0.6533204317092896, train/raw-loss = 0.6037920713424683, train/logprobs = tensor([[-0.7455, -1.9848],
        [-0.7702, -1.4583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09905683249235153
Epoch 0, Step 583: train/loss = 0.5822181701660156, train/raw-loss = 0.5210708975791931, train/logprobs = tensor([[-1.0107, -1.3325],
        [-1.3368, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1222945973277092
Epoch 0, Step 584: train/loss = 0.6161497831344604, train/raw-loss = 0.564920961856842, train/logprobs = tensor([[-0.8728, -1.2241],
        [-1.0906, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10245756804943085
Epoch 0, Step 585: train/loss = 0.6009780168533325, train/raw-loss = 0.5509287118911743, train/logprobs = tensor([[-0.7943, -1.5779],
        [-0.7726, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1000986248254776
Epoch 0, Step 586: train/loss = 0.6326554417610168, train/raw-loss = 0.5835787057876587, train/logprobs = tensor([[-1.1412, -1.2633],
        [-1.3373, -0.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981534868478775
Epoch 0, Step 587: train/loss = 0.7577991485595703, train/raw-loss = 0.7055551409721375, train/logprobs = tensor([[-2.2756, -1.8704],
        [-1.5509, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10448799282312393
Epoch 0, Step 588: train/loss = 0.5903612971305847, train/raw-loss = 0.5342825055122375, train/logprobs = tensor([[-1.1505, -1.6431],
        [-1.4242, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11215760558843613
Epoch 0, Step 589: train/loss = 0.699822187423706, train/raw-loss = 0.6379954814910889, train/logprobs = tensor([[-1.3254, -1.2903],
        [-1.2896, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12365343421697617
Epoch 0, Step 590: train/loss = 0.7888717651367188, train/raw-loss = 0.7278507351875305, train/logprobs = tensor([[-1.6791, -1.8487],
        [-1.1131, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12204208970069885
Epoch 0, Step 591: train/loss = 0.9445537328720093, train/raw-loss = 0.9056916236877441, train/logprobs = tensor([[-1.9721, -1.7386],
        [-0.9702, -1.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07772417366504669
Epoch 0, Step 592: train/loss = 0.5953651666641235, train/raw-loss = 0.5409201383590698, train/logprobs = tensor([[-1.1219, -1.1542],
        [-1.4352, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10888999700546265
Epoch 0, Step 593: train/loss = 0.5886583924293518, train/raw-loss = 0.5283299684524536, train/logprobs = tensor([[-1.3242, -2.1608],
        [-1.6197, -1.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12065690755844116
Epoch 0, Step 594: train/loss = 0.5733382105827332, train/raw-loss = 0.5262413024902344, train/logprobs = tensor([[-1.0301, -1.8608],
        [-1.0994, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09419386833906174
Epoch 0, Step 595: train/loss = 0.7241556644439697, train/raw-loss = 0.6723010540008545, train/logprobs = tensor([[-0.6398, -0.9881],
        [-0.5923, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370932519435883
Epoch 0, Step 596: train/loss = 0.7064200639724731, train/raw-loss = 0.6751961708068848, train/logprobs = tensor([[-0.7442, -0.8032],
        [-0.6080, -0.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062447689473629
Epoch 0, Step 597: train/loss = 1.032576084136963, train/raw-loss = 0.9857420921325684, train/logprobs = tensor([[-2.4408, -2.2250],
        [-1.1232, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366793185472488
Epoch 0, Step 598: train/loss = 0.7011767029762268, train/raw-loss = 0.6434154510498047, train/logprobs = tensor([[-1.3695, -1.5395],
        [-1.2787, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1155223697423935
Epoch 0, Step 599: train/loss = 0.6753928661346436, train/raw-loss = 0.6295996904373169, train/logprobs = tensor([[-1.6648, -2.0775],
        [-1.2598, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09158634394407272
Epoch 0, Step 600: train/loss = 0.7159364819526672, train/raw-loss = 0.6706370711326599, train/logprobs = tensor([[-0.6772, -0.6913],
        [-0.8940, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09059882909059525
Epoch 0, Step 601: train/loss = 0.48793497681617737, train/raw-loss = 0.43799489736557007, train/logprobs = tensor([[-1.1402, -2.6364],
        [-1.3611, -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0998801738023758
Epoch 0, Step 602: train/loss = 0.7023200988769531, train/raw-loss = 0.6639472246170044, train/logprobs = tensor([[-0.7716, -1.0607],
        [-0.5499, -0.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07674576342105865
Epoch 0, Step 603: train/loss = 0.5811588764190674, train/raw-loss = 0.5277087688446045, train/logprobs = tensor([[-0.7766, -2.5272],
        [-0.9101, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10690020024776459
Epoch 0, Step 604: train/loss = 0.7896246314048767, train/raw-loss = 0.7347089052200317, train/logprobs = tensor([[-1.6704, -1.4470],
        [-1.3630, -1.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983157902956009
Epoch 0, Step 605: train/loss = 0.7166247367858887, train/raw-loss = 0.6678889989852905, train/logprobs = tensor([[-1.0980, -1.1163],
        [-1.1139, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09747159481048584
Epoch 0, Step 606: train/loss = 0.7594348192214966, train/raw-loss = 0.7227185964584351, train/logprobs = tensor([[-1.0449, -1.1901],
        [-0.6591, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07343251258134842
Epoch 0, Step 607: train/loss = 0.6589092016220093, train/raw-loss = 0.6202430129051208, train/logprobs = tensor([[-0.6885, -1.1218],
        [-0.6407, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07733239978551865
Epoch 0, Step 608: train/loss = 0.553288996219635, train/raw-loss = 0.5077340006828308, train/logprobs = tensor([[-1.2391, -1.9036],
        [-1.3137, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09110995382070541
Epoch 0, Step 609: train/loss = 0.6422900557518005, train/raw-loss = 0.5987709760665894, train/logprobs = tensor([[-1.0511, -1.5615],
        [-0.7348, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703818917274475
Epoch 0, Step 610: train/loss = 0.7288599014282227, train/raw-loss = 0.6754012107849121, train/logprobs = tensor([[-0.9333, -0.9774],
        [-0.7719, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10691745579242706
Epoch 0, Step 611: train/loss = 0.6340011358261108, train/raw-loss = 0.5702241063117981, train/logprobs = tensor([[-1.3154, -2.6815],
        [-1.0435, -1.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12755410373210907
Epoch 0, Step 612: train/loss = 0.6774002313613892, train/raw-loss = 0.6123381853103638, train/logprobs = tensor([[-1.6435, -1.7370],
        [-1.4164, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13012398779392242
Epoch 0, Step 613: train/loss = 0.4927572011947632, train/raw-loss = 0.4166325628757477, train/logprobs = tensor([[-1.0824, -2.9778],
        [-0.9137, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152249276638031
Epoch 0, Step 614: train/loss = 0.7083946466445923, train/raw-loss = 0.6610920429229736, train/logprobs = tensor([[-0.9820, -0.9071],
        [-0.6876, -0.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09460506588220596
Epoch 0, Step 615: train/loss = 0.7235388159751892, train/raw-loss = 0.6694684624671936, train/logprobs = tensor([[-0.9312, -1.0183],
        [-0.6857, -0.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10814062505960464
Epoch 0, Step 616: train/loss = 0.652934730052948, train/raw-loss = 0.6051325798034668, train/logprobs = tensor([[-1.0829, -1.4178],
        [-0.8461, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.095604307949543
Epoch 0, Step 617: train/loss = 0.6120319962501526, train/raw-loss = 0.5545293092727661, train/logprobs = tensor([[-1.0733, -1.5771],
        [-1.0750, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11500535160303116
Epoch 0, Step 618: train/loss = 0.6226955652236938, train/raw-loss = 0.5710154175758362, train/logprobs = tensor([[-0.7501, -1.3622],
        [-0.6135, -0.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336035490036011
Epoch 0, Step 619: train/loss = 0.6498805284500122, train/raw-loss = 0.5989721417427063, train/logprobs = tensor([[-1.2373, -1.7694],
        [-0.9310, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10181678086519241
Epoch 0, Step 620: train/loss = 0.7521928548812866, train/raw-loss = 0.6976091861724854, train/logprobs = tensor([[-1.6491, -1.5982],
        [-1.2931, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916736721992493
Epoch 0, Step 621: train/loss = 0.5718148350715637, train/raw-loss = 0.5129572153091431, train/logprobs = tensor([[-2.0835, -2.3619],
        [-2.0215, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11771522462368011
Epoch 0, Step 622: train/loss = 0.804781973361969, train/raw-loss = 0.7333694696426392, train/logprobs = tensor([[-2.5582, -2.1765],
        [-2.1049, -1.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14282500743865967
Epoch 0, Step 623: train/loss = 0.7128148674964905, train/raw-loss = 0.6537652015686035, train/logprobs = tensor([[-1.0231, -1.3565],
        [-0.6632, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11809922009706497
Epoch 0, Step 624: train/loss = 0.604475736618042, train/raw-loss = 0.5330337285995483, train/logprobs = tensor([[-1.5676, -2.0384],
        [-2.0221, -1.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14288410544395447
Epoch 0, Step 625: train/loss = 0.6573874950408936, train/raw-loss = 0.6105557084083557, train/logprobs = tensor([[-0.7570, -1.4133],
        [-0.4771, -0.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366355091333389
Epoch 0, Step 626: train/loss = 0.6406154036521912, train/raw-loss = 0.5767078995704651, train/logprobs = tensor([[-1.0642, -1.4531],
        [-1.0064, -0.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278150975704193
Epoch 0, Step 627: train/loss = 0.5322213172912598, train/raw-loss = 0.464402437210083, train/logprobs = tensor([[-0.8734, -2.2874],
        [-1.1796, -1.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356378048658371
Epoch 0, Step 628: train/loss = 0.599564790725708, train/raw-loss = 0.5363223552703857, train/logprobs = tensor([[-0.9883, -1.4937],
        [-1.1336, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264849603176117
Epoch 0, Step 629: train/loss = 1.1669038534164429, train/raw-loss = 1.1181869506835938, train/logprobs = tensor([[-2.3478, -1.5008],
        [-0.8692, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09743384271860123
Epoch 0, Step 630: train/loss = 0.611541748046875, train/raw-loss = 0.5392496585845947, train/logprobs = tensor([[-0.8656, -1.4251],
        [-1.2213, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14458416402339935
Epoch 0, Step 631: train/loss = 0.625304102897644, train/raw-loss = 0.5581423044204712, train/logprobs = tensor([[-1.1342, -2.1302],
        [-1.0392, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13432367146015167
Epoch 0, Step 632: train/loss = 0.6983598470687866, train/raw-loss = 0.6511344909667969, train/logprobs = tensor([[-0.8634, -1.0896],
        [-0.6693, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0944507047533989
Epoch 0, Step 633: train/loss = 0.6369108557701111, train/raw-loss = 0.5575855374336243, train/logprobs = tensor([[-2.0907, -2.0631],
        [-1.9402, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15865066647529602
Epoch 0, Step 634: train/loss = 0.6041542887687683, train/raw-loss = 0.5490341782569885, train/logprobs = tensor([[-1.3966, -2.3056],
        [-1.1074, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11024025082588196
Epoch 0, Step 635: train/loss = 0.6268026232719421, train/raw-loss = 0.565147876739502, train/logprobs = tensor([[-1.2225, -2.3828],
        [-0.9237, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12330952286720276
Epoch 0, Step 636: train/loss = 0.7537736892700195, train/raw-loss = 0.6977667808532715, train/logprobs = tensor([[-1.4431, -1.1253],
        [-0.9778, -0.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11201383173465729
Epoch 0, Step 637: train/loss = 0.7425159811973572, train/raw-loss = 0.6799017786979675, train/logprobs = tensor([[-0.9884, -1.2080],
        [-1.0807, -1.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12522844970226288
Epoch 0, Step 638: train/loss = 0.5863426327705383, train/raw-loss = 0.5336737632751465, train/logprobs = tensor([[-0.8259, -1.3498],
        [-1.1756, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10533769428730011
Epoch 0, Step 639: train/loss = 0.6340774297714233, train/raw-loss = 0.5793027877807617, train/logprobs = tensor([[-1.0999, -1.7472],
        [-0.9079, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954926908016205
Epoch 0, Step 640: train/loss = 0.6929963827133179, train/raw-loss = 0.6390120983123779, train/logprobs = tensor([[-0.9371, -1.3169],
        [-0.9100, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10796850174665451
Epoch 0, Step 641: train/loss = 0.6325874328613281, train/raw-loss = 0.5688959360122681, train/logprobs = tensor([[-1.2830, -2.1906],
        [-0.9797, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273830682039261
Epoch 0, Step 642: train/loss = 0.567162036895752, train/raw-loss = 0.510221540927887, train/logprobs = tensor([[-1.0474, -2.0553],
        [-1.1440, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11388101428747177
Epoch 0, Step 643: train/loss = 0.6783726811408997, train/raw-loss = 0.609965443611145, train/logprobs = tensor([[-1.6500, -2.0709],
        [-1.4855, -1.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13681454956531525
Epoch 0, Step 644: train/loss = 0.6097654104232788, train/raw-loss = 0.5671868920326233, train/logprobs = tensor([[-0.7114, -1.4238],
        [-0.6166, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515694737434387
Epoch 0, Step 645: train/loss = 0.679206132888794, train/raw-loss = 0.633155345916748, train/logprobs = tensor([[-0.8264, -1.3019],
        [-0.5689, -0.5364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09210161119699478
Epoch 0, Step 646: train/loss = 0.6645238399505615, train/raw-loss = 0.5931808948516846, train/logprobs = tensor([[-2.2819, -2.9472],
        [-1.6875, -1.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1426858901977539
Epoch 0, Step 647: train/loss = 0.6700836420059204, train/raw-loss = 0.6091337203979492, train/logprobs = tensor([[-1.0742, -1.2794],
        [-0.9860, -0.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12189972400665283
Epoch 0, Step 648: train/loss = 0.7502385377883911, train/raw-loss = 0.6998135447502136, train/logprobs = tensor([[-1.8606, -2.2938],
        [-0.9680, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10085002332925797
Epoch 0, Step 649: train/loss = 0.6299142837524414, train/raw-loss = 0.5620843172073364, train/logprobs = tensor([[-1.6071, -2.5636],
        [-1.0011, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565996289253235
Epoch 0, Step 650: train/loss = 0.7066038846969604, train/raw-loss = 0.6672635078430176, train/logprobs = tensor([[-0.4290, -0.6014],
        [-0.4258, -0.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07868063449859619
Epoch 0, Step 651: train/loss = 0.8933135271072388, train/raw-loss = 0.8076934814453125, train/logprobs = tensor([[-2.0356, -2.1681],
        [-1.0231, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1712402105331421
Epoch 0, Step 652: train/loss = 0.8403672575950623, train/raw-loss = 0.7532829642295837, train/logprobs = tensor([[-3.4311, -3.6104],
        [-2.5165, -2.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17416855692863464
Epoch 0, Step 653: train/loss = 0.6372547149658203, train/raw-loss = 0.5570517778396606, train/logprobs = tensor([[-1.2392, -2.2245],
        [-1.4433, -1.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16040579974651337
Epoch 0, Step 654: train/loss = 0.5461328625679016, train/raw-loss = 0.48556435108184814, train/logprobs = tensor([[-1.3325, -2.3410],
        [-1.1979, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12113700807094574
Epoch 0, Step 655: train/loss = 0.6276313662528992, train/raw-loss = 0.5895999073982239, train/logprobs = tensor([[-0.7827, -1.6078],
        [-0.6661, -0.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07606292515993118
Epoch 0, Step 656: train/loss = 0.7233458161354065, train/raw-loss = 0.6348074674606323, train/logprobs = tensor([[-2.0355, -3.2063],
        [-1.0896, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17707666754722595
Epoch 0, Step 657: train/loss = 0.8277607560157776, train/raw-loss = 0.7692230939865112, train/logprobs = tensor([[-1.9254, -2.0380],
        [-0.9514, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707527935504913
Epoch 0, Step 658: train/loss = 0.6165767908096313, train/raw-loss = 0.5601348876953125, train/logprobs = tensor([[-0.8988, -1.7904],
        [-0.7166, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288385093212128
Epoch 0, Step 659: train/loss = 0.6911166310310364, train/raw-loss = 0.6398229598999023, train/logprobs = tensor([[-1.3553, -1.3433],
        [-1.1969, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258734226226807
Epoch 0, Step 660: train/loss = 0.6021026968955994, train/raw-loss = 0.5429669618606567, train/logprobs = tensor([[-1.5869, -2.4873],
        [-1.7531, -1.4859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11827149242162704
Epoch 0, Step 661: train/loss = 0.4817941188812256, train/raw-loss = 0.4226905405521393, train/logprobs = tensor([[-1.1942, -2.9981],
        [-1.3955, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11820711940526962
Epoch 0, Step 662: train/loss = 0.6075533628463745, train/raw-loss = 0.5419009923934937, train/logprobs = tensor([[-1.4842, -2.4953],
        [-1.1029, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13130471110343933
Epoch 0, Step 663: train/loss = 0.5813587307929993, train/raw-loss = 0.5199475884437561, train/logprobs = tensor([[-1.6629, -3.1336],
        [-1.8066, -2.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12282230705022812
Epoch 0, Step 664: train/loss = 0.5629235506057739, train/raw-loss = 0.4983963370323181, train/logprobs = tensor([[-1.1710, -1.2524],
        [-1.6794, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290544867515564
Epoch 0, Step 665: train/loss = 0.6887505054473877, train/raw-loss = 0.6352579593658447, train/logprobs = tensor([[-0.6906, -0.9998],
        [-0.6241, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10698512196540833
Epoch 0, Step 666: train/loss = 0.6612892150878906, train/raw-loss = 0.598471999168396, train/logprobs = tensor([[-1.4467, -3.1367],
        [-0.6235, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12563441693782806
Epoch 0, Step 667: train/loss = 0.7316766977310181, train/raw-loss = 0.6786376237869263, train/logprobs = tensor([[-1.1360, -0.7880],
        [-1.2219, -0.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607823729515076
Epoch 0, Step 668: train/loss = 0.5831804275512695, train/raw-loss = 0.5240433812141418, train/logprobs = tensor([[-0.6853, -1.6880],
        [-0.6537, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11827397346496582
Epoch 0, Step 669: train/loss = 0.6142567992210388, train/raw-loss = 0.5581201314926147, train/logprobs = tensor([[-1.4950, -2.0253],
        [-1.4513, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227333545684814
Epoch 0, Step 670: train/loss = 0.718973696231842, train/raw-loss = 0.660999059677124, train/logprobs = tensor([[-1.1429, -1.2268],
        [-1.0848, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11594937741756439
Epoch 0, Step 671: train/loss = 0.739635169506073, train/raw-loss = 0.6830340623855591, train/logprobs = tensor([[-1.0376, -1.0597],
        [-0.7965, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11320222914218903
Epoch 0, Step 672: train/loss = 0.6212109327316284, train/raw-loss = 0.5681211948394775, train/logprobs = tensor([[-1.7389, -2.2154],
        [-1.4800, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617934167385101
Epoch 0, Step 673: train/loss = 0.7211223840713501, train/raw-loss = 0.6618339419364929, train/logprobs = tensor([[-1.1055, -1.7253],
        [-0.9129, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11857686936855316
Epoch 0, Step 674: train/loss = 0.6469308733940125, train/raw-loss = 0.5985453724861145, train/logprobs = tensor([[-2.4840, -3.1599],
        [-1.9795, -1.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0967709943652153
Epoch 0, Step 675: train/loss = 0.5895195603370667, train/raw-loss = 0.5308008790016174, train/logprobs = tensor([[-1.1339, -2.1073],
        [-0.8760, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11743730306625366
Epoch 0, Step 676: train/loss = 0.672654390335083, train/raw-loss = 0.6348791718482971, train/logprobs = tensor([[-0.6456, -0.9743],
        [-0.5755, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07555040717124939
Epoch 0, Step 677: train/loss = 0.5677707195281982, train/raw-loss = 0.5229772329330444, train/logprobs = tensor([[-0.7468, -2.3811],
        [-0.7948, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958697319030762
Epoch 0, Step 678: train/loss = 0.7758185863494873, train/raw-loss = 0.7117360830307007, train/logprobs = tensor([[-1.8001, -1.8657],
        [-1.4648, -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281650960445404
Epoch 0, Step 679: train/loss = 0.7152007818222046, train/raw-loss = 0.6524475812911987, train/logprobs = tensor([[-1.3125, -1.0141],
        [-1.8176, -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12550628185272217
Epoch 0, Step 680: train/loss = 0.6732918620109558, train/raw-loss = 0.6315824389457703, train/logprobs = tensor([[-0.6179, -0.9017],
        [-0.6709, -0.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08341874182224274
Epoch 0, Step 681: train/loss = 0.5774900317192078, train/raw-loss = 0.5150752067565918, train/logprobs = tensor([[-1.3701, -2.7543],
        [-1.2674, -1.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12482969462871552
Epoch 0, Step 682: train/loss = 0.5070466995239258, train/raw-loss = 0.45593154430389404, train/logprobs = tensor([[-1.0129, -2.4325],
        [-0.9380, -1.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10223032534122467
Epoch 0, Step 683: train/loss = 0.7940677404403687, train/raw-loss = 0.7269126176834106, train/logprobs = tensor([[-1.7420, -2.3113],
        [-1.0222, -1.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13431020081043243
Epoch 0, Step 684: train/loss = 0.669026792049408, train/raw-loss = 0.6059027314186096, train/logprobs = tensor([[-1.1926, -1.7724],
        [-1.1260, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12624810636043549
Epoch 0, Step 685: train/loss = 0.698301374912262, train/raw-loss = 0.6593438386917114, train/logprobs = tensor([[-0.4810, -0.5561],
        [-0.4918, -0.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07791522890329361
Epoch 0, Step 686: train/loss = 0.5832701921463013, train/raw-loss = 0.5287644267082214, train/logprobs = tensor([[-1.3653, -2.1460],
        [-1.3260, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10901159048080444
Epoch 0, Step 687: train/loss = 0.6722073554992676, train/raw-loss = 0.6170657873153687, train/logprobs = tensor([[-1.4510, -2.3007],
        [-0.8865, -1.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028319597244263
Epoch 0, Step 688: train/loss = 0.7262117266654968, train/raw-loss = 0.6770853400230408, train/logprobs = tensor([[-1.1041, -1.1041],
        [-1.2540, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982528030872345
Epoch 0, Step 689: train/loss = 0.6121038198471069, train/raw-loss = 0.5592718124389648, train/logprobs = tensor([[-0.9484, -1.8240],
        [-0.7313, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10566404461860657
Epoch 0, Step 690: train/loss = 0.711057186126709, train/raw-loss = 0.6572378873825073, train/logprobs = tensor([[-1.4981, -1.3667],
        [-1.2120, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10763852298259735
Epoch 0, Step 691: train/loss = 0.5290207266807556, train/raw-loss = 0.4710768759250641, train/logprobs = tensor([[-1.1890, -2.1980],
        [-1.3709, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11588768661022186
Epoch 0, Step 692: train/loss = 0.6454495191574097, train/raw-loss = 0.5864571928977966, train/logprobs = tensor([[-1.0776, -1.8540],
        [-0.6790, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11798463761806488
Epoch 0, Step 693: train/loss = 0.7103266716003418, train/raw-loss = 0.6652965545654297, train/logprobs = tensor([[-0.6352, -0.8092],
        [-0.4956, -0.5326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006035327911377
Epoch 0, Step 694: train/loss = 0.7790700793266296, train/raw-loss = 0.7100860476493835, train/logprobs = tensor([[-0.9834, -1.1651],
        [-0.8303, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379680335521698
Epoch 0, Step 695: train/loss = 0.7039011716842651, train/raw-loss = 0.6404889822006226, train/logprobs = tensor([[-1.5101, -1.7282],
        [-1.3988, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12682436406612396
Epoch 0, Step 696: train/loss = 0.6194198131561279, train/raw-loss = 0.557433545589447, train/logprobs = tensor([[-1.7690, -3.0806],
        [-1.4868, -1.4078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12397255003452301
Epoch 0, Step 697: train/loss = 0.7289154529571533, train/raw-loss = 0.6671122312545776, train/logprobs = tensor([[-1.3164, -1.3845],
        [-0.8855, -0.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12360642105340958
Epoch 0, Step 698: train/loss = 0.7438873648643494, train/raw-loss = 0.6960745453834534, train/logprobs = tensor([[-0.7178, -1.0601],
        [-0.7096, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956256240606308
Epoch 0, Step 699: train/loss = 0.6803373098373413, train/raw-loss = 0.6304495334625244, train/logprobs = tensor([[-1.4744, -2.2385],
        [-0.9329, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997755229473114
Epoch 0, Step 700: train/loss = 0.6638680696487427, train/raw-loss = 0.610349714756012, train/logprobs = tensor([[-0.8949, -1.8230],
        [-1.0650, -1.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10703675448894501
Epoch 0, Step 701: train/loss = 0.4989076852798462, train/raw-loss = 0.43216803669929504, train/logprobs = tensor([[-0.9445, -2.2769],
        [-1.3185, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1334792971611023
Epoch 0, Step 702: train/loss = 0.6688066124916077, train/raw-loss = 0.6158896684646606, train/logprobs = tensor([[-0.8257, -1.1418],
        [-0.6981, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10583391785621643
Epoch 0, Step 703: train/loss = 0.649454653263092, train/raw-loss = 0.589356541633606, train/logprobs = tensor([[-1.1438, -1.8545],
        [-1.5120, -1.4832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12019628286361694
Epoch 0, Step 704: train/loss = 0.8367588520050049, train/raw-loss = 0.7765794396400452, train/logprobs = tensor([[-2.0603, -2.0696],
        [-1.7301, -1.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12035886198282242
Epoch 0, Step 705: train/loss = 0.7070045471191406, train/raw-loss = 0.6660525798797607, train/logprobs = tensor([[-1.1697, -1.2492],
        [-0.9712, -0.9127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190380036830902
Epoch 0, Step 706: train/loss = 0.7431817054748535, train/raw-loss = 0.6911798715591431, train/logprobs = tensor([[-1.5705, -1.2656],
        [-1.5744, -1.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1040036529302597
Epoch 0, Step 707: train/loss = 0.6113476157188416, train/raw-loss = 0.5540953278541565, train/logprobs = tensor([[-0.8537, -1.9589],
        [-0.8174, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11450450867414474
Epoch 0, Step 708: train/loss = 0.7211294174194336, train/raw-loss = 0.6788129806518555, train/logprobs = tensor([[-1.6568, -1.6774],
        [-1.4848, -1.4049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08463289588689804
Epoch 0, Step 709: train/loss = 0.5239393711090088, train/raw-loss = 0.46465861797332764, train/logprobs = tensor([[-1.4897, -2.4108],
        [-1.8881, -1.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11856160312891006
Epoch 0, Step 710: train/loss = 0.579403281211853, train/raw-loss = 0.5302998423576355, train/logprobs = tensor([[-1.3134, -2.6210],
        [-0.8401, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09820684790611267
Epoch 0, Step 711: train/loss = 0.7275497317314148, train/raw-loss = 0.655665397644043, train/logprobs = tensor([[-1.7007, -2.3295],
        [-0.9807, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14376860857009888
Epoch 0, Step 712: train/loss = 0.6558586955070496, train/raw-loss = 0.5997617244720459, train/logprobs = tensor([[-1.4348, -1.9349],
        [-1.3026, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11219392716884613
Epoch 0, Step 713: train/loss = 0.6403707265853882, train/raw-loss = 0.5718789100646973, train/logprobs = tensor([[-1.6533, -2.2150],
        [-1.4741, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13698355853557587
Epoch 0, Step 714: train/loss = 0.8720190525054932, train/raw-loss = 0.8101493716239929, train/logprobs = tensor([[-2.3565, -2.6657],
        [-0.9072, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12373939156532288
Epoch 0, Step 715: train/loss = 0.7704551219940186, train/raw-loss = 0.715535044670105, train/logprobs = tensor([[-1.4074, -1.2945],
        [-1.0814, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983999818563461
Epoch 0, Step 716: train/loss = 0.6471425890922546, train/raw-loss = 0.6053192615509033, train/logprobs = tensor([[-0.7870, -1.0866],
        [-0.7820, -0.6891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08364671468734741
Epoch 0, Step 717: train/loss = 0.4890947937965393, train/raw-loss = 0.42164891958236694, train/logprobs = tensor([[-1.6838, -2.4746],
        [-2.5454, -1.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13489177823066711
Epoch 0, Step 718: train/loss = 0.6277148127555847, train/raw-loss = 0.5792486667633057, train/logprobs = tensor([[-0.8733, -1.3578],
        [-1.1891, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0969322919845581
Epoch 0, Step 719: train/loss = 0.7291406989097595, train/raw-loss = 0.6732781529426575, train/logprobs = tensor([[-0.9126, -1.0069],
        [-0.8763, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11172507703304291
Epoch 0, Step 720: train/loss = 0.6281250715255737, train/raw-loss = 0.5831257700920105, train/logprobs = tensor([[-1.0808, -1.8120],
        [-1.0180, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0899987667798996
Epoch 0, Step 721: train/loss = 0.6665867567062378, train/raw-loss = 0.6278080940246582, train/logprobs = tensor([[-0.9011, -1.6001],
        [-0.6480, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07755723595619202
Epoch 0, Step 722: train/loss = 0.718262255191803, train/raw-loss = 0.6734793186187744, train/logprobs = tensor([[-0.8881, -1.0514],
        [-0.9612, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08956596255302429
Epoch 0, Step 723: train/loss = 0.528804361820221, train/raw-loss = 0.47214019298553467, train/logprobs = tensor([[-1.1916, -2.1097],
        [-1.7511, -1.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11332837492227554
Epoch 0, Step 724: train/loss = 0.6828859448432922, train/raw-loss = 0.6219122409820557, train/logprobs = tensor([[-0.9564, -1.3439],
        [-0.9672, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194738537073135
Epoch 0, Step 725: train/loss = 1.0975710153579712, train/raw-loss = 1.0437813997268677, train/logprobs = tensor([[-2.2039, -0.5978],
        [-1.3426, -0.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10757927596569061
Epoch 0, Step 726: train/loss = 0.7375137805938721, train/raw-loss = 0.6766438484191895, train/logprobs = tensor([[-1.5395, -1.6042],
        [-1.1757, -1.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12173984944820404
Epoch 0, Step 727: train/loss = 0.656028151512146, train/raw-loss = 0.6023062467575073, train/logprobs = tensor([[-1.5737, -1.5492],
        [-1.5913, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10744377225637436
Epoch 0, Step 728: train/loss = 0.6836709976196289, train/raw-loss = 0.631160318851471, train/logprobs = tensor([[-1.8922, -1.5176],
        [-1.8339, -1.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10502132028341293
Epoch 0, Step 729: train/loss = 0.7018416523933411, train/raw-loss = 0.645694375038147, train/logprobs = tensor([[-1.1457, -1.3154],
        [-1.2153, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11229459941387177
Epoch 0, Step 730: train/loss = 0.562464714050293, train/raw-loss = 0.5068473815917969, train/logprobs = tensor([[-0.9836, -1.7970],
        [-1.1452, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11123475432395935
Epoch 0, Step 731: train/loss = 0.5707639455795288, train/raw-loss = 0.5291825532913208, train/logprobs = tensor([[-0.5133, -1.7180],
        [-0.5289, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08316265791654587
Epoch 0, Step 732: train/loss = 0.5051657557487488, train/raw-loss = 0.4529275894165039, train/logprobs = tensor([[-1.0781, -1.6834],
        [-1.4019, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447630286216736
Epoch 0, Step 733: train/loss = 0.6156960725784302, train/raw-loss = 0.5627267360687256, train/logprobs = tensor([[-0.5577, -1.4073],
        [-0.5508, -0.7159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593853890895844
Epoch 0, Step 734: train/loss = 0.6976395845413208, train/raw-loss = 0.6413963437080383, train/logprobs = tensor([[-1.5171, -1.3772],
        [-1.4443, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11248639225959778
Epoch 0, Step 735: train/loss = 0.6364002823829651, train/raw-loss = 0.5815151929855347, train/logprobs = tensor([[-1.2451, -1.6486],
        [-1.3524, -1.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977018624544144
Epoch 0, Step 736: train/loss = 0.7815952897071838, train/raw-loss = 0.7460572123527527, train/logprobs = tensor([[-1.6592, -2.0033],
        [-1.1433, -1.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107609510421753
Epoch 0, Step 737: train/loss = 0.6544288396835327, train/raw-loss = 0.6032002568244934, train/logprobs = tensor([[-0.9414, -1.1792],
        [-0.8839, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10245727747678757
Epoch 0, Step 738: train/loss = 0.5949276685714722, train/raw-loss = 0.5426775217056274, train/logprobs = tensor([[-1.1300, -1.5615],
        [-1.5080, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10450025647878647
Epoch 0, Step 739: train/loss = 0.5721041560173035, train/raw-loss = 0.5152699947357178, train/logprobs = tensor([[-1.4566, -2.2140],
        [-1.8263, -1.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11366824805736542
Epoch 0, Step 740: train/loss = 0.6508774757385254, train/raw-loss = 0.598841667175293, train/logprobs = tensor([[-1.3899, -1.2911],
        [-1.3923, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10407160967588425
Epoch 0, Step 741: train/loss = 0.650536835193634, train/raw-loss = 0.5992398262023926, train/logprobs = tensor([[-0.5989, -1.2725],
        [-0.8441, -1.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259400308132172
Epoch 0, Step 742: train/loss = 0.8212143182754517, train/raw-loss = 0.7705613970756531, train/logprobs = tensor([[-1.7768, -1.4468],
        [-1.1325, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130587965250015
Epoch 0, Step 743: train/loss = 0.71570885181427, train/raw-loss = 0.6661916971206665, train/logprobs = tensor([[-0.6980, -0.7158],
        [-0.9265, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09903421998023987
Epoch 0, Step 744: train/loss = 0.47660428285598755, train/raw-loss = 0.4207557439804077, train/logprobs = tensor([[-0.9399, -2.1304],
        [-1.6736, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11169706284999847
Epoch 0, Step 745: train/loss = 0.6548926830291748, train/raw-loss = 0.6050400137901306, train/logprobs = tensor([[-0.7948, -1.4953],
        [-0.6223, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09970533847808838
Epoch 0, Step 746: train/loss = 0.6206142902374268, train/raw-loss = 0.5620025992393494, train/logprobs = tensor([[-1.3537, -1.4191],
        [-1.4252, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1172233372926712
Epoch 0, Step 747: train/loss = 0.6416596174240112, train/raw-loss = 0.5917146801948547, train/logprobs = tensor([[-0.8037, -1.1282],
        [-0.8694, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988991171121597
Epoch 0, Step 748: train/loss = 0.6466214060783386, train/raw-loss = 0.5960070490837097, train/logprobs = tensor([[-1.7421, -2.1062],
        [-1.7528, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10122863948345184
Epoch 0, Step 749: train/loss = 0.7355154156684875, train/raw-loss = 0.6878800392150879, train/logprobs = tensor([[-0.7177, -1.0553],
        [-0.8262, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09527065604925156
Epoch 0, Step 750: train/loss = 0.7731138467788696, train/raw-loss = 0.7146406173706055, train/logprobs = tensor([[-1.6755, -1.5317],
        [-1.7426, -1.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694653332233429
Epoch 0, Step 751: train/loss = 0.5014446377754211, train/raw-loss = 0.44599324464797974, train/logprobs = tensor([[-0.7630, -2.7385],
        [-0.7212, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11090275645256042
Epoch 0, Step 752: train/loss = 0.7240597605705261, train/raw-loss = 0.6742149591445923, train/logprobs = tensor([[-1.8986, -2.0840],
        [-1.2410, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09968947619199753
Epoch 0, Step 753: train/loss = 0.6469122767448425, train/raw-loss = 0.6007020473480225, train/logprobs = tensor([[-0.8684, -1.3145],
        [-0.8219, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09242033213376999
Epoch 0, Step 754: train/loss = 0.6936239004135132, train/raw-loss = 0.6424044966697693, train/logprobs = tensor([[-1.3718, -2.0380],
        [-0.9563, -1.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10243883728981018
Epoch 0, Step 755: train/loss = 0.6043956279754639, train/raw-loss = 0.5575817823410034, train/logprobs = tensor([[-1.0364, -1.7081],
        [-1.0081, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09362775087356567
Epoch 0, Step 756: train/loss = 0.583607017993927, train/raw-loss = 0.5383849143981934, train/logprobs = tensor([[-1.0636, -2.6344],
        [-0.9879, -1.3132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09044411778450012
Epoch 0, Step 757: train/loss = 0.630534827709198, train/raw-loss = 0.5791870355606079, train/logprobs = tensor([[-1.6082, -2.4306],
        [-1.4195, -1.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10269549489021301
Epoch 0, Step 758: train/loss = 0.636334240436554, train/raw-loss = 0.5949543118476868, train/logprobs = tensor([[-0.5852, -1.3462],
        [-0.6599, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08275982737541199
Epoch 0, Step 759: train/loss = 0.6268196105957031, train/raw-loss = 0.5743841528892517, train/logprobs = tensor([[-1.4409, -1.6923],
        [-1.3526, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10487097501754761
Epoch 0, Step 760: train/loss = 0.7161798477172852, train/raw-loss = 0.6503458619117737, train/logprobs = tensor([[-1.3184, -1.5031],
        [-1.2620, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13166794180870056
Epoch 0, Step 761: train/loss = 0.6212748289108276, train/raw-loss = 0.5806160569190979, train/logprobs = tensor([[-0.4349, -1.2251],
        [-0.4910, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08131751418113708
Epoch 0, Step 762: train/loss = 0.6911784410476685, train/raw-loss = 0.6344675421714783, train/logprobs = tensor([[-0.8833, -1.2267],
        [-0.8198, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342191696166992
Epoch 0, Step 763: train/loss = 0.6639617681503296, train/raw-loss = 0.599819004535675, train/logprobs = tensor([[-1.5753, -1.8451],
        [-1.9946, -1.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282854974269867
Epoch 0, Step 764: train/loss = 0.5785198211669922, train/raw-loss = 0.5286756753921509, train/logprobs = tensor([[-2.2805, -2.3351],
        [-2.9865, -2.0755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09968820214271545
Epoch 0, Step 765: train/loss = 0.7242015600204468, train/raw-loss = 0.678289532661438, train/logprobs = tensor([[-0.6512, -0.7297],
        [-0.8784, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182390570640564
Epoch 0, Step 766: train/loss = 0.6394702792167664, train/raw-loss = 0.5904504060745239, train/logprobs = tensor([[-1.1554, -1.7087],
        [-1.0390, -1.0161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803985059261322
Epoch 0, Step 767: train/loss = 0.6301378011703491, train/raw-loss = 0.5669864416122437, train/logprobs = tensor([[-0.9442, -1.4332],
        [-1.5414, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12630267441272736
Epoch 0, Step 768: train/loss = 0.5071600079536438, train/raw-loss = 0.45206770300865173, train/logprobs = tensor([[-1.3766, -2.2937],
        [-1.5517, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11018462479114532
Epoch 0, Step 769: train/loss = 0.5993694067001343, train/raw-loss = 0.5517662763595581, train/logprobs = tensor([[-0.6373, -1.6595],
        [-0.5983, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09520629048347473
Epoch 0, Step 770: train/loss = 0.844852089881897, train/raw-loss = 0.797197699546814, train/logprobs = tensor([[-1.9864, -1.6538],
        [-1.2688, -1.1973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530888497829437
Epoch 0, Step 771: train/loss = 0.7223352789878845, train/raw-loss = 0.6756384968757629, train/logprobs = tensor([[-0.8223, -1.0991],
        [-0.5434, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339353442192078
Epoch 0, Step 772: train/loss = 0.6991804242134094, train/raw-loss = 0.6461256742477417, train/logprobs = tensor([[-1.0967, -1.2280],
        [-1.1826, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610943287611008
Epoch 0, Step 773: train/loss = 0.6734570860862732, train/raw-loss = 0.6256729364395142, train/logprobs = tensor([[-0.6198, -1.4622],
        [-0.5732, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09556825459003448
Epoch 0, Step 774: train/loss = 0.7109438180923462, train/raw-loss = 0.6531137228012085, train/logprobs = tensor([[-0.8550, -1.5222],
        [-0.5803, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11566019058227539
Epoch 0, Step 775: train/loss = 0.4663006663322449, train/raw-loss = 0.4119653105735779, train/logprobs = tensor([[-0.7708, -2.6390],
        [-0.9670, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10867061465978622
Epoch 0, Step 776: train/loss = 0.6631124019622803, train/raw-loss = 0.6211782693862915, train/logprobs = tensor([[-1.4129, -1.7607],
        [-1.2002, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08386832475662231
Epoch 0, Step 777: train/loss = 0.6974126100540161, train/raw-loss = 0.659634530544281, train/logprobs = tensor([[-0.5613, -0.7941],
        [-0.5096, -0.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07555629312992096
Epoch 0, Step 778: train/loss = 0.6308465003967285, train/raw-loss = 0.5786750912666321, train/logprobs = tensor([[-1.0507, -1.4999],
        [-1.4151, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434283316135406
Epoch 0, Step 779: train/loss = 0.6182260513305664, train/raw-loss = 0.5606298446655273, train/logprobs = tensor([[-0.7733, -1.8542],
        [-0.8809, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11519238352775574
Epoch 0, Step 780: train/loss = 0.6529902219772339, train/raw-loss = 0.5831398963928223, train/logprobs = tensor([[-1.1410, -1.3759],
        [-1.4768, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13970056176185608
Epoch 0, Step 781: train/loss = 0.6360117197036743, train/raw-loss = 0.5710306763648987, train/logprobs = tensor([[-1.1300, -1.5527],
        [-0.9996, -0.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12996217608451843
Epoch 0, Step 782: train/loss = 0.7112327814102173, train/raw-loss = 0.6642809510231018, train/logprobs = tensor([[-1.0925, -1.3187],
        [-1.3098, -1.3532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09390375763177872
Epoch 0, Step 783: train/loss = 0.5418000817298889, train/raw-loss = 0.4812904894351959, train/logprobs = tensor([[-0.7723, -1.9667],
        [-0.8659, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12101921439170837
Epoch 0, Step 784: train/loss = 0.7036240100860596, train/raw-loss = 0.6528050899505615, train/logprobs = tensor([[-1.9307, -2.1964],
        [-1.3456, -1.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10163789242506027
Epoch 0, Step 785: train/loss = 0.5990396738052368, train/raw-loss = 0.5508260726928711, train/logprobs = tensor([[-0.8126, -1.6531],
        [-0.8594, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09642714262008667
Epoch 0, Step 786: train/loss = 0.5445991158485413, train/raw-loss = 0.49876487255096436, train/logprobs = tensor([[-0.9787, -1.7773],
        [-1.2495, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166856110095978
Epoch 0, Step 787: train/loss = 0.6425610184669495, train/raw-loss = 0.591509997844696, train/logprobs = tensor([[-1.0303, -1.6648],
        [-1.1368, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10210206359624863
Epoch 0, Step 788: train/loss = 0.6519351601600647, train/raw-loss = 0.6101093292236328, train/logprobs = tensor([[-0.9776, -0.9246],
        [-1.2892, -0.8633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836515873670578
Epoch 0, Step 789: train/loss = 0.6609777212142944, train/raw-loss = 0.6202303767204285, train/logprobs = tensor([[-1.2517, -1.1405],
        [-1.2483, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08149468153715134
Epoch 0, Step 790: train/loss = 0.6539744138717651, train/raw-loss = 0.6136161088943481, train/logprobs = tensor([[-0.4996, -1.4428],
        [-0.5273, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08071660995483398
Epoch 0, Step 791: train/loss = 0.7511566877365112, train/raw-loss = 0.6950721144676208, train/logprobs = tensor([[-1.4210, -1.2647],
        [-1.2348, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11216908693313599
Epoch 0, Step 792: train/loss = 0.6635931730270386, train/raw-loss = 0.613805890083313, train/logprobs = tensor([[-0.8303, -1.6953],
        [-0.7397, -1.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957462549209595
Epoch 0, Step 793: train/loss = 0.6744613647460938, train/raw-loss = 0.6211255788803101, train/logprobs = tensor([[-0.9512, -1.4739],
        [-1.1645, -1.2868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10667149722576141
Epoch 0, Step 794: train/loss = 0.6842396259307861, train/raw-loss = 0.6176981329917908, train/logprobs = tensor([[-1.4155, -1.7514],
        [-1.3766, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13308297097682953
Epoch 0, Step 795: train/loss = 0.7401512265205383, train/raw-loss = 0.6915035247802734, train/logprobs = tensor([[-2.2345, -2.5351],
        [-1.5377, -1.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09729545563459396
Epoch 0, Step 796: train/loss = 0.7742752432823181, train/raw-loss = 0.7246397137641907, train/logprobs = tensor([[-1.3803, -1.4957],
        [-0.6793, -0.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992710143327713
Epoch 0, Step 797: train/loss = 0.6737135052680969, train/raw-loss = 0.6204142570495605, train/logprobs = tensor([[-1.2329, -1.6825],
        [-1.0213, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10659852623939514
Epoch 0, Step 798: train/loss = 0.7134832739830017, train/raw-loss = 0.6536705493927002, train/logprobs = tensor([[-0.9973, -1.0819],
        [-1.2335, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196255162358284
Epoch 0, Step 799: train/loss = 0.6743176579475403, train/raw-loss = 0.6245957612991333, train/logprobs = tensor([[-1.0802, -1.2176],
        [-1.1629, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09944383054971695
Epoch 0, Step 800: train/loss = 0.7020997405052185, train/raw-loss = 0.6485781669616699, train/logprobs = tensor([[-1.3532, -1.4743],
        [-1.1571, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10704325139522552
Epoch 0, Step 801: train/loss = 0.5211812853813171, train/raw-loss = 0.4622366428375244, train/logprobs = tensor([[-0.7166, -2.0964],
        [-1.0201, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11788932979106903
Epoch 0, Step 802: train/loss = 0.5770232677459717, train/raw-loss = 0.51853346824646, train/logprobs = tensor([[-1.1177, -1.5478],
        [-1.4212, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11697947978973389
Epoch 0, Step 803: train/loss = 0.6544345021247864, train/raw-loss = 0.6063287258148193, train/logprobs = tensor([[-1.1731, -1.6866],
        [-1.0619, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09621158242225647
Epoch 0, Step 804: train/loss = 0.8262269496917725, train/raw-loss = 0.7655751705169678, train/logprobs = tensor([[-1.3890, -1.2972],
        [-0.9474, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12130369991064072
Epoch 0, Step 805: train/loss = 0.7374485731124878, train/raw-loss = 0.6930965781211853, train/logprobs = tensor([[-1.2530, -1.2830],
        [-1.5764, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08870403468608856
Epoch 0, Step 806: train/loss = 0.6155767440795898, train/raw-loss = 0.5535405874252319, train/logprobs = tensor([[-1.2103, -1.9345],
        [-1.1659, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407225370407104
Epoch 0, Step 807: train/loss = 0.6458528637886047, train/raw-loss = 0.5883787870407104, train/logprobs = tensor([[-1.7964, -2.5982],
        [-1.5877, -1.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11494804918766022
Epoch 0, Step 808: train/loss = 0.6572798490524292, train/raw-loss = 0.5966385006904602, train/logprobs = tensor([[-0.9316, -1.0326],
        [-1.1182, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128270417451859
Epoch 0, Step 809: train/loss = 0.6932103037834167, train/raw-loss = 0.633339524269104, train/logprobs = tensor([[-1.0693, -1.0805],
        [-1.1145, -0.7773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11974155157804489
Epoch 0, Step 810: train/loss = 0.596747875213623, train/raw-loss = 0.5537000894546509, train/logprobs = tensor([[-0.6100, -1.4265],
        [-0.8136, -0.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08609563857316971
Epoch 0, Step 811: train/loss = 0.7029998898506165, train/raw-loss = 0.6453525424003601, train/logprobs = tensor([[-1.0580, -1.2078],
        [-1.3638, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11529463529586792
Epoch 0, Step 812: train/loss = 0.6547360420227051, train/raw-loss = 0.5989899039268494, train/logprobs = tensor([[-1.2238, -1.3401],
        [-1.1592, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149222403764725
Epoch 0, Step 813: train/loss = 0.6663490533828735, train/raw-loss = 0.6029727458953857, train/logprobs = tensor([[-1.2019, -1.5798],
        [-1.2537, -1.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12675262987613678
Epoch 0, Step 814: train/loss = 0.5703514814376831, train/raw-loss = 0.5251530408859253, train/logprobs = tensor([[-0.5683, -2.0385],
        [-0.6225, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09039688855409622
Epoch 0, Step 815: train/loss = 0.5827738642692566, train/raw-loss = 0.5284693241119385, train/logprobs = tensor([[-1.4794, -2.4294],
        [-1.1928, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10860901325941086
Epoch 0, Step 816: train/loss = 0.6942136883735657, train/raw-loss = 0.6262791156768799, train/logprobs = tensor([[-1.5440, -1.6082],
        [-1.2631, -0.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13586920499801636
Epoch 0, Step 817: train/loss = 0.6450290083885193, train/raw-loss = 0.5987712740898132, train/logprobs = tensor([[-1.1711, -1.6374],
        [-1.1187, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09251537919044495
Epoch 0, Step 818: train/loss = 0.5824717283248901, train/raw-loss = 0.5287243127822876, train/logprobs = tensor([[-1.0682, -2.0760],
        [-1.1216, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10749483853578568
Epoch 0, Step 819: train/loss = 0.6545650959014893, train/raw-loss = 0.5966522097587585, train/logprobs = tensor([[-1.5380, -1.0547],
        [-1.7918, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1158258244395256
Epoch 0, Step 820: train/loss = 0.6453548669815063, train/raw-loss = 0.5916773676872253, train/logprobs = tensor([[-1.0092, -0.9056],
        [-1.4305, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073550134897232
Epoch 0, Step 821: train/loss = 0.6355198621749878, train/raw-loss = 0.5956249237060547, train/logprobs = tensor([[-0.7770, -1.6489],
        [-0.6467, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07978987693786621
Epoch 0, Step 822: train/loss = 0.512482762336731, train/raw-loss = 0.45326292514801025, train/logprobs = tensor([[-1.4969, -2.7996],
        [-1.6176, -1.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11843965202569962
Epoch 0, Step 823: train/loss = 0.6721584796905518, train/raw-loss = 0.6259180307388306, train/logprobs = tensor([[-0.5981, -0.8180],
        [-1.0304, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09248097240924835
Epoch 0, Step 824: train/loss = 0.6476589441299438, train/raw-loss = 0.5950534343719482, train/logprobs = tensor([[-1.3877, -1.9830],
        [-1.3359, -1.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521106421947479
Epoch 0, Step 825: train/loss = 0.6459658145904541, train/raw-loss = 0.6033681035041809, train/logprobs = tensor([[-0.7556, -1.1990],
        [-0.8613, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08519537001848221
Epoch 0, Step 826: train/loss = 0.6497468948364258, train/raw-loss = 0.5899280309677124, train/logprobs = tensor([[-1.8003, -1.9483],
        [-1.8807, -1.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11963774263858795
Epoch 0, Step 827: train/loss = 0.7099281549453735, train/raw-loss = 0.6602573394775391, train/logprobs = tensor([[-0.7286, -0.8888],
        [-0.8397, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934166073799133
Epoch 0, Step 828: train/loss = 0.6149488687515259, train/raw-loss = 0.5723702907562256, train/logprobs = tensor([[-0.6730, -1.2088],
        [-0.8481, -0.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515723049640656
Epoch 0, Step 829: train/loss = 0.649497926235199, train/raw-loss = 0.597214937210083, train/logprobs = tensor([[-1.2284, -1.5453],
        [-1.2253, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456584393978119
Epoch 0, Step 830: train/loss = 0.6620745062828064, train/raw-loss = 0.6049258708953857, train/logprobs = tensor([[-1.2289, -1.4705],
        [-1.1864, -0.9359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11429725587368011
Epoch 0, Step 831: train/loss = 0.7321415543556213, train/raw-loss = 0.6991415023803711, train/logprobs = tensor([[-1.6709, -1.7641],
        [-1.3109, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06600000709295273
Epoch 0, Step 832: train/loss = 0.7887558937072754, train/raw-loss = 0.7370056509971619, train/logprobs = tensor([[-1.5248, -1.0240],
        [-1.4210, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350048542022705
Epoch 0, Step 833: train/loss = 0.6807472705841064, train/raw-loss = 0.6244064569473267, train/logprobs = tensor([[-1.0610, -1.0665],
        [-1.0844, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268167197704315
Epoch 0, Step 834: train/loss = 0.7099747061729431, train/raw-loss = 0.6490611433982849, train/logprobs = tensor([[-0.8514, -0.8771],
        [-1.0888, -0.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1218271479010582
Epoch 0, Step 835: train/loss = 0.7763780355453491, train/raw-loss = 0.7162754535675049, train/logprobs = tensor([[-1.2727, -1.1902],
        [-1.2532, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1202051192522049
Epoch 0, Step 836: train/loss = 0.7377099394798279, train/raw-loss = 0.66730797290802, train/logprobs = tensor([[-1.3825, -1.2330],
        [-1.4990, -1.1934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14080406725406647
Epoch 0, Step 837: train/loss = 0.6617927551269531, train/raw-loss = 0.6119526624679565, train/logprobs = tensor([[-0.7018, -0.9107],
        [-0.9037, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09968019276857376
Epoch 0, Step 838: train/loss = 0.7106008529663086, train/raw-loss = 0.6682783365249634, train/logprobs = tensor([[-2.3103, -2.0128],
        [-1.8737, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0846450999379158
Epoch 0, Step 839: train/loss = 0.557999312877655, train/raw-loss = 0.5053904056549072, train/logprobs = tensor([[-1.5808, -2.2905],
        [-2.0928, -1.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521778464317322
Epoch 0, Step 840: train/loss = 0.6221095323562622, train/raw-loss = 0.5642699003219604, train/logprobs = tensor([[-1.3734, -1.5840],
        [-1.6474, -0.9269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567935347557068
Epoch 0, Step 841: train/loss = 0.6974528431892395, train/raw-loss = 0.637894868850708, train/logprobs = tensor([[-1.3270, -1.5419],
        [-1.1448, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11911599338054657
Epoch 0, Step 842: train/loss = 0.6032264828681946, train/raw-loss = 0.5547207593917847, train/logprobs = tensor([[-0.5828, -1.2646],
        [-0.6820, -0.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0970115140080452
Epoch 0, Step 843: train/loss = 0.6958897113800049, train/raw-loss = 0.6482648849487305, train/logprobs = tensor([[-0.9189, -1.1792],
        [-0.9905, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09524989128112793
Epoch 0, Step 844: train/loss = 0.6778847575187683, train/raw-loss = 0.6290263533592224, train/logprobs = tensor([[-0.7273, -1.3650],
        [-0.6769, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09771686047315598
Epoch 0, Step 845: train/loss = 0.8533477783203125, train/raw-loss = 0.7994469404220581, train/logprobs = tensor([[-2.1082, -2.3473],
        [-1.0604, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10780155658721924
Epoch 0, Step 846: train/loss = 0.6770845651626587, train/raw-loss = 0.6157636642456055, train/logprobs = tensor([[-1.0244, -1.3068],
        [-1.1967, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122641921043396
Epoch 0, Step 847: train/loss = 0.5796223878860474, train/raw-loss = 0.5386699438095093, train/logprobs = tensor([[-1.1411, -1.8175],
        [-1.4778, -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190497756004333
Epoch 0, Step 848: train/loss = 0.7443090081214905, train/raw-loss = 0.6853523254394531, train/logprobs = tensor([[-1.6845, -1.5350],
        [-1.4427, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11791328340768814
Epoch 0, Step 849: train/loss = 0.510917603969574, train/raw-loss = 0.4629939794540405, train/logprobs = tensor([[-0.6666, -2.7882],
        [-0.7620, -1.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09584729373455048
Epoch 0, Step 850: train/loss = 0.6368852257728577, train/raw-loss = 0.569953441619873, train/logprobs = tensor([[-1.9089, -2.9380],
        [-1.5162, -1.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386347889900208
Epoch 0, Step 851: train/loss = 0.5853869318962097, train/raw-loss = 0.5402697324752808, train/logprobs = tensor([[-1.4948, -2.0083],
        [-1.5533, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09023432433605194
Epoch 0, Step 852: train/loss = 0.7007103562355042, train/raw-loss = 0.6483296155929565, train/logprobs = tensor([[-1.4235, -1.4816],
        [-1.4029, -1.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10476135462522507
Epoch 0, Step 853: train/loss = 0.596444845199585, train/raw-loss = 0.5376059412956238, train/logprobs = tensor([[-0.9589, -1.7118],
        [-1.1559, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767777800559998
Epoch 0, Step 854: train/loss = 0.6168577671051025, train/raw-loss = 0.5651259422302246, train/logprobs = tensor([[-1.5513, -1.3979],
        [-1.7233, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10346351563930511
Epoch 0, Step 855: train/loss = 0.6158820986747742, train/raw-loss = 0.5645783543586731, train/logprobs = tensor([[-0.5383, -1.2265],
        [-0.7910, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10260748863220215
Epoch 0, Step 856: train/loss = 0.6920900344848633, train/raw-loss = 0.6353288888931274, train/logprobs = tensor([[-1.0351, -1.3240],
        [-1.0949, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11352229118347168
Epoch 0, Step 857: train/loss = 0.6228760480880737, train/raw-loss = 0.5710303783416748, train/logprobs = tensor([[-1.4186, -1.9506],
        [-1.5135, -1.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10369144380092621
Epoch 0, Step 858: train/loss = 0.6902898550033569, train/raw-loss = 0.6413403749465942, train/logprobs = tensor([[-1.9469, -2.2065],
        [-1.8334, -1.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09789909422397614
Epoch 0, Step 859: train/loss = 0.5821467638015747, train/raw-loss = 0.5248413681983948, train/logprobs = tensor([[-0.9629, -1.2710],
        [-1.3977, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11461076140403748
Epoch 0, Step 860: train/loss = 0.7437584400177002, train/raw-loss = 0.7019318342208862, train/logprobs = tensor([[-1.1565, -1.1877],
        [-0.9144, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08365322649478912
Epoch 0, Step 861: train/loss = 0.6122288107872009, train/raw-loss = 0.5705298781394958, train/logprobs = tensor([[-0.9934, -1.5281],
        [-1.1026, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08339787274599075
Epoch 0, Step 862: train/loss = 0.715032696723938, train/raw-loss = 0.6543833613395691, train/logprobs = tensor([[-1.0376, -1.2933],
        [-1.3953, -1.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12129871547222137
Epoch 0, Step 863: train/loss = 0.730613112449646, train/raw-loss = 0.6849879622459412, train/logprobs = tensor([[-1.5727, -0.9649],
        [-1.5544, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09125031530857086
Epoch 0, Step 864: train/loss = 0.5587823390960693, train/raw-loss = 0.4841139614582062, train/logprobs = tensor([[-1.2597, -2.2282],
        [-1.5189, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14933675527572632
Epoch 0, Step 865: train/loss = 0.7547699213027954, train/raw-loss = 0.6987390518188477, train/logprobs = tensor([[-1.6254, -1.4370],
        [-1.2955, -1.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11206163465976715
Epoch 0, Step 866: train/loss = 0.6676533818244934, train/raw-loss = 0.6254981756210327, train/logprobs = tensor([[-0.7718, -1.3072],
        [-0.6589, -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0843103900551796
Epoch 0, Step 867: train/loss = 0.5959150791168213, train/raw-loss = 0.5303633213043213, train/logprobs = tensor([[-1.3865, -2.5228],
        [-1.6228, -1.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13110347092151642
Epoch 0, Step 868: train/loss = 0.4971598982810974, train/raw-loss = 0.4416589140892029, train/logprobs = tensor([[-1.1494, -2.4150],
        [-1.5839, -1.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1110018938779831
Epoch 0, Step 869: train/loss = 0.64811110496521, train/raw-loss = 0.5857292413711548, train/logprobs = tensor([[-1.3836, -1.7211],
        [-1.5499, -1.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12476383149623871
Epoch 0, Step 870: train/loss = 0.7695056200027466, train/raw-loss = 0.7290276288986206, train/logprobs = tensor([[-2.7013, -2.6221],
        [-1.9125, -1.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08095595240592957
Epoch 0, Step 871: train/loss = 0.607876181602478, train/raw-loss = 0.5441322326660156, train/logprobs = tensor([[-0.9388, -1.5753],
        [-1.3965, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12748780846595764
Epoch 0, Step 872: train/loss = 0.7459760904312134, train/raw-loss = 0.6921489834785461, train/logprobs = tensor([[-1.4211, -0.9719],
        [-1.1093, -0.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10765412449836731
Epoch 0, Step 873: train/loss = 0.5594584941864014, train/raw-loss = 0.4950127601623535, train/logprobs = tensor([[-1.7839, -2.0124],
        [-2.2348, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12889155745506287
Epoch 0, Step 874: train/loss = 1.1811426877975464, train/raw-loss = 1.1202527284622192, train/logprobs = tensor([[-2.6030, -1.4876],
        [-1.6291, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177999317646027
Epoch 0, Step 875: train/loss = 0.7074231505393982, train/raw-loss = 0.6380892395973206, train/logprobs = tensor([[-1.5571, -1.7908],
        [-1.3013, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13866779208183289
Epoch 0, Step 876: train/loss = 0.6908519864082336, train/raw-loss = 0.6442991495132446, train/logprobs = tensor([[-1.3232, -1.2472],
        [-1.1012, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09310576319694519
Epoch 0, Step 877: train/loss = 0.5768817663192749, train/raw-loss = 0.5104688405990601, train/logprobs = tensor([[-1.3654, -1.9444],
        [-1.7014, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13282600045204163
Epoch 0, Step 878: train/loss = 0.6341460347175598, train/raw-loss = 0.5864278078079224, train/logprobs = tensor([[-0.8804, -1.2772],
        [-0.8861, -0.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09543637186288834
Epoch 0, Step 879: train/loss = 0.514967143535614, train/raw-loss = 0.4593049883842468, train/logprobs = tensor([[-1.5575, -2.7449],
        [-1.6424, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11132438480854034
Epoch 0, Step 880: train/loss = 0.6431869864463806, train/raw-loss = 0.5836243629455566, train/logprobs = tensor([[-1.6939, -2.2936],
        [-1.5430, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11912527680397034
Epoch 0, Step 881: train/loss = 0.5523188710212708, train/raw-loss = 0.4893213212490082, train/logprobs = tensor([[-1.2692, -2.9838],
        [-1.2253, -1.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12599515914916992
Epoch 0, Step 882: train/loss = 0.6528452634811401, train/raw-loss = 0.5896065831184387, train/logprobs = tensor([[-1.3830, -1.4947],
        [-1.7572, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264772266149521
Epoch 0, Step 883: train/loss = 0.7358852028846741, train/raw-loss = 0.679047703742981, train/logprobs = tensor([[-0.9283, -0.9606],
        [-0.9328, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367499828338623
Epoch 0, Step 884: train/loss = 0.6394851207733154, train/raw-loss = 0.5947716236114502, train/logprobs = tensor([[-1.6066, -3.1767],
        [-1.0842, -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08942697197198868
Epoch 0, Step 885: train/loss = 0.5556142330169678, train/raw-loss = 0.49760523438453674, train/logprobs = tensor([[-1.2884, -2.1092],
        [-1.5453, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11601797491312027
Epoch 0, Step 886: train/loss = 0.6608033776283264, train/raw-loss = 0.6085669994354248, train/logprobs = tensor([[-1.6435, -1.6594],
        [-1.5242, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447273403406143
Epoch 0, Step 887: train/loss = 0.757763147354126, train/raw-loss = 0.6988555192947388, train/logprobs = tensor([[-1.1887, -0.9750],
        [-0.9634, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11781521141529083
Epoch 0, Step 888: train/loss = 0.5077652931213379, train/raw-loss = 0.46081238985061646, train/logprobs = tensor([[-1.5840, -2.3588],
        [-1.8229, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09390576928853989
Epoch 0, Step 889: train/loss = 0.7017006278038025, train/raw-loss = 0.6432633399963379, train/logprobs = tensor([[-1.2796, -1.4447],
        [-1.1622, -1.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11687448620796204
Epoch 0, Step 890: train/loss = 0.6374502778053284, train/raw-loss = 0.5915444493293762, train/logprobs = tensor([[-0.9160, -1.5460],
        [-0.8636, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181170910596848
Epoch 0, Step 891: train/loss = 0.6410011649131775, train/raw-loss = 0.5662396550178528, train/logprobs = tensor([[-1.4592, -1.7304],
        [-1.7987, -1.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14952288568019867
Epoch 0, Step 892: train/loss = 0.7265445590019226, train/raw-loss = 0.6652085185050964, train/logprobs = tensor([[-1.2184, -1.2624],
        [-1.0144, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267200648784637
Epoch 0, Step 893: train/loss = 0.6850655674934387, train/raw-loss = 0.6424264311790466, train/logprobs = tensor([[-1.1453, -1.6045],
        [-1.0106, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852782279253006
Epoch 0, Step 894: train/loss = 0.5783863067626953, train/raw-loss = 0.5338289737701416, train/logprobs = tensor([[-0.8759, -2.2177],
        [-0.8837, -1.2391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911453932523727
Epoch 0, Step 895: train/loss = 0.7603714466094971, train/raw-loss = 0.7214701771736145, train/logprobs = tensor([[-1.4010, -1.2190],
        [-1.1387, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07780265808105469
Epoch 0, Step 896: train/loss = 0.5968183279037476, train/raw-loss = 0.5335750579833984, train/logprobs = tensor([[-0.7266, -1.5513],
        [-0.9714, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12648651003837585
Epoch 0, Step 897: train/loss = 0.8024718761444092, train/raw-loss = 0.7456690073013306, train/logprobs = tensor([[-1.8011, -1.6655],
        [-1.3886, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11360566318035126
Epoch 0, Step 898: train/loss = 0.5925602912902832, train/raw-loss = 0.5412692427635193, train/logprobs = tensor([[-0.8027, -1.3472],
        [-1.0287, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258211940526962
Epoch 0, Step 899: train/loss = 0.6612886190414429, train/raw-loss = 0.590447723865509, train/logprobs = tensor([[-2.0149, -2.4274],
        [-1.7502, -1.2986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14168177545070648
Epoch 0, Step 900: train/loss = 0.7182891368865967, train/raw-loss = 0.6788328886032104, train/logprobs = tensor([[-2.1252, -1.9182],
        [-2.0895, -1.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07891254127025604
Epoch 0, Step 901: train/loss = 0.7690544128417969, train/raw-loss = 0.7241989374160767, train/logprobs = tensor([[-2.3302, -2.2896],
        [-1.8555, -1.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897110253572464
Epoch 0, Step 902: train/loss = 0.7795078754425049, train/raw-loss = 0.7234072089195251, train/logprobs = tensor([[-2.4100, -2.2119],
        [-1.9845, -1.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220124363899231
Epoch 0, Step 903: train/loss = 0.6521821618080139, train/raw-loss = 0.6182355284690857, train/logprobs = tensor([[-0.9322, -1.0683],
        [-1.1016, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06789328157901764
Epoch 0, Step 904: train/loss = 0.7148592472076416, train/raw-loss = 0.661271870136261, train/logprobs = tensor([[-1.4754, -0.8931],
        [-1.5305, -0.7789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10717472434043884
Epoch 0, Step 905: train/loss = 0.5966587662696838, train/raw-loss = 0.5429287552833557, train/logprobs = tensor([[-1.1848, -0.9507],
        [-1.5743, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10746004432439804
Epoch 0, Step 906: train/loss = 0.6760034561157227, train/raw-loss = 0.6108733415603638, train/logprobs = tensor([[-1.0139, -1.9757],
        [-1.2899, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026025891304016
Epoch 0, Step 907: train/loss = 0.6591813564300537, train/raw-loss = 0.6011613607406616, train/logprobs = tensor([[-0.9295, -2.0096],
        [-1.0737, -1.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11604003608226776
Epoch 0, Step 908: train/loss = 0.6693907976150513, train/raw-loss = 0.6128196716308594, train/logprobs = tensor([[-1.6578, -2.2570],
        [-1.3038, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11314219236373901
Epoch 0, Step 909: train/loss = 0.6275995373725891, train/raw-loss = 0.5769867300987244, train/logprobs = tensor([[-0.7503, -1.5909],
        [-0.7772, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012255847454071
Epoch 0, Step 910: train/loss = 0.7954251766204834, train/raw-loss = 0.7247406840324402, train/logprobs = tensor([[-2.0229, -1.8729],
        [-1.4010, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1413688063621521
Epoch 0, Step 911: train/loss = 0.6801002621650696, train/raw-loss = 0.6172806620597839, train/logprobs = tensor([[-1.2614, -1.5965],
        [-1.2506, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256391406059265
Epoch 0, Step 912: train/loss = 0.7071764469146729, train/raw-loss = 0.6630202531814575, train/logprobs = tensor([[-2.0302, -1.5864],
        [-1.7442, -0.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08831234276294708
Epoch 0, Step 913: train/loss = 0.523199737071991, train/raw-loss = 0.46871596574783325, train/logprobs = tensor([[-0.9680, -3.4264],
        [-1.1980, -2.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10896746814250946
Epoch 0, Step 914: train/loss = 0.5600211024284363, train/raw-loss = 0.4957670569419861, train/logprobs = tensor([[-0.8243, -1.5410],
        [-1.1401, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12850813567638397
Epoch 0, Step 915: train/loss = 0.6064799427986145, train/raw-loss = 0.542906641960144, train/logprobs = tensor([[-1.1496, -2.1587],
        [-1.1454, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12714651226997375
Epoch 0, Step 916: train/loss = 0.6981926560401917, train/raw-loss = 0.6445242762565613, train/logprobs = tensor([[-1.3865, -2.0517],
        [-1.1949, -1.4417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10733683407306671
Epoch 0, Step 917: train/loss = 0.7370628118515015, train/raw-loss = 0.6727514863014221, train/logprobs = tensor([[-1.7229, -1.8539],
        [-1.2440, -1.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12862253189086914
Epoch 0, Step 918: train/loss = 0.7267822623252869, train/raw-loss = 0.6722369194030762, train/logprobs = tensor([[-1.5001, -1.4610],
        [-1.4872, -1.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10909081995487213
Epoch 0, Step 919: train/loss = 0.7097366452217102, train/raw-loss = 0.6582722663879395, train/logprobs = tensor([[-1.2025, -1.0269],
        [-1.0637, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10292871296405792
Epoch 0, Step 920: train/loss = 0.5648276805877686, train/raw-loss = 0.49874553084373474, train/logprobs = tensor([[-1.3365, -1.9364],
        [-1.7090, -1.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13216421008110046
Epoch 0, Step 921: train/loss = 0.643476665019989, train/raw-loss = 0.6025974750518799, train/logprobs = tensor([[-0.7860, -1.3762],
        [-0.8372, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08175840973854065
Epoch 0, Step 922: train/loss = 0.6607088446617126, train/raw-loss = 0.5991684198379517, train/logprobs = tensor([[-1.1828, -1.7273],
        [-1.3645, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12308087199926376
Epoch 0, Step 923: train/loss = 0.6491581797599792, train/raw-loss = 0.5925872325897217, train/logprobs = tensor([[-2.0387, -2.4782],
        [-1.9085, -1.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11314191669225693
Epoch 0, Step 924: train/loss = 0.626379132270813, train/raw-loss = 0.5862942934036255, train/logprobs = tensor([[-0.4988, -1.0627],
        [-0.5550, -0.4932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08016984164714813
Epoch 0, Step 925: train/loss = 0.6282213926315308, train/raw-loss = 0.5619822144508362, train/logprobs = tensor([[-1.9533, -1.8498],
        [-2.2306, -1.5310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13247837126255035
Epoch 0, Step 926: train/loss = 0.8160368800163269, train/raw-loss = 0.7688231468200684, train/logprobs = tensor([[-1.9191, -2.1275],
        [-1.3681, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09442734718322754
Epoch 0, Step 927: train/loss = 0.5051661729812622, train/raw-loss = 0.4342153072357178, train/logprobs = tensor([[-1.2130, -2.0679],
        [-1.5307, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190168678760529
Epoch 0, Step 928: train/loss = 0.6723978519439697, train/raw-loss = 0.6219102144241333, train/logprobs = tensor([[-1.2691, -1.2652],
        [-1.1082, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10097523778676987
Epoch 0, Step 929: train/loss = 0.5786653757095337, train/raw-loss = 0.5210349559783936, train/logprobs = tensor([[-1.0169, -1.7675],
        [-1.3838, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11526075005531311
Epoch 0, Step 930: train/loss = 0.6923182010650635, train/raw-loss = 0.6247072815895081, train/logprobs = tensor([[-1.5581, -1.3709],
        [-1.8250, -1.2755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13522198796272278
Epoch 0, Step 931: train/loss = 0.688776969909668, train/raw-loss = 0.6391121745109558, train/logprobs = tensor([[-1.2775, -1.2768],
        [-1.1766, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932965040206909
Epoch 0, Step 932: train/loss = 0.7214133739471436, train/raw-loss = 0.6700069904327393, train/logprobs = tensor([[-0.9113, -0.8978],
        [-0.9778, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281290113925934
Epoch 0, Step 933: train/loss = 0.6908266544342041, train/raw-loss = 0.6501746773719788, train/logprobs = tensor([[-0.6191, -0.7136],
        [-0.6756, -0.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08130407333374023
Epoch 0, Step 934: train/loss = 0.6443591713905334, train/raw-loss = 0.5772629976272583, train/logprobs = tensor([[-0.9846, -1.7035],
        [-1.5352, -1.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341923177242279
Epoch 0, Step 935: train/loss = 0.8039119243621826, train/raw-loss = 0.750536322593689, train/logprobs = tensor([[-1.7406, -0.9151],
        [-1.6814, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10675127804279327
Epoch 0, Step 936: train/loss = 0.6773312091827393, train/raw-loss = 0.6199026107788086, train/logprobs = tensor([[-1.0321, -1.1606],
        [-0.9117, -0.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485714465379715
Epoch 0, Step 937: train/loss = 0.633228063583374, train/raw-loss = 0.5799365639686584, train/logprobs = tensor([[-0.6970, -1.7905],
        [-0.7899, -1.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658302158117294
Epoch 0, Step 938: train/loss = 0.7847957015037537, train/raw-loss = 0.7207199335098267, train/logprobs = tensor([[-1.9404, -2.1745],
        [-1.4757, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12815161049365997
Epoch 0, Step 939: train/loss = 0.7478872537612915, train/raw-loss = 0.6878728866577148, train/logprobs = tensor([[-1.4191, -1.3744],
        [-0.9915, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12002873420715332
Epoch 0, Step 940: train/loss = 0.5855583548545837, train/raw-loss = 0.5218183994293213, train/logprobs = tensor([[-1.2490, -2.3381],
        [-1.5501, -1.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12747980654239655
Epoch 0, Step 941: train/loss = 0.6547547578811646, train/raw-loss = 0.6016592383384705, train/logprobs = tensor([[-1.5497, -1.9419],
        [-1.3227, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10619106888771057
Epoch 0, Step 942: train/loss = 0.7526133060455322, train/raw-loss = 0.6921777725219727, train/logprobs = tensor([[-2.1389, -2.1276],
        [-1.8037, -1.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12087089568376541
Epoch 0, Step 943: train/loss = 0.545031726360321, train/raw-loss = 0.4960682988166809, train/logprobs = tensor([[-0.8040, -2.0108],
        [-0.8780, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09792675822973251
Epoch 0, Step 944: train/loss = 0.6391434669494629, train/raw-loss = 0.5903415679931641, train/logprobs = tensor([[-0.7172, -0.8817],
        [-0.9402, -0.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09760383516550064
Epoch 0, Step 945: train/loss = 0.6612634658813477, train/raw-loss = 0.6132520437240601, train/logprobs = tensor([[-0.7789, -1.2797],
        [-0.8803, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09602275490760803
Epoch 0, Step 946: train/loss = 0.7398836612701416, train/raw-loss = 0.6773413419723511, train/logprobs = tensor([[-1.7113, -1.7367],
        [-1.6932, -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12508462369441986
Epoch 0, Step 947: train/loss = 0.7119009494781494, train/raw-loss = 0.6699349880218506, train/logprobs = tensor([[-2.3306, -2.8716],
        [-1.8048, -2.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08393194526433945
Epoch 0, Step 948: train/loss = 0.6520498991012573, train/raw-loss = 0.5963866114616394, train/logprobs = tensor([[-0.9753, -1.7101],
        [-0.7875, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11132656037807465
Epoch 0, Step 949: train/loss = 0.7059376835823059, train/raw-loss = 0.6659473180770874, train/logprobs = tensor([[-1.2256, -1.3439],
        [-1.0602, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07998062670230865
Epoch 0, Step 950: train/loss = 0.6782431602478027, train/raw-loss = 0.6133532524108887, train/logprobs = tensor([[-1.2482, -1.4471],
        [-1.3374, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1297798454761505
Epoch 0, Step 951: train/loss = 0.6121957302093506, train/raw-loss = 0.5516049861907959, train/logprobs = tensor([[-0.7007, -1.9543],
        [-0.8106, -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12118151038885117
Epoch 0, Step 952: train/loss = 0.640461266040802, train/raw-loss = 0.57989501953125, train/logprobs = tensor([[-2.1265, -3.5126],
        [-1.5919, -1.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12113253027200699
Epoch 0, Step 953: train/loss = 0.7257876396179199, train/raw-loss = 0.6725248098373413, train/logprobs = tensor([[-1.4880, -1.1830],
        [-1.4276, -1.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10652574896812439
Epoch 0, Step 954: train/loss = 0.6833804845809937, train/raw-loss = 0.6438336372375488, train/logprobs = tensor([[-0.8959, -1.0968],
        [-0.9038, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07909370958805084
Epoch 0, Step 955: train/loss = 0.6345311403274536, train/raw-loss = 0.579445481300354, train/logprobs = tensor([[-1.1955, -1.7318],
        [-1.1179, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11017139256000519
Epoch 0, Step 956: train/loss = 0.5674495100975037, train/raw-loss = 0.5056816339492798, train/logprobs = tensor([[-1.4884, -3.0789],
        [-1.3958, -1.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12353583425283432
Epoch 0, Step 957: train/loss = 0.6672192811965942, train/raw-loss = 0.6232342720031738, train/logprobs = tensor([[-0.9485, -0.6647],
        [-1.2567, -0.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879700630903244
Epoch 0, Step 958: train/loss = 0.6415926218032837, train/raw-loss = 0.5747252702713013, train/logprobs = tensor([[-1.4396, -2.6920],
        [-1.1313, -1.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13373467326164246
Epoch 0, Step 959: train/loss = 0.617457389831543, train/raw-loss = 0.5598236322402954, train/logprobs = tensor([[-1.5570, -2.3726],
        [-1.3276, -1.1825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11526750773191452
Epoch 0, Step 960: train/loss = 0.5844351053237915, train/raw-loss = 0.5081074237823486, train/logprobs = tensor([[-1.5115, -1.9576],
        [-2.0050, -1.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15265518426895142
Epoch 0, Step 961: train/loss = 0.7123069167137146, train/raw-loss = 0.6602901220321655, train/logprobs = tensor([[-1.1342, -1.3550],
        [-1.0803, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10403362661600113
Epoch 0, Step 962: train/loss = 0.6187422275543213, train/raw-loss = 0.5580859184265137, train/logprobs = tensor([[-0.9790, -1.9662],
        [-1.3840, -1.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12131248414516449
Epoch 0, Step 963: train/loss = 0.5694905519485474, train/raw-loss = 0.49677714705467224, train/logprobs = tensor([[-1.4865, -2.2799],
        [-1.5252, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14542682468891144
Epoch 0, Step 964: train/loss = 0.6104937791824341, train/raw-loss = 0.5472007989883423, train/logprobs = tensor([[-0.6260, -1.5993],
        [-0.8600, -1.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12658600509166718
Epoch 0, Step 965: train/loss = 0.6144420504570007, train/raw-loss = 0.5507165193557739, train/logprobs = tensor([[-1.3340, -2.4312],
        [-1.3615, -1.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12745118141174316
Epoch 0, Step 966: train/loss = 0.6393855810165405, train/raw-loss = 0.5764257907867432, train/logprobs = tensor([[-0.9475, -1.7039],
        [-1.0629, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259196400642395
Epoch 0, Step 967: train/loss = 0.6437290906906128, train/raw-loss = 0.5744653940200806, train/logprobs = tensor([[-1.4992, -2.0798],
        [-1.7373, -1.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13852733373641968
Epoch 0, Step 968: train/loss = 0.6578577756881714, train/raw-loss = 0.602294921875, train/logprobs = tensor([[-1.8334, -2.3932],
        [-1.8057, -1.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11112590879201889
Epoch 0, Step 969: train/loss = 0.680307149887085, train/raw-loss = 0.6306172609329224, train/logprobs = tensor([[-0.8334, -0.6804],
        [-1.2294, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09937968105077744
Epoch 0, Step 970: train/loss = 0.7767821550369263, train/raw-loss = 0.7195258140563965, train/logprobs = tensor([[-2.2242, -1.4258],
        [-2.0004, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11451271176338196
Epoch 0, Step 971: train/loss = 0.4772428870201111, train/raw-loss = 0.42048853635787964, train/logprobs = tensor([[-1.0595, -2.9623],
        [-1.1370, -1.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11350871622562408
Epoch 0, Step 972: train/loss = 0.7326043844223022, train/raw-loss = 0.6877248287200928, train/logprobs = tensor([[-1.3447, -0.7984],
        [-1.1696, -0.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08975890278816223
Epoch 0, Step 973: train/loss = 0.6138601303100586, train/raw-loss = 0.5571176409721375, train/logprobs = tensor([[-0.8770, -1.7874],
        [-0.9782, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11348491162061691
Epoch 0, Step 974: train/loss = 0.6156702041625977, train/raw-loss = 0.5622667074203491, train/logprobs = tensor([[-0.9141, -1.4025],
        [-1.0131, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1068069189786911
Epoch 0, Step 975: train/loss = 0.6980518698692322, train/raw-loss = 0.6425725221633911, train/logprobs = tensor([[-1.1666, -1.3567],
        [-1.3122, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095878481864929
Epoch 0, Step 976: train/loss = 0.6625485420227051, train/raw-loss = 0.6018940210342407, train/logprobs = tensor([[-0.9070, -1.2990],
        [-1.1057, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12130899727344513
Epoch 0, Step 977: train/loss = 0.6876822113990784, train/raw-loss = 0.6262577772140503, train/logprobs = tensor([[-1.3897, -1.6832],
        [-1.5934, -1.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12284886837005615
Epoch 0, Step 978: train/loss = 0.6313406229019165, train/raw-loss = 0.5527199506759644, train/logprobs = tensor([[-1.7968, -2.1214],
        [-1.8867, -1.5654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572413146495819
Epoch 0, Step 979: train/loss = 0.6067143678665161, train/raw-loss = 0.5381130576133728, train/logprobs = tensor([[-1.7041, -2.4080],
        [-1.9323, -1.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13720253109931946
Epoch 0, Step 980: train/loss = 0.660290539264679, train/raw-loss = 0.6136791706085205, train/logprobs = tensor([[-0.9163, -1.2036],
        [-1.0265, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322278946638107
Epoch 0, Step 981: train/loss = 0.6244608163833618, train/raw-loss = 0.5711016654968262, train/logprobs = tensor([[-1.3255, -2.4085],
        [-1.0732, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10671833902597427
Epoch 0, Step 982: train/loss = 0.7286883592605591, train/raw-loss = 0.6769788265228271, train/logprobs = tensor([[-1.4909, -1.5938],
        [-1.1982, -1.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10341905057430267
Epoch 0, Step 983: train/loss = 0.7232229709625244, train/raw-loss = 0.6638761758804321, train/logprobs = tensor([[-1.4363, -1.3570],
        [-1.4829, -1.2727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11869356036186218
Epoch 0, Step 984: train/loss = 0.7092028260231018, train/raw-loss = 0.6419757008552551, train/logprobs = tensor([[-1.4756, -1.9497],
        [-1.6978, -1.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13445426523685455
Epoch 0, Step 985: train/loss = 0.6746131777763367, train/raw-loss = 0.6168779134750366, train/logprobs = tensor([[-0.7733, -1.4619],
        [-0.8818, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11547045409679413
Epoch 0, Step 986: train/loss = 0.6686444282531738, train/raw-loss = 0.6226935386657715, train/logprobs = tensor([[-0.7368, -0.9732],
        [-0.9626, -0.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0919017493724823
Epoch 0, Step 987: train/loss = 0.6603724956512451, train/raw-loss = 0.6010394096374512, train/logprobs = tensor([[-1.1567, -1.8033],
        [-1.2629, -1.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1186661347746849
Epoch 0, Step 988: train/loss = 0.5606844425201416, train/raw-loss = 0.5023237466812134, train/logprobs = tensor([[-1.5451, -1.7941],
        [-1.6268, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672139167785645
Epoch 0, Step 989: train/loss = 0.5630792379379272, train/raw-loss = 0.5120531916618347, train/logprobs = tensor([[-1.3153, -1.8218],
        [-1.4790, -0.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10205208510160446
Epoch 0, Step 990: train/loss = 0.6639094352722168, train/raw-loss = 0.5975740551948547, train/logprobs = tensor([[-2.0787, -2.2293],
        [-2.0836, -1.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13267076015472412
Epoch 0, Step 991: train/loss = 0.6698489189147949, train/raw-loss = 0.6203683614730835, train/logprobs = tensor([[-1.0241, -1.1189],
        [-1.2897, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09896113723516464
Epoch 0, Step 992: train/loss = 0.6451235413551331, train/raw-loss = 0.5782989263534546, train/logprobs = tensor([[-1.0475, -1.7853],
        [-0.9647, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364923000335693
Epoch 0, Step 993: train/loss = 0.710914671421051, train/raw-loss = 0.6665730476379395, train/logprobs = tensor([[-1.0832, -1.4614],
        [-0.9843, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08868344128131866
Epoch 0, Step 994: train/loss = 0.6358715891838074, train/raw-loss = 0.5731140971183777, train/logprobs = tensor([[-0.8394, -1.0122],
        [-1.2171, -0.8483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12551504373550415
Epoch 0, Step 995: train/loss = 0.5316259264945984, train/raw-loss = 0.4516362249851227, train/logprobs = tensor([[-1.5906, -2.5477],
        [-2.0968, -1.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15997937321662903
Epoch 0, Step 996: train/loss = 0.6600445508956909, train/raw-loss = 0.5954197645187378, train/logprobs = tensor([[-0.8165, -1.7496],
        [-1.2801, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12924964725971222
Epoch 0, Step 997: train/loss = 0.7062703371047974, train/raw-loss = 0.6667719483375549, train/logprobs = tensor([[-1.1420, -0.7542],
        [-1.2937, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07899685949087143
Epoch 0, Step 998: train/loss = 0.6879690885543823, train/raw-loss = 0.6325125694274902, train/logprobs = tensor([[-1.6635, -1.6788],
        [-1.7502, -1.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109132394194603
Epoch 0, Step 999: train/loss = 0.5622974038124084, train/raw-loss = 0.4936436414718628, train/logprobs = tensor([[-0.9708, -2.2517],
        [-1.3243, -1.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13730750977993011
eval/loss: 0.6606944799423218
Epoch 0, Step 1000: train/loss = 0.6378765106201172, train/raw-loss = 0.5904534459114075, train/logprobs = tensor([[-0.7310, -0.9354],
        [-1.0950, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484609961509705
Epoch 0, Step 1001: train/loss = 0.7812429666519165, train/raw-loss = 0.7239523530006409, train/logprobs = tensor([[-1.5967, -1.2510],
        [-1.3297, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458113044500351
Epoch 0, Step 1002: train/loss = 0.530977725982666, train/raw-loss = 0.4750673174858093, train/logprobs = tensor([[-0.9782, -1.7673],
        [-1.3754, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.111820749938488
Epoch 0, Step 1003: train/loss = 0.6182087659835815, train/raw-loss = 0.5594099164009094, train/logprobs = tensor([[-0.9638, -1.7450],
        [-1.0379, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11759775876998901
Epoch 0, Step 1004: train/loss = 0.706031858921051, train/raw-loss = 0.6685217022895813, train/logprobs = tensor([[-0.9735, -0.5699],
        [-0.9596, -0.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075020432472229
Epoch 0, Step 1005: train/loss = 0.6611528992652893, train/raw-loss = 0.6192386150360107, train/logprobs = tensor([[-1.4133, -2.1702],
        [-1.4641, -1.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08382854610681534
Epoch 0, Step 1006: train/loss = 0.7100694179534912, train/raw-loss = 0.6688418388366699, train/logprobs = tensor([[-0.5643, -1.0107],
        [-0.6104, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245530724525452
Epoch 0, Step 1007: train/loss = 0.5503332614898682, train/raw-loss = 0.4962957501411438, train/logprobs = tensor([[-1.3019, -2.4911],
        [-1.6129, -1.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1080750972032547
Epoch 0, Step 1008: train/loss = 0.6194447875022888, train/raw-loss = 0.5499916076660156, train/logprobs = tensor([[-1.1718, -2.0467],
        [-1.4152, -1.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890649378299713
Epoch 0, Step 1009: train/loss = 0.5962997078895569, train/raw-loss = 0.5468204021453857, train/logprobs = tensor([[-1.0423, -1.7843],
        [-1.0488, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09895861148834229
Epoch 0, Step 1010: train/loss = 0.6736059188842773, train/raw-loss = 0.6332836151123047, train/logprobs = tensor([[-1.0570, -1.6106],
        [-0.9166, -0.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08064470440149307
Epoch 0, Step 1011: train/loss = 0.6716915369033813, train/raw-loss = 0.5976160168647766, train/logprobs = tensor([[-0.9839, -1.2453],
        [-1.5729, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1481509506702423
Epoch 0, Step 1012: train/loss = 0.8161807060241699, train/raw-loss = 0.7610504627227783, train/logprobs = tensor([[-2.1008, -1.8303],
        [-1.5583, -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11026042699813843
Epoch 0, Step 1013: train/loss = 0.6626644730567932, train/raw-loss = 0.6132991313934326, train/logprobs = tensor([[-2.2858, -2.2369],
        [-1.9539, -1.2857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09873073548078537
Epoch 0, Step 1014: train/loss = 0.6896999478340149, train/raw-loss = 0.6377184391021729, train/logprobs = tensor([[-1.5650, -1.9946],
        [-1.2276, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039629876613617
Epoch 0, Step 1015: train/loss = 0.6329518556594849, train/raw-loss = 0.5751484632492065, train/logprobs = tensor([[-0.9238, -1.5837],
        [-1.1091, -1.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11560674011707306
Epoch 0, Step 1016: train/loss = 0.6465523838996887, train/raw-loss = 0.5936884880065918, train/logprobs = tensor([[-1.3198, -1.6818],
        [-1.2922, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10572770982980728
Epoch 0, Step 1017: train/loss = 0.7070425748825073, train/raw-loss = 0.6441248655319214, train/logprobs = tensor([[-1.9940, -2.3615],
        [-1.5970, -1.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258355677127838
Epoch 0, Step 1018: train/loss = 0.7021762132644653, train/raw-loss = 0.6578106880187988, train/logprobs = tensor([[-0.9930, -1.5163],
        [-0.9479, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08873114734888077
Epoch 0, Step 1019: train/loss = 0.727077841758728, train/raw-loss = 0.6564809083938599, train/logprobs = tensor([[-1.8111, -1.4450],
        [-1.7586, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14119385182857513
Epoch 0, Step 1020: train/loss = 0.7082434296607971, train/raw-loss = 0.659995436668396, train/logprobs = tensor([[-1.6300, -2.1301],
        [-1.2275, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649600833654404
Epoch 0, Step 1021: train/loss = 0.7502850294113159, train/raw-loss = 0.6924594044685364, train/logprobs = tensor([[-1.1865, -1.0159],
        [-1.3581, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11565126478672028
Epoch 0, Step 1022: train/loss = 0.7656316757202148, train/raw-loss = 0.7105912566184998, train/logprobs = tensor([[-1.4533, -1.2759],
        [-1.2007, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1100810095667839
Epoch 0, Step 1023: train/loss = 0.7272526025772095, train/raw-loss = 0.6748338937759399, train/logprobs = tensor([[-0.8219, -0.8676],
        [-1.2741, -1.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10483738780021667
Epoch 0, Step 1024: train/loss = 0.7020053863525391, train/raw-loss = 0.6497244238853455, train/logprobs = tensor([[-1.3166, -1.4907],
        [-1.2852, -1.2697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456182807683945
Epoch 0, Step 1025: train/loss = 0.6178840398788452, train/raw-loss = 0.5587773323059082, train/logprobs = tensor([[-0.8449, -1.8235],
        [-0.9706, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11821337044239044
Epoch 0, Step 1026: train/loss = 0.6691298484802246, train/raw-loss = 0.6163631677627563, train/logprobs = tensor([[-0.8432, -1.0136],
        [-1.0849, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10553327202796936
Epoch 0, Step 1027: train/loss = 0.6528586149215698, train/raw-loss = 0.591934084892273, train/logprobs = tensor([[-2.4284, -2.8316],
        [-2.3579, -2.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12184906005859375
Epoch 0, Step 1028: train/loss = 0.6115196943283081, train/raw-loss = 0.5635846257209778, train/logprobs = tensor([[-1.3403, -3.1059],
        [-1.1291, -1.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09587018191814423
Epoch 0, Step 1029: train/loss = 0.6427665948867798, train/raw-loss = 0.5883378386497498, train/logprobs = tensor([[-1.1389, -1.2794],
        [-1.5107, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10885747522115707
Epoch 0, Step 1030: train/loss = 0.6693480610847473, train/raw-loss = 0.6272002458572388, train/logprobs = tensor([[-2.2686, -2.9481],
        [-1.9136, -2.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08429570496082306
Epoch 0, Step 1031: train/loss = 0.6988087892532349, train/raw-loss = 0.6645019054412842, train/logprobs = tensor([[-0.6893, -1.0416],
        [-0.5806, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06861376017332077
Epoch 0, Step 1032: train/loss = 0.722109854221344, train/raw-loss = 0.6624407768249512, train/logprobs = tensor([[-1.3488, -1.7441],
        [-1.4807, -1.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193380206823349
Epoch 0, Step 1033: train/loss = 0.6832717061042786, train/raw-loss = 0.6202915906906128, train/logprobs = tensor([[-1.2900, -1.3831],
        [-1.4411, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125960111618042
Epoch 0, Step 1034: train/loss = 0.6467329859733582, train/raw-loss = 0.5867397785186768, train/logprobs = tensor([[-1.2773, -2.1677],
        [-1.5103, -1.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11998647451400757
Epoch 0, Step 1035: train/loss = 0.6742323040962219, train/raw-loss = 0.6240948438644409, train/logprobs = tensor([[-1.1007, -1.5997],
        [-1.0406, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10027489811182022
Epoch 0, Step 1036: train/loss = 0.6869348287582397, train/raw-loss = 0.6228566765785217, train/logprobs = tensor([[-1.8620, -1.7630],
        [-1.8818, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12815631926059723
Epoch 0, Step 1037: train/loss = 0.7472416162490845, train/raw-loss = 0.7101702690124512, train/logprobs = tensor([[-2.0955, -2.0955],
        [-1.9462, -1.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414262741804123
Epoch 0, Step 1038: train/loss = 0.561686635017395, train/raw-loss = 0.5240890383720398, train/logprobs = tensor([[-1.1095, -1.9155],
        [-1.2399, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07519515603780746
Epoch 0, Step 1039: train/loss = 0.6109594106674194, train/raw-loss = 0.5578002333641052, train/logprobs = tensor([[-1.5008, -2.2543],
        [-1.1999, -0.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10631836950778961
Epoch 0, Step 1040: train/loss = 0.651065468788147, train/raw-loss = 0.5980137586593628, train/logprobs = tensor([[-0.9948, -1.2195],
        [-1.1976, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610349476337433
Epoch 0, Step 1041: train/loss = 0.5899989604949951, train/raw-loss = 0.527362585067749, train/logprobs = tensor([[-1.4022, -1.3423],
        [-1.7229, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12527278065681458
Epoch 0, Step 1042: train/loss = 0.7666215896606445, train/raw-loss = 0.7192487716674805, train/logprobs = tensor([[-4.6330, -4.6582],
        [-3.6882, -3.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474553167819977
Epoch 0, Step 1043: train/loss = 0.5099432468414307, train/raw-loss = 0.45535436272621155, train/logprobs = tensor([[-1.2130, -2.6045],
        [-1.3447, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10917782038450241
Epoch 0, Step 1044: train/loss = 0.6333392262458801, train/raw-loss = 0.584023118019104, train/logprobs = tensor([[-2.9695, -3.4229],
        [-3.2641, -3.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09863227605819702
Epoch 0, Step 1045: train/loss = 0.6441318392753601, train/raw-loss = 0.5903327465057373, train/logprobs = tensor([[-1.2892, -1.1829],
        [-1.3341, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1075982004404068
Epoch 0, Step 1046: train/loss = 0.8166373372077942, train/raw-loss = 0.7542861104011536, train/logprobs = tensor([[-1.2552, -1.2607],
        [-1.0594, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12470237910747528
Epoch 0, Step 1047: train/loss = 0.5707120895385742, train/raw-loss = 0.5188491940498352, train/logprobs = tensor([[-1.3036, -1.8154],
        [-1.3755, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10372582077980042
Epoch 0, Step 1048: train/loss = 0.4232659935951233, train/raw-loss = 0.37122642993927, train/logprobs = tensor([[-1.3061, -2.9797],
        [-1.6815, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10407915711402893
Epoch 0, Step 1049: train/loss = 0.4610377550125122, train/raw-loss = 0.4112241268157959, train/logprobs = tensor([[-0.6426, -3.2060],
        [-0.8741, -1.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09962725639343262
Epoch 0, Step 1050: train/loss = 0.5750961303710938, train/raw-loss = 0.5153418779373169, train/logprobs = tensor([[-1.0605, -1.6663],
        [-1.6670, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11950862407684326
Epoch 0, Step 1051: train/loss = 0.6649327874183655, train/raw-loss = 0.6191312670707703, train/logprobs = tensor([[-0.4994, -1.1935],
        [-0.5760, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09160307794809341
Epoch 0, Step 1052: train/loss = 0.6157639026641846, train/raw-loss = 0.5507825613021851, train/logprobs = tensor([[-1.3354, -1.5994],
        [-2.1325, -1.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299627423286438
Epoch 0, Step 1053: train/loss = 0.6136516332626343, train/raw-loss = 0.5469988584518433, train/logprobs = tensor([[-1.0634, -1.3458],
        [-1.3127, -0.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333054155111313
Epoch 0, Step 1054: train/loss = 0.7341817021369934, train/raw-loss = 0.6834242343902588, train/logprobs = tensor([[-0.7425, -0.4106],
        [-0.8622, -0.4803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10151499509811401
Epoch 0, Step 1055: train/loss = 0.7154087424278259, train/raw-loss = 0.6572944521903992, train/logprobs = tensor([[-2.1245, -2.4274],
        [-1.8448, -1.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11622849106788635
Epoch 0, Step 1056: train/loss = 0.6982164978981018, train/raw-loss = 0.6632595062255859, train/logprobs = tensor([[-0.9621, -0.9486],
        [-1.0619, -0.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06991389393806458
Epoch 0, Step 1057: train/loss = 0.5816767811775208, train/raw-loss = 0.516036331653595, train/logprobs = tensor([[-1.2135, -3.1569],
        [-1.2162, -1.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312808245420456
Epoch 0, Step 1058: train/loss = 0.7570613622665405, train/raw-loss = 0.6895645260810852, train/logprobs = tensor([[-1.9913, -1.0767],
        [-1.7476, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13499359786510468
Epoch 0, Step 1059: train/loss = 0.6329278945922852, train/raw-loss = 0.5778157711029053, train/logprobs = tensor([[-2.4869, -3.1155],
        [-2.3308, -2.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11022421717643738
Epoch 0, Step 1060: train/loss = 0.6357806324958801, train/raw-loss = 0.594124436378479, train/logprobs = tensor([[-0.4521, -1.5599],
        [-0.4786, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08331237733364105
Epoch 0, Step 1061: train/loss = 0.6310150027275085, train/raw-loss = 0.561294436454773, train/logprobs = tensor([[-1.2921, -2.1610],
        [-1.3560, -1.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1394411027431488
Epoch 0, Step 1062: train/loss = 0.7126719951629639, train/raw-loss = 0.6649618148803711, train/logprobs = tensor([[-1.4157, -1.4725],
        [-1.4885, -1.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954202339053154
Epoch 0, Step 1063: train/loss = 0.6611697673797607, train/raw-loss = 0.6125145554542542, train/logprobs = tensor([[-0.4879, -1.2084],
        [-0.5366, -0.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09731046110391617
Epoch 0, Step 1064: train/loss = 0.7210638523101807, train/raw-loss = 0.6457384824752808, train/logprobs = tensor([[-1.0691, -1.9961],
        [-1.1922, -1.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15065079927444458
Epoch 0, Step 1065: train/loss = 0.6828713417053223, train/raw-loss = 0.6291650533676147, train/logprobs = tensor([[-1.4867, -2.1373],
        [-1.4147, -1.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10741250216960907
Epoch 0, Step 1066: train/loss = 0.7006499171257019, train/raw-loss = 0.6611989736557007, train/logprobs = tensor([[-1.0291, -0.6634],
        [-1.0609, -0.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07890187203884125
Epoch 0, Step 1067: train/loss = 0.6646672487258911, train/raw-loss = 0.6052719354629517, train/logprobs = tensor([[-1.5756, -2.3172],
        [-1.3336, -1.6071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879058927297592
Epoch 0, Step 1068: train/loss = 0.6895934343338013, train/raw-loss = 0.6534762382507324, train/logprobs = tensor([[-1.1623, -1.2726],
        [-1.1326, -1.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07223442941904068
Epoch 0, Step 1069: train/loss = 0.7213184833526611, train/raw-loss = 0.6653720736503601, train/logprobs = tensor([[-0.9920, -0.6211],
        [-1.1546, -0.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11189287900924683
Epoch 0, Step 1070: train/loss = 0.6362481117248535, train/raw-loss = 0.5694401264190674, train/logprobs = tensor([[-2.2104, -1.8840],
        [-2.2890, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13361600041389465
Epoch 0, Step 1071: train/loss = 0.7053409814834595, train/raw-loss = 0.6557003259658813, train/logprobs = tensor([[-0.8425, -0.9460],
        [-0.9614, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09928128123283386
Epoch 0, Step 1072: train/loss = 0.6341370344161987, train/raw-loss = 0.5763062238693237, train/logprobs = tensor([[-1.6661, -1.4414],
        [-1.9017, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156616359949112
Epoch 0, Step 1073: train/loss = 0.7184500098228455, train/raw-loss = 0.6619002819061279, train/logprobs = tensor([[-0.5758, -1.1272],
        [-0.7404, -1.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11309954524040222
Epoch 0, Step 1074: train/loss = 0.5940868258476257, train/raw-loss = 0.5266005992889404, train/logprobs = tensor([[-0.9252, -2.1026],
        [-1.1960, -1.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13497240841388702
Epoch 0, Step 1075: train/loss = 0.7219544649124146, train/raw-loss = 0.6710255146026611, train/logprobs = tensor([[-0.8039, -0.9576],
        [-1.1023, -1.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10185776650905609
Epoch 0, Step 1076: train/loss = 0.6847227215766907, train/raw-loss = 0.6292389035224915, train/logprobs = tensor([[-1.8805, -1.6359],
        [-1.9445, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11096768081188202
Epoch 0, Step 1077: train/loss = 0.5763740539550781, train/raw-loss = 0.5255298614501953, train/logprobs = tensor([[-1.0011, -1.0293],
        [-1.4217, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168846696615219
Epoch 0, Step 1078: train/loss = 0.677619993686676, train/raw-loss = 0.6177347898483276, train/logprobs = tensor([[-1.3453, -1.6076],
        [-1.1580, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11977043747901917
Epoch 0, Step 1079: train/loss = 0.5816091299057007, train/raw-loss = 0.5396938323974609, train/logprobs = tensor([[-0.9041, -2.3602],
        [-0.9888, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383055776357651
Epoch 0, Step 1080: train/loss = 0.6767191886901855, train/raw-loss = 0.6248853206634521, train/logprobs = tensor([[-1.2682, -1.9408],
        [-1.2091, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10366780310869217
Epoch 0, Step 1081: train/loss = 0.6593284606933594, train/raw-loss = 0.5930874943733215, train/logprobs = tensor([[-1.6239, -1.4546],
        [-1.8522, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13248193264007568
Epoch 0, Step 1082: train/loss = 0.7101085186004639, train/raw-loss = 0.6673251986503601, train/logprobs = tensor([[-0.3842, -0.5030],
        [-0.5609, -0.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08556652069091797
Epoch 0, Step 1083: train/loss = 0.6972199082374573, train/raw-loss = 0.6405168771743774, train/logprobs = tensor([[-1.0791, -1.6063],
        [-1.0708, -1.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11340595781803131
Epoch 0, Step 1084: train/loss = 0.6402580738067627, train/raw-loss = 0.5948377251625061, train/logprobs = tensor([[-0.7890, -1.0066],
        [-0.9952, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09084068983793259
Epoch 0, Step 1085: train/loss = 0.6020221710205078, train/raw-loss = 0.5557742118835449, train/logprobs = tensor([[-1.2797, -2.2316],
        [-1.3743, -1.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09249584376811981
Epoch 0, Step 1086: train/loss = 0.6596663594245911, train/raw-loss = 0.6158329248428345, train/logprobs = tensor([[-0.5553, -0.9945],
        [-0.7003, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08766684681177139
Epoch 0, Step 1087: train/loss = 0.7453237175941467, train/raw-loss = 0.7005774974822998, train/logprobs = tensor([[-1.9726, -2.0169],
        [-1.8847, -1.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08949248492717743
Epoch 0, Step 1088: train/loss = 0.7426581382751465, train/raw-loss = 0.6697988510131836, train/logprobs = tensor([[-1.1749, -1.3832],
        [-1.2566, -1.3432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14571845531463623
Epoch 0, Step 1089: train/loss = 0.6779747605323792, train/raw-loss = 0.6316362619400024, train/logprobs = tensor([[-1.3335, -1.8200],
        [-1.3905, -1.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267692267894745
Epoch 0, Step 1090: train/loss = 0.6216254830360413, train/raw-loss = 0.5789101123809814, train/logprobs = tensor([[-1.0208, -2.1130],
        [-0.8531, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08543068170547485
Epoch 0, Step 1091: train/loss = 0.6547883749008179, train/raw-loss = 0.5947645902633667, train/logprobs = tensor([[-1.8782, -2.9735],
        [-1.8252, -2.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004757672548294
Epoch 0, Step 1092: train/loss = 0.5683140158653259, train/raw-loss = 0.5259225964546204, train/logprobs = tensor([[-1.4793, -1.9842],
        [-1.5419, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08478285372257233
Epoch 0, Step 1093: train/loss = 0.7016755938529968, train/raw-loss = 0.6345339417457581, train/logprobs = tensor([[-0.9131, -1.5621],
        [-0.8642, -1.2038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13428336381912231
Epoch 0, Step 1094: train/loss = 0.7565019726753235, train/raw-loss = 0.6947818398475647, train/logprobs = tensor([[-1.0977, -1.0588],
        [-1.4903, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12344028055667877
Epoch 0, Step 1095: train/loss = 0.6408174633979797, train/raw-loss = 0.591482400894165, train/logprobs = tensor([[-1.9222, -2.2132],
        [-1.7994, -1.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.098670095205307
Epoch 0, Step 1096: train/loss = 0.5493420958518982, train/raw-loss = 0.48316690325737, train/logprobs = tensor([[-0.9188, -2.6265],
        [-1.1545, -1.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323503702878952
Epoch 0, Step 1097: train/loss = 0.6978084444999695, train/raw-loss = 0.6482399702072144, train/logprobs = tensor([[-1.8613, -2.4198],
        [-1.3893, -1.4815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09913704544305801
Epoch 0, Step 1098: train/loss = 0.732380211353302, train/raw-loss = 0.6661653518676758, train/logprobs = tensor([[-1.2833, -1.1892],
        [-1.5239, -1.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13242965936660767
Epoch 0, Step 1099: train/loss = 0.6406030654907227, train/raw-loss = 0.5862056016921997, train/logprobs = tensor([[-0.8907, -1.2334],
        [-1.0562, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1087949275970459
Epoch 0, Step 1100: train/loss = 0.666176438331604, train/raw-loss = 0.6107022762298584, train/logprobs = tensor([[-1.0581, -1.2854],
        [-1.1134, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11094839125871658
Epoch 0, Step 1101: train/loss = 0.7155214548110962, train/raw-loss = 0.6498520374298096, train/logprobs = tensor([[-1.1040, -2.2562],
        [-1.0824, -2.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13133884966373444
Epoch 0, Step 1102: train/loss = 0.7309232950210571, train/raw-loss = 0.6764997243881226, train/logprobs = tensor([[-1.3552, -1.4160],
        [-1.4251, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884712636470795
Epoch 0, Step 1103: train/loss = 0.7674443125724792, train/raw-loss = 0.7096941471099854, train/logprobs = tensor([[-1.2463, -1.9233],
        [-1.1742, -1.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11550036817789078
Epoch 0, Step 1104: train/loss = 0.6843084096908569, train/raw-loss = 0.6367573738098145, train/logprobs = tensor([[-1.0462, -1.3295],
        [-1.0780, -1.0903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09510188549757004
Epoch 0, Step 1105: train/loss = 0.6317625045776367, train/raw-loss = 0.5878123044967651, train/logprobs = tensor([[-1.0400, -1.6033],
        [-1.0384, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.087900310754776
Epoch 0, Step 1106: train/loss = 0.6540870666503906, train/raw-loss = 0.6002331972122192, train/logprobs = tensor([[-1.3236, -1.4497],
        [-1.4337, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10770769417285919
Epoch 0, Step 1107: train/loss = 0.5202755331993103, train/raw-loss = 0.4509790539741516, train/logprobs = tensor([[-1.1567, -2.2172],
        [-1.4346, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13859300315380096
Epoch 0, Step 1108: train/loss = 0.7846108675003052, train/raw-loss = 0.7070167660713196, train/logprobs = tensor([[-1.5672, -1.0640],
        [-1.6663, -1.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15518812835216522
Epoch 0, Step 1109: train/loss = 0.7206902503967285, train/raw-loss = 0.6617563366889954, train/logprobs = tensor([[-1.5611, -1.6916],
        [-1.6828, -1.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11786769330501556
Epoch 0, Step 1110: train/loss = 0.6108537316322327, train/raw-loss = 0.5731247663497925, train/logprobs = tensor([[-1.6399, -3.6155],
        [-1.5295, -2.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075457863509655
Epoch 0, Step 1111: train/loss = 0.6764495372772217, train/raw-loss = 0.6299136281013489, train/logprobs = tensor([[-1.0062, -1.6230],
        [-1.0354, -1.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09307180345058441
Epoch 0, Step 1112: train/loss = 0.7386699914932251, train/raw-loss = 0.6493101119995117, train/logprobs = tensor([[-1.3632, -1.6360],
        [-1.6466, -1.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17871984839439392
Epoch 0, Step 1113: train/loss = 0.6887389421463013, train/raw-loss = 0.6364529132843018, train/logprobs = tensor([[-1.1384, -0.8896],
        [-1.3537, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10457219183444977
Epoch 0, Step 1114: train/loss = 0.6770722270011902, train/raw-loss = 0.6286681294441223, train/logprobs = tensor([[-1.0087, -1.4464],
        [-0.8668, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968082919716835
Epoch 0, Step 1115: train/loss = 0.6809250712394714, train/raw-loss = 0.6290916800498962, train/logprobs = tensor([[-0.9074, -1.1451],
        [-1.0641, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10366682708263397
Epoch 0, Step 1116: train/loss = 0.6251158118247986, train/raw-loss = 0.5741462111473083, train/logprobs = tensor([[-1.3347, -2.0953],
        [-1.2746, -1.4071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10193920880556107
Epoch 0, Step 1117: train/loss = 0.7488759756088257, train/raw-loss = 0.6773478984832764, train/logprobs = tensor([[-1.6255, -1.6175],
        [-1.5858, -1.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14305633306503296
Epoch 0, Step 1118: train/loss = 0.6620750427246094, train/raw-loss = 0.6065537929534912, train/logprobs = tensor([[-0.7747, -1.6858],
        [-0.7660, -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104245483875275
Epoch 0, Step 1119: train/loss = 0.6861391067504883, train/raw-loss = 0.6391425728797913, train/logprobs = tensor([[-1.3255, -1.5903],
        [-1.3832, -1.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09399295598268509
Epoch 0, Step 1120: train/loss = 0.7219603061676025, train/raw-loss = 0.6826262474060059, train/logprobs = tensor([[-1.2352, -0.8387],
        [-1.0848, -0.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07866813242435455
Epoch 0, Step 1121: train/loss = 0.6892592906951904, train/raw-loss = 0.6388282775878906, train/logprobs = tensor([[-1.5171, -2.2716],
        [-1.0975, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086208581924438
Epoch 0, Step 1122: train/loss = 0.5749460458755493, train/raw-loss = 0.5160152316093445, train/logprobs = tensor([[-1.4930, -2.4583],
        [-1.7083, -1.6650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1178615540266037
Epoch 0, Step 1123: train/loss = 0.6704365611076355, train/raw-loss = 0.620682954788208, train/logprobs = tensor([[-1.8594, -1.1607],
        [-1.8551, -0.8114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09950720518827438
Epoch 0, Step 1124: train/loss = 0.6511271595954895, train/raw-loss = 0.5891063213348389, train/logprobs = tensor([[-1.4860, -1.5005],
        [-1.7396, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12404157966375351
Epoch 0, Step 1125: train/loss = 0.6624219417572021, train/raw-loss = 0.6209348440170288, train/logprobs = tensor([[-0.5361, -0.5322],
        [-0.8054, -0.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08297427743673325
Epoch 0, Step 1126: train/loss = 0.7040330171585083, train/raw-loss = 0.6272790431976318, train/logprobs = tensor([[-1.9577, -1.3038],
        [-1.9033, -0.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15350791811943054
Epoch 0, Step 1127: train/loss = 0.7370315790176392, train/raw-loss = 0.6885083317756653, train/logprobs = tensor([[-0.8845, -0.7966],
        [-0.8385, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09704641252756119
Epoch 0, Step 1128: train/loss = 0.7704135775566101, train/raw-loss = 0.6926118731498718, train/logprobs = tensor([[-1.8740, -2.1366],
        [-1.6249, -1.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15560348331928253
Epoch 0, Step 1129: train/loss = 0.6804685592651367, train/raw-loss = 0.6142505407333374, train/logprobs = tensor([[-1.2797, -1.6902],
        [-1.3777, -1.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13243600726127625
Epoch 0, Step 1130: train/loss = 0.5547782778739929, train/raw-loss = 0.5086774230003357, train/logprobs = tensor([[-1.5205, -2.3133],
        [-1.6015, -1.2720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09220172464847565
Epoch 0, Step 1131: train/loss = 0.6629860401153564, train/raw-loss = 0.6061869859695435, train/logprobs = tensor([[-1.3560, -2.4687],
        [-1.4077, -2.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1135980561375618
Epoch 0, Step 1132: train/loss = 0.7035819292068481, train/raw-loss = 0.6560982465744019, train/logprobs = tensor([[-1.2053, -1.0661],
        [-1.2566, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949673131108284
Epoch 0, Step 1133: train/loss = 0.7457219958305359, train/raw-loss = 0.6981658339500427, train/logprobs = tensor([[-1.2376, -1.2390],
        [-1.0522, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09511224180459976
Epoch 0, Step 1134: train/loss = 0.5412843227386475, train/raw-loss = 0.48066914081573486, train/logprobs = tensor([[-1.8001, -2.0444],
        [-2.2239, -1.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123025208711624
Epoch 0, Step 1135: train/loss = 0.6381890177726746, train/raw-loss = 0.5907564163208008, train/logprobs = tensor([[-1.6959, -2.4297],
        [-1.9608, -2.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09486521035432816
Epoch 0, Step 1136: train/loss = 0.6206536293029785, train/raw-loss = 0.5759439468383789, train/logprobs = tensor([[-0.5543, -1.3550],
        [-0.6069, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08941926062107086
Epoch 0, Step 1137: train/loss = 0.6622438430786133, train/raw-loss = 0.6036957502365112, train/logprobs = tensor([[-0.8719, -1.6148],
        [-0.7880, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11709632724523544
Epoch 0, Step 1138: train/loss = 0.6857263445854187, train/raw-loss = 0.6364542245864868, train/logprobs = tensor([[-0.7358, -1.0383],
        [-0.7263, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09854428470134735
Epoch 0, Step 1139: train/loss = 0.7041646838188171, train/raw-loss = 0.6490002870559692, train/logprobs = tensor([[-1.5558, -1.9914],
        [-1.3638, -1.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11032866686582565
Epoch 0, Step 1140: train/loss = 0.6452009677886963, train/raw-loss = 0.5915732383728027, train/logprobs = tensor([[-0.6378, -2.4086],
        [-0.6522, -1.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10725562274456024
Epoch 0, Step 1141: train/loss = 0.6251111030578613, train/raw-loss = 0.5615205764770508, train/logprobs = tensor([[-1.0811, -2.0090],
        [-1.2721, -1.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12718093395233154
Epoch 0, Step 1142: train/loss = 0.7897760272026062, train/raw-loss = 0.7059754729270935, train/logprobs = tensor([[-2.1374, -2.1499],
        [-2.2966, -2.3101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16760103404521942
Epoch 0, Step 1143: train/loss = 0.5836846828460693, train/raw-loss = 0.5382531881332397, train/logprobs = tensor([[-0.7321, -1.7814],
        [-0.8061, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09086303412914276
Epoch 0, Step 1144: train/loss = 0.7010031342506409, train/raw-loss = 0.6394950747489929, train/logprobs = tensor([[-2.0237, -1.4058],
        [-2.0292, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12301623076200485
Epoch 0, Step 1145: train/loss = 0.6395456790924072, train/raw-loss = 0.5890079140663147, train/logprobs = tensor([[-0.8817, -1.3859],
        [-0.9781, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10107547044754028
Epoch 0, Step 1146: train/loss = 0.6978124976158142, train/raw-loss = 0.6577666997909546, train/logprobs = tensor([[-1.3033, -1.3438],
        [-1.3890, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08009165525436401
Epoch 0, Step 1147: train/loss = 0.7089618444442749, train/raw-loss = 0.6536486148834229, train/logprobs = tensor([[-0.9393, -0.6601],
        [-1.1129, -0.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062650382518768
Epoch 0, Step 1148: train/loss = 0.7117347717285156, train/raw-loss = 0.6216739416122437, train/logprobs = tensor([[-1.5303, -1.8202],
        [-1.8182, -1.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18012158572673798
Epoch 0, Step 1149: train/loss = 0.6463537216186523, train/raw-loss = 0.6076529622077942, train/logprobs = tensor([[-1.5614, -2.2321],
        [-1.1283, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07740142941474915
Epoch 0, Step 1150: train/loss = 0.6794205904006958, train/raw-loss = 0.6278122663497925, train/logprobs = tensor([[-1.3075, -1.6093],
        [-1.3154, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10321664810180664
Epoch 0, Step 1151: train/loss = 0.7066904306411743, train/raw-loss = 0.6467898488044739, train/logprobs = tensor([[-1.2845, -1.7922],
        [-1.2123, -1.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11980118602514267
Epoch 0, Step 1152: train/loss = 0.7558547258377075, train/raw-loss = 0.6897614002227783, train/logprobs = tensor([[-0.9299, -0.9411],
        [-0.8787, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321866363286972
Epoch 0, Step 1153: train/loss = 0.6867244243621826, train/raw-loss = 0.6363472938537598, train/logprobs = tensor([[-0.5711, -1.0470],
        [-0.6477, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10075423121452332
Epoch 0, Step 1154: train/loss = 0.6276731491088867, train/raw-loss = 0.5843958258628845, train/logprobs = tensor([[-1.1650, -1.3528],
        [-1.1717, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08655454218387604
Epoch 0, Step 1155: train/loss = 0.6734588146209717, train/raw-loss = 0.603601336479187, train/logprobs = tensor([[-1.3887, -1.8032],
        [-1.5557, -1.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13971495628356934
Epoch 0, Step 1156: train/loss = 0.5743796825408936, train/raw-loss = 0.51827073097229, train/logprobs = tensor([[-1.0929, -2.2102],
        [-1.4540, -1.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11221781373023987
Epoch 0, Step 1157: train/loss = 0.7365342378616333, train/raw-loss = 0.6724771857261658, train/logprobs = tensor([[-1.5255, -1.5584],
        [-1.5885, -1.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12811405956745148
Epoch 0, Step 1158: train/loss = 0.6823239326477051, train/raw-loss = 0.6475664377212524, train/logprobs = tensor([[-1.4398, -1.8766],
        [-1.4346, -1.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06951512396335602
Epoch 0, Step 1159: train/loss = 0.6518726348876953, train/raw-loss = 0.6038272380828857, train/logprobs = tensor([[-1.0341, -1.5290],
        [-0.9052, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609076380729675
Epoch 0, Step 1160: train/loss = 0.697791576385498, train/raw-loss = 0.653023362159729, train/logprobs = tensor([[-1.5281, -1.6057],
        [-1.3305, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953654021024704
Epoch 0, Step 1161: train/loss = 0.7137387990951538, train/raw-loss = 0.6743975877761841, train/logprobs = tensor([[-0.6660, -0.8688],
        [-0.6987, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07868234813213348
Epoch 0, Step 1162: train/loss = 0.7097922563552856, train/raw-loss = 0.648983895778656, train/logprobs = tensor([[-1.7473, -1.7684],
        [-1.8137, -1.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12161669135093689
Epoch 0, Step 1163: train/loss = 0.7005099058151245, train/raw-loss = 0.6491522192955017, train/logprobs = tensor([[-1.5184, -1.6672],
        [-1.4529, -1.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271541029214859
Epoch 0, Step 1164: train/loss = 0.6094099879264832, train/raw-loss = 0.5588438510894775, train/logprobs = tensor([[-0.7326, -1.0872],
        [-1.0956, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10113219916820526
Epoch 0, Step 1165: train/loss = 0.6485538482666016, train/raw-loss = 0.5877476334571838, train/logprobs = tensor([[-1.6310, -2.5813],
        [-1.6752, -2.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12161237001419067
Epoch 0, Step 1166: train/loss = 0.6409210562705994, train/raw-loss = 0.5695594549179077, train/logprobs = tensor([[-2.0586, -2.2661],
        [-1.8594, -1.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427232176065445
Epoch 0, Step 1167: train/loss = 0.6958850622177124, train/raw-loss = 0.6477875709533691, train/logprobs = tensor([[-1.2302, -1.0997],
        [-1.4356, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0961950346827507
Epoch 0, Step 1168: train/loss = 0.704153299331665, train/raw-loss = 0.6542040705680847, train/logprobs = tensor([[-1.3932, -1.2524],
        [-1.4325, -1.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09989848732948303
Epoch 0, Step 1169: train/loss = 0.6770296096801758, train/raw-loss = 0.6075136661529541, train/logprobs = tensor([[-1.1312, -1.8964],
        [-1.1609, -1.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13903187215328217
Epoch 0, Step 1170: train/loss = 0.6591531038284302, train/raw-loss = 0.6087607145309448, train/logprobs = tensor([[-1.2869, -1.5221],
        [-1.1885, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078473389148712
Epoch 0, Step 1171: train/loss = 0.5101281404495239, train/raw-loss = 0.4537035822868347, train/logprobs = tensor([[-0.8567, -2.3784],
        [-1.1195, -1.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11284901201725006
Epoch 0, Step 1172: train/loss = 0.678363561630249, train/raw-loss = 0.6417194604873657, train/logprobs = tensor([[-1.0103, -1.8000],
        [-1.0552, -1.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07328812777996063
Epoch 0, Step 1173: train/loss = 0.7137100100517273, train/raw-loss = 0.6775285601615906, train/logprobs = tensor([[-1.3421, -1.3728],
        [-1.1350, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07236298173666
Epoch 0, Step 1174: train/loss = 0.701917290687561, train/raw-loss = 0.6408026218414307, train/logprobs = tensor([[-1.3377, -1.5477],
        [-1.4181, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12222932279109955
Epoch 0, Step 1175: train/loss = 0.6959317922592163, train/raw-loss = 0.6309366226196289, train/logprobs = tensor([[-1.6810, -2.0367],
        [-1.6466, -1.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299903839826584
Epoch 0, Step 1176: train/loss = 0.6815145611763, train/raw-loss = 0.6423107385635376, train/logprobs = tensor([[-1.6789, -1.7633],
        [-1.6523, -1.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840755581855774
Epoch 0, Step 1177: train/loss = 0.7631534337997437, train/raw-loss = 0.6897594332695007, train/logprobs = tensor([[-1.0605, -1.2941],
        [-1.1170, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14678801596164703
Epoch 0, Step 1178: train/loss = 0.7604410648345947, train/raw-loss = 0.701614499092102, train/logprobs = tensor([[-1.2400, -1.3191],
        [-1.2071, -1.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11765323579311371
Epoch 0, Step 1179: train/loss = 0.7025697231292725, train/raw-loss = 0.6496712565422058, train/logprobs = tensor([[-1.3355, -1.7997],
        [-1.4509, -1.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10579701513051987
Epoch 0, Step 1180: train/loss = 0.7546850442886353, train/raw-loss = 0.6809977293014526, train/logprobs = tensor([[-1.4371, -1.1119],
        [-1.4215, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14737489819526672
Epoch 0, Step 1181: train/loss = 0.712490975856781, train/raw-loss = 0.6578811407089233, train/logprobs = tensor([[-1.4844, -1.3527],
        [-1.4081, -1.1191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10921960324048996
Epoch 0, Step 1182: train/loss = 0.604511022567749, train/raw-loss = 0.5429685711860657, train/logprobs = tensor([[-0.6748, -1.4354],
        [-0.8925, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12308486551046371
Epoch 0, Step 1183: train/loss = 0.7242732048034668, train/raw-loss = 0.6727837324142456, train/logprobs = tensor([[-1.9667, -1.5161],
        [-1.5719, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10297892987728119
Epoch 0, Step 1184: train/loss = 0.6026115417480469, train/raw-loss = 0.5553205609321594, train/logprobs = tensor([[-1.6567, -2.8116],
        [-1.5749, -2.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0945819616317749
Epoch 0, Step 1185: train/loss = 0.6720400452613831, train/raw-loss = 0.6255236268043518, train/logprobs = tensor([[-2.0125, -2.3846],
        [-1.8618, -1.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09303278475999832
Epoch 0, Step 1186: train/loss = 0.7153635025024414, train/raw-loss = 0.6671918630599976, train/logprobs = tensor([[-1.2512, -1.2423],
        [-1.2639, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09634334594011307
Epoch 0, Step 1187: train/loss = 0.726372480392456, train/raw-loss = 0.6829382181167603, train/logprobs = tensor([[-1.4980, -1.6517],
        [-1.2329, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08686847984790802
Epoch 0, Step 1188: train/loss = 0.7508780360221863, train/raw-loss = 0.6815848350524902, train/logprobs = tensor([[-1.7791, -2.1952],
        [-1.7796, -2.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385863870382309
Epoch 0, Step 1189: train/loss = 0.6672983169555664, train/raw-loss = 0.6097983121871948, train/logprobs = tensor([[-1.1170, -1.0513],
        [-1.2939, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11500005424022675
Epoch 0, Step 1190: train/loss = 0.678533136844635, train/raw-loss = 0.630192756652832, train/logprobs = tensor([[-0.8612, -1.4868],
        [-0.8872, -1.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0966806411743164
Epoch 0, Step 1191: train/loss = 0.7116944193840027, train/raw-loss = 0.6715757846832275, train/logprobs = tensor([[-0.7545, -0.7641],
        [-0.8692, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08023720979690552
Epoch 0, Step 1192: train/loss = 0.7346153259277344, train/raw-loss = 0.6956542730331421, train/logprobs = tensor([[-1.7503, -1.5495],
        [-1.5861, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07792197167873383
Epoch 0, Step 1193: train/loss = 0.7474339008331299, train/raw-loss = 0.6731790900230408, train/logprobs = tensor([[-1.7844, -1.1483],
        [-1.7834, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14850959181785583
Epoch 0, Step 1194: train/loss = 0.6328805088996887, train/raw-loss = 0.5699947476387024, train/logprobs = tensor([[-1.5014, -1.8447],
        [-1.8906, -1.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12577147781848907
Epoch 0, Step 1195: train/loss = 0.6316385269165039, train/raw-loss = 0.5687359571456909, train/logprobs = tensor([[-1.0284, -1.4139],
        [-1.3680, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258050948381424
Epoch 0, Step 1196: train/loss = 0.7157021164894104, train/raw-loss = 0.6624094843864441, train/logprobs = tensor([[-1.0148, -0.8750],
        [-0.9158, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658524930477142
Epoch 0, Step 1197: train/loss = 0.6530991792678833, train/raw-loss = 0.5931659936904907, train/logprobs = tensor([[-0.8447, -0.9133],
        [-0.9989, -0.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986639350652695
Epoch 0, Step 1198: train/loss = 0.7159578204154968, train/raw-loss = 0.6603623628616333, train/logprobs = tensor([[-1.2398, -1.4839],
        [-1.2202, -1.3166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119097471237183
Epoch 0, Step 1199: train/loss = 0.7070208787918091, train/raw-loss = 0.6666703820228577, train/logprobs = tensor([[-1.3281, -1.7022],
        [-1.4003, -1.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08070103079080582
Epoch 0, Step 1200: train/loss = 0.6411333680152893, train/raw-loss = 0.5841760635375977, train/logprobs = tensor([[-1.1112, -0.8675],
        [-1.5421, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391450464725494
Epoch 0, Step 1201: train/loss = 0.6677705645561218, train/raw-loss = 0.6056880354881287, train/logprobs = tensor([[-1.0572, -1.9910],
        [-1.0973, -1.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12416495382785797
Epoch 0, Step 1202: train/loss = 0.6779211759567261, train/raw-loss = 0.6259250044822693, train/logprobs = tensor([[-1.1770, -2.3562],
        [-1.0353, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039922833442688
Epoch 0, Step 1203: train/loss = 0.6290853023529053, train/raw-loss = 0.5904442071914673, train/logprobs = tensor([[-0.6768, -1.0172],
        [-0.8752, -0.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07728225737810135
Epoch 0, Step 1204: train/loss = 0.7103747725486755, train/raw-loss = 0.6583998203277588, train/logprobs = tensor([[-0.9280, -1.0035],
        [-0.9470, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10394986718893051
Epoch 0, Step 1205: train/loss = 0.6020596623420715, train/raw-loss = 0.5499449372291565, train/logprobs = tensor([[-1.3011, -1.6652],
        [-1.6508, -1.3225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422947257757187
Epoch 0, Step 1206: train/loss = 0.6779567003250122, train/raw-loss = 0.6053637266159058, train/logprobs = tensor([[-1.2742, -1.6841],
        [-1.4380, -1.2759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14518597722053528
Epoch 0, Step 1207: train/loss = 0.7364335060119629, train/raw-loss = 0.6879100799560547, train/logprobs = tensor([[-0.9541, -1.5743],
        [-0.9648, -1.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0970468521118164
Epoch 0, Step 1208: train/loss = 0.6873152256011963, train/raw-loss = 0.6348809599876404, train/logprobs = tensor([[-0.9153, -1.3782],
        [-0.9512, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10486839711666107
Epoch 0, Step 1209: train/loss = 0.6166068911552429, train/raw-loss = 0.5560830235481262, train/logprobs = tensor([[-1.6298, -1.8210],
        [-1.7345, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12104770541191101
Epoch 0, Step 1210: train/loss = 0.6891595125198364, train/raw-loss = 0.6328320503234863, train/logprobs = tensor([[-1.5507, -1.8080],
        [-1.2918, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11265486478805542
Epoch 0, Step 1211: train/loss = 0.6676198840141296, train/raw-loss = 0.6028217077255249, train/logprobs = tensor([[-1.1424, -1.4220],
        [-1.1642, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12959635257720947
Epoch 0, Step 1212: train/loss = 0.5696554780006409, train/raw-loss = 0.5254929065704346, train/logprobs = tensor([[-1.3123, -2.3881],
        [-1.2248, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08832518011331558
Epoch 0, Step 1213: train/loss = 0.7010782957077026, train/raw-loss = 0.6378450989723206, train/logprobs = tensor([[-1.5571, -1.7500],
        [-1.4372, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12646642327308655
Epoch 0, Step 1214: train/loss = 0.5387074947357178, train/raw-loss = 0.49116218090057373, train/logprobs = tensor([[-1.2838, -2.3786],
        [-1.2058, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09509068727493286
Epoch 0, Step 1215: train/loss = 0.6826366186141968, train/raw-loss = 0.6198066473007202, train/logprobs = tensor([[-1.3128, -2.0031],
        [-1.2906, -1.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12565982341766357
Epoch 0, Step 1216: train/loss = 0.6678470969200134, train/raw-loss = 0.6188905835151672, train/logprobs = tensor([[-1.0012, -1.2076],
        [-1.0588, -0.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09791312366724014
Epoch 0, Step 1217: train/loss = 0.7350306510925293, train/raw-loss = 0.6903011798858643, train/logprobs = tensor([[-1.4204, -1.3595],
        [-1.2366, -1.1241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894589051604271
Epoch 0, Step 1218: train/loss = 0.6175609230995178, train/raw-loss = 0.5653471350669861, train/logprobs = tensor([[-1.0502, -1.7539],
        [-0.9760, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10442763566970825
Epoch 0, Step 1219: train/loss = 0.601364016532898, train/raw-loss = 0.5450242757797241, train/logprobs = tensor([[-1.2824, -2.3618],
        [-1.3932, -1.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11267948895692825
Epoch 0, Step 1220: train/loss = 0.6025221943855286, train/raw-loss = 0.5345094799995422, train/logprobs = tensor([[-1.4967, -2.2681],
        [-1.3997, -1.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13602538406848907
Epoch 0, Step 1221: train/loss = 0.7312471270561218, train/raw-loss = 0.69010329246521, train/logprobs = tensor([[-0.5025, -0.4563],
        [-0.5358, -0.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08228769898414612
Epoch 0, Step 1222: train/loss = 0.713848352432251, train/raw-loss = 0.660785436630249, train/logprobs = tensor([[-1.0341, -1.1855],
        [-0.9881, -0.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10612595826387405
Epoch 0, Step 1223: train/loss = 0.5534812808036804, train/raw-loss = 0.483875572681427, train/logprobs = tensor([[-1.2916, -2.4189],
        [-1.5433, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13921135663986206
Epoch 0, Step 1224: train/loss = 0.654427170753479, train/raw-loss = 0.6041591167449951, train/logprobs = tensor([[-0.7968, -1.3763],
        [-0.6692, -0.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10053607821464539
Epoch 0, Step 1225: train/loss = 0.5880404114723206, train/raw-loss = 0.5431863069534302, train/logprobs = tensor([[-1.1376, -2.1421],
        [-1.1353, -1.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897083505988121
Epoch 0, Step 1226: train/loss = 0.7116591930389404, train/raw-loss = 0.6700338125228882, train/logprobs = tensor([[-1.2670, -0.8534],
        [-1.1532, -0.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0832507535815239
Epoch 0, Step 1227: train/loss = 0.6856058239936829, train/raw-loss = 0.6245938539505005, train/logprobs = tensor([[-1.0368, -1.5083],
        [-1.1017, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12202402204275131
Epoch 0, Step 1228: train/loss = 0.7035404443740845, train/raw-loss = 0.6611908674240112, train/logprobs = tensor([[-1.4490, -1.7808],
        [-1.5839, -1.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08469921350479126
Epoch 0, Step 1229: train/loss = 0.7131578922271729, train/raw-loss = 0.6723977327346802, train/logprobs = tensor([[-1.4581, -1.6134],
        [-1.4699, -1.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152014017105103
Epoch 0, Step 1230: train/loss = 0.632502555847168, train/raw-loss = 0.5588852763175964, train/logprobs = tensor([[-1.0643, -2.0200],
        [-1.2638, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14723455905914307
Epoch 0, Step 1231: train/loss = 0.6652669310569763, train/raw-loss = 0.6015766859054565, train/logprobs = tensor([[-1.0884, -1.2956],
        [-1.3027, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12738056480884552
Epoch 0, Step 1232: train/loss = 0.6389456987380981, train/raw-loss = 0.5869319438934326, train/logprobs = tensor([[-0.5890, -0.9624],
        [-0.7135, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10402753949165344
Epoch 0, Step 1233: train/loss = 0.6920126080513, train/raw-loss = 0.6466419696807861, train/logprobs = tensor([[-0.9979, -1.1463],
        [-1.0492, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09074123203754425
Epoch 0, Step 1234: train/loss = 0.7493423819541931, train/raw-loss = 0.6932111978530884, train/logprobs = tensor([[-0.9362, -0.8917],
        [-0.9969, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11226245015859604
Epoch 0, Step 1235: train/loss = 0.6563780307769775, train/raw-loss = 0.586674153804779, train/logprobs = tensor([[-1.4195, -1.8668],
        [-1.5387, -1.5045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940779864788055
Epoch 0, Step 1236: train/loss = 0.6513349413871765, train/raw-loss = 0.5975877642631531, train/logprobs = tensor([[-1.3143, -1.9805],
        [-1.2311, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10749433934688568
Epoch 0, Step 1237: train/loss = 0.753440797328949, train/raw-loss = 0.7032645344734192, train/logprobs = tensor([[-2.9615, -3.0359],
        [-3.0100, -3.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10035247355699539
Epoch 0, Step 1238: train/loss = 0.6132543683052063, train/raw-loss = 0.5715516805648804, train/logprobs = tensor([[-1.1577, -1.9515],
        [-1.0754, -1.2683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08340533077716827
Epoch 0, Step 1239: train/loss = 0.5514431595802307, train/raw-loss = 0.5051568746566772, train/logprobs = tensor([[-1.6441, -2.0220],
        [-2.1184, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0925726443529129
Epoch 0, Step 1240: train/loss = 0.6873166561126709, train/raw-loss = 0.6327295899391174, train/logprobs = tensor([[-1.5907, -1.9177],
        [-1.4615, -1.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091742143034935
Epoch 0, Step 1241: train/loss = 0.5890389680862427, train/raw-loss = 0.5281984806060791, train/logprobs = tensor([[-1.0304, -1.5610],
        [-1.5438, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168089300394058
Epoch 0, Step 1242: train/loss = 0.6634703278541565, train/raw-loss = 0.5973496437072754, train/logprobs = tensor([[-0.9188, -2.3573],
        [-1.1368, -2.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13224130868911743
Epoch 0, Step 1243: train/loss = 0.5602346658706665, train/raw-loss = 0.4915521442890167, train/logprobs = tensor([[-0.9581, -2.4270],
        [-1.2383, -1.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13736513257026672
Epoch 0, Step 1244: train/loss = 0.7165557146072388, train/raw-loss = 0.6688993573188782, train/logprobs = tensor([[-1.0623, -1.2702],
        [-1.1628, -1.2670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09531266987323761
Epoch 0, Step 1245: train/loss = 0.7641656398773193, train/raw-loss = 0.7070086002349854, train/logprobs = tensor([[-1.2992, -1.1888],
        [-1.1952, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11431415379047394
Epoch 0, Step 1246: train/loss = 0.5691648721694946, train/raw-loss = 0.5231547355651855, train/logprobs = tensor([[-0.7713, -1.8667],
        [-0.8723, -1.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09202024340629578
Epoch 0, Step 1247: train/loss = 0.7307205200195312, train/raw-loss = 0.667039155960083, train/logprobs = tensor([[-1.9116, -1.4778],
        [-1.7492, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273626834154129
Epoch 0, Step 1248: train/loss = 0.5970631837844849, train/raw-loss = 0.546450138092041, train/logprobs = tensor([[-1.1423, -1.6154],
        [-1.1986, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012260913848877
Epoch 0, Step 1249: train/loss = 0.6039282083511353, train/raw-loss = 0.539250373840332, train/logprobs = tensor([[-1.4559, -1.7966],
        [-1.5864, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12935562431812286
Epoch 0, Step 1250: train/loss = 0.6166488528251648, train/raw-loss = 0.5682881474494934, train/logprobs = tensor([[-1.7934, -3.3780],
        [-1.9417, -2.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09672136604785919
Epoch 0, Step 1251: train/loss = 0.6123857498168945, train/raw-loss = 0.5518731474876404, train/logprobs = tensor([[-1.4877, -2.0720],
        [-1.3626, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12102523446083069
Epoch 0, Step 1252: train/loss = 0.8095759749412537, train/raw-loss = 0.7474018335342407, train/logprobs = tensor([[-1.0576, -0.8936],
        [-0.6815, -0.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12434829771518707
Epoch 0, Step 1253: train/loss = 0.5666097402572632, train/raw-loss = 0.5027117729187012, train/logprobs = tensor([[-1.1885, -2.5896],
        [-1.3381, -1.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12779609858989716
Epoch 0, Step 1254: train/loss = 0.651278555393219, train/raw-loss = 0.5975232720375061, train/logprobs = tensor([[-1.1388, -2.2549],
        [-1.1677, -1.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10751070082187653
Epoch 0, Step 1255: train/loss = 0.7277525663375854, train/raw-loss = 0.6750773787498474, train/logprobs = tensor([[-1.9958, -2.1709],
        [-1.6623, -1.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10535040497779846
Epoch 0, Step 1256: train/loss = 0.7595343589782715, train/raw-loss = 0.6952781677246094, train/logprobs = tensor([[-1.4613, -0.9862],
        [-1.3507, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12851224839687347
Epoch 0, Step 1257: train/loss = 0.7867785692214966, train/raw-loss = 0.726657509803772, train/logprobs = tensor([[-1.4390, -1.2872],
        [-1.4015, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12024201452732086
Epoch 0, Step 1258: train/loss = 0.709403932094574, train/raw-loss = 0.6488404870033264, train/logprobs = tensor([[-1.6442, -1.4193],
        [-1.3676, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12112684547901154
Epoch 0, Step 1259: train/loss = 0.7614046931266785, train/raw-loss = 0.6952471733093262, train/logprobs = tensor([[-1.8682, -1.3508],
        [-1.9041, -1.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13231518864631653
Epoch 0, Step 1260: train/loss = 0.6969093084335327, train/raw-loss = 0.6278281211853027, train/logprobs = tensor([[-1.5583, -1.9978],
        [-1.5119, -1.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13816238939762115
Epoch 0, Step 1261: train/loss = 0.5682937502861023, train/raw-loss = 0.529977023601532, train/logprobs = tensor([[-0.9545, -1.9578],
        [-1.0351, -1.2535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07663340866565704
Epoch 0, Step 1262: train/loss = 0.672980546951294, train/raw-loss = 0.6427993774414062, train/logprobs = tensor([[-1.5624, -1.8068],
        [-1.2806, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06036224961280823
Epoch 0, Step 1263: train/loss = 0.7126100063323975, train/raw-loss = 0.6546487808227539, train/logprobs = tensor([[-1.0091, -1.9046],
        [-0.8557, -1.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1159224733710289
Epoch 0, Step 1264: train/loss = 0.6633033752441406, train/raw-loss = 0.6131879091262817, train/logprobs = tensor([[-0.9535, -1.5330],
        [-1.1426, -1.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10023096948862076
Epoch 0, Step 1265: train/loss = 0.7161422967910767, train/raw-loss = 0.6631950736045837, train/logprobs = tensor([[-1.3751, -1.4061],
        [-1.3162, -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10589441657066345
Epoch 0, Step 1266: train/loss = 0.6098422408103943, train/raw-loss = 0.571212887763977, train/logprobs = tensor([[-0.9891, -1.3271],
        [-1.0126, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07725867629051208
Epoch 0, Step 1267: train/loss = 0.7372756600379944, train/raw-loss = 0.669594407081604, train/logprobs = tensor([[-1.6124, -1.6112],
        [-1.5752, -1.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1353624314069748
Epoch 0, Step 1268: train/loss = 0.723143458366394, train/raw-loss = 0.6832997798919678, train/logprobs = tensor([[-0.5096, -0.6755],
        [-0.4795, -0.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07968734949827194
Epoch 0, Step 1269: train/loss = 0.6972661018371582, train/raw-loss = 0.6229250431060791, train/logprobs = tensor([[-1.3296, -1.4563],
        [-1.3594, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14868202805519104
Epoch 0, Step 1270: train/loss = 0.4622304439544678, train/raw-loss = 0.3990840017795563, train/logprobs = tensor([[-1.0054, -2.8037],
        [-1.0398, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12629280984401703
Epoch 0, Step 1271: train/loss = 0.7225589752197266, train/raw-loss = 0.6610500812530518, train/logprobs = tensor([[-1.6718, -2.1379],
        [-1.4699, -1.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1230178028345108
Epoch 0, Step 1272: train/loss = 0.6206239461898804, train/raw-loss = 0.5737215876579285, train/logprobs = tensor([[-0.9140, -2.2532],
        [-0.7613, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.093804731965065
Epoch 0, Step 1273: train/loss = 0.6655671000480652, train/raw-loss = 0.6031174063682556, train/logprobs = tensor([[-1.3609, -2.1336],
        [-1.1112, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489943206310272
Epoch 0, Step 1274: train/loss = 0.5919919610023499, train/raw-loss = 0.5161033868789673, train/logprobs = tensor([[-1.7535, -1.7138],
        [-1.8793, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1517772078514099
Epoch 0, Step 1275: train/loss = 0.6164000630378723, train/raw-loss = 0.5711476802825928, train/logprobs = tensor([[-1.4731, -2.1602],
        [-1.4430, -1.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09050466120243073
Epoch 0, Step 1276: train/loss = 0.6821088194847107, train/raw-loss = 0.6216248869895935, train/logprobs = tensor([[-0.9068, -1.5910],
        [-1.3166, -1.6230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12096785008907318
Epoch 0, Step 1277: train/loss = 0.6043541431427002, train/raw-loss = 0.5303716659545898, train/logprobs = tensor([[-1.1191, -1.9616],
        [-1.4983, -1.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14796487987041473
Epoch 0, Step 1278: train/loss = 0.7278827428817749, train/raw-loss = 0.6742631196975708, train/logprobs = tensor([[-1.9154, -1.7026],
        [-1.7072, -1.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10723931342363358
Epoch 0, Step 1279: train/loss = 0.6626330614089966, train/raw-loss = 0.5929949283599854, train/logprobs = tensor([[-1.4277, -1.9273],
        [-1.5981, -1.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13927620649337769
Epoch 0, Step 1280: train/loss = 0.7682247161865234, train/raw-loss = 0.7322652339935303, train/logprobs = tensor([[-1.5859, -1.3993],
        [-0.9583, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07191906124353409
Epoch 0, Step 1281: train/loss = 0.6159601211547852, train/raw-loss = 0.5661432147026062, train/logprobs = tensor([[-0.8820, -2.2571],
        [-0.7824, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996338352560997
Epoch 0, Step 1282: train/loss = 0.7120193243026733, train/raw-loss = 0.6572186350822449, train/logprobs = tensor([[-1.1404, -1.6773],
        [-0.9379, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10960130393505096
Epoch 0, Step 1283: train/loss = 0.6926248073577881, train/raw-loss = 0.6511791944503784, train/logprobs = tensor([[-1.1154, -1.2199],
        [-1.2682, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08289118856191635
Epoch 0, Step 1284: train/loss = 0.9224029183387756, train/raw-loss = 0.8740074634552002, train/logprobs = tensor([[-2.1386, -1.6521],
        [-1.5115, -1.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679093956947327
Epoch 0, Step 1285: train/loss = 0.6995781064033508, train/raw-loss = 0.6557788848876953, train/logprobs = tensor([[-0.8306, -0.8701],
        [-0.7688, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.087598517537117
Epoch 0, Step 1286: train/loss = 0.7434918284416199, train/raw-loss = 0.7083675861358643, train/logprobs = tensor([[-1.1716, -0.8530],
        [-0.9666, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07024841010570526
Epoch 0, Step 1287: train/loss = 0.7214713096618652, train/raw-loss = 0.6696417331695557, train/logprobs = tensor([[-0.8247, -0.8063],
        [-0.8778, -0.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1036592349410057
Epoch 0, Step 1288: train/loss = 0.7298242449760437, train/raw-loss = 0.6942312717437744, train/logprobs = tensor([[-0.4484, -0.3521],
        [-0.5175, -0.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07118590176105499
Epoch 0, Step 1289: train/loss = 0.6798877120018005, train/raw-loss = 0.6298242211341858, train/logprobs = tensor([[-1.7104, -1.3099],
        [-1.7452, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012701153755188
Epoch 0, Step 1290: train/loss = 0.7226210832595825, train/raw-loss = 0.6335709691047668, train/logprobs = tensor([[-1.9942, -1.8323],
        [-2.1454, -1.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17810021340847015
Epoch 0, Step 1291: train/loss = 0.7561505436897278, train/raw-loss = 0.6901054978370667, train/logprobs = tensor([[-2.0003, -2.2561],
        [-1.7310, -1.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13209010660648346
Epoch 0, Step 1292: train/loss = 0.6428800225257874, train/raw-loss = 0.5979422330856323, train/logprobs = tensor([[-1.1862, -1.8559],
        [-0.8634, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987564593553543
Epoch 0, Step 1293: train/loss = 0.7359038591384888, train/raw-loss = 0.6730003356933594, train/logprobs = tensor([[-1.3040, -1.2172],
        [-0.9766, -0.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258070468902588
Epoch 0, Step 1294: train/loss = 0.6659525632858276, train/raw-loss = 0.607719361782074, train/logprobs = tensor([[-1.4158, -1.2537],
        [-1.5745, -1.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11646641790866852
Epoch 0, Step 1295: train/loss = 0.5789080858230591, train/raw-loss = 0.5352970361709595, train/logprobs = tensor([[-0.8400, -1.4765],
        [-0.9322, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08722224831581116
Epoch 0, Step 1296: train/loss = 0.600779116153717, train/raw-loss = 0.5486446619033813, train/logprobs = tensor([[-0.9115, -1.2889],
        [-1.1537, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10426878929138184
Epoch 0, Step 1297: train/loss = 0.6229601502418518, train/raw-loss = 0.5737424492835999, train/logprobs = tensor([[-1.0364, -1.9683],
        [-1.0494, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0984354317188263
Epoch 0, Step 1298: train/loss = 0.6930962204933167, train/raw-loss = 0.6347076296806335, train/logprobs = tensor([[-1.8440, -2.4716],
        [-1.4909, -1.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677727103233337
Epoch 0, Step 1299: train/loss = 0.537121593952179, train/raw-loss = 0.4717447757720947, train/logprobs = tensor([[-1.0969, -2.3545],
        [-1.1275, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13075363636016846
Epoch 0, Step 1300: train/loss = 0.5365911722183228, train/raw-loss = 0.48016485571861267, train/logprobs = tensor([[-1.1783, -1.7338],
        [-1.4471, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11285259574651718
Epoch 0, Step 1301: train/loss = 0.6814136505126953, train/raw-loss = 0.6290494799613953, train/logprobs = tensor([[-1.4702, -2.5646],
        [-1.1195, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047283411026001
Epoch 0, Step 1302: train/loss = 0.5758983492851257, train/raw-loss = 0.5265606045722961, train/logprobs = tensor([[-1.0370, -1.7604],
        [-1.0878, -0.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09867552667856216
Epoch 0, Step 1303: train/loss = 0.7000054121017456, train/raw-loss = 0.6355774402618408, train/logprobs = tensor([[-1.6703, -1.9710],
        [-1.5584, -1.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12885582447052002
Epoch 0, Step 1304: train/loss = 0.6502648591995239, train/raw-loss = 0.5977258682250977, train/logprobs = tensor([[-0.6227, -1.1700],
        [-0.8325, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10507814586162567
Epoch 0, Step 1305: train/loss = 0.7238450050354004, train/raw-loss = 0.6575284004211426, train/logprobs = tensor([[-1.9181, -2.1959],
        [-1.8772, -1.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326332688331604
Epoch 0, Step 1306: train/loss = 0.6957665681838989, train/raw-loss = 0.647671639919281, train/logprobs = tensor([[-1.1866, -1.4606],
        [-1.2049, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09618990868330002
Epoch 0, Step 1307: train/loss = 0.7215012907981873, train/raw-loss = 0.6556556820869446, train/logprobs = tensor([[-1.2505, -1.0086],
        [-1.4199, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316911280155182
Epoch 0, Step 1308: train/loss = 0.708006739616394, train/raw-loss = 0.6534937620162964, train/logprobs = tensor([[-0.8567, -1.0033],
        [-0.7721, -0.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902593284845352
Epoch 0, Step 1309: train/loss = 0.6054816246032715, train/raw-loss = 0.5629485249519348, train/logprobs = tensor([[-1.0752, -1.4999],
        [-1.1511, -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08506617695093155
Epoch 0, Step 1310: train/loss = 0.5978207588195801, train/raw-loss = 0.5542723536491394, train/logprobs = tensor([[-0.5780, -1.2923],
        [-0.7804, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0870969295501709
Epoch 0, Step 1311: train/loss = 0.756110429763794, train/raw-loss = 0.7036998271942139, train/logprobs = tensor([[-2.1371, -1.4566],
        [-1.8238, -1.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10482127964496613
Epoch 0, Step 1312: train/loss = 0.744782567024231, train/raw-loss = 0.6921855211257935, train/logprobs = tensor([[-1.5552, -1.5438],
        [-1.8512, -1.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519415140151978
Epoch 0, Step 1313: train/loss = 0.7013984322547913, train/raw-loss = 0.649659276008606, train/logprobs = tensor([[-2.5913, -1.8681],
        [-2.6935, -1.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10347837954759598
Epoch 0, Step 1314: train/loss = 0.7240073680877686, train/raw-loss = 0.6543681621551514, train/logprobs = tensor([[-0.9314, -1.2117],
        [-1.1467, -1.2259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13927841186523438
Epoch 0, Step 1315: train/loss = 0.63358074426651, train/raw-loss = 0.5828402042388916, train/logprobs = tensor([[-0.9063, -1.5095],
        [-0.8486, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10148122161626816
Epoch 0, Step 1316: train/loss = 0.7336323261260986, train/raw-loss = 0.6775087714195251, train/logprobs = tensor([[-1.6248, -1.5140],
        [-1.4281, -1.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11224715411663055
Epoch 0, Step 1317: train/loss = 0.5959364175796509, train/raw-loss = 0.542630136013031, train/logprobs = tensor([[-1.4658, -1.2468],
        [-1.7886, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10661260038614273
Epoch 0, Step 1318: train/loss = 0.6177286505699158, train/raw-loss = 0.5677107572555542, train/logprobs = tensor([[-0.8808, -1.7982],
        [-1.1697, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10003577172756195
Epoch 0, Step 1319: train/loss = 0.6650660634040833, train/raw-loss = 0.6035358905792236, train/logprobs = tensor([[-1.5058, -2.1366],
        [-1.2604, -1.4191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306038290262222
Epoch 0, Step 1320: train/loss = 0.7072875499725342, train/raw-loss = 0.6568549871444702, train/logprobs = tensor([[-0.8273, -1.6296],
        [-0.6931, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086530447006226
Epoch 0, Step 1321: train/loss = 0.6374284029006958, train/raw-loss = 0.5796942710876465, train/logprobs = tensor([[-0.6650, -1.6495],
        [-0.8096, -1.2289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11546823382377625
Epoch 0, Step 1322: train/loss = 0.6656376123428345, train/raw-loss = 0.6134663224220276, train/logprobs = tensor([[-1.8408, -2.0163],
        [-1.6573, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434254258871078
Epoch 0, Step 1323: train/loss = 0.7656388282775879, train/raw-loss = 0.7142782807350159, train/logprobs = tensor([[-0.7508, -0.7189],
        [-0.6117, -0.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10272099822759628
Epoch 0, Step 1324: train/loss = 0.7321152091026306, train/raw-loss = 0.668602466583252, train/logprobs = tensor([[-0.9570, -1.0788],
        [-1.1040, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12702547013759613
Epoch 0, Step 1325: train/loss = 0.6780015230178833, train/raw-loss = 0.6099200248718262, train/logprobs = tensor([[-1.6393, -2.1461],
        [-1.6404, -1.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361628919839859
Epoch 0, Step 1326: train/loss = 0.742194414138794, train/raw-loss = 0.6893004179000854, train/logprobs = tensor([[-1.8659, -1.8931],
        [-2.0189, -1.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10578788816928864
Epoch 0, Step 1327: train/loss = 0.6807284951210022, train/raw-loss = 0.614324152469635, train/logprobs = tensor([[-1.5585, -1.6434],
        [-1.5890, -1.2777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13280877470970154
Epoch 0, Step 1328: train/loss = 0.6261128187179565, train/raw-loss = 0.5739924907684326, train/logprobs = tensor([[-1.0725, -2.2209],
        [-0.8794, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10424064844846725
Epoch 0, Step 1329: train/loss = 0.702384352684021, train/raw-loss = 0.6381515264511108, train/logprobs = tensor([[-1.1435, -1.6706],
        [-1.1936, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12846557796001434
Epoch 0, Step 1330: train/loss = 0.723949670791626, train/raw-loss = 0.6630380153656006, train/logprobs = tensor([[-1.0916, -1.0890],
        [-1.1055, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12182337045669556
Epoch 0, Step 1331: train/loss = 0.7764456868171692, train/raw-loss = 0.714139997959137, train/logprobs = tensor([[-1.9715, -1.5910],
        [-1.8562, -1.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12461145222187042
Epoch 0, Step 1332: train/loss = 0.49972328543663025, train/raw-loss = 0.4376979470252991, train/logprobs = tensor([[-0.8166, -2.5225],
        [-0.8308, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12405067682266235
Epoch 0, Step 1333: train/loss = 0.7491517663002014, train/raw-loss = 0.6991477608680725, train/logprobs = tensor([[-0.9609, -0.9856],
        [-0.7649, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10000797361135483
Epoch 0, Step 1334: train/loss = 0.5741488337516785, train/raw-loss = 0.5208657383918762, train/logprobs = tensor([[-1.2089, -2.0559],
        [-1.2418, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656624287366867
Epoch 0, Step 1335: train/loss = 0.6453112363815308, train/raw-loss = 0.5939428806304932, train/logprobs = tensor([[-1.5244, -1.0390],
        [-1.7625, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273672640323639
Epoch 0, Step 1336: train/loss = 0.5801188945770264, train/raw-loss = 0.5227568745613098, train/logprobs = tensor([[-1.8077, -2.0653],
        [-1.6886, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11472412198781967
Epoch 0, Step 1337: train/loss = 0.7617983818054199, train/raw-loss = 0.7208847999572754, train/logprobs = tensor([[-1.5421, -1.2020],
        [-1.4548, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818270593881607
Epoch 0, Step 1338: train/loss = 0.6310819983482361, train/raw-loss = 0.5739941596984863, train/logprobs = tensor([[-1.6757, -2.1025],
        [-1.6902, -1.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11417566239833832
Epoch 0, Step 1339: train/loss = 0.75075763463974, train/raw-loss = 0.696629524230957, train/logprobs = tensor([[-1.5804, -1.6433],
        [-1.4278, -1.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825614631175995
Epoch 0, Step 1340: train/loss = 0.8084031343460083, train/raw-loss = 0.7532233595848083, train/logprobs = tensor([[-1.5201, -1.3157],
        [-1.1051, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11035951972007751
Epoch 0, Step 1341: train/loss = 0.7916696071624756, train/raw-loss = 0.7433215379714966, train/logprobs = tensor([[-1.0149, -2.2600],
        [-1.1038, -2.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09669610112905502
Epoch 0, Step 1342: train/loss = 0.7460185289382935, train/raw-loss = 0.6792794466018677, train/logprobs = tensor([[-1.8899, -1.6004],
        [-1.8365, -1.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13347816467285156
Epoch 0, Step 1343: train/loss = 0.6283105611801147, train/raw-loss = 0.5800891518592834, train/logprobs = tensor([[-1.0656, -1.3222],
        [-1.2165, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09644284844398499
Epoch 0, Step 1344: train/loss = 0.6262246370315552, train/raw-loss = 0.5785653591156006, train/logprobs = tensor([[-0.8986, -1.5554],
        [-0.8414, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09531866014003754
Epoch 0, Step 1345: train/loss = 0.6700991988182068, train/raw-loss = 0.6258706450462341, train/logprobs = tensor([[-1.6446, -2.0418],
        [-1.6297, -1.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08845710754394531
Epoch 0, Step 1346: train/loss = 0.6262263655662537, train/raw-loss = 0.5596454739570618, train/logprobs = tensor([[-1.5003, -1.6701],
        [-1.8772, -1.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13316167891025543
Epoch 0, Step 1347: train/loss = 0.6363787055015564, train/raw-loss = 0.5913857817649841, train/logprobs = tensor([[-1.3232, -1.9527],
        [-1.2788, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0899859294295311
Epoch 0, Step 1348: train/loss = 0.5756621360778809, train/raw-loss = 0.49506813287734985, train/logprobs = tensor([[-1.5927, -2.2856],
        [-1.9580, -1.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16118793189525604
Epoch 0, Step 1349: train/loss = 0.6670541167259216, train/raw-loss = 0.6184407472610474, train/logprobs = tensor([[-0.9025, -1.7893],
        [-1.1094, -1.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09722673892974854
Epoch 0, Step 1350: train/loss = 0.6551697254180908, train/raw-loss = 0.5993329286575317, train/logprobs = tensor([[-0.8272, -1.0825],
        [-1.1955, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11167345941066742
Epoch 0, Step 1351: train/loss = 0.6511681079864502, train/raw-loss = 0.5919828414916992, train/logprobs = tensor([[-1.1183, -1.4990],
        [-1.1350, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11837054789066315
Epoch 0, Step 1352: train/loss = 0.619571328163147, train/raw-loss = 0.5646135807037354, train/logprobs = tensor([[-1.1081, -1.8862],
        [-1.1446, -1.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10991549491882324
Epoch 0, Step 1353: train/loss = 0.7916552424430847, train/raw-loss = 0.7366235256195068, train/logprobs = tensor([[-1.9667, -2.1783],
        [-1.5061, -1.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11006343364715576
Epoch 0, Step 1354: train/loss = 0.7212633490562439, train/raw-loss = 0.6556313037872314, train/logprobs = tensor([[-1.4284, -2.2420],
        [-1.3477, -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312640756368637
Epoch 0, Step 1355: train/loss = 0.7539606094360352, train/raw-loss = 0.692020058631897, train/logprobs = tensor([[-1.6336, -1.1636],
        [-1.5393, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12388117611408234
Epoch 0, Step 1356: train/loss = 0.6321183443069458, train/raw-loss = 0.5873770713806152, train/logprobs = tensor([[-1.5537, -3.0005],
        [-1.5815, -1.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08948244899511337
Epoch 0, Step 1357: train/loss = 0.6506814360618591, train/raw-loss = 0.6021351218223572, train/logprobs = tensor([[-0.9935, -1.2233],
        [-1.1177, -0.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09709261357784271
Epoch 0, Step 1358: train/loss = 0.6625517010688782, train/raw-loss = 0.6074053049087524, train/logprobs = tensor([[-1.1405, -1.5690],
        [-1.0263, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11029288172721863
Epoch 0, Step 1359: train/loss = 0.808632493019104, train/raw-loss = 0.7523659467697144, train/logprobs = tensor([[-1.8350, -1.4199],
        [-1.3669, -1.0581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11253316700458527
Epoch 0, Step 1360: train/loss = 0.6874920725822449, train/raw-loss = 0.6249373555183411, train/logprobs = tensor([[-1.9661, -2.2487],
        [-1.5967, -1.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510937452316284
Epoch 0, Step 1361: train/loss = 0.6863973736763, train/raw-loss = 0.6308078765869141, train/logprobs = tensor([[-1.7548, -1.4409],
        [-1.7671, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11117887496948242
Epoch 0, Step 1362: train/loss = 0.689474880695343, train/raw-loss = 0.6442145705223083, train/logprobs = tensor([[-1.5913, -2.2340],
        [-1.0504, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09052067995071411
Epoch 0, Step 1363: train/loss = 0.5980195999145508, train/raw-loss = 0.5476288795471191, train/logprobs = tensor([[-1.1608, -2.5586],
        [-1.1449, -1.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078159719705582
Epoch 0, Step 1364: train/loss = 0.6647458076477051, train/raw-loss = 0.5963358879089355, train/logprobs = tensor([[-1.7844, -1.8649],
        [-1.8339, -1.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13681966066360474
Epoch 0, Step 1365: train/loss = 0.5937076807022095, train/raw-loss = 0.5319848656654358, train/logprobs = tensor([[-1.1625, -1.6708],
        [-1.3228, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12344564497470856
Epoch 0, Step 1366: train/loss = 0.7401494979858398, train/raw-loss = 0.6982194781303406, train/logprobs = tensor([[-1.2796, -1.1285],
        [-1.0080, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08386009931564331
Epoch 0, Step 1367: train/loss = 0.6699872016906738, train/raw-loss = 0.620193600654602, train/logprobs = tensor([[-0.9261, -1.0143],
        [-1.0903, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09958727657794952
Epoch 0, Step 1368: train/loss = 0.6028326749801636, train/raw-loss = 0.5513333082199097, train/logprobs = tensor([[-1.0639, -2.3432],
        [-1.0118, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10299865156412125
Epoch 0, Step 1369: train/loss = 0.7759596705436707, train/raw-loss = 0.718370258808136, train/logprobs = tensor([[-1.3463, -1.4079],
        [-1.1586, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11517883837223053
Epoch 0, Step 1370: train/loss = 0.678987443447113, train/raw-loss = 0.6255719065666199, train/logprobs = tensor([[-0.8004, -1.6829],
        [-0.7761, -1.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10683103650808334
Epoch 0, Step 1371: train/loss = 0.7066183686256409, train/raw-loss = 0.6551429033279419, train/logprobs = tensor([[-0.7840, -0.8908],
        [-0.6606, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295084863901138
Epoch 0, Step 1372: train/loss = 0.6740551590919495, train/raw-loss = 0.6335912942886353, train/logprobs = tensor([[-0.9812, -0.8204],
        [-0.9894, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092770725488663
Epoch 0, Step 1373: train/loss = 0.6499372720718384, train/raw-loss = 0.5995934009552002, train/logprobs = tensor([[-1.1545, -1.4524],
        [-1.2545, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068760067224503
Epoch 0, Step 1374: train/loss = 0.6213917136192322, train/raw-loss = 0.5716995000839233, train/logprobs = tensor([[-0.9274, -1.6900],
        [-0.8432, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09938438981771469
Epoch 0, Step 1375: train/loss = 0.5981684923171997, train/raw-loss = 0.5527755618095398, train/logprobs = tensor([[-1.8733, -3.8034],
        [-1.4544, -2.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09078599512577057
Epoch 0, Step 1376: train/loss = 0.6990025043487549, train/raw-loss = 0.6225134134292603, train/logprobs = tensor([[-1.6638, -1.1509],
        [-1.8520, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1529781073331833
Epoch 0, Step 1377: train/loss = 0.6618986129760742, train/raw-loss = 0.5966801643371582, train/logprobs = tensor([[-1.6837, -2.4888],
        [-1.4238, -1.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13043685257434845
Epoch 0, Step 1378: train/loss = 0.6850923895835876, train/raw-loss = 0.624254584312439, train/logprobs = tensor([[-1.5531, -1.3574],
        [-1.4813, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12167558819055557
Epoch 0, Step 1379: train/loss = 0.6604750156402588, train/raw-loss = 0.5963885188102722, train/logprobs = tensor([[-1.1736, -1.6028],
        [-1.3783, -1.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12817300856113434
Epoch 0, Step 1380: train/loss = 0.5437599420547485, train/raw-loss = 0.4886188209056854, train/logprobs = tensor([[-1.2632, -2.3509],
        [-1.3581, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028222739696503
Epoch 0, Step 1381: train/loss = 0.6580353379249573, train/raw-loss = 0.5993685722351074, train/logprobs = tensor([[-1.5691, -3.1772],
        [-1.2755, -1.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1173335462808609
Epoch 0, Step 1382: train/loss = 0.611505389213562, train/raw-loss = 0.539685070514679, train/logprobs = tensor([[-1.2134, -1.9587],
        [-1.4629, -1.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14364062249660492
Epoch 0, Step 1383: train/loss = 0.6112779974937439, train/raw-loss = 0.5509089231491089, train/logprobs = tensor([[-0.8708, -1.7105],
        [-0.8127, -0.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12073814868927002
Epoch 0, Step 1384: train/loss = 0.7122412919998169, train/raw-loss = 0.6714200973510742, train/logprobs = tensor([[-2.2963, -1.8295],
        [-1.8762, -1.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08164235204458237
Epoch 0, Step 1385: train/loss = 0.688536524772644, train/raw-loss = 0.6369099617004395, train/logprobs = tensor([[-0.5749, -0.8083],
        [-0.6965, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10325315594673157
Epoch 0, Step 1386: train/loss = 0.6641769409179688, train/raw-loss = 0.5921669006347656, train/logprobs = tensor([[-1.6183, -2.2096],
        [-1.7434, -1.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14402003586292267
Epoch 0, Step 1387: train/loss = 0.6777522563934326, train/raw-loss = 0.612326979637146, train/logprobs = tensor([[-1.3386, -2.0431],
        [-1.5305, -1.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13085055351257324
Epoch 0, Step 1388: train/loss = 0.6210588216781616, train/raw-loss = 0.5844385623931885, train/logprobs = tensor([[-0.8470, -3.1541],
        [-0.8045, -2.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07324063032865524
Epoch 0, Step 1389: train/loss = 0.7348479628562927, train/raw-loss = 0.6810447573661804, train/logprobs = tensor([[-1.0268, -1.4615],
        [-0.8661, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10760629177093506
Epoch 0, Step 1390: train/loss = 0.6210854053497314, train/raw-loss = 0.5674869418144226, train/logprobs = tensor([[-1.0086, -1.7809],
        [-1.1651, -1.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10719697177410126
Epoch 0, Step 1391: train/loss = 0.6258759498596191, train/raw-loss = 0.5701794028282166, train/logprobs = tensor([[-0.8293, -1.1585],
        [-1.0941, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139299720525742
Epoch 0, Step 1392: train/loss = 0.5886318683624268, train/raw-loss = 0.5367242097854614, train/logprobs = tensor([[-0.9444, -1.9606],
        [-0.7458, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10381527990102768
Epoch 0, Step 1393: train/loss = 0.6724188327789307, train/raw-loss = 0.6085186004638672, train/logprobs = tensor([[-1.0705, -1.7252],
        [-1.3177, -1.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12780046463012695
Epoch 0, Step 1394: train/loss = 0.6694278120994568, train/raw-loss = 0.626549482345581, train/logprobs = tensor([[-1.1375, -1.2789],
        [-0.9365, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08575665950775146
Epoch 0, Step 1395: train/loss = 0.7292574048042297, train/raw-loss = 0.6746706366539001, train/logprobs = tensor([[-1.4213, -1.6668],
        [-1.2110, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10917343944311142
Epoch 0, Step 1396: train/loss = 0.6228747367858887, train/raw-loss = 0.5751966238021851, train/logprobs = tensor([[-0.8207, -1.2840],
        [-1.1148, -1.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09535615891218185
Epoch 0, Step 1397: train/loss = 0.6735129356384277, train/raw-loss = 0.6189512014389038, train/logprobs = tensor([[-1.1590, -1.6767],
        [-1.2450, -1.3950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10912343859672546
Epoch 0, Step 1398: train/loss = 0.6890060305595398, train/raw-loss = 0.6518334746360779, train/logprobs = tensor([[-0.6538, -0.8286],
        [-0.6407, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743451714515686
Epoch 0, Step 1399: train/loss = 0.7285299301147461, train/raw-loss = 0.6726449131965637, train/logprobs = tensor([[-1.5751, -1.3867],
        [-1.2599, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11177000403404236
Epoch 0, Step 1400: train/loss = 0.7836790680885315, train/raw-loss = 0.7003461122512817, train/logprobs = tensor([[-1.4236, -1.4136],
        [-1.4982, -1.5020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666659116744995
Epoch 0, Step 1401: train/loss = 0.6906749606132507, train/raw-loss = 0.6333187818527222, train/logprobs = tensor([[-1.6433, -2.1351],
        [-2.0510, -2.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11471231281757355
Epoch 0, Step 1402: train/loss = 0.7702839374542236, train/raw-loss = 0.7135952711105347, train/logprobs = tensor([[-0.9546, -0.9353],
        [-0.6803, -0.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11337744444608688
Epoch 0, Step 1403: train/loss = 0.7398210763931274, train/raw-loss = 0.6862665414810181, train/logprobs = tensor([[-0.8946, -1.3566],
        [-0.8342, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1071089655160904
Epoch 0, Step 1404: train/loss = 0.6528313755989075, train/raw-loss = 0.599794864654541, train/logprobs = tensor([[-0.7334, -1.3669],
        [-0.8119, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607299953699112
Epoch 0, Step 1405: train/loss = 0.6141343116760254, train/raw-loss = 0.5571702718734741, train/logprobs = tensor([[-1.6159, -1.3493],
        [-1.9619, -0.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11392806470394135
Epoch 0, Step 1406: train/loss = 0.6404215097427368, train/raw-loss = 0.5840065479278564, train/logprobs = tensor([[-1.2287, -1.9487],
        [-1.3576, -1.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282997578382492
Epoch 0, Step 1407: train/loss = 0.7213490009307861, train/raw-loss = 0.6669089198112488, train/logprobs = tensor([[-1.3034, -1.5356],
        [-1.1982, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088801920413971
Epoch 0, Step 1408: train/loss = 0.7341827154159546, train/raw-loss = 0.6831467747688293, train/logprobs = tensor([[-1.3690, -1.2743],
        [-1.2956, -1.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10207204520702362
Epoch 0, Step 1409: train/loss = 0.7659439444541931, train/raw-loss = 0.730056643486023, train/logprobs = tensor([[-1.1187, -1.1386],
        [-1.7549, -1.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07177455723285675
Epoch 0, Step 1410: train/loss = 0.673508882522583, train/raw-loss = 0.6255654096603394, train/logprobs = tensor([[-0.6468, -0.7622],
        [-0.9065, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09588689357042313
Epoch 0, Step 1411: train/loss = 0.6010756492614746, train/raw-loss = 0.5560959577560425, train/logprobs = tensor([[-1.1367, -2.3508],
        [-1.1141, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995938301086426
Epoch 0, Step 1412: train/loss = 0.6699420213699341, train/raw-loss = 0.6147100329399109, train/logprobs = tensor([[-1.5407, -2.1088],
        [-1.2203, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11046406626701355
Epoch 0, Step 1413: train/loss = 0.5789108872413635, train/raw-loss = 0.5309444665908813, train/logprobs = tensor([[-1.0693, -1.7868],
        [-1.0634, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09593281149864197
Epoch 0, Step 1414: train/loss = 0.6516015529632568, train/raw-loss = 0.6116904616355896, train/logprobs = tensor([[-1.1153, -1.4836],
        [-1.2062, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07982222735881805
Epoch 0, Step 1415: train/loss = 0.6835035085678101, train/raw-loss = 0.6080965995788574, train/logprobs = tensor([[-2.0847, -2.3706],
        [-2.0013, -1.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15081387758255005
Epoch 0, Step 1416: train/loss = 0.5097254514694214, train/raw-loss = 0.4569112956523895, train/logprobs = tensor([[-1.3315, -2.0620],
        [-1.5631, -1.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10562826693058014
Epoch 0, Step 1417: train/loss = 0.551237165927887, train/raw-loss = 0.4917554259300232, train/logprobs = tensor([[-1.1689, -2.7497],
        [-1.1169, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11896350979804993
Epoch 0, Step 1418: train/loss = 0.6430737972259521, train/raw-loss = 0.5933175086975098, train/logprobs = tensor([[-1.1197, -0.6661],
        [-1.3401, -0.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09951265156269073
Epoch 0, Step 1419: train/loss = 0.6669778823852539, train/raw-loss = 0.6120182275772095, train/logprobs = tensor([[-1.4829, -1.2491],
        [-1.7626, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10991928726434708
Epoch 0, Step 1420: train/loss = 0.6960252523422241, train/raw-loss = 0.6343746185302734, train/logprobs = tensor([[-1.5730, -1.7019],
        [-1.6285, -1.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12330131232738495
Epoch 0, Step 1421: train/loss = 0.7670121192932129, train/raw-loss = 0.7166579961776733, train/logprobs = tensor([[-1.9158, -1.7171],
        [-1.5035, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10070814192295074
Epoch 0, Step 1422: train/loss = 0.507304310798645, train/raw-loss = 0.4589061141014099, train/logprobs = tensor([[-1.2724, -2.2312],
        [-1.3831, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679638594388962
Epoch 0, Step 1423: train/loss = 0.6700592637062073, train/raw-loss = 0.6179205179214478, train/logprobs = tensor([[-0.6124, -0.9941],
        [-0.9414, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10427743196487427
Epoch 0, Step 1424: train/loss = 0.6767004728317261, train/raw-loss = 0.6247494220733643, train/logprobs = tensor([[-1.0541, -1.3873],
        [-1.2418, -1.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10390225052833557
Epoch 0, Step 1425: train/loss = 0.6081230640411377, train/raw-loss = 0.5590057373046875, train/logprobs = tensor([[-1.5683, -2.0961],
        [-1.5850, -1.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09823448210954666
Epoch 0, Step 1426: train/loss = 0.6122299432754517, train/raw-loss = 0.5479998588562012, train/logprobs = tensor([[-1.6349, -2.1426],
        [-1.5662, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12846018373966217
Epoch 0, Step 1427: train/loss = 0.6530851125717163, train/raw-loss = 0.5894282460212708, train/logprobs = tensor([[-1.2019, -1.6962],
        [-1.0938, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12731367349624634
Epoch 0, Step 1428: train/loss = 0.6555078029632568, train/raw-loss = 0.6075823307037354, train/logprobs = tensor([[-1.1366, -1.6894],
        [-0.8870, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09585079550743103
Epoch 0, Step 1429: train/loss = 0.6851515769958496, train/raw-loss = 0.6457923650741577, train/logprobs = tensor([[-0.9801, -1.5293],
        [-0.7995, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07871834933757782
Epoch 0, Step 1430: train/loss = 0.6601817607879639, train/raw-loss = 0.6015801429748535, train/logprobs = tensor([[-1.3677, -1.9970],
        [-1.3133, -1.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11720319837331772
Epoch 0, Step 1431: train/loss = 0.6837866306304932, train/raw-loss = 0.6149787306785583, train/logprobs = tensor([[-1.9564, -1.9267],
        [-2.1494, -1.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376158446073532
Epoch 0, Step 1432: train/loss = 0.4865650236606598, train/raw-loss = 0.43048685789108276, train/logprobs = tensor([[-1.3441, -2.8911],
        [-1.6406, -1.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11215630173683167
Epoch 0, Step 1433: train/loss = 0.5821447968482971, train/raw-loss = 0.5172700881958008, train/logprobs = tensor([[-1.1025, -1.8002],
        [-1.3093, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12974943220615387
Epoch 0, Step 1434: train/loss = 0.6405795812606812, train/raw-loss = 0.5758330821990967, train/logprobs = tensor([[-1.1958, -1.6876],
        [-1.3174, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12949290871620178
Epoch 0, Step 1435: train/loss = 0.6181927919387817, train/raw-loss = 0.5684186816215515, train/logprobs = tensor([[-1.4660, -1.6004],
        [-1.5746, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954831749200821
Epoch 0, Step 1436: train/loss = 0.6336619853973389, train/raw-loss = 0.5777631998062134, train/logprobs = tensor([[-1.5075, -2.9553],
        [-1.3563, -1.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11179769784212112
Epoch 0, Step 1437: train/loss = 0.6472569108009338, train/raw-loss = 0.5783022046089172, train/logprobs = tensor([[-1.3932, -1.8640],
        [-1.7859, -1.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13790953159332275
Epoch 0, Step 1438: train/loss = 0.709382176399231, train/raw-loss = 0.6527249813079834, train/logprobs = tensor([[-1.9197, -2.6743],
        [-1.7976, -2.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11331436038017273
Epoch 0, Step 1439: train/loss = 0.8159818649291992, train/raw-loss = 0.7572159767150879, train/logprobs = tensor([[-0.9541, -0.9701],
        [-1.3150, -1.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11753183603286743
Epoch 0, Step 1440: train/loss = 0.7178471088409424, train/raw-loss = 0.6505579948425293, train/logprobs = tensor([[-1.4679, -1.7776],
        [-1.6537, -1.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13457812368869781
Epoch 0, Step 1441: train/loss = 0.6863874197006226, train/raw-loss = 0.6433007717132568, train/logprobs = tensor([[-0.9939, -1.0662],
        [-1.0611, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08617336302995682
Epoch 0, Step 1442: train/loss = 0.6304622292518616, train/raw-loss = 0.576916515827179, train/logprobs = tensor([[-0.9984, -1.2099],
        [-1.1196, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10709135979413986
Epoch 0, Step 1443: train/loss = 0.7008145451545715, train/raw-loss = 0.6634825468063354, train/logprobs = tensor([[-1.5960, -1.8078],
        [-1.2059, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07466395944356918
Epoch 0, Step 1444: train/loss = 0.7333768606185913, train/raw-loss = 0.668978750705719, train/logprobs = tensor([[-1.5983, -1.8145],
        [-1.5098, -1.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12879621982574463
Epoch 0, Step 1445: train/loss = 0.6663912534713745, train/raw-loss = 0.6199542880058289, train/logprobs = tensor([[-1.4720, -1.1275],
        [-1.4321, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09287384152412415
Epoch 0, Step 1446: train/loss = 0.6395770311355591, train/raw-loss = 0.5960517525672913, train/logprobs = tensor([[-0.7699, -1.0448],
        [-0.8052, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08705060184001923
Epoch 0, Step 1447: train/loss = 0.651824414730072, train/raw-loss = 0.5898367166519165, train/logprobs = tensor([[-1.4258, -2.0417],
        [-1.7003, -1.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12397526949644089
Epoch 0, Step 1448: train/loss = 0.6388415098190308, train/raw-loss = 0.5869276523590088, train/logprobs = tensor([[-1.0105, -1.0048],
        [-1.2752, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382778197526932
Epoch 0, Step 1449: train/loss = 0.5478466153144836, train/raw-loss = 0.5010615587234497, train/logprobs = tensor([[-0.6529, -1.5052],
        [-0.9189, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09357015043497086
Epoch 0, Step 1450: train/loss = 0.6624919176101685, train/raw-loss = 0.6134649515151978, train/logprobs = tensor([[-0.9640, -1.0165],
        [-1.0483, -0.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09805391728878021
Epoch 0, Step 1451: train/loss = 0.6931581497192383, train/raw-loss = 0.6532292366027832, train/logprobs = tensor([[-0.8733, -1.2102],
        [-0.6193, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985781878232956
Epoch 0, Step 1452: train/loss = 0.6825828552246094, train/raw-loss = 0.6409146785736084, train/logprobs = tensor([[-0.9572, -1.5116],
        [-0.8651, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08333642035722733
Epoch 0, Step 1453: train/loss = 0.6552395820617676, train/raw-loss = 0.6065919399261475, train/logprobs = tensor([[-1.1274, -1.6532],
        [-1.1124, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0972953736782074
Epoch 0, Step 1454: train/loss = 0.6346138715744019, train/raw-loss = 0.5792806148529053, train/logprobs = tensor([[-1.1883, -1.4355],
        [-1.3874, -1.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066648364067078
Epoch 0, Step 1455: train/loss = 0.6407380700111389, train/raw-loss = 0.5940120220184326, train/logprobs = tensor([[-0.9014, -1.2259],
        [-0.9845, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09345223009586334
Epoch 0, Step 1456: train/loss = 0.6196204423904419, train/raw-loss = 0.5586493611335754, train/logprobs = tensor([[-1.2956, -2.0557],
        [-1.3847, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194231152534485
Epoch 0, Step 1457: train/loss = 0.6818128228187561, train/raw-loss = 0.6320271492004395, train/logprobs = tensor([[-1.1133, -1.8668],
        [-0.8333, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957141429185867
Epoch 0, Step 1458: train/loss = 0.646356463432312, train/raw-loss = 0.5964568853378296, train/logprobs = tensor([[-1.2074, -1.8535],
        [-1.3065, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09979908168315887
Epoch 0, Step 1459: train/loss = 0.6246739625930786, train/raw-loss = 0.5726467967033386, train/logprobs = tensor([[-1.1851, -2.2459],
        [-1.2538, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10405442118644714
Epoch 0, Step 1460: train/loss = 0.7068028450012207, train/raw-loss = 0.6674472093582153, train/logprobs = tensor([[-1.1217, -1.2927],
        [-0.7623, -0.7080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0787111148238182
Epoch 0, Step 1461: train/loss = 0.7240982055664062, train/raw-loss = 0.6760926246643066, train/logprobs = tensor([[-1.1440, -1.3417],
        [-1.0088, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0960114449262619
Epoch 0, Step 1462: train/loss = 0.709864616394043, train/raw-loss = 0.6611456871032715, train/logprobs = tensor([[-1.5090, -1.7406],
        [-1.1969, -1.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09743773937225342
Epoch 0, Step 1463: train/loss = 0.5214850306510925, train/raw-loss = 0.4677107334136963, train/logprobs = tensor([[-0.8957, -3.0601],
        [-1.1755, -1.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10754858702421188
Epoch 0, Step 1464: train/loss = 0.6335140466690063, train/raw-loss = 0.5878369808197021, train/logprobs = tensor([[-0.6127, -1.0408],
        [-0.6822, -0.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09135420620441437
Epoch 0, Step 1465: train/loss = 0.639991819858551, train/raw-loss = 0.5856994390487671, train/logprobs = tensor([[-1.6684, -1.8600],
        [-1.6512, -1.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10858476161956787
Epoch 0, Step 1466: train/loss = 0.5831899046897888, train/raw-loss = 0.5288543701171875, train/logprobs = tensor([[-1.6837, -2.5082],
        [-1.8812, -1.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10867109894752502
Epoch 0, Step 1467: train/loss = 0.7240903973579407, train/raw-loss = 0.670937180519104, train/logprobs = tensor([[-1.8052, -1.6976],
        [-1.7778, -1.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630643367767334
Epoch 0, Step 1468: train/loss = 0.6456999778747559, train/raw-loss = 0.5875920653343201, train/logprobs = tensor([[-1.5223, -2.1760],
        [-1.8086, -1.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11621583998203278
Epoch 0, Step 1469: train/loss = 0.6787697076797485, train/raw-loss = 0.6420749425888062, train/logprobs = tensor([[-0.8210, -1.2349],
        [-0.6592, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0733894407749176
Epoch 0, Step 1470: train/loss = 0.6304779648780823, train/raw-loss = 0.5681334733963013, train/logprobs = tensor([[-1.3242, -1.7658],
        [-1.3584, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468905746936798
Epoch 0, Step 1471: train/loss = 0.7377619743347168, train/raw-loss = 0.7028013467788696, train/logprobs = tensor([[-0.7409, -0.6102],
        [-0.5333, -0.4191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06992124021053314
Epoch 0, Step 1472: train/loss = 0.6277338862419128, train/raw-loss = 0.580453634262085, train/logprobs = tensor([[-0.8612, -1.3107],
        [-0.9796, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09456052631139755
Epoch 0, Step 1473: train/loss = 0.6183843612670898, train/raw-loss = 0.5616297125816345, train/logprobs = tensor([[-1.5389, -2.0296],
        [-1.9425, -1.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11350931227207184
Epoch 0, Step 1474: train/loss = 0.5885272026062012, train/raw-loss = 0.5386370420455933, train/logprobs = tensor([[-1.2474, -1.9178],
        [-1.6053, -1.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09978041052818298
Epoch 0, Step 1475: train/loss = 0.5922410488128662, train/raw-loss = 0.5207874774932861, train/logprobs = tensor([[-0.8526, -1.6407],
        [-1.3915, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1429072618484497
Epoch 0, Step 1476: train/loss = 0.6486377716064453, train/raw-loss = 0.6116377115249634, train/logprobs = tensor([[-1.1390, -1.5220],
        [-0.9873, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07400011271238327
Epoch 0, Step 1477: train/loss = 0.6564448475837708, train/raw-loss = 0.5899211764335632, train/logprobs = tensor([[-1.1106, -1.7271],
        [-1.3298, -1.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13304737210273743
Epoch 0, Step 1478: train/loss = 0.697137713432312, train/raw-loss = 0.6609988808631897, train/logprobs = tensor([[-1.0246, -0.9669],
        [-1.0389, -0.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07227779179811478
Epoch 0, Step 1479: train/loss = 0.6565122604370117, train/raw-loss = 0.6011397242546082, train/logprobs = tensor([[-1.4112, -1.2620],
        [-1.6374, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11074504256248474
Epoch 0, Step 1480: train/loss = 0.6628828048706055, train/raw-loss = 0.6271892189979553, train/logprobs = tensor([[-0.7987, -0.8797],
        [-0.7836, -0.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07138720899820328
Epoch 0, Step 1481: train/loss = 0.709930956363678, train/raw-loss = 0.6517201662063599, train/logprobs = tensor([[-1.3373, -0.6858],
        [-1.6200, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11642153561115265
Epoch 0, Step 1482: train/loss = 0.6087179183959961, train/raw-loss = 0.5564094185829163, train/logprobs = tensor([[-0.9528, -1.8944],
        [-1.0029, -1.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10461695492267609
Epoch 0, Step 1483: train/loss = 0.6798166036605835, train/raw-loss = 0.6327493190765381, train/logprobs = tensor([[-1.3193, -2.0669],
        [-1.1356, -1.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09413456916809082
Epoch 0, Step 1484: train/loss = 0.5891521573066711, train/raw-loss = 0.5400925874710083, train/logprobs = tensor([[-0.9466, -0.9339],
        [-1.3902, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09811915457248688
Epoch 0, Step 1485: train/loss = 0.6622491478919983, train/raw-loss = 0.6035346984863281, train/logprobs = tensor([[-0.8179, -1.1589],
        [-1.0449, -0.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11742892861366272
Epoch 0, Step 1486: train/loss = 0.690737783908844, train/raw-loss = 0.6362300515174866, train/logprobs = tensor([[-1.5097, -1.8005],
        [-1.4016, -1.3339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10901548713445663
Epoch 0, Step 1487: train/loss = 0.5926576852798462, train/raw-loss = 0.542790949344635, train/logprobs = tensor([[-0.7286, -1.7186],
        [-0.9033, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09973344951868057
Epoch 0, Step 1488: train/loss = 0.5489722490310669, train/raw-loss = 0.49374163150787354, train/logprobs = tensor([[-1.6025, -2.9821],
        [-1.7075, -2.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11046113073825836
Epoch 0, Step 1489: train/loss = 0.6469295024871826, train/raw-loss = 0.6027050614356995, train/logprobs = tensor([[-1.6176, -2.4915],
        [-1.1679, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08844888210296631
Epoch 0, Step 1490: train/loss = 0.6769127249717712, train/raw-loss = 0.6245750188827515, train/logprobs = tensor([[-2.1598, -3.0217],
        [-2.2943, -2.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10467548668384552
Epoch 0, Step 1491: train/loss = 0.6459524035453796, train/raw-loss = 0.6030313968658447, train/logprobs = tensor([[-1.0137, -1.2321],
        [-1.1052, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08584193140268326
Epoch 0, Step 1492: train/loss = 0.6577743291854858, train/raw-loss = 0.6089535355567932, train/logprobs = tensor([[-0.6999, -0.9566],
        [-0.8243, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09764154255390167
Epoch 0, Step 1493: train/loss = 0.5911059379577637, train/raw-loss = 0.5370438098907471, train/logprobs = tensor([[-0.8891, -1.3895],
        [-1.1959, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10812432318925858
Epoch 0, Step 1494: train/loss = 0.6977698802947998, train/raw-loss = 0.6554087400436401, train/logprobs = tensor([[-0.9789, -1.2317],
        [-0.8827, -0.8769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472228050231934
Epoch 0, Step 1495: train/loss = 0.6207584738731384, train/raw-loss = 0.5679072141647339, train/logprobs = tensor([[-0.9923, -1.4817],
        [-1.0266, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10570250451564789
Epoch 0, Step 1496: train/loss = 0.6820164918899536, train/raw-loss = 0.6396951675415039, train/logprobs = tensor([[-1.5165, -1.1959],
        [-1.3820, -0.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08464266359806061
Epoch 0, Step 1497: train/loss = 0.5212615728378296, train/raw-loss = 0.4705832600593567, train/logprobs = tensor([[-0.7171, -2.4227],
        [-0.8311, -0.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013566330075264
Epoch 0, Step 1498: train/loss = 0.706277072429657, train/raw-loss = 0.6455947756767273, train/logprobs = tensor([[-1.1805, -1.4205],
        [-1.2907, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12136461585760117
Epoch 0, Step 1499: train/loss = 0.6925254464149475, train/raw-loss = 0.6425455808639526, train/logprobs = tensor([[-1.6206, -2.1241],
        [-1.3810, -1.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995973110198975
eval/loss: 0.6496603488922119
Epoch 0, Step 1500: train/loss = 0.6714891791343689, train/raw-loss = 0.609553337097168, train/logprobs = tensor([[-1.3924, -1.4924],
        [-1.5523, -1.2028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12387171387672424
Epoch 0, Step 1501: train/loss = 0.5580573081970215, train/raw-loss = 0.5043373703956604, train/logprobs = tensor([[-0.8400, -1.4185],
        [-1.2628, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.107439786195755
Epoch 0, Step 1502: train/loss = 0.6125906705856323, train/raw-loss = 0.5585826635360718, train/logprobs = tensor([[-1.2970, -2.1468],
        [-1.6455, -1.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10801593214273453
Epoch 0, Step 1503: train/loss = 0.6450903415679932, train/raw-loss = 0.6018601655960083, train/logprobs = tensor([[-1.1254, -1.2913],
        [-0.9059, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646029233932495
Epoch 0, Step 1504: train/loss = 0.6729403138160706, train/raw-loss = 0.6279752254486084, train/logprobs = tensor([[-1.1082, -1.4204],
        [-1.1810, -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08993014693260193
Epoch 0, Step 1505: train/loss = 0.670363187789917, train/raw-loss = 0.6144552826881409, train/logprobs = tensor([[-1.0339, -1.0957],
        [-1.1372, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1118159294128418
Epoch 0, Step 1506: train/loss = 0.5991948843002319, train/raw-loss = 0.5525015592575073, train/logprobs = tensor([[-1.1816, -1.2772],
        [-1.4140, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09338675439357758
Epoch 0, Step 1507: train/loss = 0.637793779373169, train/raw-loss = 0.579948902130127, train/logprobs = tensor([[-0.7432, -1.1535],
        [-1.0532, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11568980664014816
Epoch 0, Step 1508: train/loss = 0.7397953271865845, train/raw-loss = 0.6917787790298462, train/logprobs = tensor([[-1.3312, -1.6108],
        [-1.2956, -1.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09603317081928253
Epoch 0, Step 1509: train/loss = 0.48529720306396484, train/raw-loss = 0.42317327857017517, train/logprobs = tensor([[-1.7790, -2.9928],
        [-2.3306, -1.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12424787878990173
Epoch 0, Step 1510: train/loss = 0.6742606163024902, train/raw-loss = 0.626102089881897, train/logprobs = tensor([[-0.9437, -1.2812],
        [-0.7801, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09631702303886414
Epoch 0, Step 1511: train/loss = 0.6502169370651245, train/raw-loss = 0.6134688854217529, train/logprobs = tensor([[-0.7582, -1.2147],
        [-0.6930, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07349619269371033
Epoch 0, Step 1512: train/loss = 0.6059502959251404, train/raw-loss = 0.5476186275482178, train/logprobs = tensor([[-0.8086, -1.8055],
        [-1.0356, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11666328459978104
Epoch 0, Step 1513: train/loss = 0.5709316730499268, train/raw-loss = 0.5135257840156555, train/logprobs = tensor([[-1.3354, -1.7938],
        [-1.4683, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11481180787086487
Epoch 0, Step 1514: train/loss = 0.6500298976898193, train/raw-loss = 0.6029492020606995, train/logprobs = tensor([[-1.2312, -1.5118],
        [-1.4422, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416142851114273
Epoch 0, Step 1515: train/loss = 0.7983188033103943, train/raw-loss = 0.7650743722915649, train/logprobs = tensor([[-0.8864, -1.9672],
        [-1.0960, -2.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06648888438940048
Epoch 0, Step 1516: train/loss = 0.633245050907135, train/raw-loss = 0.5822866559028625, train/logprobs = tensor([[-1.2297, -1.8073],
        [-1.1735, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191680490970612
Epoch 0, Step 1517: train/loss = 0.6796573400497437, train/raw-loss = 0.6376726031303406, train/logprobs = tensor([[-0.9807, -1.1861],
        [-0.9133, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08396949619054794
Epoch 0, Step 1518: train/loss = 0.6888779401779175, train/raw-loss = 0.6216685771942139, train/logprobs = tensor([[-1.5799, -1.9023],
        [-1.6579, -1.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13441863656044006
Epoch 0, Step 1519: train/loss = 0.6730095744132996, train/raw-loss = 0.6261779069900513, train/logprobs = tensor([[-1.1280, -1.2150],
        [-1.0080, -0.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366333484649658
Epoch 0, Step 1520: train/loss = 0.5889995098114014, train/raw-loss = 0.5354979634284973, train/logprobs = tensor([[-1.5881, -1.8000],
        [-2.0282, -1.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700307786464691
Epoch 0, Step 1521: train/loss = 0.7469656467437744, train/raw-loss = 0.7016240358352661, train/logprobs = tensor([[-1.8043, -1.4538],
        [-1.5774, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09068301320075989
Epoch 0, Step 1522: train/loss = 0.6606066823005676, train/raw-loss = 0.5992717742919922, train/logprobs = tensor([[-2.1021, -2.3732],
        [-2.0936, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1226697713136673
Epoch 0, Step 1523: train/loss = 0.7556887865066528, train/raw-loss = 0.7023158669471741, train/logprobs = tensor([[-1.4228, -1.1574],
        [-1.5059, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1067458838224411
Epoch 0, Step 1524: train/loss = 0.5977999567985535, train/raw-loss = 0.5460362434387207, train/logprobs = tensor([[-1.0917, -1.4559],
        [-1.4219, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035274937748909
Epoch 0, Step 1525: train/loss = 0.7467947602272034, train/raw-loss = 0.6824183464050293, train/logprobs = tensor([[-1.7852, -1.2821],
        [-1.7299, -1.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12875276803970337
Epoch 0, Step 1526: train/loss = 0.680728554725647, train/raw-loss = 0.6288013458251953, train/logprobs = tensor([[-1.8068, -1.7607],
        [-1.7230, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385437309741974
Epoch 0, Step 1527: train/loss = 0.6659101843833923, train/raw-loss = 0.6103869676589966, train/logprobs = tensor([[-1.4535, -0.9233],
        [-1.6198, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104648560285568
Epoch 0, Step 1528: train/loss = 0.6772294044494629, train/raw-loss = 0.6207340359687805, train/logprobs = tensor([[-1.2889, -1.2770],
        [-1.2817, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11299088597297668
Epoch 0, Step 1529: train/loss = 0.7096565961837769, train/raw-loss = 0.6554124355316162, train/logprobs = tensor([[-1.0103, -1.3217],
        [-1.1071, -1.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10848818719387054
Epoch 0, Step 1530: train/loss = 0.6474385261535645, train/raw-loss = 0.5888211727142334, train/logprobs = tensor([[-1.8512, -2.0040],
        [-1.8866, -1.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11723476648330688
Epoch 0, Step 1531: train/loss = 0.6752115488052368, train/raw-loss = 0.6261211037635803, train/logprobs = tensor([[-1.2874, -1.6078],
        [-1.3675, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09818097949028015
Epoch 0, Step 1532: train/loss = 0.6324574947357178, train/raw-loss = 0.5714278221130371, train/logprobs = tensor([[-1.5609, -1.6965],
        [-1.8671, -1.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1220594048500061
Epoch 0, Step 1533: train/loss = 0.6821863651275635, train/raw-loss = 0.6307708621025085, train/logprobs = tensor([[-0.6471, -0.9991],
        [-0.8986, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10283108055591583
Epoch 0, Step 1534: train/loss = 0.6317093968391418, train/raw-loss = 0.5771082043647766, train/logprobs = tensor([[-1.0999, -1.5209],
        [-1.0584, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10920247435569763
Epoch 0, Step 1535: train/loss = 0.6381890177726746, train/raw-loss = 0.5761620402336121, train/logprobs = tensor([[-0.8460, -1.6780],
        [-0.7419, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12405387312173843
Epoch 0, Step 1536: train/loss = 0.7101247310638428, train/raw-loss = 0.6677051186561584, train/logprobs = tensor([[-0.9216, -0.9515],
        [-0.9672, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483923226594925
Epoch 0, Step 1537: train/loss = 0.6202479004859924, train/raw-loss = 0.5707963705062866, train/logprobs = tensor([[-1.1130, -1.9209],
        [-1.2086, -1.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09890308976173401
Epoch 0, Step 1538: train/loss = 0.7718446850776672, train/raw-loss = 0.7343735694885254, train/logprobs = tensor([[-1.4483, -1.2269],
        [-1.2173, -1.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07494217902421951
Epoch 0, Step 1539: train/loss = 0.640539288520813, train/raw-loss = 0.5942441821098328, train/logprobs = tensor([[-1.3780, -1.6201],
        [-1.4215, -1.2065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09259021282196045
Epoch 0, Step 1540: train/loss = 0.5813432931900024, train/raw-loss = 0.5362557768821716, train/logprobs = tensor([[-0.6985, -1.5027],
        [-0.7599, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09017501771450043
Epoch 0, Step 1541: train/loss = 0.6073976755142212, train/raw-loss = 0.5525776147842407, train/logprobs = tensor([[-0.9442, -1.6523],
        [-1.0847, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10964007675647736
Epoch 0, Step 1542: train/loss = 0.5985314846038818, train/raw-loss = 0.5480474233627319, train/logprobs = tensor([[-1.0453, -1.4648],
        [-1.5256, -1.1669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10096800327301025
Epoch 0, Step 1543: train/loss = 0.6628249883651733, train/raw-loss = 0.6007107496261597, train/logprobs = tensor([[-1.4588, -1.4717],
        [-1.7331, -1.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12422849237918854
Epoch 0, Step 1544: train/loss = 0.6039553880691528, train/raw-loss = 0.5475873947143555, train/logprobs = tensor([[-1.6608, -2.1238],
        [-1.6947, -1.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11273600161075592
Epoch 0, Step 1545: train/loss = 0.6607665419578552, train/raw-loss = 0.6157705783843994, train/logprobs = tensor([[-0.8871, -1.9343],
        [-0.8423, -1.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08999187499284744
Epoch 0, Step 1546: train/loss = 0.7366761565208435, train/raw-loss = 0.6863371729850769, train/logprobs = tensor([[-1.8697, -2.3927],
        [-1.5965, -2.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10067787021398544
Epoch 0, Step 1547: train/loss = 0.7260385751724243, train/raw-loss = 0.6870335340499878, train/logprobs = tensor([[-0.9405, -0.9482],
        [-0.9971, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0780099481344223
Epoch 0, Step 1548: train/loss = 0.5608032941818237, train/raw-loss = 0.5030902028083801, train/logprobs = tensor([[-0.9598, -1.8040],
        [-1.2011, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1154262125492096
Epoch 0, Step 1549: train/loss = 0.7849874496459961, train/raw-loss = 0.7441821694374084, train/logprobs = tensor([[-2.1746, -2.3131],
        [-1.4362, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08161073923110962
Epoch 0, Step 1550: train/loss = 0.566424548625946, train/raw-loss = 0.5153858065605164, train/logprobs = tensor([[-1.3737, -3.4472],
        [-0.9561, -0.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10207753628492355
Epoch 0, Step 1551: train/loss = 0.6289424300193787, train/raw-loss = 0.5858609676361084, train/logprobs = tensor([[-1.3775, -2.1064],
        [-0.9205, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861630067229271
Epoch 0, Step 1552: train/loss = 0.6658118963241577, train/raw-loss = 0.6232424974441528, train/logprobs = tensor([[-1.2215, -1.2481],
        [-1.1287, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0851387083530426
Epoch 0, Step 1553: train/loss = 0.6530465483665466, train/raw-loss = 0.609798789024353, train/logprobs = tensor([[-1.3004, -1.4117],
        [-1.2932, -0.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08649545907974243
Epoch 0, Step 1554: train/loss = 0.686798632144928, train/raw-loss = 0.6293238997459412, train/logprobs = tensor([[-1.2592, -1.7350],
        [-1.2240, -1.3585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11494942009449005
Epoch 0, Step 1555: train/loss = 0.7419025897979736, train/raw-loss = 0.6769388914108276, train/logprobs = tensor([[-2.1159, -2.1757],
        [-2.3617, -2.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12992744147777557
Epoch 0, Step 1556: train/loss = 0.7044051289558411, train/raw-loss = 0.6621444821357727, train/logprobs = tensor([[-0.4745, -0.6271],
        [-0.6888, -0.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08452130854129791
Epoch 0, Step 1557: train/loss = 0.7137100696563721, train/raw-loss = 0.6640984416007996, train/logprobs = tensor([[-1.2838, -1.5084],
        [-1.1322, -1.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09922308474779129
Epoch 0, Step 1558: train/loss = 0.5245587229728699, train/raw-loss = 0.4788725674152374, train/logprobs = tensor([[-0.7949, -1.9445],
        [-0.9793, -1.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09137231856584549
Epoch 0, Step 1559: train/loss = 0.6179604530334473, train/raw-loss = 0.5722032785415649, train/logprobs = tensor([[-1.3065, -2.2566],
        [-1.2853, -1.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09151433408260345
Epoch 0, Step 1560: train/loss = 0.48381274938583374, train/raw-loss = 0.4273267984390259, train/logprobs = tensor([[-1.1332, -2.4225],
        [-1.3092, -1.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11297188699245453
Epoch 0, Step 1561: train/loss = 0.6876728534698486, train/raw-loss = 0.6302698850631714, train/logprobs = tensor([[-1.2310, -1.4782],
        [-1.4757, -1.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11480601131916046
Epoch 0, Step 1562: train/loss = 0.7422994375228882, train/raw-loss = 0.6913716197013855, train/logprobs = tensor([[-0.9835, -1.0224],
        [-1.2099, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10185550153255463
Epoch 0, Step 1563: train/loss = 0.5278231501579285, train/raw-loss = 0.4630897045135498, train/logprobs = tensor([[-1.2859, -2.0310],
        [-1.7366, -1.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294669657945633
Epoch 0, Step 1564: train/loss = 0.5098022222518921, train/raw-loss = 0.46611618995666504, train/logprobs = tensor([[-1.1973, -2.8069],
        [-1.2004, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08737196773290634
Epoch 0, Step 1565: train/loss = 0.6999571323394775, train/raw-loss = 0.6400565505027771, train/logprobs = tensor([[-1.6005, -2.2970],
        [-1.7753, -2.2343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1198011040687561
