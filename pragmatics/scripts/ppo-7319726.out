[2024-03-01 15:39:52,785][root][INFO] - beta: 1.5
[2024-03-01 15:39:52,785][root][INFO] - loss no_reference
[2024-03-01 15:39:52,786][root][INFO] - max_iter: 0
[2024-03-01 15:39:52,786][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-1.5-helpful-iteration-1-0-2k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 1870
n harmless: 1173
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-1.5-helpful-iteration-1-0-2k after each epoch.
tokenized 1776 training examples...
train dataset has 1776 examples.
eval dataset has 94 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-1.5-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-1.5-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-1.5-helpful-iteration-1-0-2k after each epoch.
Epoch 0, Step 0: train/loss = 0.691168487071991, train/raw-loss = 0.691168487071991, train/logprobs = tensor([[-0.5706, -0.8947],
        [-0.5884, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6914133429527283, train/raw-loss = 0.6914133429527283, train/logprobs = tensor([[-0.4531, -0.6281],
        [-0.4579, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6514632105827332, train/raw-loss = 0.6514632105827332, train/logprobs = tensor([[-0.4815, -1.8998],
        [-0.4921, -1.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.684298574924469, train/raw-loss = 0.684298574924469, train/logprobs = tensor([[-0.5683, -2.2087],
        [-0.5737, -2.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6806185841560364, train/raw-loss = 0.6806185841560364, train/logprobs = tensor([[-0.4501, -0.9317],
        [-0.4524, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6818892955780029, train/raw-loss = 0.6818892955780029, train/logprobs = tensor([[-0.5194, -1.3384],
        [-0.5245, -1.2980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6323404312133789, train/raw-loss = 0.6323404312133789, train/logprobs = tensor([[-0.3065, -2.2226],
        [-0.3075, -1.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6588633060455322, train/raw-loss = 0.6588633060455322, train/logprobs = tensor([[-0.4188, -1.9635],
        [-0.4214, -1.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6751775741577148, train/raw-loss = 0.6751775741577148, train/logprobs = tensor([[-0.5600, -1.0486],
        [-0.5659, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6863553524017334, train/raw-loss = 0.6863553524017334, train/logprobs = tensor([[-0.5418, -1.3805],
        [-0.5354, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6920734643936157, train/raw-loss = 0.6920734643936157, train/logprobs = tensor([[-0.4725, -1.2523],
        [-0.4761, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6817732453346252, train/raw-loss = 0.6817732453346252, train/logprobs = tensor([[-0.4965, -1.2112],
        [-0.5123, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6841890811920166, train/raw-loss = 0.6841890811920166, train/logprobs = tensor([[-0.4480, -0.7413],
        [-0.4433, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6892263293266296, train/raw-loss = 0.6892263293266296, train/logprobs = tensor([[-0.6424, -1.4638],
        [-0.6504, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.690991222858429, train/raw-loss = 0.690991222858429, train/logprobs = tensor([[-0.5512, -1.1008],
        [-0.5519, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6878229975700378, train/raw-loss = 0.6878229975700378, train/logprobs = tensor([[-0.5526, -0.8018],
        [-0.5484, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6888250708580017, train/raw-loss = 0.6888250708580017, train/logprobs = tensor([[-0.6245, -1.1522],
        [-0.6246, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6923377513885498, train/raw-loss = 0.6923377513885498, train/logprobs = tensor([[-0.6946, -0.8476],
        [-0.6862, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6461166143417358, train/raw-loss = 0.6461166143417358, train/logprobs = tensor([[-0.4243, -2.0105],
        [-0.4247, -1.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6872643232345581, train/raw-loss = 0.6872643232345581, train/logprobs = tensor([[-0.8183, -1.2543],
        [-0.8097, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6881037950515747, train/raw-loss = 0.6881037950515747, train/logprobs = tensor([[-0.5630, -0.6275],
        [-0.5608, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6813585758209229, train/raw-loss = 0.6813585758209229, train/logprobs = tensor([[-0.5133, -1.2954],
        [-0.4958, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6904762983322144, train/raw-loss = 0.6904762983322144, train/logprobs = tensor([[-0.4790, -0.8023],
        [-0.4770, -0.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6661308407783508, train/raw-loss = 0.6661308407783508, train/logprobs = tensor([[-0.9560, -1.2218],
        [-0.9616, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6525288820266724, train/raw-loss = 0.6525288820266724, train/logprobs = tensor([[-0.5501, -2.0784],
        [-0.5423, -1.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6834758520126343, train/raw-loss = 0.6834758520126343, train/logprobs = tensor([[-0.5855, -1.2581],
        [-0.5847, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6939085125923157, train/raw-loss = 0.6939085125923157, train/logprobs = tensor([[-0.5270, -1.2218],
        [-0.5256, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6855214238166809, train/raw-loss = 0.6855214238166809, train/logprobs = tensor([[-0.5594, -1.1913],
        [-0.5540, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6883843541145325, train/raw-loss = 0.6883843541145325, train/logprobs = tensor([[-0.6161, -1.2269],
        [-0.6157, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6704338788986206, train/raw-loss = 0.6704338788986206, train/logprobs = tensor([[-0.5070, -1.4604],
        [-0.5081, -1.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6890362501144409, train/raw-loss = 0.6890362501144409, train/logprobs = tensor([[-0.5486, -0.9842],
        [-0.5522, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6586874127388, train/raw-loss = 0.6586874127388, train/logprobs = tensor([[-0.5142, -2.2095],
        [-0.5153, -2.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.680763840675354, train/raw-loss = 0.6785872578620911, train/logprobs = tensor([[-0.4561, -0.8887],
        [-0.4558, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001451084390282631
Epoch 0, Step 33: train/loss = 0.6875359416007996, train/raw-loss = 0.6853209733963013, train/logprobs = tensor([[-0.6969, -0.6690],
        [-0.6839, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014766502426937222
Epoch 0, Step 34: train/loss = 0.6828103065490723, train/raw-loss = 0.6808947324752808, train/logprobs = tensor([[-0.5555, -0.8312],
        [-0.5548, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012770823668688536
Epoch 0, Step 35: train/loss = 0.6856831908226013, train/raw-loss = 0.682799756526947, train/logprobs = tensor([[-0.5979, -0.8344],
        [-0.5933, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019223315175622702
Epoch 0, Step 36: train/loss = 0.6875975131988525, train/raw-loss = 0.6850890517234802, train/logprobs = tensor([[-0.4715, -0.9101],
        [-0.4726, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001672276179306209
Epoch 0, Step 37: train/loss = 0.6976382732391357, train/raw-loss = 0.6948931813240051, train/logprobs = tensor([[-0.6604, -0.9986],
        [-0.6734, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001830082037486136
Epoch 0, Step 38: train/loss = 0.6602388024330139, train/raw-loss = 0.6578498482704163, train/logprobs = tensor([[-0.5881, -1.4876],
        [-0.5859, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015926193445920944
Epoch 0, Step 39: train/loss = 0.6378685832023621, train/raw-loss = 0.6356569528579712, train/logprobs = tensor([[-0.3462, -2.4203],
        [-0.3388, -2.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001474400283768773
Epoch 0, Step 40: train/loss = 0.6428549289703369, train/raw-loss = 0.6408306956291199, train/logprobs = tensor([[-0.5179, -1.7497],
        [-0.5103, -1.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013494810555130243
Epoch 0, Step 41: train/loss = 0.6270993947982788, train/raw-loss = 0.6248260736465454, train/logprobs = tensor([[-0.6740, -2.5658],
        [-0.6667, -2.2498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015155873261392117
Epoch 0, Step 42: train/loss = 0.6876986026763916, train/raw-loss = 0.6856915354728699, train/logprobs = tensor([[-0.5243, -1.3506],
        [-0.5135, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013380162417888641
Epoch 0, Step 43: train/loss = 0.6907764673233032, train/raw-loss = 0.6880971193313599, train/logprobs = tensor([[-0.6985, -0.9571],
        [-0.7003, -0.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017862129025161266
Epoch 0, Step 44: train/loss = 0.6575007438659668, train/raw-loss = 0.6553666591644287, train/logprobs = tensor([[-0.4012, -1.5325],
        [-0.4003, -1.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001422683009877801
Epoch 0, Step 45: train/loss = 0.5449299216270447, train/raw-loss = 0.5423362851142883, train/logprobs = tensor([[-0.6742, -2.7478],
        [-0.6644, -1.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017290873220190406
Epoch 0, Step 46: train/loss = 0.6078322529792786, train/raw-loss = 0.6052571535110474, train/logprobs = tensor([[-0.4333, -2.2777],
        [-0.4373, -1.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017167283222079277
Epoch 0, Step 47: train/loss = 0.638256311416626, train/raw-loss = 0.6357214450836182, train/logprobs = tensor([[-0.6789, -2.1593],
        [-0.6785, -1.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016898892354220152
Epoch 0, Step 48: train/loss = 0.6591606736183167, train/raw-loss = 0.6485872268676758, train/logprobs = tensor([[-0.5847, -1.3705],
        [-0.5710, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007048994768410921
Epoch 0, Step 49: train/loss = 0.6929525136947632, train/raw-loss = 0.6812070608139038, train/logprobs = tensor([[-0.6073, -1.1928],
        [-0.5755, -1.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007830281741917133
Epoch 0, Step 50: train/loss = 0.6676971912384033, train/raw-loss = 0.6565259099006653, train/logprobs = tensor([[-0.6223, -1.2165],
        [-0.6191, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007447527721524239
Epoch 0, Step 51: train/loss = 0.682169497013092, train/raw-loss = 0.6721733212471008, train/logprobs = tensor([[-0.5735, -1.0484],
        [-0.5644, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006664101034402847
Epoch 0, Step 52: train/loss = 0.6742314100265503, train/raw-loss = 0.6641669273376465, train/logprobs = tensor([[-0.5804, -1.1968],
        [-0.5557, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006709671579301357
Epoch 0, Step 53: train/loss = 0.7007322907447815, train/raw-loss = 0.6912504434585571, train/logprobs = tensor([[-0.8234, -0.8904],
        [-0.7880, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006321258842945099
Epoch 0, Step 54: train/loss = 0.5575803518295288, train/raw-loss = 0.5466666221618652, train/logprobs = tensor([[-0.8620, -3.3549],
        [-0.8278, -2.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007275808602571487
Epoch 0, Step 55: train/loss = 0.6935537457466125, train/raw-loss = 0.6821200251579285, train/logprobs = tensor([[-0.8491, -1.1372],
        [-0.8084, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007622482255101204
Epoch 0, Step 56: train/loss = 0.6654146313667297, train/raw-loss = 0.6532432436943054, train/logprobs = tensor([[-0.6342, -1.2330],
        [-0.5854, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008114269934594631
Epoch 0, Step 57: train/loss = 0.6530025601387024, train/raw-loss = 0.640375018119812, train/logprobs = tensor([[-0.5276, -1.6772],
        [-0.5275, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008418375626206398
Epoch 0, Step 58: train/loss = 0.6561369299888611, train/raw-loss = 0.647003173828125, train/logprobs = tensor([[-0.4487, -0.9046],
        [-0.4387, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060892109759151936
Epoch 0, Step 59: train/loss = 0.6512003540992737, train/raw-loss = 0.6393178701400757, train/logprobs = tensor([[-0.8244, -1.8109],
        [-0.8191, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007921647280454636
Epoch 0, Step 60: train/loss = 0.6207824945449829, train/raw-loss = 0.6090846657752991, train/logprobs = tensor([[-0.4951, -1.9945],
        [-0.4858, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007798551116138697
Epoch 0, Step 61: train/loss = 0.6695227026939392, train/raw-loss = 0.6594310402870178, train/logprobs = tensor([[-0.5470, -1.1387],
        [-0.5363, -0.9873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006727809086441994
Epoch 0, Step 62: train/loss = 0.6743423938751221, train/raw-loss = 0.6636732816696167, train/logprobs = tensor([[-0.5215, -1.6299],
        [-0.5083, -1.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007112765219062567
Epoch 0, Step 63: train/loss = 0.665266752243042, train/raw-loss = 0.6554466485977173, train/logprobs = tensor([[-0.4367, -1.5109],
        [-0.4353, -1.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006546707823872566
Epoch 0, Step 64: train/loss = 0.9168506860733032, train/raw-loss = 0.601290225982666, train/logprobs = tensor([[-0.4991, -1.4455],
        [-0.5537, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21037369966506958
Epoch 0, Step 65: train/loss = 0.8285818099975586, train/raw-loss = 0.5983866453170776, train/logprobs = tensor([[-0.5546, -1.4890],
        [-0.5066, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15346340835094452
Epoch 0, Step 66: train/loss = 0.8010674715042114, train/raw-loss = 0.6627137660980225, train/logprobs = tensor([[-0.7350, -1.2698],
        [-0.6464, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09223577380180359
Epoch 0, Step 67: train/loss = 0.806606113910675, train/raw-loss = 0.6327789425849915, train/logprobs = tensor([[-0.4663, -1.1359],
        [-0.4517, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11588477343320847
Epoch 0, Step 68: train/loss = 0.8358416557312012, train/raw-loss = 0.5716085433959961, train/logprobs = tensor([[-0.4111, -1.8757],
        [-0.3906, -1.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17615540325641632
Epoch 0, Step 69: train/loss = 0.7802097797393799, train/raw-loss = 0.5374177694320679, train/logprobs = tensor([[-0.4925, -3.2323],
        [-0.4807, -2.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1618613600730896
Epoch 0, Step 70: train/loss = 0.766414225101471, train/raw-loss = 0.6755560040473938, train/logprobs = tensor([[-0.6047, -0.7822],
        [-0.5886, -0.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06057216227054596
Epoch 0, Step 71: train/loss = 0.8270618915557861, train/raw-loss = 0.5745730400085449, train/logprobs = tensor([[-0.3760, -1.5052],
        [-0.3567, -0.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16832590103149414
Epoch 0, Step 72: train/loss = 0.7519167065620422, train/raw-loss = 0.6541725397109985, train/logprobs = tensor([[-1.9888, -1.0134],
        [-1.8395, -0.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0651627779006958
Epoch 0, Step 73: train/loss = 0.8465733528137207, train/raw-loss = 0.6647536754608154, train/logprobs = tensor([[-0.5298, -0.9678],
        [-0.5102, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121308594942093
Epoch 0, Step 74: train/loss = 0.81279057264328, train/raw-loss = 0.636145830154419, train/logprobs = tensor([[-0.5679, -1.0625],
        [-0.5490, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1177632063627243
Epoch 0, Step 75: train/loss = 0.7633475661277771, train/raw-loss = 0.5271792411804199, train/logprobs = tensor([[-0.6382, -2.6825],
        [-0.5826, -1.6493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574455350637436
Epoch 0, Step 76: train/loss = 0.8501703143119812, train/raw-loss = 0.6534883975982666, train/logprobs = tensor([[-0.5456, -0.8659],
        [-0.5280, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13112127780914307
Epoch 0, Step 77: train/loss = 0.797878623008728, train/raw-loss = 0.540215015411377, train/logprobs = tensor([[-0.4979, -2.4936],
        [-0.4777, -1.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17177575826644897
Epoch 0, Step 78: train/loss = 0.9726910591125488, train/raw-loss = 0.6277192831039429, train/logprobs = tensor([[-0.5275, -0.9637],
        [-0.4982, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2299811989068985
Epoch 0, Step 79: train/loss = 0.8475085496902466, train/raw-loss = 0.6231480240821838, train/logprobs = tensor([[-0.5599, -1.1048],
        [-0.5207, -0.7491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1495736688375473
Epoch 0, Step 80: train/loss = 0.6580977439880371, train/raw-loss = 0.5209494233131409, train/logprobs = tensor([[-0.5496, -3.8241],
        [-0.5351, -1.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09143224358558655
Epoch 0, Step 81: train/loss = 0.7123568654060364, train/raw-loss = 0.5476219058036804, train/logprobs = tensor([[-0.3118, -1.6922],
        [-0.3083, -0.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1098233014345169
Epoch 0, Step 82: train/loss = 0.7847118377685547, train/raw-loss = 0.6183895468711853, train/logprobs = tensor([[-0.4055, -3.6873],
        [-0.4073, -2.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11088155955076218
Epoch 0, Step 83: train/loss = 0.7065120935440063, train/raw-loss = 0.6188067197799683, train/logprobs = tensor([[-0.4351, -1.2583],
        [-0.4067, -0.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0584702342748642
Epoch 0, Step 84: train/loss = 0.6848215460777283, train/raw-loss = 0.5986506342887878, train/logprobs = tensor([[-0.3816, -1.3571],
        [-0.3520, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05744731426239014
Epoch 0, Step 85: train/loss = 0.7001628875732422, train/raw-loss = 0.5757370591163635, train/logprobs = tensor([[-0.6494, -1.7376],
        [-0.6429, -1.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08295058459043503
Epoch 0, Step 86: train/loss = 0.6837148070335388, train/raw-loss = 0.5370792746543884, train/logprobs = tensor([[-0.5276, -2.1600],
        [-0.5098, -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977569967508316
Epoch 0, Step 87: train/loss = 0.6546263694763184, train/raw-loss = 0.5149267911911011, train/logprobs = tensor([[-0.5424, -3.0252],
        [-0.5079, -2.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09313307702541351
Epoch 0, Step 88: train/loss = 0.7530164122581482, train/raw-loss = 0.6362927556037903, train/logprobs = tensor([[-0.4402, -0.8662],
        [-0.4311, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07781580090522766
Epoch 0, Step 89: train/loss = 0.6997279524803162, train/raw-loss = 0.5852108001708984, train/logprobs = tensor([[-0.4911, -1.2529],
        [-0.4723, -0.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07634474337100983
Epoch 0, Step 90: train/loss = 0.6418676376342773, train/raw-loss = 0.5362840294837952, train/logprobs = tensor([[-0.6956, -2.2024],
        [-0.5731, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07038908451795578
Epoch 0, Step 91: train/loss = 0.7739577889442444, train/raw-loss = 0.6574597358703613, train/logprobs = tensor([[-0.3951, -0.8078],
        [-0.3688, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07766537368297577
Epoch 0, Step 92: train/loss = 0.6566340327262878, train/raw-loss = 0.5471199750900269, train/logprobs = tensor([[-0.7027, -2.3833],
        [-0.6456, -1.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07300938665866852
Epoch 0, Step 93: train/loss = 0.7525386214256287, train/raw-loss = 0.6542261838912964, train/logprobs = tensor([[-0.5854, -1.2927],
        [-0.5771, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06554162502288818
Epoch 0, Step 94: train/loss = 0.7384985685348511, train/raw-loss = 0.6422218084335327, train/logprobs = tensor([[-0.6279, -1.1027],
        [-0.5846, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06418448686599731
Epoch 0, Step 95: train/loss = 0.771629273891449, train/raw-loss = 0.6651486754417419, train/logprobs = tensor([[-0.4132, -0.5620],
        [-0.4004, -0.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0709870457649231
Epoch 0, Step 96: train/loss = 0.700652539730072, train/raw-loss = 0.6285722255706787, train/logprobs = tensor([[-0.7082, -1.3620],
        [-0.6283, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04805354028940201
Epoch 0, Step 97: train/loss = 0.6730777621269226, train/raw-loss = 0.5764539837837219, train/logprobs = tensor([[-0.4354, -1.2898],
        [-0.4202, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.064415842294693
Epoch 0, Step 98: train/loss = 0.7386744022369385, train/raw-loss = 0.619551956653595, train/logprobs = tensor([[-0.5949, -1.1340],
        [-0.5735, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07941502332687378
Epoch 0, Step 99: train/loss = 0.6310535073280334, train/raw-loss = 0.5170453786849976, train/logprobs = tensor([[-0.5695, -2.7734],
        [-0.5150, -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07600539177656174
Epoch 0, Step 100: train/loss = 0.7281622290611267, train/raw-loss = 0.6189316511154175, train/logprobs = tensor([[-0.5867, -0.9809],
        [-0.5629, -0.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07282038778066635
Epoch 0, Step 101: train/loss = 0.6282904148101807, train/raw-loss = 0.46617552638053894, train/logprobs = tensor([[-0.4103, -3.0573],
        [-0.3779, -1.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10807661712169647
Epoch 0, Step 102: train/loss = 0.708907961845398, train/raw-loss = 0.5863416194915771, train/logprobs = tensor([[-0.5758, -4.0249],
        [-0.5284, -3.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08171090483665466
Epoch 0, Step 103: train/loss = 0.7487413883209229, train/raw-loss = 0.6398957371711731, train/logprobs = tensor([[-0.6558, -0.8190],
        [-0.5906, -0.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0725637674331665
Epoch 0, Step 104: train/loss = 0.6761492490768433, train/raw-loss = 0.558326005935669, train/logprobs = tensor([[-0.6603, -1.5917],
        [-0.5894, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07854881882667542
Epoch 0, Step 105: train/loss = 0.7143750190734863, train/raw-loss = 0.6052766442298889, train/logprobs = tensor([[-0.5978, -1.0788],
        [-0.5480, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07273225486278534
Epoch 0, Step 106: train/loss = 0.7141982316970825, train/raw-loss = 0.6391370892524719, train/logprobs = tensor([[-0.4713, -0.7082],
        [-0.4328, -0.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050040751695632935
Epoch 0, Step 107: train/loss = 0.7500668168067932, train/raw-loss = 0.5963852405548096, train/logprobs = tensor([[-0.6361, -1.4460],
        [-0.5686, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10245439410209656
Epoch 0, Step 108: train/loss = 0.7256618738174438, train/raw-loss = 0.5907727479934692, train/logprobs = tensor([[-0.5002, -1.2153],
        [-0.4753, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08992607146501541
Epoch 0, Step 109: train/loss = 0.6789799928665161, train/raw-loss = 0.5772076845169067, train/logprobs = tensor([[-0.5625, -1.4987],
        [-0.5157, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06784819811582565
Epoch 0, Step 110: train/loss = 0.7290593385696411, train/raw-loss = 0.6090242862701416, train/logprobs = tensor([[-0.7173, -1.3550],
        [-0.5996, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800234004855156
Epoch 0, Step 111: train/loss = 0.731452226638794, train/raw-loss = 0.6235160827636719, train/logprobs = tensor([[-0.5050, -1.4086],
        [-0.4384, -1.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07195743918418884
Epoch 0, Step 112: train/loss = 0.5784059762954712, train/raw-loss = 0.4763393700122833, train/logprobs = tensor([[-0.7889, -2.8217],
        [-0.7260, -1.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804441660642624
Epoch 0, Step 113: train/loss = 0.6438500881195068, train/raw-loss = 0.5314516425132751, train/logprobs = tensor([[-0.6685, -2.0016],
        [-0.5719, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07493230700492859
Epoch 0, Step 114: train/loss = 0.6464754343032837, train/raw-loss = 0.5269941091537476, train/logprobs = tensor([[-0.8470, -1.8312],
        [-0.6590, -0.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07965424656867981
Epoch 0, Step 115: train/loss = 0.7162837982177734, train/raw-loss = 0.5994578003883362, train/logprobs = tensor([[-0.5924, -1.1420],
        [-0.5180, -0.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0778840109705925
Epoch 0, Step 116: train/loss = 0.6180320978164673, train/raw-loss = 0.5214682817459106, train/logprobs = tensor([[-0.8516, -2.2827],
        [-0.6848, -1.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06437590718269348
Epoch 0, Step 117: train/loss = 0.6946349143981934, train/raw-loss = 0.559566080570221, train/logprobs = tensor([[-0.8011, -1.6317],
        [-0.7141, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09004589170217514
Epoch 0, Step 118: train/loss = 0.7071388959884644, train/raw-loss = 0.6170897483825684, train/logprobs = tensor([[-0.6340, -1.1906],
        [-0.5285, -0.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06003279238939285
Epoch 0, Step 119: train/loss = 0.6210591197013855, train/raw-loss = 0.5106545090675354, train/logprobs = tensor([[-0.5320, -1.7607],
        [-0.4869, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.073603056371212
Epoch 0, Step 120: train/loss = 0.6773818135261536, train/raw-loss = 0.5613530874252319, train/logprobs = tensor([[-0.5266, -1.3679],
        [-0.4568, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07735248655080795
Epoch 0, Step 121: train/loss = 0.7054997682571411, train/raw-loss = 0.5924578309059143, train/logprobs = tensor([[-0.8331, -2.0219],
        [-0.5465, -0.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07536132633686066
Epoch 0, Step 122: train/loss = 0.6816132068634033, train/raw-loss = 0.553365170955658, train/logprobs = tensor([[-0.8261, -2.3455],
        [-0.6641, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08549867570400238
Epoch 0, Step 123: train/loss = 0.6614863872528076, train/raw-loss = 0.5133899450302124, train/logprobs = tensor([[-0.6317, -1.8701],
        [-0.5345, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987309142947197
Epoch 0, Step 124: train/loss = 0.7460827827453613, train/raw-loss = 0.6296126246452332, train/logprobs = tensor([[-0.7390, -1.0170],
        [-0.6060, -0.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07764677703380585
Epoch 0, Step 125: train/loss = 0.7148377895355225, train/raw-loss = 0.5968670845031738, train/logprobs = tensor([[-0.5967, -1.0536],
        [-0.5308, -0.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07864715158939362
Epoch 0, Step 126: train/loss = 0.6125121116638184, train/raw-loss = 0.46585285663604736, train/logprobs = tensor([[-0.5707, -2.2674],
        [-0.4630, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09777285903692245
Epoch 0, Step 127: train/loss = 0.7421553730964661, train/raw-loss = 0.6437506675720215, train/logprobs = tensor([[-0.3197, -0.6894],
        [-0.2926, -0.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06560318171977997
Epoch 0, Step 128: train/loss = 0.7384551763534546, train/raw-loss = 0.6216883063316345, train/logprobs = tensor([[-0.6344, -1.0504],
        [-0.5398, -0.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07784456759691238
Epoch 0, Step 129: train/loss = 0.5837346315383911, train/raw-loss = 0.46985960006713867, train/logprobs = tensor([[-1.0376, -3.2534],
        [-0.8134, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591667771339417
Epoch 0, Step 130: train/loss = 0.6071373224258423, train/raw-loss = 0.4707155227661133, train/logprobs = tensor([[-0.3954, -2.0343],
        [-0.3548, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09094789624214172
Epoch 0, Step 131: train/loss = 0.6004714369773865, train/raw-loss = 0.47074002027511597, train/logprobs = tensor([[-0.4582, -2.2790],
        [-0.3920, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08648762851953506
