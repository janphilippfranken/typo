[2024-02-19 17:34:35,034][root][INFO] - beta: 0.4
[2024-02-19 17:34:35,034][root][INFO] - temperature: 1
[2024-02-19 17:34:35,034][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.4-batch-size-64
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.4-batch-size-64 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.4-batch-size-64 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.4-batch-size-64 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.4-batch-size-64 after each epoch.
Epoch 0, Step 0: train/loss = 0.7040798664093018, train/raw-loss = 0.7040798664093018, train/logprobs = tensor([[-0.9533, -0.9948],
        [-0.9302, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7164785265922546, train/raw-loss = 0.7164785265922546, train/logprobs = tensor([[-1.0724, -1.4169],
        [-1.1293, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7007112503051758, train/raw-loss = 0.7007112503051758, train/logprobs = tensor([[-0.8302, -0.9350],
        [-0.7845, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6975338459014893, train/raw-loss = 0.6975338459014893, train/logprobs = tensor([[-0.9099, -0.9087],
        [-0.9060, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6946052312850952, train/raw-loss = 0.6946052312850952, train/logprobs = tensor([[-0.7761, -0.8804],
        [-0.8097, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7074680328369141, train/raw-loss = 0.7074680328369141, train/logprobs = tensor([[-1.2210, -1.1801],
        [-1.2999, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6987193822860718, train/raw-loss = 0.6987193822860718, train/logprobs = tensor([[-1.1771, -1.2348],
        [-1.1741, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.7075663805007935, train/raw-loss = 0.7075663805007935, train/logprobs = tensor([[-0.7880, -0.6978],
        [-0.8163, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.742479681968689, train/raw-loss = 0.742479681968689, train/logprobs = tensor([[-0.9000, -1.5068],
        [-0.8656, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6987901329994202, train/raw-loss = 0.6987901329994202, train/logprobs = tensor([[-0.9074, -1.1629],
        [-0.9010, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7119882702827454, train/raw-loss = 0.7119882702827454, train/logprobs = tensor([[-1.2293, -1.1969],
        [-1.2240, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7207285761833191, train/raw-loss = 0.7207285761833191, train/logprobs = tensor([[-1.0679, -0.9060],
        [-1.0898, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7011242508888245, train/raw-loss = 0.7011242508888245, train/logprobs = tensor([[-0.8549, -1.0949],
        [-0.8891, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.7031682729721069, train/raw-loss = 0.7031682729721069, train/logprobs = tensor([[-0.8906, -1.0827],
        [-0.9134, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7142623662948608, train/raw-loss = 0.7142623662948608, train/logprobs = tensor([[-0.8982, -0.9696],
        [-0.8924, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7054764628410339, train/raw-loss = 0.7054764628410339, train/logprobs = tensor([[-0.5966, -0.8092],
        [-0.5724, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6938965320587158, train/raw-loss = 0.6938965320587158, train/logprobs = tensor([[-1.0988, -1.1515],
        [-1.0541, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7236944437026978, train/raw-loss = 0.7236944437026978, train/logprobs = tensor([[-0.8199, -1.2773],
        [-0.7945, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6943728923797607, train/raw-loss = 0.6943728923797607, train/logprobs = tensor([[-1.0141, -1.0339],
        [-1.0263, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6956578493118286, train/raw-loss = 0.6956578493118286, train/logprobs = tensor([[-1.1737, -1.1441],
        [-1.1765, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7437841296195984, train/raw-loss = 0.7437841296195984, train/logprobs = tensor([[-0.5573, -1.0747],
        [-0.5540, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7071292996406555, train/raw-loss = 0.7071292996406555, train/logprobs = tensor([[-1.0698, -0.9658],
        [-1.0991, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7120579481124878, train/raw-loss = 0.7120579481124878, train/logprobs = tensor([[-1.1177, -1.1496],
        [-1.1588, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7534469962120056, train/raw-loss = 0.7534469962120056, train/logprobs = tensor([[-0.9588, -1.4736],
        [-0.9477, -1.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6944814920425415, train/raw-loss = 0.6944814920425415, train/logprobs = tensor([[-1.3211, -1.4845],
        [-1.2829, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7182225584983826, train/raw-loss = 0.7182225584983826, train/logprobs = tensor([[-0.9310, -0.9236],
        [-0.9353, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7320457696914673, train/raw-loss = 0.7320457696914673, train/logprobs = tensor([[-0.9226, -1.0176],
        [-0.9618, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7064348459243774, train/raw-loss = 0.7064348459243774, train/logprobs = tensor([[-0.9682, -1.0804],
        [-0.9400, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7004761099815369, train/raw-loss = 0.7004761099815369, train/logprobs = tensor([[-1.0793, -1.2677],
        [-1.0354, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7071655988693237, train/raw-loss = 0.7071655988693237, train/logprobs = tensor([[-0.8737, -0.9530],
        [-0.8765, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7233868837356567, train/raw-loss = 0.7233868837356567, train/logprobs = tensor([[-0.9774, -1.2341],
        [-0.9461, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.8921672105789185, train/raw-loss = 0.8921672105789185, train/logprobs = tensor([[-0.7943, -1.4819],
        [-0.8081, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.7118006944656372, train/raw-loss = 0.7117993831634521, train/logprobs = tensor([[-0.8874, -1.0011],
        [-0.9079, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2706448109820485e-06
Epoch 0, Step 33: train/loss = 0.7009071111679077, train/raw-loss = 0.7009002566337585, train/logprobs = tensor([[-0.9855, -0.9325],
        [-0.9714, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7093814676627517e-05
Epoch 0, Step 34: train/loss = 0.7560075521469116, train/raw-loss = 0.7559796571731567, train/logprobs = tensor([[-0.6012, -1.2203],
        [-0.5871, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.966687215026468e-05
Epoch 0, Step 35: train/loss = 0.6857401132583618, train/raw-loss = 0.6857386231422424, train/logprobs = tensor([[-0.8457, -1.0260],
        [-1.1829, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7732752389274538e-06
Epoch 0, Step 36: train/loss = 0.6973508596420288, train/raw-loss = 0.6973342895507812, train/logprobs = tensor([[-0.9115, -1.0264],
        [-0.9280, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1555769712431356e-05
Epoch 0, Step 37: train/loss = 0.7981610894203186, train/raw-loss = 0.7981580495834351, train/logprobs = tensor([[-0.6715, -1.1981],
        [-0.6756, -1.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.486789399990812e-06
Epoch 0, Step 38: train/loss = 0.6937661170959473, train/raw-loss = 0.6937659978866577, train/logprobs = tensor([[-0.7693, -0.8381],
        [-0.8074, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7665631680283695e-07
Epoch 0, Step 39: train/loss = 0.6967452764511108, train/raw-loss = 0.696743905544281, train/logprobs = tensor([[-0.7979, -0.7418],
        [-0.8102, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4001677704509348e-06
Epoch 0, Step 40: train/loss = 0.6990064382553101, train/raw-loss = 0.698998749256134, train/logprobs = tensor([[-0.8220, -0.8239],
        [-0.8717, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8981998437084258e-05
Epoch 0, Step 41: train/loss = 0.6955974698066711, train/raw-loss = 0.6955854892730713, train/logprobs = tensor([[-1.0475, -0.9817],
        [-1.0746, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.014364483533427e-05
Epoch 0, Step 42: train/loss = 0.6967177987098694, train/raw-loss = 0.6967142224311829, train/logprobs = tensor([[-1.2466, -1.4883],
        [-1.2753, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.891644938557874e-06
Epoch 0, Step 43: train/loss = 0.953783392906189, train/raw-loss = 0.9537484049797058, train/logprobs = tensor([[-0.6983, -1.9201],
        [-0.8220, -1.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.757988689467311e-05
Epoch 0, Step 44: train/loss = 0.7408015131950378, train/raw-loss = 0.7407896518707275, train/logprobs = tensor([[-0.9447, -1.3736],
        [-0.9681, -1.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.961041172966361e-05
Epoch 0, Step 45: train/loss = 0.7039939165115356, train/raw-loss = 0.703973114490509, train/logprobs = tensor([[-0.7386, -1.0756],
        [-0.7445, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.182712629903108e-05
Epoch 0, Step 46: train/loss = 0.7073694467544556, train/raw-loss = 0.7073608040809631, train/logprobs = tensor([[-1.2168, -1.4766],
        [-1.2532, -1.4470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1484127501025796e-05
Epoch 0, Step 47: train/loss = 0.7041785717010498, train/raw-loss = 0.7041685581207275, train/logprobs = tensor([[-1.0087, -0.8354],
        [-1.0175, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5034823920577765e-05
Epoch 0, Step 48: train/loss = 0.7309790253639221, train/raw-loss = 0.7309503555297852, train/logprobs = tensor([[-0.8501, -1.2709],
        [-0.8172, -1.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.174117490649223e-05
Epoch 0, Step 49: train/loss = 0.7065314054489136, train/raw-loss = 0.7064943909645081, train/logprobs = tensor([[-1.1670, -0.9911],
        [-1.2072, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.264890104532242e-05
Epoch 0, Step 50: train/loss = 0.697665810585022, train/raw-loss = 0.6976418495178223, train/logprobs = tensor([[-0.9581, -1.1829],
        [-1.0565, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.986185715300962e-05
Epoch 0, Step 51: train/loss = 0.7399861216545105, train/raw-loss = 0.7398653626441956, train/logprobs = tensor([[-0.8919, -1.4059],
        [-0.9198, -1.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030191848054528236
Epoch 0, Step 52: train/loss = 0.7305470705032349, train/raw-loss = 0.7304556369781494, train/logprobs = tensor([[-0.7309, -1.0955],
        [-0.8721, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022836390417069197
Epoch 0, Step 53: train/loss = 0.6957590579986572, train/raw-loss = 0.6957317590713501, train/logprobs = tensor([[-0.9979, -1.0979],
        [-1.0378, -1.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.820866838097572e-05
Epoch 0, Step 54: train/loss = 0.7066088914871216, train/raw-loss = 0.7065287828445435, train/logprobs = tensor([[-1.2558, -1.3998],
        [-1.2657, -1.2768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020009645959362388
Epoch 0, Step 55: train/loss = 0.7239415645599365, train/raw-loss = 0.723895251750946, train/logprobs = tensor([[-0.9826, -1.5952],
        [-1.0432, -1.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011567238834686577
Epoch 0, Step 56: train/loss = 0.6910747289657593, train/raw-loss = 0.6909754276275635, train/logprobs = tensor([[-1.0079, -1.1991],
        [-1.2021, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000248208234552294
Epoch 0, Step 57: train/loss = 0.7225749492645264, train/raw-loss = 0.7225548028945923, train/logprobs = tensor([[-1.0464, -0.8532],
        [-1.0916, -0.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.026073267799802e-05
Epoch 0, Step 58: train/loss = 0.6948462724685669, train/raw-loss = 0.6947245597839355, train/logprobs = tensor([[-0.9215, -1.0138],
        [-0.9915, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003045637276954949
Epoch 0, Step 59: train/loss = 0.7138720750808716, train/raw-loss = 0.7138272523880005, train/logprobs = tensor([[-0.8884, -0.8871],
        [-0.9321, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000112201101728715
Epoch 0, Step 60: train/loss = 0.697871208190918, train/raw-loss = 0.6978332996368408, train/logprobs = tensor([[-0.6026, -0.6676],
        [-0.6650, -0.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.477404819335788e-05
Epoch 0, Step 61: train/loss = 0.7056697607040405, train/raw-loss = 0.7056545615196228, train/logprobs = tensor([[-0.7944, -0.7779],
        [-0.8716, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8054713513702154e-05
Epoch 0, Step 62: train/loss = 0.699349582195282, train/raw-loss = 0.6993440389633179, train/logprobs = tensor([[-0.7626, -0.9880],
        [-0.7781, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3809527445118874e-05
Epoch 0, Step 63: train/loss = 0.7068756222724915, train/raw-loss = 0.7068159580230713, train/logprobs = tensor([[-1.0798, -0.8835],
        [-1.0607, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001493515446782112
Epoch 0, Step 64: train/loss = 0.7062061429023743, train/raw-loss = 0.7061718702316284, train/logprobs = tensor([[-0.6517, -0.8020],
        [-0.6880, -0.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.567671466153115e-05
Epoch 0, Step 65: train/loss = 0.6995587944984436, train/raw-loss = 0.6994760036468506, train/logprobs = tensor([[-0.6583, -0.8598],
        [-0.6868, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020691129611805081
Epoch 0, Step 66: train/loss = 0.6937923431396484, train/raw-loss = 0.6937767267227173, train/logprobs = tensor([[-0.8223, -0.7993],
        [-0.8967, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9087492041289806e-05
Epoch 0, Step 67: train/loss = 0.6953359842300415, train/raw-loss = 0.6950352787971497, train/logprobs = tensor([[-0.7061, -0.8115],
        [-0.8113, -0.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007517614867538214
Epoch 0, Step 68: train/loss = 0.7393396496772766, train/raw-loss = 0.7393131256103516, train/logprobs = tensor([[-1.0926, -1.0214],
        [-1.0915, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.630373536609113e-05
Epoch 0, Step 69: train/loss = 0.791304886341095, train/raw-loss = 0.7907761931419373, train/logprobs = tensor([[-1.0952, -1.2502],
        [-1.1650, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013218519743531942
Epoch 0, Step 70: train/loss = 0.7011730074882507, train/raw-loss = 0.7011580467224121, train/logprobs = tensor([[-0.9102, -0.7884],
        [-0.9589, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.751392068807036e-05
Epoch 0, Step 71: train/loss = 0.7231447100639343, train/raw-loss = 0.7230648398399353, train/logprobs = tensor([[-1.0109, -0.8022],
        [-1.0658, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019972215523011982
Epoch 0, Step 72: train/loss = 0.6969648003578186, train/raw-loss = 0.6968885660171509, train/logprobs = tensor([[-0.9391, -0.8873],
        [-1.1009, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019052307470701635
Epoch 0, Step 73: train/loss = 0.6988049149513245, train/raw-loss = 0.6988009810447693, train/logprobs = tensor([[-0.9008, -0.9623],
        [-0.8977, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.831270290305838e-06
Epoch 0, Step 74: train/loss = 0.7422730922698975, train/raw-loss = 0.7416859865188599, train/logprobs = tensor([[-0.6764, -0.9364],
        [-0.7438, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014676257269456983
Epoch 0, Step 75: train/loss = 0.6954102516174316, train/raw-loss = 0.6952961683273315, train/logprobs = tensor([[-0.8326, -0.9556],
        [-0.8371, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002851372992154211
Epoch 0, Step 76: train/loss = 0.7415543794631958, train/raw-loss = 0.741509199142456, train/logprobs = tensor([[-0.7778, -1.0369],
        [-0.8810, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011310558329569176
Epoch 0, Step 77: train/loss = 0.6957722902297974, train/raw-loss = 0.6957688927650452, train/logprobs = tensor([[-0.9118, -0.9518],
        [-0.9850, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.44264286570251e-06
Epoch 0, Step 78: train/loss = 0.7286406755447388, train/raw-loss = 0.7282301187515259, train/logprobs = tensor([[-0.7677, -1.0267],
        [-0.8084, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010262955911457539
Epoch 0, Step 79: train/loss = 0.7030245065689087, train/raw-loss = 0.7028051614761353, train/logprobs = tensor([[-0.8340, -0.8706],
        [-0.8996, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005482616252265871
Epoch 0, Step 80: train/loss = 0.6997755169868469, train/raw-loss = 0.6995916962623596, train/logprobs = tensor([[-0.6770, -0.7966],
        [-0.6828, -0.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004593317862600088
Epoch 0, Step 81: train/loss = 0.7048275470733643, train/raw-loss = 0.7045876979827881, train/logprobs = tensor([[-1.0081, -1.0508],
        [-1.1271, -1.1121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000599726103246212
Epoch 0, Step 82: train/loss = 0.6944496035575867, train/raw-loss = 0.6937204599380493, train/logprobs = tensor([[-0.9007, -1.0240],
        [-0.9841, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018227414693683386
Epoch 0, Step 83: train/loss = 0.7052139639854431, train/raw-loss = 0.7051272392272949, train/logprobs = tensor([[-0.7879, -0.8872],
        [-0.9644, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021689102868549526
Epoch 0, Step 84: train/loss = 0.6977590322494507, train/raw-loss = 0.6977548599243164, train/logprobs = tensor([[-0.9533, -0.7973],
        [-1.3324, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0567920980975032e-05
Epoch 0, Step 85: train/loss = 0.7526498436927795, train/raw-loss = 0.7524051070213318, train/logprobs = tensor([[-1.2569, -1.5428],
        [-1.3351, -1.2657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006119455792941153
Epoch 0, Step 86: train/loss = 0.6931356191635132, train/raw-loss = 0.6931034922599792, train/logprobs = tensor([[-0.7777, -0.7922],
        [-0.8238, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.028058800846338e-05
Epoch 0, Step 87: train/loss = 0.7058970928192139, train/raw-loss = 0.7058459520339966, train/logprobs = tensor([[-0.7401, -0.8111],
        [-0.7893, -0.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001279623684240505
Epoch 0, Step 88: train/loss = 0.7010734677314758, train/raw-loss = 0.7009353637695312, train/logprobs = tensor([[-0.7168, -0.9534],
        [-0.7414, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003450912772677839
Epoch 0, Step 89: train/loss = 0.6943166255950928, train/raw-loss = 0.6942412853240967, train/logprobs = tensor([[-0.8598, -0.9498],
        [-0.9656, -0.9191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018839584663510323
Epoch 0, Step 90: train/loss = 0.7501911520957947, train/raw-loss = 0.7499017715454102, train/logprobs = tensor([[-0.7154, -1.2672],
        [-0.8054, -1.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007233208743855357
Epoch 0, Step 91: train/loss = 0.7118419408798218, train/raw-loss = 0.7118295431137085, train/logprobs = tensor([[-0.8890, -0.9488],
        [-0.8999, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.085007119807415e-05
Epoch 0, Step 92: train/loss = 0.7492832541465759, train/raw-loss = 0.7474411129951477, train/logprobs = tensor([[-0.7167, -1.3169],
        [-0.7613, -1.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0046053542755544186
Epoch 0, Step 93: train/loss = 0.7010672688484192, train/raw-loss = 0.7006177306175232, train/logprobs = tensor([[-0.6815, -0.8134],
        [-0.7422, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011238656006753445
Epoch 0, Step 94: train/loss = 0.7119966149330139, train/raw-loss = 0.7118740081787109, train/logprobs = tensor([[-0.9838, -0.8950],
        [-1.0751, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003063345793634653
Epoch 0, Step 95: train/loss = 0.7008236050605774, train/raw-loss = 0.7007882595062256, train/logprobs = tensor([[-0.7156, -0.7864],
        [-0.7622, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.83073007571511e-05
Epoch 0, Step 96: train/loss = 0.6981333494186401, train/raw-loss = 0.6977517008781433, train/logprobs = tensor([[-0.7881, -0.9752],
        [-0.8756, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009540974861010909
Epoch 0, Step 97: train/loss = 0.6977267265319824, train/raw-loss = 0.6977121233940125, train/logprobs = tensor([[-0.7183, -0.7884],
        [-0.8135, -0.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6531826481223106e-05
Epoch 0, Step 98: train/loss = 0.6915072798728943, train/raw-loss = 0.6911575198173523, train/logprobs = tensor([[-0.8835, -0.9209],
        [-0.9561, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008743626531213522
Epoch 0, Step 99: train/loss = 0.7146885991096497, train/raw-loss = 0.7146748900413513, train/logprobs = tensor([[-0.8770, -0.8249],
        [-0.9140, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4287048038095236e-05
Epoch 0, Step 100: train/loss = 0.6962813138961792, train/raw-loss = 0.6960269212722778, train/logprobs = tensor([[-0.6923, -0.7360],
        [-0.7412, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006360565894283354
Epoch 0, Step 101: train/loss = 0.6963935494422913, train/raw-loss = 0.6963620781898499, train/logprobs = tensor([[-0.5371, -0.6499],
        [-0.5671, -0.6448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.879763870732859e-05
Epoch 0, Step 102: train/loss = 0.7203605771064758, train/raw-loss = 0.7202191352844238, train/logprobs = tensor([[-1.0369, -0.8408],
        [-1.0590, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003535207360982895
Epoch 0, Step 103: train/loss = 0.7041181921958923, train/raw-loss = 0.7038353085517883, train/logprobs = tensor([[-0.8807, -0.8212],
        [-0.9538, -0.7910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000707194791175425
Epoch 0, Step 104: train/loss = 0.7142267823219299, train/raw-loss = 0.7142135500907898, train/logprobs = tensor([[-0.7950, -0.5441],
        [-0.8123, -0.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.313535125926137e-05
Epoch 0, Step 105: train/loss = 0.6979609727859497, train/raw-loss = 0.6979496479034424, train/logprobs = tensor([[-0.6376, -0.8523],
        [-0.6841, -0.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.826817217282951e-05
Epoch 0, Step 106: train/loss = 0.7415390014648438, train/raw-loss = 0.7414448261260986, train/logprobs = tensor([[-0.6822, -1.1088],
        [-0.7386, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023526482982560992
Epoch 0, Step 107: train/loss = 0.70079106092453, train/raw-loss = 0.7007546424865723, train/logprobs = tensor([[-0.6734, -0.6070],
        [-0.7443, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.119458263739944e-05
Epoch 0, Step 108: train/loss = 0.6981916427612305, train/raw-loss = 0.6980188488960266, train/logprobs = tensor([[-0.8310, -0.9975],
        [-0.9072, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043200235813856125
Epoch 0, Step 109: train/loss = 0.6988339424133301, train/raw-loss = 0.6979707479476929, train/logprobs = tensor([[-0.7959, -0.9492],
        [-0.8987, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021579996682703495
Epoch 0, Step 110: train/loss = 0.7119525074958801, train/raw-loss = 0.7114499807357788, train/logprobs = tensor([[-0.7254, -0.6142],
        [-0.7778, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001256401650607586
Epoch 0, Step 111: train/loss = 0.7061684727668762, train/raw-loss = 0.7061541080474854, train/logprobs = tensor([[-0.6731, -0.9054],
        [-0.7085, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.577729512471706e-05
Epoch 0, Step 112: train/loss = 0.6970566511154175, train/raw-loss = 0.6969654560089111, train/logprobs = tensor([[-0.6489, -0.8340],
        [-0.7366, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022789754439145327
Epoch 0, Step 113: train/loss = 0.708321213722229, train/raw-loss = 0.7082322239875793, train/logprobs = tensor([[-0.8217, -0.8433],
        [-0.8174, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022232707124203444
Epoch 0, Step 114: train/loss = 0.6963462233543396, train/raw-loss = 0.696281909942627, train/logprobs = tensor([[-0.7660, -0.8473],
        [-0.8398, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000160696217790246
Epoch 0, Step 115: train/loss = 0.7004573941230774, train/raw-loss = 0.7000184059143066, train/logprobs = tensor([[-0.7171, -1.0061],
        [-0.7952, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010974175529554486
Epoch 0, Step 116: train/loss = 0.7222862243652344, train/raw-loss = 0.7222374677658081, train/logprobs = tensor([[-0.8522, -0.4944],
        [-1.0462, -0.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012192089343443513
Epoch 0, Step 117: train/loss = 0.7027632594108582, train/raw-loss = 0.7025516033172607, train/logprobs = tensor([[-0.8430, -0.7376],
        [-0.9239, -0.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000529166660271585
Epoch 0, Step 118: train/loss = 0.6997847557067871, train/raw-loss = 0.6997122764587402, train/logprobs = tensor([[-0.5723, -0.7516],
        [-0.6462, -0.7159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001810083631426096
Epoch 0, Step 119: train/loss = 0.6952426433563232, train/raw-loss = 0.6947414875030518, train/logprobs = tensor([[-0.6295, -0.6861],
        [-0.6550, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001252766465768218
Epoch 0, Step 120: train/loss = 0.7261724472045898, train/raw-loss = 0.7257879972457886, train/logprobs = tensor([[-1.0429, -0.9260],
        [-1.2251, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009610868874005973
Epoch 0, Step 121: train/loss = 0.6962370276451111, train/raw-loss = 0.696174144744873, train/logprobs = tensor([[-0.6992, -0.8196],
        [-0.6856, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015727849677205086
Epoch 0, Step 122: train/loss = 0.7146760821342468, train/raw-loss = 0.7143228650093079, train/logprobs = tensor([[-1.0108, -0.7260],
        [-1.0796, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008829745347611606
Epoch 0, Step 123: train/loss = 0.6937850713729858, train/raw-loss = 0.6937766075134277, train/logprobs = tensor([[-0.7309, -0.7631],
        [-0.7972, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1213993022684008e-05
Epoch 0, Step 124: train/loss = 0.7047746181488037, train/raw-loss = 0.7046040892601013, train/logprobs = tensor([[-0.6740, -0.5702],
        [-0.7227, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042637804290279746
Epoch 0, Step 125: train/loss = 0.7012194395065308, train/raw-loss = 0.7010625004768372, train/logprobs = tensor([[-0.8878, -0.8477],
        [-0.9747, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039238500175997615
Epoch 0, Step 126: train/loss = 0.7193360328674316, train/raw-loss = 0.7192333340644836, train/logprobs = tensor([[-0.9081, -1.1483],
        [-0.9806, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025671455659903586
Epoch 0, Step 127: train/loss = 0.7098634243011475, train/raw-loss = 0.7097529172897339, train/logprobs = tensor([[-0.6843, -0.9011],
        [-0.7014, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002761510550044477
Epoch 0, Step 128: train/loss = 0.7458111047744751, train/raw-loss = 0.7455591559410095, train/logprobs = tensor([[-0.9322, -0.4717],
        [-0.9413, -0.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006299051456153393
Epoch 0, Step 129: train/loss = 0.7085395455360413, train/raw-loss = 0.7084543704986572, train/logprobs = tensor([[-0.7944, -0.5830],
        [-0.8122, -0.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021302001550793648
Epoch 0, Step 130: train/loss = 0.7089689373970032, train/raw-loss = 0.7085874080657959, train/logprobs = tensor([[-0.8543, -0.6849],
        [-0.9604, -0.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009538001613691449
Epoch 0, Step 131: train/loss = 0.6967441439628601, train/raw-loss = 0.6965751647949219, train/logprobs = tensor([[-0.6865, -0.7601],
        [-0.7409, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004223397118039429
Epoch 0, Step 132: train/loss = 0.695930004119873, train/raw-loss = 0.6958668231964111, train/logprobs = tensor([[-0.8269, -0.7742],
        [-0.9106, -0.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015795018407516181
Epoch 0, Step 133: train/loss = 0.6978944540023804, train/raw-loss = 0.697769820690155, train/logprobs = tensor([[-0.6339, -0.7514],
        [-0.7067, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003114917199127376
Epoch 0, Step 134: train/loss = 0.7719789743423462, train/raw-loss = 0.7718976140022278, train/logprobs = tensor([[-0.9579, -0.9077],
        [-1.0440, -0.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002034726203419268
Epoch 0, Step 135: train/loss = 0.6975239515304565, train/raw-loss = 0.6974930167198181, train/logprobs = tensor([[-0.5995, -0.6097],
        [-0.5826, -0.5967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.726557669229805e-05
Epoch 0, Step 136: train/loss = 0.7030093669891357, train/raw-loss = 0.7030009627342224, train/logprobs = tensor([[-0.7921, -0.7251],
        [-1.0779, -0.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.107411273755133e-05
Epoch 0, Step 137: train/loss = 0.7157313823699951, train/raw-loss = 0.7126659154891968, train/logprobs = tensor([[-0.5396, -0.8792],
        [-0.6024, -0.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007663751486688852
Epoch 0, Step 138: train/loss = 0.7018323540687561, train/raw-loss = 0.7017862796783447, train/logprobs = tensor([[-0.5572, -0.4722],
        [-0.6024, -0.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011515151709318161
Epoch 0, Step 139: train/loss = 0.7099138498306274, train/raw-loss = 0.709760844707489, train/logprobs = tensor([[-0.5281, -0.7151],
        [-0.5588, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038254231913015246
Epoch 0, Step 140: train/loss = 0.7171152830123901, train/raw-loss = 0.7170618772506714, train/logprobs = tensor([[-0.6000, -0.8317],
        [-0.5996, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013336364645510912
Epoch 0, Step 141: train/loss = 0.719696581363678, train/raw-loss = 0.7195438146591187, train/logprobs = tensor([[-0.5069, -0.8305],
        [-0.5592, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038184202276170254
Epoch 0, Step 142: train/loss = 0.700267493724823, train/raw-loss = 0.7000749111175537, train/logprobs = tensor([[-0.7514, -0.6394],
        [-0.8497, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004813592822756618
Epoch 0, Step 143: train/loss = 0.6865766048431396, train/raw-loss = 0.6855674982070923, train/logprobs = tensor([[-0.8281, -0.7976],
        [-1.3137, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002522846916690469
Epoch 0, Step 144: train/loss = 0.7200913429260254, train/raw-loss = 0.7195045351982117, train/logprobs = tensor([[-0.7802, -0.7667],
        [-0.8599, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001467087073251605
Epoch 0, Step 145: train/loss = 0.7076346278190613, train/raw-loss = 0.7075904607772827, train/logprobs = tensor([[-0.7955, -0.6414],
        [-0.8330, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011034245835617185
Epoch 0, Step 146: train/loss = 0.7666597366333008, train/raw-loss = 0.7664263248443604, train/logprobs = tensor([[-0.8513, -0.5502],
        [-0.9245, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005833985633216798
Epoch 0, Step 147: train/loss = 0.7038294672966003, train/raw-loss = 0.7036597728729248, train/logprobs = tensor([[-0.6294, -0.7354],
        [-0.7238, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004243024159222841
Epoch 0, Step 148: train/loss = 0.7073105573654175, train/raw-loss = 0.707304835319519, train/logprobs = tensor([[-0.6713, -0.4899],
        [-0.6745, -0.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.444376539438963e-05
Epoch 0, Step 149: train/loss = 0.6973913908004761, train/raw-loss = 0.6972682476043701, train/logprobs = tensor([[-0.7238, -0.7092],
        [-0.7905, -0.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030772265745326877
Epoch 0, Step 150: train/loss = 0.6958849430084229, train/raw-loss = 0.6958675384521484, train/logprobs = tensor([[-0.6843, -0.6554],
        [-0.7107, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.362617983133532e-05
Epoch 0, Step 151: train/loss = 0.6963754892349243, train/raw-loss = 0.6963591575622559, train/logprobs = tensor([[-0.7196, -0.7307],
        [-0.7441, -0.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.080807411810383e-05
Epoch 0, Step 152: train/loss = 0.7114303112030029, train/raw-loss = 0.7112398743629456, train/logprobs = tensor([[-0.7553, -0.5707],
        [-0.8469, -0.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004760552546940744
Epoch 0, Step 153: train/loss = 0.6958789229393005, train/raw-loss = 0.6958516240119934, train/logprobs = tensor([[-0.5508, -0.6685],
        [-0.6091, -0.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.831545033492148e-05
Epoch 0, Step 154: train/loss = 0.6961404085159302, train/raw-loss = 0.6958884000778198, train/logprobs = tensor([[-0.6747, -0.6270],
        [-0.7834, -0.5836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006299745291471481
Epoch 0, Step 155: train/loss = 0.7110339403152466, train/raw-loss = 0.7108930349349976, train/logprobs = tensor([[-0.5572, -0.7853],
        [-0.5686, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003521516628097743
Epoch 0, Step 156: train/loss = 0.7082457542419434, train/raw-loss = 0.7082180976867676, train/logprobs = tensor([[-0.5023, -0.6564],
        [-0.5314, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.910157389938831e-05
Epoch 0, Step 157: train/loss = 0.7332347631454468, train/raw-loss = 0.7307013869285583, train/logprobs = tensor([[-0.9202, -0.6519],
        [-0.9583, -0.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006333490367978811
Epoch 0, Step 158: train/loss = 0.7459573745727539, train/raw-loss = 0.7457650899887085, train/logprobs = tensor([[-1.0008, -0.5916],
        [-0.9996, -0.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004806974611710757
Epoch 0, Step 159: train/loss = 0.704997718334198, train/raw-loss = 0.704910397529602, train/logprobs = tensor([[-0.5825, -0.8702],
        [-0.5816, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002183749747928232
Epoch 0, Step 160: train/loss = 0.6955995559692383, train/raw-loss = 0.6953020095825195, train/logprobs = tensor([[-0.7797, -0.7232],
        [-0.8450, -0.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007439433829858899
Epoch 0, Step 161: train/loss = 0.6922617554664612, train/raw-loss = 0.6911098957061768, train/logprobs = tensor([[-0.6081, -0.6842],
        [-0.6709, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002879701554775238
Epoch 0, Step 162: train/loss = 0.7037999033927917, train/raw-loss = 0.7030579447746277, train/logprobs = tensor([[-0.8041, -0.8185],
        [-0.9006, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001854968024417758
Epoch 0, Step 163: train/loss = 0.7010517120361328, train/raw-loss = 0.7009767293930054, train/logprobs = tensor([[-0.8436, -0.7174],
        [-0.9908, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001874202280305326
Epoch 0, Step 164: train/loss = 0.710423469543457, train/raw-loss = 0.7102500200271606, train/logprobs = tensor([[-0.6746, -0.9577],
        [-0.7545, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043363167787902057
Epoch 0, Step 165: train/loss = 0.8082091808319092, train/raw-loss = 0.8080689907073975, train/logprobs = tensor([[-0.8523, -1.3743],
        [-0.9349, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003504875930957496
Epoch 0, Step 166: train/loss = 0.7086589932441711, train/raw-loss = 0.7085216045379639, train/logprobs = tensor([[-0.7872, -0.8380],
        [-0.8218, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003436573315411806
Epoch 0, Step 167: train/loss = 0.6998803019523621, train/raw-loss = 0.699576735496521, train/logprobs = tensor([[-0.6606, -0.7694],
        [-0.6984, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007589275483042002
Epoch 0, Step 168: train/loss = 0.6951855421066284, train/raw-loss = 0.6951431035995483, train/logprobs = tensor([[-0.6699, -0.7347],
        [-0.7138, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010584114352241158
Epoch 0, Step 169: train/loss = 0.6944406628608704, train/raw-loss = 0.6943522691726685, train/logprobs = tensor([[-0.5328, -0.5059],
        [-0.5509, -0.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022101355716586113
Epoch 0, Step 170: train/loss = 0.694969654083252, train/raw-loss = 0.6949045658111572, train/logprobs = tensor([[-0.7208, -0.6893],
        [-0.7537, -0.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016263927682302892
Epoch 0, Step 171: train/loss = 0.6978837847709656, train/raw-loss = 0.6974343061447144, train/logprobs = tensor([[-0.6003, -0.7308],
        [-0.6337, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011236219434067607
Epoch 0, Step 172: train/loss = 0.7250857353210449, train/raw-loss = 0.7250754833221436, train/logprobs = tensor([[-0.9582, -0.7759],
        [-1.0388, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5620116502977908e-05
Epoch 0, Step 173: train/loss = 0.7041007280349731, train/raw-loss = 0.7004460096359253, train/logprobs = tensor([[-0.6798, -0.9916],
        [-0.6458, -0.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009136884473264217
Epoch 0, Step 174: train/loss = 0.6896001100540161, train/raw-loss = 0.6869724988937378, train/logprobs = tensor([[-0.6135, -0.7516],
        [-0.6988, -0.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065691061317920685
Epoch 0, Step 175: train/loss = 0.6989676356315613, train/raw-loss = 0.6983932256698608, train/logprobs = tensor([[-0.8966, -0.9068],
        [-0.9987, -0.7132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014360245550051332
Epoch 0, Step 176: train/loss = 0.6996594667434692, train/raw-loss = 0.6992247104644775, train/logprobs = tensor([[-0.8005, -0.8086],
        [-0.8578, -0.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010867968667298555
Epoch 0, Step 177: train/loss = 0.696386992931366, train/raw-loss = 0.6962692737579346, train/logprobs = tensor([[-0.8387, -0.8157],
        [-0.9560, -0.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029430881841108203
Epoch 0, Step 178: train/loss = 0.686930239200592, train/raw-loss = 0.6748266220092773, train/logprobs = tensor([[-0.7014, -1.3696],
        [-0.8454, -0.7700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03025897964835167
Epoch 0, Step 179: train/loss = 0.6988224983215332, train/raw-loss = 0.698731005191803, train/logprobs = tensor([[-0.6046, -0.5516],
        [-0.5883, -0.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002287037204951048
Epoch 0, Step 180: train/loss = 0.7174191474914551, train/raw-loss = 0.7166703939437866, train/logprobs = tensor([[-0.7254, -0.6377],
        [-0.8255, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018719916697591543
Epoch 0, Step 181: train/loss = 0.7029663324356079, train/raw-loss = 0.7022508382797241, train/logprobs = tensor([[-0.6872, -0.7452],
        [-0.7170, -0.6234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017886394634842873
Epoch 0, Step 182: train/loss = 0.708336353302002, train/raw-loss = 0.7082568407058716, train/logprobs = tensor([[-0.8151, -0.9866],
        [-0.8279, -0.9729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019877060549333692
Epoch 0, Step 183: train/loss = 0.6997028589248657, train/raw-loss = 0.6988978385925293, train/logprobs = tensor([[-0.7165, -0.8355],
        [-0.7812, -0.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020125715527683496
Epoch 0, Step 184: train/loss = 0.7006587982177734, train/raw-loss = 0.7005399465560913, train/logprobs = tensor([[-0.7957, -0.7021],
        [-0.8438, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002970228670164943
Epoch 0, Step 185: train/loss = 0.6939204931259155, train/raw-loss = 0.6935173273086548, train/logprobs = tensor([[-0.7675, -1.0850],
        [-0.8005, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010079136118292809
Epoch 0, Step 186: train/loss = 0.7039848566055298, train/raw-loss = 0.703848659992218, train/logprobs = tensor([[-0.8949, -0.7613],
        [-0.9129, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003406641189940274
Epoch 0, Step 187: train/loss = 0.6946234703063965, train/raw-loss = 0.6936601400375366, train/logprobs = tensor([[-0.6596, -0.7473],
        [-0.7319, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024083168245851994
Epoch 0, Step 188: train/loss = 0.7037352323532104, train/raw-loss = 0.7036725282669067, train/logprobs = tensor([[-0.7177, -0.8115],
        [-0.7610, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015667901607230306
Epoch 0, Step 189: train/loss = 0.7056820392608643, train/raw-loss = 0.7055810689926147, train/logprobs = tensor([[-0.5385, -0.6660],
        [-0.6840, -0.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025229668244719505
Epoch 0, Step 190: train/loss = 0.6935015916824341, train/raw-loss = 0.693056046962738, train/logprobs = tensor([[-0.5611, -0.6622],
        [-0.6502, -0.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011138271074742079
Epoch 0, Step 191: train/loss = 0.6949875950813293, train/raw-loss = 0.6949843764305115, train/logprobs = tensor([[-0.7671, -0.7112],
        [-0.7462, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.908340194262564e-06
Epoch 0, Step 192: train/loss = 0.6938583850860596, train/raw-loss = 0.6936972737312317, train/logprobs = tensor([[-0.6291, -0.6023],
        [-0.6772, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040273688500747085
Epoch 0, Step 193: train/loss = 0.7055246233940125, train/raw-loss = 0.7050285339355469, train/logprobs = tensor([[-0.5764, -0.9429],
        [-0.7049, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012402416905388236
Epoch 0, Step 194: train/loss = 0.7198600769042969, train/raw-loss = 0.7152426242828369, train/logprobs = tensor([[-0.7562, -1.1623],
        [-0.9201, -0.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011543499305844307
Epoch 0, Step 195: train/loss = 0.7448427677154541, train/raw-loss = 0.7446934580802917, train/logprobs = tensor([[-1.0349, -0.8365],
        [-1.1096, -0.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037326620076783
Epoch 0, Step 196: train/loss = 0.6947050094604492, train/raw-loss = 0.6928147077560425, train/logprobs = tensor([[-0.9853, -0.9692],
        [-1.0291, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047258781269192696
Epoch 0, Step 197: train/loss = 0.7223557233810425, train/raw-loss = 0.7219020128250122, train/logprobs = tensor([[-0.6170, -0.9511],
        [-0.6616, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011342905927449465
Epoch 0, Step 198: train/loss = 0.7279376983642578, train/raw-loss = 0.7269511222839355, train/logprobs = tensor([[-1.2884, -1.1610],
        [-1.3163, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024663901422172785
Epoch 0, Step 199: train/loss = 0.7048062086105347, train/raw-loss = 0.7038100957870483, train/logprobs = tensor([[-0.8517, -0.8745],
        [-0.8958, -0.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024902429431676865
Epoch 0, Step 200: train/loss = 0.6953389644622803, train/raw-loss = 0.6950150728225708, train/logprobs = tensor([[-0.7790, -0.8264],
        [-0.7990, -0.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008097344543784857
Epoch 0, Step 201: train/loss = 0.7013261318206787, train/raw-loss = 0.6978374719619751, train/logprobs = tensor([[-0.7667, -1.2534],
        [-0.9376, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008721644058823586
Epoch 0, Step 202: train/loss = 0.6966313719749451, train/raw-loss = 0.6962719559669495, train/logprobs = tensor([[-0.9913, -0.9090],
        [-0.9992, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008984623709693551
Epoch 0, Step 203: train/loss = 0.6991032361984253, train/raw-loss = 0.6973340511322021, train/logprobs = tensor([[-0.7133, -0.9120],
        [-0.8059, -0.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044227177277207375
Epoch 0, Step 204: train/loss = 0.7051283717155457, train/raw-loss = 0.7030948400497437, train/logprobs = tensor([[-0.8093, -1.0507],
        [-0.8536, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005083941854536533
Epoch 0, Step 205: train/loss = 0.7008254528045654, train/raw-loss = 0.7007845640182495, train/logprobs = tensor([[-0.8333, -0.6875],
        [-0.8835, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010236349771730602
Epoch 0, Step 206: train/loss = 0.6979354023933411, train/raw-loss = 0.6979104280471802, train/logprobs = tensor([[-0.6244, -0.5078],
        [-0.6906, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.228975689737126e-05
Epoch 0, Step 207: train/loss = 0.6970521807670593, train/raw-loss = 0.6966651082038879, train/logprobs = tensor([[-0.6962, -0.9313],
        [-0.7470, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009676959016360343
Epoch 0, Step 208: train/loss = 0.6964163184165955, train/raw-loss = 0.6960710287094116, train/logprobs = tensor([[-0.6724, -0.6922],
        [-0.6613, -0.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008631161181256175
Epoch 0, Step 209: train/loss = 0.7541988492012024, train/raw-loss = 0.753669261932373, train/logprobs = tensor([[-0.8045, -1.1207],
        [-0.8073, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013238515239208937
Epoch 0, Step 210: train/loss = 0.6939700841903687, train/raw-loss = 0.6939509510993958, train/logprobs = tensor([[-0.6651, -0.6929],
        [-0.6752, -0.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.782975520356558e-05
Epoch 0, Step 211: train/loss = 0.7001773715019226, train/raw-loss = 0.7000151872634888, train/logprobs = tensor([[-0.7268, -0.7044],
        [-0.7638, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004056359175592661
Epoch 0, Step 212: train/loss = 0.708667516708374, train/raw-loss = 0.7069920897483826, train/logprobs = tensor([[-0.7187, -0.9350],
        [-0.7844, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004188652150332928
Epoch 0, Step 213: train/loss = 0.7984134554862976, train/raw-loss = 0.7934069633483887, train/logprobs = tensor([[-0.8188, -1.3313],
        [-0.9285, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01251630112528801
Epoch 0, Step 214: train/loss = 0.6973033547401428, train/raw-loss = 0.6972532272338867, train/logprobs = tensor([[-0.6151, -0.5213],
        [-0.7345, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012529813102446496
Epoch 0, Step 215: train/loss = 0.7023836374282837, train/raw-loss = 0.7018676996231079, train/logprobs = tensor([[-0.6460, -0.8522],
        [-0.6494, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001289987238124013
Epoch 0, Step 216: train/loss = 0.7160806655883789, train/raw-loss = 0.7137143611907959, train/logprobs = tensor([[-0.8235, -1.0453],
        [-0.8212, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059157987125217915
Epoch 0, Step 217: train/loss = 0.6949015855789185, train/raw-loss = 0.6945613622665405, train/logprobs = tensor([[-0.6923, -0.6516],
        [-0.8279, -0.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000850504613481462
Epoch 0, Step 218: train/loss = 0.7117087841033936, train/raw-loss = 0.7112688422203064, train/logprobs = tensor([[-0.9458, -0.7766],
        [-0.9979, -0.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001099954592064023
Epoch 0, Step 219: train/loss = 0.714878499507904, train/raw-loss = 0.7144057154655457, train/logprobs = tensor([[-0.6635, -0.9564],
        [-0.8375, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011818816419690847
Epoch 0, Step 220: train/loss = 0.7010621428489685, train/raw-loss = 0.6991872787475586, train/logprobs = tensor([[-0.7975, -1.0284],
        [-0.8343, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00468717236071825
Epoch 0, Step 221: train/loss = 0.6959080100059509, train/raw-loss = 0.69443678855896, train/logprobs = tensor([[-0.7924, -0.7784],
        [-0.8019, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036781993694603443
Epoch 0, Step 222: train/loss = 0.6942991018295288, train/raw-loss = 0.6937242150306702, train/logprobs = tensor([[-0.6984, -0.7109],
        [-0.8031, -0.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014370367862284184
Epoch 0, Step 223: train/loss = 0.7048702239990234, train/raw-loss = 0.7044262886047363, train/logprobs = tensor([[-0.7434, -0.6241],
        [-0.8143, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00110981788020581
Epoch 0, Step 224: train/loss = 0.740786075592041, train/raw-loss = 0.7386784553527832, train/logprobs = tensor([[-1.1870, -1.1428],
        [-1.2934, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005269169807434082
Epoch 0, Step 225: train/loss = 0.7281928062438965, train/raw-loss = 0.7268080711364746, train/logprobs = tensor([[-0.9073, -1.2062],
        [-1.0653, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034616587217897177
Epoch 0, Step 226: train/loss = 0.7156882286071777, train/raw-loss = 0.7149467468261719, train/logprobs = tensor([[-0.9486, -0.8317],
        [-1.0399, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018538222648203373
Epoch 0, Step 227: train/loss = 0.7112042307853699, train/raw-loss = 0.7070761919021606, train/logprobs = tensor([[-0.6649, -1.2789],
        [-0.7305, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010320156812667847
Epoch 0, Step 228: train/loss = 0.6882338523864746, train/raw-loss = 0.678908109664917, train/logprobs = tensor([[-1.0303, -1.4558],
        [-0.9347, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023314138874411583
Epoch 0, Step 229: train/loss = 0.7003218531608582, train/raw-loss = 0.6996465921401978, train/logprobs = tensor([[-0.7190, -1.0075],
        [-0.7174, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001688286429271102
Epoch 0, Step 230: train/loss = 0.7304421663284302, train/raw-loss = 0.7258453965187073, train/logprobs = tensor([[-0.6175, -1.3524],
        [-0.6343, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011491945013403893
Epoch 0, Step 231: train/loss = 0.6962101459503174, train/raw-loss = 0.6957718729972839, train/logprobs = tensor([[-0.5776, -0.6880],
        [-0.6038, -0.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010956573532894254
Epoch 0, Step 232: train/loss = 0.7062218189239502, train/raw-loss = 0.7059077620506287, train/logprobs = tensor([[-0.7508, -0.9136],
        [-0.7866, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007852135458961129
Epoch 0, Step 233: train/loss = 0.693742573261261, train/raw-loss = 0.6849251985549927, train/logprobs = tensor([[-0.7630, -1.1688],
        [-0.8328, -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022043323144316673
Epoch 0, Step 234: train/loss = 0.7097695469856262, train/raw-loss = 0.7092558145523071, train/logprobs = tensor([[-0.9599, -0.7795],
        [-1.0496, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012842994183301926
Epoch 0, Step 235: train/loss = 0.6941155791282654, train/raw-loss = 0.6934777498245239, train/logprobs = tensor([[-0.7402, -0.7718],
        [-0.8132, -0.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015946491621434689
Epoch 0, Step 236: train/loss = 0.7169197797775269, train/raw-loss = 0.7037715911865234, train/logprobs = tensor([[-1.1147, -1.8319],
        [-0.9418, -0.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03287046402692795
Epoch 0, Step 237: train/loss = 0.6961439847946167, train/raw-loss = 0.6938067674636841, train/logprobs = tensor([[-0.8144, -0.9140],
        [-0.8049, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005843030288815498
Epoch 0, Step 238: train/loss = 0.710933268070221, train/raw-loss = 0.7083896398544312, train/logprobs = tensor([[-0.6468, -0.8272],
        [-0.6717, -0.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006358984857797623
Epoch 0, Step 239: train/loss = 0.7053921818733215, train/raw-loss = 0.7049028873443604, train/logprobs = tensor([[-0.8033, -0.7504],
        [-0.8515, -0.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012234655441716313
Epoch 0, Step 240: train/loss = 0.6983358263969421, train/raw-loss = 0.6982724666595459, train/logprobs = tensor([[-0.9303, -0.8459],
        [-0.8934, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015835862723179162
Epoch 0, Step 241: train/loss = 0.7558385133743286, train/raw-loss = 0.7526931762695312, train/logprobs = tensor([[-1.0032, -1.1956],
        [-1.0964, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007863285951316357
Epoch 0, Step 242: train/loss = 0.7024246454238892, train/raw-loss = 0.6878529787063599, train/logprobs = tensor([[-0.8639, -1.4727],
        [-1.0171, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036429163068532944
Epoch 0, Step 243: train/loss = 0.7073113918304443, train/raw-loss = 0.7045696973800659, train/logprobs = tensor([[-0.9832, -1.4339],
        [-1.0647, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006854199338704348
Epoch 0, Step 244: train/loss = 0.6954358816146851, train/raw-loss = 0.6932060718536377, train/logprobs = tensor([[-0.8555, -1.1140],
        [-0.8228, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005574540235102177
Epoch 0, Step 245: train/loss = 0.7399129271507263, train/raw-loss = 0.7394938468933105, train/logprobs = tensor([[-0.7237, -1.1564],
        [-0.7832, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010475729359313846
Epoch 0, Step 246: train/loss = 0.7259877324104309, train/raw-loss = 0.723102331161499, train/logprobs = tensor([[-1.0277, -0.7160],
        [-1.2458, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007213530596345663
Epoch 0, Step 247: train/loss = 0.7091262340545654, train/raw-loss = 0.7087565660476685, train/logprobs = tensor([[-0.6881, -0.9007],
        [-0.7348, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009242137894034386
Epoch 0, Step 248: train/loss = 0.7186200618743896, train/raw-loss = 0.7174630761146545, train/logprobs = tensor([[-0.9782, -1.4933],
        [-0.9506, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028924839571118355
Epoch 0, Step 249: train/loss = 0.6951556205749512, train/raw-loss = 0.6951390504837036, train/logprobs = tensor([[-0.6359, -0.7901],
        [-0.6236, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.140094097238034e-05
Epoch 0, Step 250: train/loss = 0.6950255632400513, train/raw-loss = 0.6940281391143799, train/logprobs = tensor([[-0.6855, -0.8621],
        [-0.8178, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00249366438947618
Epoch 0, Step 251: train/loss = 0.7286019921302795, train/raw-loss = 0.7258737683296204, train/logprobs = tensor([[-0.8755, -1.3853],
        [-0.9456, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0068204584531486034
Epoch 0, Step 252: train/loss = 0.7144697308540344, train/raw-loss = 0.7143510580062866, train/logprobs = tensor([[-0.7255, -0.9228],
        [-0.7586, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002966375323012471
Epoch 0, Step 253: train/loss = 0.7061041593551636, train/raw-loss = 0.7028926610946655, train/logprobs = tensor([[-0.9633, -0.8465],
        [-1.0541, -0.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008028768002986908
Epoch 0, Step 254: train/loss = 0.7161504030227661, train/raw-loss = 0.7137229442596436, train/logprobs = tensor([[-0.8356, -1.3742],
        [-0.9181, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006068683695048094
Epoch 0, Step 255: train/loss = 0.7140757441520691, train/raw-loss = 0.7125701904296875, train/logprobs = tensor([[-0.6082, -0.7533],
        [-0.8388, -0.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037637860514223576
Epoch 0, Step 256: train/loss = 0.6965630054473877, train/raw-loss = 0.6960886716842651, train/logprobs = tensor([[-1.1011, -1.0585],
        [-0.9927, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011858762009069324
Epoch 0, Step 257: train/loss = 0.6929454803466797, train/raw-loss = 0.6899377703666687, train/logprobs = tensor([[-0.9873, -1.2833],
        [-0.9328, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007519317790865898
Epoch 0, Step 258: train/loss = 0.6928996443748474, train/raw-loss = 0.6832569241523743, train/logprobs = tensor([[-0.8359, -1.3821],
        [-1.1678, -0.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024106763303279877
Epoch 0, Step 259: train/loss = 0.6953153610229492, train/raw-loss = 0.6939542889595032, train/logprobs = tensor([[-0.7095, -0.9384],
        [-0.6981, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034027965739369392
Epoch 0, Step 260: train/loss = 0.713782787322998, train/raw-loss = 0.7078429460525513, train/logprobs = tensor([[-0.8327, -1.3035],
        [-0.8815, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01484951563179493
Epoch 0, Step 261: train/loss = 0.7113745808601379, train/raw-loss = 0.7108786106109619, train/logprobs = tensor([[-0.8314, -1.1724],
        [-0.8496, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012398381950333714
Epoch 0, Step 262: train/loss = 0.7158617973327637, train/raw-loss = 0.7119957208633423, train/logprobs = tensor([[-1.1090, -1.1800],
        [-1.1552, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00966518372297287
Epoch 0, Step 263: train/loss = 0.6945019960403442, train/raw-loss = 0.6944977045059204, train/logprobs = tensor([[-0.5632, -0.5611],
        [-0.5701, -0.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0574218322290108e-05
Epoch 0, Step 264: train/loss = 0.7311922311782837, train/raw-loss = 0.7279324531555176, train/logprobs = tensor([[-0.7243, -1.3484],
        [-0.7691, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008149417117238045
Epoch 0, Step 265: train/loss = 0.7227066159248352, train/raw-loss = 0.7197142243385315, train/logprobs = tensor([[-0.9447, -1.4904],
        [-0.9140, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007481047417968512
Epoch 0, Step 266: train/loss = 0.7347584366798401, train/raw-loss = 0.7313074469566345, train/logprobs = tensor([[-1.0486, -1.2024],
        [-1.0851, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008627363480627537
Epoch 0, Step 267: train/loss = 0.699898362159729, train/raw-loss = 0.6992778182029724, train/logprobs = tensor([[-0.7689, -0.9711],
        [-0.7059, -0.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015513768885284662
Epoch 0, Step 268: train/loss = 0.8187176585197449, train/raw-loss = 0.8181631565093994, train/logprobs = tensor([[-0.9528, -1.7595],
        [-0.7184, -1.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013861771440133452
Epoch 0, Step 269: train/loss = 0.6979119181632996, train/raw-loss = 0.6950244307518005, train/logprobs = tensor([[-0.8003, -1.1682],
        [-0.8066, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007218754384666681
Epoch 0, Step 270: train/loss = 0.716722846031189, train/raw-loss = 0.7142011523246765, train/logprobs = tensor([[-0.6178, -1.1669],
        [-0.6064, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006304049864411354
Epoch 0, Step 271: train/loss = 0.7015079259872437, train/raw-loss = 0.7012301683425903, train/logprobs = tensor([[-1.1047, -1.0204],
        [-1.1296, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006945680361241102
Epoch 0, Step 272: train/loss = 0.6980079412460327, train/raw-loss = 0.6974859237670898, train/logprobs = tensor([[-0.9489, -0.8165],
        [-1.0015, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013047961983829737
Epoch 0, Step 273: train/loss = 0.6935850381851196, train/raw-loss = 0.6906064748764038, train/logprobs = tensor([[-0.8092, -1.0251],
        [-0.8625, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00744650699198246
Epoch 0, Step 274: train/loss = 0.8177100419998169, train/raw-loss = 0.8047825694084167, train/logprobs = tensor([[-0.8139, -1.7829],
        [-0.8251, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03231886401772499
Epoch 0, Step 275: train/loss = 0.6988127827644348, train/raw-loss = 0.6983181238174438, train/logprobs = tensor([[-0.7221, -0.9133],
        [-0.7269, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012367512099444866
Epoch 0, Step 276: train/loss = 0.7148360013961792, train/raw-loss = 0.7130073308944702, train/logprobs = tensor([[-0.8271, -1.0067],
        [-0.8338, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00457184761762619
Epoch 0, Step 277: train/loss = 0.6930892467498779, train/raw-loss = 0.6927163600921631, train/logprobs = tensor([[-1.0595, -1.1539],
        [-0.8313, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009320402750745416
Epoch 0, Step 278: train/loss = 0.6978809833526611, train/raw-loss = 0.6942214965820312, train/logprobs = tensor([[-0.8145, -1.1834],
        [-0.7788, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00914863683283329
Epoch 0, Step 279: train/loss = 0.6938957571983337, train/raw-loss = 0.6935672760009766, train/logprobs = tensor([[-1.0824, -1.2660],
        [-1.1624, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008211625972762704
Epoch 0, Step 280: train/loss = 0.7159847021102905, train/raw-loss = 0.714091420173645, train/logprobs = tensor([[-0.7550, -1.0143],
        [-0.9116, -0.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00473335525020957
Epoch 0, Step 281: train/loss = 0.6940653920173645, train/raw-loss = 0.6920995712280273, train/logprobs = tensor([[-1.1783, -1.4513],
        [-1.0511, -0.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004914548248052597
Epoch 0, Step 282: train/loss = 0.6996903419494629, train/raw-loss = 0.6996488571166992, train/logprobs = tensor([[-0.9307, -0.8533],
        [-0.8068, -0.7337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010351116361562163
Epoch 0, Step 283: train/loss = 0.6861164569854736, train/raw-loss = 0.6824264526367188, train/logprobs = tensor([[-1.0009, -1.1779],
        [-1.1756, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009225063025951385
Epoch 0, Step 284: train/loss = 0.7007341980934143, train/raw-loss = 0.7006151676177979, train/logprobs = tensor([[-0.7844, -0.6279],
        [-0.7419, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029746678774245083
Epoch 0, Step 285: train/loss = 0.7080396413803101, train/raw-loss = 0.7065942883491516, train/logprobs = tensor([[-1.4026, -1.3110],
        [-1.3080, -0.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036134563852101564
Epoch 0, Step 286: train/loss = 0.694291889667511, train/raw-loss = 0.694218635559082, train/logprobs = tensor([[-0.6416, -0.6337],
        [-0.5182, -0.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018325558630749583
Epoch 0, Step 287: train/loss = 0.7269055247306824, train/raw-loss = 0.7164912819862366, train/logprobs = tensor([[-0.9366, -1.4897],
        [-0.8564, -0.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026035601273179054
Epoch 0, Step 288: train/loss = 0.6949341297149658, train/raw-loss = 0.6824275255203247, train/logprobs = tensor([[-0.9254, -1.4793],
        [-1.0703, -1.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031266432255506516
Epoch 0, Step 289: train/loss = 0.6976761817932129, train/raw-loss = 0.6957588195800781, train/logprobs = tensor([[-0.8772, -1.0911],
        [-0.9970, -0.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004793261643499136
Epoch 0, Step 290: train/loss = 0.7213128805160522, train/raw-loss = 0.720547080039978, train/logprobs = tensor([[-1.1281, -0.8644],
        [-1.1242, -0.7611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019142614910379052
Epoch 0, Step 291: train/loss = 0.6950675249099731, train/raw-loss = 0.6932964324951172, train/logprobs = tensor([[-0.9230, -1.1816],
        [-0.9333, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004427697975188494
Epoch 0, Step 292: train/loss = 0.7009718418121338, train/raw-loss = 0.6993599534034729, train/logprobs = tensor([[-0.6033, -0.8705],
        [-0.6528, -0.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004029684700071812
Epoch 0, Step 293: train/loss = 0.6901118159294128, train/raw-loss = 0.6839543581008911, train/logprobs = tensor([[-0.8121, -0.9370],
        [-0.8871, -0.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015393683686852455
Epoch 0, Step 294: train/loss = 0.7015078067779541, train/raw-loss = 0.6968098878860474, train/logprobs = tensor([[-0.9436, -1.3876],
        [-0.9703, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011744766496121883
Epoch 0, Step 295: train/loss = 0.7054262161254883, train/raw-loss = 0.7051301002502441, train/logprobs = tensor([[-0.8162, -0.7236],
        [-0.8202, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007403283379971981
Epoch 0, Step 296: train/loss = 0.6943204402923584, train/raw-loss = 0.6932417750358582, train/logprobs = tensor([[-0.9178, -0.9743],
        [-0.9949, -0.9101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026965292636305094
Epoch 0, Step 297: train/loss = 0.7080242037773132, train/raw-loss = 0.7072400450706482, train/logprobs = tensor([[-1.0163, -1.2193],
        [-1.1902, -1.1892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019605462439358234
Epoch 0, Step 298: train/loss = 0.68758225440979, train/raw-loss = 0.6771647334098816, train/logprobs = tensor([[-0.8627, -1.4044],
        [-0.9740, -0.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02604379504919052
Epoch 0, Step 299: train/loss = 0.6952835321426392, train/raw-loss = 0.6945105791091919, train/logprobs = tensor([[-0.6938, -0.7325],
        [-0.7416, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019322556909173727
Epoch 0, Step 300: train/loss = 0.7313690185546875, train/raw-loss = 0.7055408358573914, train/logprobs = tensor([[-0.7921, -1.6670],
        [-0.9625, -0.6232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645703375339508
Epoch 0, Step 301: train/loss = 0.6998956799507141, train/raw-loss = 0.6994380354881287, train/logprobs = tensor([[-0.8441, -0.9029],
        [-0.7913, -0.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011441236129030585
Epoch 0, Step 302: train/loss = 0.6988699436187744, train/raw-loss = 0.6974475383758545, train/logprobs = tensor([[-0.9330, -0.8773],
        [-1.0463, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035559432581067085
Epoch 0, Step 303: train/loss = 0.6945876479148865, train/raw-loss = 0.6935100555419922, train/logprobs = tensor([[-0.8957, -1.1304],
        [-0.9436, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002693967893719673
Epoch 0, Step 304: train/loss = 0.7070446014404297, train/raw-loss = 0.7011275291442871, train/logprobs = tensor([[-0.8889, -1.2458],
        [-0.9925, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014792654663324356
Epoch 0, Step 305: train/loss = 0.7176333665847778, train/raw-loss = 0.7171307802200317, train/logprobs = tensor([[-1.0148, -1.1907],
        [-0.9836, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012562474003061652
Epoch 0, Step 306: train/loss = 0.6961714625358582, train/raw-loss = 0.6952108144760132, train/logprobs = tensor([[-0.8218, -0.8865],
        [-0.9517, -0.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024017090909183025
Epoch 0, Step 307: train/loss = 0.6998167634010315, train/raw-loss = 0.6975810527801514, train/logprobs = tensor([[-0.8359, -0.9382],
        [-0.9575, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00558928307145834
Epoch 0, Step 308: train/loss = 0.6923031210899353, train/raw-loss = 0.6903002858161926, train/logprobs = tensor([[-0.6701, -0.8387],
        [-0.7624, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005007200874388218
Epoch 0, Step 309: train/loss = 0.7097039818763733, train/raw-loss = 0.6789015531539917, train/logprobs = tensor([[-0.9756, -1.8713],
        [-1.1191, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07700613141059875
Epoch 0, Step 310: train/loss = 0.6963002681732178, train/raw-loss = 0.6937328577041626, train/logprobs = tensor([[-0.7821, -1.0055],
        [-0.9123, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006418383214622736
Epoch 0, Step 311: train/loss = 0.6992204189300537, train/raw-loss = 0.6983013153076172, train/logprobs = tensor([[-0.8198, -0.7606],
        [-0.8035, -0.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002297858940437436
Epoch 0, Step 312: train/loss = 0.7043084502220154, train/raw-loss = 0.6961987018585205, train/logprobs = tensor([[-0.8390, -1.3411],
        [-0.9132, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020274396985769272
Epoch 0, Step 313: train/loss = 0.6975763440132141, train/raw-loss = 0.6974307298660278, train/logprobs = tensor([[-0.7488, -0.7130],
        [-0.9172, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036408263258636
Epoch 0, Step 314: train/loss = 0.7016656398773193, train/raw-loss = 0.6991880536079407, train/logprobs = tensor([[-1.1150, -1.2950],
        [-1.2295, -1.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00619392329826951
Epoch 0, Step 315: train/loss = 0.7083146572113037, train/raw-loss = 0.707046389579773, train/logprobs = tensor([[-0.7853, -1.1073],
        [-1.0284, -1.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031708241440355778
Epoch 0, Step 316: train/loss = 0.7235091328620911, train/raw-loss = 0.7216140627861023, train/logprobs = tensor([[-1.1180, -0.8826],
        [-1.3146, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047377352602779865
Epoch 0, Step 317: train/loss = 0.6950784921646118, train/raw-loss = 0.6942629814147949, train/logprobs = tensor([[-0.9007, -0.9717],
        [-0.9793, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020386811811476946
Epoch 0, Step 318: train/loss = 0.6873692274093628, train/raw-loss = 0.6823984384536743, train/logprobs = tensor([[-0.8783, -1.1041],
        [-1.0317, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012427114881575108
Epoch 0, Step 319: train/loss = 0.7056761980056763, train/raw-loss = 0.7008140683174133, train/logprobs = tensor([[-1.2500, -1.6206],
        [-1.0035, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01215532049536705
Epoch 0, Step 320: train/loss = 0.707481861114502, train/raw-loss = 0.7051239609718323, train/logprobs = tensor([[-0.9709, -1.2395],
        [-1.0288, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00589471822604537
Epoch 0, Step 321: train/loss = 0.6942409873008728, train/raw-loss = 0.6903034448623657, train/logprobs = tensor([[-0.8153, -0.8750],
        [-0.8701, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009843735955655575
Epoch 0, Step 322: train/loss = 0.702211320400238, train/raw-loss = 0.7011334896087646, train/logprobs = tensor([[-1.0211, -1.1877],
        [-1.0140, -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026944593992084265
Epoch 0, Step 323: train/loss = 0.6981278657913208, train/raw-loss = 0.6965949535369873, train/logprobs = tensor([[-0.8421, -0.8275],
        [-0.9677, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003832255955785513
Epoch 0, Step 324: train/loss = 0.7453757524490356, train/raw-loss = 0.7426668405532837, train/logprobs = tensor([[-1.0119, -1.1349],
        [-1.2693, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006772375199943781
Epoch 0, Step 325: train/loss = 0.6955162882804871, train/raw-loss = 0.6952536106109619, train/logprobs = tensor([[-0.9263, -0.9315],
        [-1.0999, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000656828167848289
Epoch 0, Step 326: train/loss = 0.6910731196403503, train/raw-loss = 0.6812689304351807, train/logprobs = tensor([[-1.3024, -1.6925],
        [-1.5082, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024510400369763374
Epoch 0, Step 327: train/loss = 0.7005614042282104, train/raw-loss = 0.699726402759552, train/logprobs = tensor([[-0.9412, -0.9321],
        [-1.0132, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002087601227685809
Epoch 0, Step 328: train/loss = 0.727552056312561, train/raw-loss = 0.7146514654159546, train/logprobs = tensor([[-1.0748, -1.3165],
        [-1.4483, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03225143998861313
Epoch 0, Step 329: train/loss = 0.6970984935760498, train/raw-loss = 0.6946967244148254, train/logprobs = tensor([[-0.7794, -0.7714],
        [-0.8053, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006004282273352146
Epoch 0, Step 330: train/loss = 0.7205977439880371, train/raw-loss = 0.7179020643234253, train/logprobs = tensor([[-0.7854, -1.2525],
        [-0.9747, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006739006377756596
Epoch 0, Step 331: train/loss = 0.7177184820175171, train/raw-loss = 0.7148392200469971, train/logprobs = tensor([[-0.9725, -0.7902],
        [-1.0505, -0.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007198134902864695
Epoch 0, Step 332: train/loss = 0.6909583806991577, train/raw-loss = 0.6887772679328918, train/logprobs = tensor([[-1.0030, -1.0581],
        [-1.1601, -0.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005452671088278294
Epoch 0, Step 333: train/loss = 0.7011529207229614, train/raw-loss = 0.7000478506088257, train/logprobs = tensor([[-0.8110, -0.9708],
        [-0.8396, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002762644784525037
Epoch 0, Step 334: train/loss = 0.7012375593185425, train/raw-loss = 0.7005548477172852, train/logprobs = tensor([[-0.9489, -1.2451],
        [-1.1674, -1.1735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017066732980310917
Epoch 0, Step 335: train/loss = 0.6913403868675232, train/raw-loss = 0.6860398054122925, train/logprobs = tensor([[-1.0887, -1.2051],
        [-1.3434, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013251472264528275
Epoch 0, Step 336: train/loss = 0.7059776186943054, train/raw-loss = 0.6921437978744507, train/logprobs = tensor([[-0.9070, -1.3907],
        [-1.0490, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034584492444992065
Epoch 0, Step 337: train/loss = 0.699373185634613, train/raw-loss = 0.6981272101402283, train/logprobs = tensor([[-0.9998, -1.3080],
        [-1.1518, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031150206923484802
Epoch 0, Step 338: train/loss = 0.6915574073791504, train/raw-loss = 0.6863009333610535, train/logprobs = tensor([[-1.0018, -1.1138],
        [-1.3014, -0.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013141224160790443
Epoch 0, Step 339: train/loss = 0.7166821956634521, train/raw-loss = 0.7161911725997925, train/logprobs = tensor([[-0.9808, -0.8059],
        [-1.0873, -0.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012276037596166134
Epoch 0, Step 340: train/loss = 0.6944001913070679, train/raw-loss = 0.6942594051361084, train/logprobs = tensor([[-0.9615, -0.8930],
        [-0.9902, -0.8706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003521576290950179
Epoch 0, Step 341: train/loss = 0.6866462826728821, train/raw-loss = 0.6834133267402649, train/logprobs = tensor([[-0.8375, -1.0093],
        [-1.1823, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008082294836640358
Epoch 0, Step 342: train/loss = 0.7115907073020935, train/raw-loss = 0.7081190943717957, train/logprobs = tensor([[-1.1330, -1.0806],
        [-1.2184, -0.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00867899414151907
Epoch 0, Step 343: train/loss = 0.6989510655403137, train/raw-loss = 0.6982107162475586, train/logprobs = tensor([[-0.9495, -0.8993],
        [-1.0882, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018508939538151026
Epoch 0, Step 344: train/loss = 0.7028915286064148, train/raw-loss = 0.7009491920471191, train/logprobs = tensor([[-1.1085, -1.1110],
        [-1.2683, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004855911247432232
Epoch 0, Step 345: train/loss = 0.6962026953697205, train/raw-loss = 0.694380521774292, train/logprobs = tensor([[-1.1467, -1.1555],
        [-1.3725, -1.0542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004555244464427233
Epoch 0, Step 346: train/loss = 0.7449913024902344, train/raw-loss = 0.7419627904891968, train/logprobs = tensor([[-0.9477, -1.0561],
        [-1.0960, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0075712669640779495
Epoch 0, Step 347: train/loss = 0.7190327048301697, train/raw-loss = 0.7138519883155823, train/logprobs = tensor([[-1.0377, -0.9322],
        [-1.3754, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01295169722288847
Epoch 0, Step 348: train/loss = 0.6939102411270142, train/raw-loss = 0.6936602592468262, train/logprobs = tensor([[-1.2345, -1.2097],
        [-1.2726, -1.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006249747239053249
Epoch 0, Step 349: train/loss = 0.6979790329933167, train/raw-loss = 0.6973626613616943, train/logprobs = tensor([[-0.8599, -0.7910],
        [-0.9174, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015410498017445207
Epoch 0, Step 350: train/loss = 0.698733925819397, train/raw-loss = 0.6986081004142761, train/logprobs = tensor([[-0.9661, -0.8896],
        [-1.0417, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003146544913761318
Epoch 0, Step 351: train/loss = 0.7017911672592163, train/raw-loss = 0.6994956731796265, train/logprobs = tensor([[-1.0687, -1.0121],
        [-1.2998, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005738668143749237
Epoch 0, Step 352: train/loss = 0.6957515478134155, train/raw-loss = 0.6894826889038086, train/logprobs = tensor([[-1.2289, -1.4086],
        [-1.3001, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015671925619244576
Epoch 0, Step 353: train/loss = 0.6778367161750793, train/raw-loss = 0.6577714085578918, train/logprobs = tensor([[-0.8358, -1.3508],
        [-1.0737, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050163205713033676
Epoch 0, Step 354: train/loss = 0.7204136848449707, train/raw-loss = 0.7181433439254761, train/logprobs = tensor([[-1.0681, -1.1646],
        [-1.3043, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005675978492945433
Epoch 0, Step 355: train/loss = 0.7171682119369507, train/raw-loss = 0.7117428779602051, train/logprobs = tensor([[-1.5504, -1.6845],
        [-1.2270, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013563377782702446
Epoch 0, Step 356: train/loss = 0.7059668302536011, train/raw-loss = 0.7034891247749329, train/logprobs = tensor([[-1.3753, -1.4435],
        [-1.4443, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006194159388542175
Epoch 0, Step 357: train/loss = 0.700234055519104, train/raw-loss = 0.6920892000198364, train/logprobs = tensor([[-0.9062, -1.4619],
        [-0.9511, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020362092182040215
Epoch 0, Step 358: train/loss = 0.7096983194351196, train/raw-loss = 0.7055066823959351, train/logprobs = tensor([[-0.7809, -1.1729],
        [-1.0423, -0.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010478912852704525
Epoch 0, Step 359: train/loss = 0.6976927518844604, train/raw-loss = 0.6903960704803467, train/logprobs = tensor([[-0.8490, -1.3123],
        [-1.1655, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018241792917251587
Epoch 0, Step 360: train/loss = 0.7222509384155273, train/raw-loss = 0.711797297000885, train/logprobs = tensor([[-1.1334, -1.9313],
        [-1.4216, -1.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026134027168154716
Epoch 0, Step 361: train/loss = 0.7174093723297119, train/raw-loss = 0.7142922878265381, train/logprobs = tensor([[-1.2789, -0.9899],
        [-1.0832, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0077926781959831715
Epoch 0, Step 362: train/loss = 0.6950130462646484, train/raw-loss = 0.6946614980697632, train/logprobs = tensor([[-1.0114, -1.0418],
        [-1.1010, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000879122584592551
Epoch 0, Step 363: train/loss = 0.703865647315979, train/raw-loss = 0.7011126279830933, train/logprobs = tensor([[-0.9160, -1.3323],
        [-0.8914, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006882485933601856
Epoch 0, Step 364: train/loss = 0.7020777463912964, train/raw-loss = 0.6971715688705444, train/logprobs = tensor([[-1.0020, -0.8888],
        [-1.4616, -0.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012265529483556747
Epoch 0, Step 365: train/loss = 0.6933097839355469, train/raw-loss = 0.6908640265464783, train/logprobs = tensor([[-0.8597, -0.9932],
        [-0.9093, -0.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006114238873124123
Epoch 0, Step 366: train/loss = 0.7058007717132568, train/raw-loss = 0.7024630308151245, train/logprobs = tensor([[-1.1197, -1.1371],
        [-1.2553, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008344290778040886
Epoch 0, Step 367: train/loss = 0.6945747137069702, train/raw-loss = 0.689532458782196, train/logprobs = tensor([[-0.8152, -1.2357],
        [-0.8601, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012605484575033188
Epoch 0, Step 368: train/loss = 0.6924824714660645, train/raw-loss = 0.688772976398468, train/logprobs = tensor([[-1.1564, -1.3978],
        [-1.0309, -0.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009273707866668701
Epoch 0, Step 369: train/loss = 0.6952927112579346, train/raw-loss = 0.6937307715415955, train/logprobs = tensor([[-0.9434, -0.9537],
        [-1.0463, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003904839977622032
Epoch 0, Step 370: train/loss = 0.6942603588104248, train/raw-loss = 0.6939957737922668, train/logprobs = tensor([[-1.0092, -0.9832],
        [-1.0796, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006613961886614561
Epoch 0, Step 371: train/loss = 0.7058348059654236, train/raw-loss = 0.7017065286636353, train/logprobs = tensor([[-1.1151, -1.3061],
        [-1.1425, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010320579633116722
Epoch 0, Step 372: train/loss = 0.6994568705558777, train/raw-loss = 0.6982752084732056, train/logprobs = tensor([[-1.2656, -1.2859],
        [-0.9230, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029541263356804848
Epoch 0, Step 373: train/loss = 0.7105473279953003, train/raw-loss = 0.7052918672561646, train/logprobs = tensor([[-1.0009, -1.1509],
        [-1.2481, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01313885860145092
Epoch 0, Step 374: train/loss = 0.7472882270812988, train/raw-loss = 0.7456391453742981, train/logprobs = tensor([[-1.1225, -0.8763],
        [-1.1648, -0.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041229380294680595
Epoch 0, Step 375: train/loss = 0.698405385017395, train/raw-loss = 0.6973851323127747, train/logprobs = tensor([[-1.0659, -1.0443],
        [-1.0937, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025504862423986197
Epoch 0, Step 376: train/loss = 0.6945405006408691, train/raw-loss = 0.688822329044342, train/logprobs = tensor([[-1.0670, -1.4413],
        [-1.1057, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014295320026576519
Epoch 0, Step 377: train/loss = 0.7015584707260132, train/raw-loss = 0.6985510587692261, train/logprobs = tensor([[-1.0072, -0.9884],
        [-1.1059, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007518520578742027
Epoch 0, Step 378: train/loss = 0.735363245010376, train/raw-loss = 0.7234457731246948, train/logprobs = tensor([[-0.8894, -1.4372],
        [-1.0596, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02979390323162079
Epoch 0, Step 379: train/loss = 0.7030040621757507, train/raw-loss = 0.7023046016693115, train/logprobs = tensor([[-0.8686, -1.1932],
        [-0.8984, -1.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017484510317444801
Epoch 0, Step 380: train/loss = 0.7075076103210449, train/raw-loss = 0.7061184644699097, train/logprobs = tensor([[-1.0412, -0.9666],
        [-1.1272, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034731081686913967
Epoch 0, Step 381: train/loss = 0.7048827409744263, train/raw-loss = 0.7036613821983337, train/logprobs = tensor([[-1.2172, -1.0817],
        [-1.0466, -0.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030532865785062313
Epoch 0, Step 382: train/loss = 0.6870377063751221, train/raw-loss = 0.6741626262664795, train/logprobs = tensor([[-1.0566, -1.4292],
        [-1.3008, -0.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03218776732683182
Epoch 0, Step 383: train/loss = 0.6970195770263672, train/raw-loss = 0.6938327550888062, train/logprobs = tensor([[-0.9916, -0.9875],
        [-1.2531, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007967186160385609
Epoch 0, Step 384: train/loss = 0.6935426592826843, train/raw-loss = 0.692997932434082, train/logprobs = tensor([[-0.8379, -0.9116],
        [-0.8214, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013618560042232275
Epoch 0, Step 385: train/loss = 0.6944172382354736, train/raw-loss = 0.6886393427848816, train/logprobs = tensor([[-1.0905, -1.3363],
        [-1.0400, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014444769360125065
Epoch 0, Step 386: train/loss = 0.7095568776130676, train/raw-loss = 0.7090966105461121, train/logprobs = tensor([[-1.0479, -1.0602],
        [-1.1020, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001150776632130146
Epoch 0, Step 387: train/loss = 0.6966877579689026, train/raw-loss = 0.6939629316329956, train/logprobs = tensor([[-1.0634, -1.3240],
        [-1.2010, -1.0710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006812171544879675
Epoch 0, Step 388: train/loss = 0.7079554796218872, train/raw-loss = 0.703295111656189, train/logprobs = tensor([[-1.4005, -1.6081],
        [-1.4188, -1.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011651101522147655
Epoch 0, Step 389: train/loss = 0.7136147618293762, train/raw-loss = 0.7111850380897522, train/logprobs = tensor([[-1.0818, -1.3168],
        [-1.1488, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006074224598705769
Epoch 0, Step 390: train/loss = 0.6899556517601013, train/raw-loss = 0.6785954236984253, train/logprobs = tensor([[-1.0576, -1.4806],
        [-1.3350, -1.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028400614857673645
Epoch 0, Step 391: train/loss = 0.7153107523918152, train/raw-loss = 0.713969349861145, train/logprobs = tensor([[-1.0058, -1.0320],
        [-1.0827, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003353697946295142
Epoch 0, Step 392: train/loss = 0.7164169549942017, train/raw-loss = 0.7116299271583557, train/logprobs = tensor([[-1.0542, -1.4748],
        [-1.2337, -1.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01196768507361412
Epoch 0, Step 393: train/loss = 0.7035054564476013, train/raw-loss = 0.7033748626708984, train/logprobs = tensor([[-0.9232, -0.8821],
        [-0.9976, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003264971892349422
Epoch 0, Step 394: train/loss = 0.694731593132019, train/raw-loss = 0.692595899105072, train/logprobs = tensor([[-0.8144, -0.8537],
        [-1.0135, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005339242517948151
Epoch 0, Step 395: train/loss = 0.6936981678009033, train/raw-loss = 0.6920647025108337, train/logprobs = tensor([[-1.0325, -1.3243],
        [-1.1849, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004083754029124975
Epoch 0, Step 396: train/loss = 0.7030913233757019, train/raw-loss = 0.6958116292953491, train/logprobs = tensor([[-1.1479, -1.7657],
        [-1.0294, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01819918118417263
Epoch 0, Step 397: train/loss = 0.7118614315986633, train/raw-loss = 0.6905584335327148, train/logprobs = tensor([[-1.2222, -1.7164],
        [-1.3026, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05325765907764435
Epoch 0, Step 398: train/loss = 0.7095317840576172, train/raw-loss = 0.7094293832778931, train/logprobs = tensor([[-0.9776, -0.7018],
        [-1.0450, -0.6776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025590904988348484
Epoch 0, Step 399: train/loss = 0.6875712275505066, train/raw-loss = 0.6796311140060425, train/logprobs = tensor([[-1.1730, -1.3547],
        [-1.3208, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019850578159093857
Epoch 0, Step 400: train/loss = 0.6952189207077026, train/raw-loss = 0.6950070858001709, train/logprobs = tensor([[-1.1015, -1.1251],
        [-0.8313, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000529530574567616
Epoch 0, Step 401: train/loss = 0.7135530710220337, train/raw-loss = 0.7080041170120239, train/logprobs = tensor([[-0.9756, -1.3775],
        [-0.9804, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013872446492314339
Epoch 0, Step 402: train/loss = 0.716630220413208, train/raw-loss = 0.7164873480796814, train/logprobs = tensor([[-1.2449, -1.0074],
        [-1.3634, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000357256387360394
Epoch 0, Step 403: train/loss = 0.738289475440979, train/raw-loss = 0.7354093790054321, train/logprobs = tensor([[-0.8925, -1.2472],
        [-0.9081, -1.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0072003016248345375
Epoch 0, Step 404: train/loss = 0.688775897026062, train/raw-loss = 0.6629947423934937, train/logprobs = tensor([[-0.9622, -1.5482],
        [-1.1587, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06445297598838806
Epoch 0, Step 405: train/loss = 0.6917875409126282, train/raw-loss = 0.6850701570510864, train/logprobs = tensor([[-1.0237, -1.3115],
        [-1.2218, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016793549060821533
Epoch 0, Step 406: train/loss = 0.751872718334198, train/raw-loss = 0.7425700426101685, train/logprobs = tensor([[-1.2174, -1.6273],
        [-1.2795, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02325652353465557
Epoch 0, Step 407: train/loss = 0.7073548436164856, train/raw-loss = 0.7036916017532349, train/logprobs = tensor([[-1.0324, -1.5851],
        [-1.1042, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009158103726804256
Epoch 0, Step 408: train/loss = 0.7072542905807495, train/raw-loss = 0.689570426940918, train/logprobs = tensor([[-0.9092, -1.4898],
        [-1.1499, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04420985281467438
Epoch 0, Step 409: train/loss = 0.6967973709106445, train/raw-loss = 0.6947095990180969, train/logprobs = tensor([[-1.1469, -1.1513],
        [-1.3151, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005219414830207825
Epoch 0, Step 410: train/loss = 0.7133103609085083, train/raw-loss = 0.6957091093063354, train/logprobs = tensor([[-0.8289, -1.5892],
        [-0.9500, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04400307312607765
Epoch 0, Step 411: train/loss = 0.6902770400047302, train/raw-loss = 0.6871546506881714, train/logprobs = tensor([[-1.1650, -1.2699],
        [-1.1135, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007805962581187487
Epoch 0, Step 412: train/loss = 0.7017167210578918, train/raw-loss = 0.699646532535553, train/logprobs = tensor([[-1.4205, -1.3265],
        [-1.3718, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00517545361071825
Epoch 0, Step 413: train/loss = 0.6958390474319458, train/raw-loss = 0.6934587955474854, train/logprobs = tensor([[-1.1717, -1.1897],
        [-1.0425, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005950485821813345
Epoch 0, Step 414: train/loss = 0.7117069959640503, train/raw-loss = 0.707640528678894, train/logprobs = tensor([[-0.9083, -1.0765],
        [-1.1156, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010166100226342678
Epoch 0, Step 415: train/loss = 0.6907529830932617, train/raw-loss = 0.687792181968689, train/logprobs = tensor([[-0.8832, -1.0982],
        [-0.9353, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007401860319077969
Epoch 0, Step 416: train/loss = 0.7484616041183472, train/raw-loss = 0.7270818948745728, train/logprobs = tensor([[-1.3156, -2.1418],
        [-1.3784, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053449273109436035
Epoch 0, Step 417: train/loss = 0.7502925992012024, train/raw-loss = 0.7463393807411194, train/logprobs = tensor([[-0.9983, -0.9230],
        [-1.1612, -0.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009883235208690166
Epoch 0, Step 418: train/loss = 0.7035396099090576, train/raw-loss = 0.702106773853302, train/logprobs = tensor([[-1.7074, -1.7180],
        [-1.3358, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035821564961224794
Epoch 0, Step 419: train/loss = 0.6959563493728638, train/raw-loss = 0.694386899471283, train/logprobs = tensor([[-1.3010, -1.4516],
        [-1.1327, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003923711366951466
Epoch 0, Step 420: train/loss = 0.698239803314209, train/raw-loss = 0.681748628616333, train/logprobs = tensor([[-1.0268, -1.4520],
        [-1.0326, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041227832436561584
Epoch 0, Step 421: train/loss = 0.7041699886322021, train/raw-loss = 0.6947016716003418, train/logprobs = tensor([[-1.2720, -1.8144],
        [-1.2533, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02367078699171543
Epoch 0, Step 422: train/loss = 0.6948465704917908, train/raw-loss = 0.6913854479789734, train/logprobs = tensor([[-1.1076, -1.3590],
        [-1.1935, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00865283515304327
Epoch 0, Step 423: train/loss = 0.7080879807472229, train/raw-loss = 0.7051931619644165, train/logprobs = tensor([[-1.3564, -1.2981],
        [-1.5207, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0072369882836937904
Epoch 0, Step 424: train/loss = 0.7069571018218994, train/raw-loss = 0.7046388387680054, train/logprobs = tensor([[-1.1371, -1.0743],
        [-1.1612, -0.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005795614793896675
Epoch 0, Step 425: train/loss = 0.6870216131210327, train/raw-loss = 0.6806929111480713, train/logprobs = tensor([[-0.9512, -1.4050],
        [-1.0587, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015821797773241997
Epoch 0, Step 426: train/loss = 0.7147616147994995, train/raw-loss = 0.7099209427833557, train/logprobs = tensor([[-1.3951, -1.1732],
        [-1.4603, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012101918458938599
Epoch 0, Step 427: train/loss = 0.7100954055786133, train/raw-loss = 0.7062696814537048, train/logprobs = tensor([[-1.0186, -1.1418],
        [-1.1293, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00956436712294817
Epoch 0, Step 428: train/loss = 0.7137247323989868, train/raw-loss = 0.71169114112854, train/logprobs = tensor([[-1.1010, -0.9854],
        [-1.1837, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005083995871245861
Epoch 0, Step 429: train/loss = 0.702417254447937, train/raw-loss = 0.7005825638771057, train/logprobs = tensor([[-0.9591, -1.0049],
        [-1.1257, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045868344604969025
Epoch 0, Step 430: train/loss = 0.7109562754631042, train/raw-loss = 0.7069368362426758, train/logprobs = tensor([[-0.8907, -1.2689],
        [-0.9551, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010048449970781803
Epoch 0, Step 431: train/loss = 0.7109491229057312, train/raw-loss = 0.7105673551559448, train/logprobs = tensor([[-1.2217, -1.5828],
        [-1.3279, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009542916668578982
Epoch 0, Step 432: train/loss = 0.7010149359703064, train/raw-loss = 0.6977123022079468, train/logprobs = tensor([[-1.2787, -1.3080],
        [-1.2552, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008256440050899982
Epoch 0, Step 433: train/loss = 0.7120702266693115, train/raw-loss = 0.7056899070739746, train/logprobs = tensor([[-0.9540, -1.0955],
        [-0.9919, -0.6187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01595090702176094
Epoch 0, Step 434: train/loss = 0.6956626176834106, train/raw-loss = 0.6937349438667297, train/logprobs = tensor([[-1.4455, -1.4815],
        [-1.2591, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004819138906896114
Epoch 0, Step 435: train/loss = 0.753907322883606, train/raw-loss = 0.7449972033500671, train/logprobs = tensor([[-1.3831, -1.8534],
        [-1.3472, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022275196388363838
Epoch 0, Step 436: train/loss = 0.7019705176353455, train/raw-loss = 0.694600522518158, train/logprobs = tensor([[-0.9250, -1.4238],
        [-0.8901, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018424980342388153
Epoch 0, Step 437: train/loss = 0.7154483199119568, train/raw-loss = 0.7103897333145142, train/logprobs = tensor([[-1.4296, -1.2399],
        [-1.2500, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012646527960896492
Epoch 0, Step 438: train/loss = 0.6952571272850037, train/raw-loss = 0.6860910654067993, train/logprobs = tensor([[-0.9483, -1.1700],
        [-1.2113, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022915156558156013
Epoch 0, Step 439: train/loss = 0.7173742055892944, train/raw-loss = 0.7126782536506653, train/logprobs = tensor([[-1.3886, -1.5886],
        [-1.4302, -1.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011739898473024368
Epoch 0, Step 440: train/loss = 0.7014216184616089, train/raw-loss = 0.6995536684989929, train/logprobs = tensor([[-1.2346, -1.4277],
        [-1.3368, -1.2484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004669721703976393
Epoch 0, Step 441: train/loss = 0.6963664293289185, train/raw-loss = 0.6865416169166565, train/logprobs = tensor([[-1.2291, -1.4388],
        [-1.4148, -0.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02456221543252468
Epoch 0, Step 442: train/loss = 0.6987139582633972, train/raw-loss = 0.6954505443572998, train/logprobs = tensor([[-0.9146, -0.8567],
        [-1.0409, -0.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008158481679856777
Epoch 0, Step 443: train/loss = 0.7167222499847412, train/raw-loss = 0.7165511846542358, train/logprobs = tensor([[-1.0653, -0.7830],
        [-0.9008, -0.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004276760737411678
Epoch 0, Step 444: train/loss = 0.7155407071113586, train/raw-loss = 0.6866041421890259, train/logprobs = tensor([[-0.9021, -1.9357],
        [-1.0924, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07234141230583191
Epoch 0, Step 445: train/loss = 0.7142335176467896, train/raw-loss = 0.704136312007904, train/logprobs = tensor([[-1.0067, -1.4469],
        [-1.0890, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025242991745471954
Epoch 0, Step 446: train/loss = 0.6918452382087708, train/raw-loss = 0.6811137199401855, train/logprobs = tensor([[-0.9205, -1.3681],
        [-0.9203, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026828816160559654
Epoch 0, Step 447: train/loss = 0.6931695938110352, train/raw-loss = 0.6878653764724731, train/logprobs = tensor([[-1.0526, -1.3067],
        [-0.9609, -0.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013260651379823685
Epoch 0, Step 448: train/loss = 0.7368642687797546, train/raw-loss = 0.7308956980705261, train/logprobs = tensor([[-1.1802, -1.6229],
        [-1.0868, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014921547845005989
Epoch 0, Step 449: train/loss = 0.6893635988235474, train/raw-loss = 0.6865617036819458, train/logprobs = tensor([[-1.3213, -1.4181],
        [-1.5128, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007004780229181051
Epoch 0, Step 450: train/loss = 0.7292650938034058, train/raw-loss = 0.729083240032196, train/logprobs = tensor([[-1.4096, -1.1364],
        [-1.2767, -0.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004546585550997406
Epoch 0, Step 451: train/loss = 0.7142834663391113, train/raw-loss = 0.6940194368362427, train/logprobs = tensor([[-0.9420, -1.7623],
        [-1.0922, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05066005885601044
Epoch 0, Step 452: train/loss = 0.7009531259536743, train/raw-loss = 0.6966357231140137, train/logprobs = tensor([[-1.2538, -1.7549],
        [-0.8161, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010793579742312431
Epoch 0, Step 453: train/loss = 0.7054744362831116, train/raw-loss = 0.6955585479736328, train/logprobs = tensor([[-1.0979, -1.4872],
        [-1.0767, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02478976547718048
Epoch 0, Step 454: train/loss = 0.6885385513305664, train/raw-loss = 0.6821819543838501, train/logprobs = tensor([[-1.1183, -1.2949],
        [-1.2211, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015891682356595993
Epoch 0, Step 455: train/loss = 0.712441086769104, train/raw-loss = 0.7036247253417969, train/logprobs = tensor([[-1.1583, -1.4417],
        [-1.1229, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0220407173037529
Epoch 0, Step 456: train/loss = 0.6941842436790466, train/raw-loss = 0.6935990452766418, train/logprobs = tensor([[-0.8922, -0.9642],
        [-0.8784, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001463166787289083
Epoch 0, Step 457: train/loss = 0.7152752876281738, train/raw-loss = 0.705167293548584, train/logprobs = tensor([[-0.9677, -1.4130],
        [-1.1180, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025269899517297745
Epoch 0, Step 458: train/loss = 0.7484314441680908, train/raw-loss = 0.7433029413223267, train/logprobs = tensor([[-1.0015, -1.6773],
        [-1.0148, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012821229174733162
Epoch 0, Step 459: train/loss = 0.717682957649231, train/raw-loss = 0.7128047347068787, train/logprobs = tensor([[-1.5995, -1.6719],
        [-1.3393, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012195611372590065
Epoch 0, Step 460: train/loss = 0.7061589956283569, train/raw-loss = 0.702793538570404, train/logprobs = tensor([[-1.2095, -1.2882],
        [-1.4192, -0.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008413831703364849
Epoch 0, Step 461: train/loss = 0.6876052021980286, train/raw-loss = 0.6872977614402771, train/logprobs = tensor([[-1.2878, -1.4021],
        [-1.0430, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007687191246077418
Epoch 0, Step 462: train/loss = 0.6710444688796997, train/raw-loss = 0.6680558919906616, train/logprobs = tensor([[-1.3167, -1.7743],
        [-1.3016, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007471336983144283
Epoch 0, Step 463: train/loss = 0.7513405680656433, train/raw-loss = 0.7053596377372742, train/logprobs = tensor([[-1.1948, -2.2121],
        [-1.1680, -1.1829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11495217680931091
Epoch 0, Step 464: train/loss = 0.6912102699279785, train/raw-loss = 0.6857292056083679, train/logprobs = tensor([[-1.3349, -1.5224],
        [-1.2324, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01370261050760746
Epoch 0, Step 465: train/loss = 0.7128406763076782, train/raw-loss = 0.7112957239151001, train/logprobs = tensor([[-1.0497, -1.1911],
        [-1.0781, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038622356951236725
Epoch 0, Step 466: train/loss = 0.7017149329185486, train/raw-loss = 0.7010185122489929, train/logprobs = tensor([[-1.0474, -1.1203],
        [-1.0087, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017410260625183582
Epoch 0, Step 467: train/loss = 0.6956939101219177, train/raw-loss = 0.6931305527687073, train/logprobs = tensor([[-1.3396, -1.6718],
        [-1.4993, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006408426910638809
Epoch 0, Step 468: train/loss = 0.7070377469062805, train/raw-loss = 0.6997383236885071, train/logprobs = tensor([[-0.9212, -1.4573],
        [-0.8820, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018248507753014565
Epoch 0, Step 469: train/loss = 0.6970650553703308, train/raw-loss = 0.6951935291290283, train/logprobs = tensor([[-1.0673, -1.0234],
        [-1.1269, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004679052624851465
Epoch 0, Step 470: train/loss = 0.6990633010864258, train/raw-loss = 0.6961177587509155, train/logprobs = tensor([[-1.0236, -1.3074],
        [-1.1141, -1.2060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073638479225337505
Epoch 0, Step 471: train/loss = 0.7035329341888428, train/raw-loss = 0.7013034224510193, train/logprobs = tensor([[-1.0678, -1.3542],
        [-1.3386, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005573879927396774
Epoch 0, Step 472: train/loss = 0.685938835144043, train/raw-loss = 0.6626036763191223, train/logprobs = tensor([[-1.2250, -1.7464],
        [-1.3010, -0.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058338016271591187
Epoch 0, Step 473: train/loss = 0.6933245658874512, train/raw-loss = 0.6921886205673218, train/logprobs = tensor([[-1.5138, -1.6345],
        [-1.6341, -1.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002839906606823206
Epoch 0, Step 474: train/loss = 0.7087951302528381, train/raw-loss = 0.7030266523361206, train/logprobs = tensor([[-1.0136, -1.4802],
        [-1.1322, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014421101659536362
Epoch 0, Step 475: train/loss = 0.7051334381103516, train/raw-loss = 0.7017320394515991, train/logprobs = tensor([[-0.9434, -1.2537],
        [-1.0384, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008503543213009834
Epoch 0, Step 476: train/loss = 0.7407590746879578, train/raw-loss = 0.7364792227745056, train/logprobs = tensor([[-1.5293, -1.4183],
        [-1.8424, -1.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010699573904275894
Epoch 0, Step 477: train/loss = 0.6852338314056396, train/raw-loss = 0.6703224182128906, train/logprobs = tensor([[-1.3608, -1.5519],
        [-1.4133, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03727860376238823
Epoch 0, Step 478: train/loss = 0.7081581950187683, train/raw-loss = 0.7044996023178101, train/logprobs = tensor([[-0.9402, -1.2229],
        [-1.0831, -1.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0091461893171072
Epoch 0, Step 479: train/loss = 0.7010029554367065, train/raw-loss = 0.7007755041122437, train/logprobs = tensor([[-1.1987, -1.1021],
        [-1.3899, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005684857023879886
Epoch 0, Step 480: train/loss = 0.6982647776603699, train/raw-loss = 0.6973519325256348, train/logprobs = tensor([[-1.0849, -1.0226],
        [-1.0026, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022820867598056793
Epoch 0, Step 481: train/loss = 0.6955045461654663, train/raw-loss = 0.6856497526168823, train/logprobs = tensor([[-1.1931, -1.4025],
        [-1.2673, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02463693544268608
Epoch 0, Step 482: train/loss = 0.7105628848075867, train/raw-loss = 0.7012420296669006, train/logprobs = tensor([[-1.4093, -1.3843],
        [-1.4101, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023302150890231133
Epoch 0, Step 483: train/loss = 0.6923556923866272, train/raw-loss = 0.6804828643798828, train/logprobs = tensor([[-1.1741, -1.4376],
        [-1.0724, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02968195453286171
Epoch 0, Step 484: train/loss = 0.7222821116447449, train/raw-loss = 0.717946469783783, train/logprobs = tensor([[-1.1023, -1.7459],
        [-1.2845, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010839133523404598
Epoch 0, Step 485: train/loss = 0.6866871118545532, train/raw-loss = 0.6775458455085754, train/logprobs = tensor([[-1.0252, -1.4137],
        [-0.9943, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022853173315525055
Epoch 0, Step 486: train/loss = 0.7214056253433228, train/raw-loss = 0.7208982706069946, train/logprobs = tensor([[-1.0768, -1.2481],
        [-1.1479, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012684176908805966
Epoch 0, Step 487: train/loss = 0.6940895915031433, train/raw-loss = 0.6933399438858032, train/logprobs = tensor([[-1.1214, -1.1655],
        [-0.9763, -0.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018742764368653297
Epoch 0, Step 488: train/loss = 0.6976901292800903, train/raw-loss = 0.6881431341171265, train/logprobs = tensor([[-1.3239, -1.6069],
        [-1.2365, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023867404088377953
Epoch 0, Step 489: train/loss = 0.7240005731582642, train/raw-loss = 0.7169814705848694, train/logprobs = tensor([[-0.9423, -1.5715],
        [-1.0488, -1.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017547715455293655
Epoch 0, Step 490: train/loss = 0.693008303642273, train/raw-loss = 0.6861443519592285, train/logprobs = tensor([[-1.0236, -1.3580],
        [-1.0702, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01716005429625511
Epoch 0, Step 491: train/loss = 0.6930673122406006, train/raw-loss = 0.6849053502082825, train/logprobs = tensor([[-1.0758, -1.2016],
        [-1.1752, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020404784008860588
Epoch 0, Step 492: train/loss = 0.7025974988937378, train/raw-loss = 0.6997172832489014, train/logprobs = tensor([[-0.9836, -1.0846],
        [-1.0048, -0.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0072006285190582275
Epoch 0, Step 493: train/loss = 0.7909803986549377, train/raw-loss = 0.7823095321655273, train/logprobs = tensor([[-1.0098, -1.7649],
        [-1.1008, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021677132695913315
Epoch 0, Step 494: train/loss = 0.6926210522651672, train/raw-loss = 0.6894851922988892, train/logprobs = tensor([[-1.3349, -1.2705],
        [-1.1280, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007839763537049294
Epoch 0, Step 495: train/loss = 0.6988316774368286, train/raw-loss = 0.6939697265625, train/logprobs = tensor([[-0.9307, -1.1534],
        [-1.0551, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012154915370047092
Epoch 0, Step 496: train/loss = 0.6923694014549255, train/raw-loss = 0.6903582811355591, train/logprobs = tensor([[-1.0492, -1.1429],
        [-1.1772, -1.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005027732811868191
Epoch 0, Step 497: train/loss = 0.722865641117096, train/raw-loss = 0.7217578887939453, train/logprobs = tensor([[-1.2262, -1.0358],
        [-1.0764, -0.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002769460901618004
Epoch 0, Step 498: train/loss = 0.7106486558914185, train/raw-loss = 0.6929446458816528, train/logprobs = tensor([[-1.0027, -1.9386],
        [-1.0489, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044260039925575256
Epoch 0, Step 499: train/loss = 0.6958566904067993, train/raw-loss = 0.686048150062561, train/logprobs = tensor([[-0.8793, -1.1063],
        [-0.9576, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02452138438820839
eval/loss: 0.7083003520965576
Epoch 0, Step 500: train/loss = 0.7220448851585388, train/raw-loss = 0.7169190645217896, train/logprobs = tensor([[-1.3020, -1.3557],
        [-1.1345, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012814461253583431
Epoch 0, Step 501: train/loss = 0.7175799012184143, train/raw-loss = 0.7142730951309204, train/logprobs = tensor([[-1.3439, -1.5413],
        [-1.3970, -1.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008267086930572987
Epoch 0, Step 502: train/loss = 0.7149720191955566, train/raw-loss = 0.708899199962616, train/logprobs = tensor([[-1.4112, -1.7756],
        [-1.3156, -1.2668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015182087197899818
Epoch 0, Step 503: train/loss = 0.7400140762329102, train/raw-loss = 0.7287980318069458, train/logprobs = tensor([[-1.3977, -1.4300],
        [-1.3250, -1.3905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028040241450071335
Epoch 0, Step 504: train/loss = 0.7242054343223572, train/raw-loss = 0.7234591245651245, train/logprobs = tensor([[-1.3207, -1.1190],
        [-1.3976, -1.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018658707849681377
Epoch 0, Step 505: train/loss = 0.7147308588027954, train/raw-loss = 0.7129988670349121, train/logprobs = tensor([[-0.9829, -0.9851],
        [-1.0111, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00433000735938549
Epoch 0, Step 506: train/loss = 0.7146831750869751, train/raw-loss = 0.7117758989334106, train/logprobs = tensor([[-0.8181, -1.1667],
        [-0.9030, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007268182933330536
Epoch 0, Step 507: train/loss = 0.6880874633789062, train/raw-loss = 0.6820203065872192, train/logprobs = tensor([[-1.2341, -1.5255],
        [-1.3601, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015167822130024433
Epoch 0, Step 508: train/loss = 0.7022907733917236, train/raw-loss = 0.701828122138977, train/logprobs = tensor([[-1.0000, -0.9497],
        [-1.0451, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011567638721317053
Epoch 0, Step 509: train/loss = 0.6978504061698914, train/raw-loss = 0.6951584815979004, train/logprobs = tensor([[-0.8929, -1.1762],
        [-0.9400, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00672970712184906
Epoch 0, Step 510: train/loss = 0.6863164901733398, train/raw-loss = 0.6756285429000854, train/logprobs = tensor([[-1.0617, -1.3392],
        [-1.1881, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026719890534877777
Epoch 0, Step 511: train/loss = 0.6787287592887878, train/raw-loss = 0.6641281843185425, train/logprobs = tensor([[-1.3076, -1.7806],
        [-1.1711, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036501478403806686
Epoch 0, Step 512: train/loss = 0.6947193741798401, train/raw-loss = 0.69050532579422, train/logprobs = tensor([[-1.0495, -1.2564],
        [-1.0717, -1.0230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010535109788179398
Epoch 0, Step 513: train/loss = 0.7202609777450562, train/raw-loss = 0.7195475697517395, train/logprobs = tensor([[-0.8666, -0.6562],
        [-0.9327, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017835474573075771
Epoch 0, Step 514: train/loss = 0.70672208070755, train/raw-loss = 0.6988705396652222, train/logprobs = tensor([[-1.1732, -1.2498],
        [-1.3201, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01962876319885254
Epoch 0, Step 515: train/loss = 0.7223977446556091, train/raw-loss = 0.707082211971283, train/logprobs = tensor([[-1.0953, -1.8610],
        [-0.9587, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03828892111778259
Epoch 0, Step 516: train/loss = 0.738035261631012, train/raw-loss = 0.7280730605125427, train/logprobs = tensor([[-0.9173, -1.3004],
        [-1.0281, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024905521422624588
Epoch 0, Step 517: train/loss = 0.6910595893859863, train/raw-loss = 0.6850268244743347, train/logprobs = tensor([[-1.0764, -1.3171],
        [-1.2458, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015081989578902721
Epoch 0, Step 518: train/loss = 0.7165815830230713, train/raw-loss = 0.6888645887374878, train/logprobs = tensor([[-0.9742, -1.8469],
        [-1.1398, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06929244101047516
Epoch 0, Step 519: train/loss = 0.6937333345413208, train/raw-loss = 0.688963770866394, train/logprobs = tensor([[-1.1035, -1.2876],
        [-1.0924, -0.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011923766694962978
Epoch 0, Step 520: train/loss = 0.7338645458221436, train/raw-loss = 0.7259868383407593, train/logprobs = tensor([[-1.3336, -1.2180],
        [-1.3963, -0.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019694168120622635
Epoch 0, Step 521: train/loss = 0.7349092960357666, train/raw-loss = 0.7272796630859375, train/logprobs = tensor([[-1.0135, -1.7028],
        [-1.0787, -1.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019074149429798126
Epoch 0, Step 522: train/loss = 0.7033922672271729, train/raw-loss = 0.6755250692367554, train/logprobs = tensor([[-0.9088, -1.8885],
        [-1.0810, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06966812908649445
Epoch 0, Step 523: train/loss = 0.7066947817802429, train/raw-loss = 0.7026014924049377, train/logprobs = tensor([[-1.1103, -1.6640],
        [-1.0502, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010233161970973015
Epoch 0, Step 524: train/loss = 0.6942286491394043, train/raw-loss = 0.6937506198883057, train/logprobs = tensor([[-1.1740, -1.2127],
        [-1.1688, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011950491461902857
Epoch 0, Step 525: train/loss = 0.7270452976226807, train/raw-loss = 0.7196778059005737, train/logprobs = tensor([[-0.8075, -1.2848],
        [-0.9340, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018418829888105392
Epoch 0, Step 526: train/loss = 0.6935281157493591, train/raw-loss = 0.6862339973449707, train/logprobs = tensor([[-1.0733, -1.3444],
        [-1.1157, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018235385417938232
Epoch 0, Step 527: train/loss = 0.7366917133331299, train/raw-loss = 0.7338487505912781, train/logprobs = tensor([[-1.2664, -1.0970],
        [-1.5915, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007107370533049107
Epoch 0, Step 528: train/loss = 0.6864252686500549, train/raw-loss = 0.6732600927352905, train/logprobs = tensor([[-1.3341, -1.6180],
        [-1.3780, -0.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03291304409503937
Epoch 0, Step 529: train/loss = 0.7010239362716675, train/raw-loss = 0.691853940486908, train/logprobs = tensor([[-0.9788, -1.0315],
        [-1.1700, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022924890741705894
Epoch 0, Step 530: train/loss = 0.7133380770683289, train/raw-loss = 0.7127033472061157, train/logprobs = tensor([[-1.0608, -1.0213],
        [-1.0355, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015868101036176085
Epoch 0, Step 531: train/loss = 0.6971196532249451, train/raw-loss = 0.696158766746521, train/logprobs = tensor([[-1.2149, -1.1663],
        [-1.2298, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024022283032536507
Epoch 0, Step 532: train/loss = 0.7122366428375244, train/raw-loss = 0.709809422492981, train/logprobs = tensor([[-1.3818, -1.7036],
        [-1.3492, -1.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006068057380616665
Epoch 0, Step 533: train/loss = 0.7361177206039429, train/raw-loss = 0.7338963747024536, train/logprobs = tensor([[-1.0550, -1.4274],
        [-1.1351, -1.1429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055535342544317245
Epoch 0, Step 534: train/loss = 0.6929165720939636, train/raw-loss = 0.6880843639373779, train/logprobs = tensor([[-0.9091, -0.9816],
        [-0.9234, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01208049152046442
Epoch 0, Step 535: train/loss = 0.7109948992729187, train/raw-loss = 0.7008827924728394, train/logprobs = tensor([[-1.2616, -1.5013],
        [-1.4429, -0.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02528051659464836
Epoch 0, Step 536: train/loss = 0.7010828852653503, train/raw-loss = 0.6855175495147705, train/logprobs = tensor([[-1.2180, -1.6556],
        [-1.2403, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03891351819038391
Epoch 0, Step 537: train/loss = 0.6839976906776428, train/raw-loss = 0.6566052436828613, train/logprobs = tensor([[-1.0292, -1.5984],
        [-1.1251, -0.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06848111003637314
Epoch 0, Step 538: train/loss = 0.6977161765098572, train/raw-loss = 0.6971179246902466, train/logprobs = tensor([[-0.8430, -0.8712],
        [-0.8788, -0.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014955918304622173
Epoch 0, Step 539: train/loss = 0.716447114944458, train/raw-loss = 0.6920914649963379, train/logprobs = tensor([[-1.3595, -2.1952],
        [-1.5574, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06088912487030029
Epoch 0, Step 540: train/loss = 0.6951491832733154, train/raw-loss = 0.693533718585968, train/logprobs = tensor([[-0.9072, -0.9602],
        [-1.0522, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00403869291767478
Epoch 0, Step 541: train/loss = 0.6997066736221313, train/raw-loss = 0.6961052417755127, train/logprobs = tensor([[-1.0967, -1.1581],
        [-1.2163, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009003747254610062
Epoch 0, Step 542: train/loss = 0.6967291831970215, train/raw-loss = 0.687038779258728, train/logprobs = tensor([[-1.2819, -1.3608],
        [-1.0997, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024226047098636627
Epoch 0, Step 543: train/loss = 0.7223221063613892, train/raw-loss = 0.714658260345459, train/logprobs = tensor([[-1.1275, -0.9383],
        [-1.4460, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019159391522407532
Epoch 0, Step 544: train/loss = 0.6943281888961792, train/raw-loss = 0.6890075206756592, train/logprobs = tensor([[-1.5923, -1.6599],
        [-1.6707, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013301735743880272
Epoch 0, Step 545: train/loss = 0.7024577856063843, train/raw-loss = 0.7020527124404907, train/logprobs = tensor([[-1.8266, -1.6813],
        [-1.3906, -1.2615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010126044508069754
Epoch 0, Step 546: train/loss = 0.7127506732940674, train/raw-loss = 0.6988751292228699, train/logprobs = tensor([[-1.6319, -2.2642],
        [-1.4375, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03468882665038109
Epoch 0, Step 547: train/loss = 0.7130670547485352, train/raw-loss = 0.7107153534889221, train/logprobs = tensor([[-1.2292, -1.3963],
        [-0.9270, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005879326723515987
Epoch 0, Step 548: train/loss = 0.6969268321990967, train/raw-loss = 0.6802471876144409, train/logprobs = tensor([[-1.0265, -1.5919],
        [-1.3198, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04169894754886627
Epoch 0, Step 549: train/loss = 0.6966211199760437, train/raw-loss = 0.6918867826461792, train/logprobs = tensor([[-1.1155, -1.3605],
        [-1.2701, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011835986748337746
Epoch 0, Step 550: train/loss = 0.6828197240829468, train/raw-loss = 0.6761370897293091, train/logprobs = tensor([[-1.2439, -1.4422],
        [-1.2932, -1.0710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016706570982933044
Epoch 0, Step 551: train/loss = 0.7097293138504028, train/raw-loss = 0.6945917010307312, train/logprobs = tensor([[-1.0308, -1.6929],
        [-0.9549, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03784392029047012
Epoch 0, Step 552: train/loss = 0.8088491559028625, train/raw-loss = 0.7973664402961731, train/logprobs = tensor([[-0.9762, -1.9132],
        [-1.3327, -1.5523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02870684303343296
Epoch 0, Step 553: train/loss = 0.7047556042671204, train/raw-loss = 0.6926136016845703, train/logprobs = tensor([[-1.4423, -2.0115],
        [-1.2109, -1.2256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030355023220181465
Epoch 0, Step 554: train/loss = 0.7251854538917542, train/raw-loss = 0.7198632955551147, train/logprobs = tensor([[-1.0951, -1.5389],
        [-1.1249, -1.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013305241242051125
Epoch 0, Step 555: train/loss = 0.6970018148422241, train/raw-loss = 0.6964367032051086, train/logprobs = tensor([[-1.4082, -1.4989],
        [-1.4157, -1.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001412711339071393
Epoch 0, Step 556: train/loss = 0.7012829184532166, train/raw-loss = 0.6908870339393616, train/logprobs = tensor([[-1.2463, -1.5795],
        [-1.0639, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025989551097154617
Epoch 0, Step 557: train/loss = 0.6950899958610535, train/raw-loss = 0.6949554681777954, train/logprobs = tensor([[-0.9533, -0.9957],
        [-0.9907, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033636699663475156
Epoch 0, Step 558: train/loss = 0.694973349571228, train/raw-loss = 0.6826519966125488, train/logprobs = tensor([[-1.0316, -1.4265],
        [-1.0087, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03080342523753643
Epoch 0, Step 559: train/loss = 0.706217348575592, train/raw-loss = 0.7056028246879578, train/logprobs = tensor([[-1.2337, -1.4515],
        [-1.2479, -1.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015362807316705585
Epoch 0, Step 560: train/loss = 0.6988989114761353, train/raw-loss = 0.697916567325592, train/logprobs = tensor([[-0.8982, -0.8397],
        [-0.9463, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024558273144066334
Epoch 0, Step 561: train/loss = 0.749008059501648, train/raw-loss = 0.7431820631027222, train/logprobs = tensor([[-1.1489, -1.4700],
        [-1.1539, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014565123245120049
Epoch 0, Step 562: train/loss = 0.7204622030258179, train/raw-loss = 0.7016923427581787, train/logprobs = tensor([[-0.9270, -1.5144],
        [-0.9581, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04692475497722626
Epoch 0, Step 563: train/loss = 0.7093493342399597, train/raw-loss = 0.7060971260070801, train/logprobs = tensor([[-1.1672, -1.4427],
        [-1.2494, -1.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008130572736263275
Epoch 0, Step 564: train/loss = 0.7258904576301575, train/raw-loss = 0.7026599049568176, train/logprobs = tensor([[-0.8673, -1.7586],
        [-1.0894, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05807633325457573
Epoch 0, Step 565: train/loss = 0.7281491160392761, train/raw-loss = 0.7138278484344482, train/logprobs = tensor([[-1.0735, -1.9345],
        [-1.2224, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03580313175916672
Epoch 0, Step 566: train/loss = 0.6939598917961121, train/raw-loss = 0.6939231157302856, train/logprobs = tensor([[-1.1015, -1.1447],
        [-1.0331, -1.0314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.203382069244981e-05
Epoch 0, Step 567: train/loss = 0.7038178443908691, train/raw-loss = 0.6965759992599487, train/logprobs = tensor([[-1.1104, -1.7796],
        [-1.2979, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01810467801988125
Epoch 0, Step 568: train/loss = 0.6955611705780029, train/raw-loss = 0.6937748193740845, train/logprobs = tensor([[-1.1275, -1.0848],
        [-1.2862, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004465847741812468
Epoch 0, Step 569: train/loss = 0.7455261945724487, train/raw-loss = 0.7441977262496948, train/logprobs = tensor([[-1.2937, -1.0023],
        [-1.3211, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033212313428521156
Epoch 0, Step 570: train/loss = 0.6998891234397888, train/raw-loss = 0.6973917484283447, train/logprobs = tensor([[-1.2282, -1.5787],
        [-1.0750, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006243505049496889
Epoch 0, Step 571: train/loss = 0.7039692401885986, train/raw-loss = 0.6911159157752991, train/logprobs = tensor([[-1.0632, -1.5810],
        [-1.2383, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321335531771183
Epoch 0, Step 572: train/loss = 0.7418469190597534, train/raw-loss = 0.7322506308555603, train/logprobs = tensor([[-0.9624, -1.8074],
        [-1.1553, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023990660905838013
Epoch 0, Step 573: train/loss = 0.705493688583374, train/raw-loss = 0.7053118348121643, train/logprobs = tensor([[-1.1210, -1.0546],
        [-1.0750, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004544926923699677
Epoch 0, Step 574: train/loss = 0.7427428960800171, train/raw-loss = 0.7349982857704163, train/logprobs = tensor([[-0.8470, -1.7331],
        [-0.8093, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01936161518096924
Epoch 0, Step 575: train/loss = 0.7129111289978027, train/raw-loss = 0.7101446986198425, train/logprobs = tensor([[-1.0543, -0.9597],
        [-1.1893, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006915947422385216
Epoch 0, Step 576: train/loss = 0.7368248701095581, train/raw-loss = 0.732036828994751, train/logprobs = tensor([[-1.3066, -1.5213],
        [-1.5286, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011970005929470062
Epoch 0, Step 577: train/loss = 0.7022837996482849, train/raw-loss = 0.6939540505409241, train/logprobs = tensor([[-1.1448, -1.4081],
        [-1.2300, -1.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020824437960982323
Epoch 0, Step 578: train/loss = 0.7204896211624146, train/raw-loss = 0.7146844863891602, train/logprobs = tensor([[-1.2644, -1.7811],
        [-1.1784, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014512677676975727
Epoch 0, Step 579: train/loss = 0.6931892037391663, train/raw-loss = 0.6881948709487915, train/logprobs = tensor([[-1.2551, -1.5638],
        [-1.2540, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012485935352742672
Epoch 0, Step 580: train/loss = 0.7143943905830383, train/raw-loss = 0.6886006593704224, train/logprobs = tensor([[-0.9965, -1.9043],
        [-1.1561, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448438763618469
Epoch 0, Step 581: train/loss = 0.6929461359977722, train/raw-loss = 0.6923959255218506, train/logprobs = tensor([[-0.9359, -1.0041],
        [-0.9794, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013753733364865184
Epoch 0, Step 582: train/loss = 0.731913149356842, train/raw-loss = 0.7234033346176147, train/logprobs = tensor([[-0.9481, -1.4580],
        [-1.0631, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021274538710713387
Epoch 0, Step 583: train/loss = 0.7020076513290405, train/raw-loss = 0.697462260723114, train/logprobs = tensor([[-1.0929, -1.4240],
        [-1.1906, -0.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011363474652171135
Epoch 0, Step 584: train/loss = 0.6974430680274963, train/raw-loss = 0.696609616279602, train/logprobs = tensor([[-1.6064, -1.7032],
        [-1.2321, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002083734842017293
Epoch 0, Step 585: train/loss = 0.7465382814407349, train/raw-loss = 0.7464447021484375, train/logprobs = tensor([[-0.7852, -0.9674],
        [-0.7221, -0.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023401121143251657
Epoch 0, Step 586: train/loss = 0.6989390850067139, train/raw-loss = 0.6984128952026367, train/logprobs = tensor([[-1.2081, -1.1755],
        [-1.2088, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013153123436495662
Epoch 0, Step 587: train/loss = 0.6932274103164673, train/raw-loss = 0.6892102360725403, train/logprobs = tensor([[-1.8326, -1.8583],
        [-1.6106, -1.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010042966343462467
Epoch 0, Step 588: train/loss = 0.7595154047012329, train/raw-loss = 0.735279381275177, train/logprobs = tensor([[-0.9336, -2.1801],
        [-1.0549, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06059013307094574
Epoch 0, Step 589: train/loss = 0.7221745252609253, train/raw-loss = 0.7113230228424072, train/logprobs = tensor([[-1.0928, -1.7793],
        [-1.1281, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02712886780500412
Epoch 0, Step 590: train/loss = 0.7049583196640015, train/raw-loss = 0.7035471200942993, train/logprobs = tensor([[-1.1555, -1.4225],
        [-0.9694, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035280094016343355
Epoch 0, Step 591: train/loss = 0.705629289150238, train/raw-loss = 0.7035718560218811, train/logprobs = tensor([[-1.0784, -1.4389],
        [-1.0829, -1.2986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005143573507666588
Epoch 0, Step 592: train/loss = 0.7007189989089966, train/raw-loss = 0.6960018277168274, train/logprobs = tensor([[-1.0996, -1.6391],
        [-1.1878, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011792793869972229
Epoch 0, Step 593: train/loss = 0.6871867179870605, train/raw-loss = 0.6805877685546875, train/logprobs = tensor([[-1.3179, -1.6739],
        [-1.2904, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016497410833835602
Epoch 0, Step 594: train/loss = 0.6893333196640015, train/raw-loss = 0.6851519346237183, train/logprobs = tensor([[-1.3626, -1.7101],
        [-1.3491, -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01045346911996603
Epoch 0, Step 595: train/loss = 0.6806902289390564, train/raw-loss = 0.6716877222061157, train/logprobs = tensor([[-1.1460, -1.8809],
        [-2.1189, -1.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02250635251402855
Epoch 0, Step 596: train/loss = 0.6956461071968079, train/raw-loss = 0.694317102432251, train/logprobs = tensor([[-1.1999, -1.3264],
        [-1.3833, -1.2423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033225486986339092
Epoch 0, Step 597: train/loss = 0.6871986389160156, train/raw-loss = 0.6801534295082092, train/logprobs = tensor([[-1.0380, -1.4597],
        [-1.2188, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017612893134355545
Epoch 0, Step 598: train/loss = 0.6943112015724182, train/raw-loss = 0.6924861669540405, train/logprobs = tensor([[-0.9402, -0.9880],
        [-0.9372, -0.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004562645219266415
Epoch 0, Step 599: train/loss = 0.6945093870162964, train/raw-loss = 0.6944988369941711, train/logprobs = tensor([[-0.9381, -0.9988],
        [-0.8626, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6347002858528867e-05
Epoch 0, Step 600: train/loss = 0.7001022100448608, train/raw-loss = 0.6993314027786255, train/logprobs = tensor([[-1.0924, -1.3208],
        [-1.1251, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001927154022268951
Epoch 0, Step 601: train/loss = 0.6987654566764832, train/raw-loss = 0.6987490653991699, train/logprobs = tensor([[-0.9397, -0.8648],
        [-0.9526, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.102589446119964e-05
Epoch 0, Step 602: train/loss = 0.6962835788726807, train/raw-loss = 0.6959088444709778, train/logprobs = tensor([[-1.0024, -1.0581],
        [-0.9375, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009368182509206235
Epoch 0, Step 603: train/loss = 0.7117733955383301, train/raw-loss = 0.7062383890151978, train/logprobs = tensor([[-0.9647, -1.6802],
        [-1.1059, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01383756473660469
Epoch 0, Step 604: train/loss = 0.7137393951416016, train/raw-loss = 0.7131897211074829, train/logprobs = tensor([[-1.2228, -1.0998],
        [-1.2081, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013741126749664545
Epoch 0, Step 605: train/loss = 0.7018405199050903, train/raw-loss = 0.6955031156539917, train/logprobs = tensor([[-0.9216, -1.3136],
        [-0.9843, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015843665227293968
Epoch 0, Step 606: train/loss = 0.6969760656356812, train/raw-loss = 0.6965200901031494, train/logprobs = tensor([[-1.1542, -1.0632],
        [-1.0875, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011401011142879725
Epoch 0, Step 607: train/loss = 0.7238522171974182, train/raw-loss = 0.7168663144111633, train/logprobs = tensor([[-0.8547, -1.4933],
        [-0.8977, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01746489480137825
Epoch 0, Step 608: train/loss = 0.6952999234199524, train/raw-loss = 0.6952295303344727, train/logprobs = tensor([[-0.9817, -0.9663],
        [-0.9386, -0.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017590285278856754
Epoch 0, Step 609: train/loss = 0.6888072490692139, train/raw-loss = 0.6694899797439575, train/logprobs = tensor([[-1.0204, -1.5071],
        [-1.3339, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0482931062579155
Epoch 0, Step 610: train/loss = 0.6984910368919373, train/raw-loss = 0.6984350681304932, train/logprobs = tensor([[-1.0499, -1.0703],
        [-1.1680, -1.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013993220636621118
Epoch 0, Step 611: train/loss = 0.792718231678009, train/raw-loss = 0.7875707149505615, train/logprobs = tensor([[-1.6215, -1.3228],
        [-1.6775, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012868709862232208
Epoch 0, Step 612: train/loss = 0.7168713808059692, train/raw-loss = 0.7165448665618896, train/logprobs = tensor([[-1.0029, -0.7895],
        [-1.1291, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008162874728441238
Epoch 0, Step 613: train/loss = 0.7169331312179565, train/raw-loss = 0.7146146297454834, train/logprobs = tensor([[-0.9564, -1.2568],
        [-1.0644, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005796186625957489
Epoch 0, Step 614: train/loss = 0.715959370136261, train/raw-loss = 0.715391218662262, train/logprobs = tensor([[-1.3402, -1.0945],
        [-1.3504, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014203765895217657
Epoch 0, Step 615: train/loss = 0.7008718848228455, train/raw-loss = 0.6998656392097473, train/logprobs = tensor([[-1.4447, -1.4544],
        [-1.2685, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025157355703413486
Epoch 0, Step 616: train/loss = 0.7547924518585205, train/raw-loss = 0.7366148829460144, train/logprobs = tensor([[-1.1115, -2.0141],
        [-1.1175, -1.2980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04544384032487869
Epoch 0, Step 617: train/loss = 0.7125588059425354, train/raw-loss = 0.7090034484863281, train/logprobs = tensor([[-0.7752, -1.3739],
        [-0.8965, -1.0539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008888376876711845
Epoch 0, Step 618: train/loss = 0.7178260087966919, train/raw-loss = 0.7146183252334595, train/logprobs = tensor([[-1.3187, -1.1714],
        [-1.2733, -1.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008019217289984226
Epoch 0, Step 619: train/loss = 0.7007483243942261, train/raw-loss = 0.6997913718223572, train/logprobs = tensor([[-1.1963, -1.2303],
        [-1.4957, -1.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023923544213175774
Epoch 0, Step 620: train/loss = 0.7562873959541321, train/raw-loss = 0.7478516101837158, train/logprobs = tensor([[-1.0123, -1.7612],
        [-1.1500, -1.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021089477464556694
Epoch 0, Step 621: train/loss = 0.7191680073738098, train/raw-loss = 0.7180148959159851, train/logprobs = tensor([[-1.0013, -1.0245],
        [-1.0670, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028827982023358345
Epoch 0, Step 622: train/loss = 0.69776850938797, train/raw-loss = 0.6838217973709106, train/logprobs = tensor([[-1.0517, -1.6252],
        [-1.1354, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034866753965616226
Epoch 0, Step 623: train/loss = 0.7861241102218628, train/raw-loss = 0.784178614616394, train/logprobs = tensor([[-1.3981, -1.0742],
        [-1.4663, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004863744135946035
Epoch 0, Step 624: train/loss = 0.7342623472213745, train/raw-loss = 0.7284438610076904, train/logprobs = tensor([[-1.0002, -1.5696],
        [-1.0582, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014546195976436138
Epoch 0, Step 625: train/loss = 0.7292259931564331, train/raw-loss = 0.7274330854415894, train/logprobs = tensor([[-0.6578, -1.2730],
        [-0.6937, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004482264630496502
Epoch 0, Step 626: train/loss = 0.6975951790809631, train/raw-loss = 0.6966025829315186, train/logprobs = tensor([[-1.2519, -1.1728],
        [-1.3478, -1.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002481545088812709
Epoch 0, Step 627: train/loss = 0.7086014151573181, train/raw-loss = 0.7075790166854858, train/logprobs = tensor([[-1.6607, -1.4314],
        [-1.4042, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025559423957020044
Epoch 0, Step 628: train/loss = 0.7053730487823486, train/raw-loss = 0.7002965807914734, train/logprobs = tensor([[-1.0907, -1.1967],
        [-1.3857, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01269123237580061
Epoch 0, Step 629: train/loss = 0.6930946707725525, train/raw-loss = 0.6843501925468445, train/logprobs = tensor([[-1.1804, -1.6294],
        [-1.2267, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021861186251044273
Epoch 0, Step 630: train/loss = 0.7308240532875061, train/raw-loss = 0.7255085706710815, train/logprobs = tensor([[-0.8320, -1.1681],
        [-0.9660, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013288858346641064
Epoch 0, Step 631: train/loss = 0.685825526714325, train/raw-loss = 0.6721478700637817, train/logprobs = tensor([[-1.0341, -1.7857],
        [-1.2336, -1.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034194108098745346
Epoch 0, Step 632: train/loss = 0.7048324942588806, train/raw-loss = 0.6971244812011719, train/logprobs = tensor([[-1.2915, -1.8054],
        [-1.2838, -1.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019270095974206924
Epoch 0, Step 633: train/loss = 0.6932811141014099, train/raw-loss = 0.6930192112922668, train/logprobs = tensor([[-1.5164, -1.5745],
        [-1.2771, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006548921810463071
Epoch 0, Step 634: train/loss = 0.6889657974243164, train/raw-loss = 0.6682277917861938, train/logprobs = tensor([[-1.4064, -1.9405],
        [-1.3286, -1.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05184509605169296
Epoch 0, Step 635: train/loss = 0.6974055767059326, train/raw-loss = 0.6969792246818542, train/logprobs = tensor([[-1.3664, -1.3663],
        [-0.9230, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010658532846719027
Epoch 0, Step 636: train/loss = 0.6986203789710999, train/raw-loss = 0.682684600353241, train/logprobs = tensor([[-1.1521, -1.6115],
        [-1.2613, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03983951732516289
Epoch 0, Step 637: train/loss = 0.6946366429328918, train/raw-loss = 0.6910519599914551, train/logprobs = tensor([[-0.9012, -1.1529],
        [-1.0922, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0089617520570755
Epoch 0, Step 638: train/loss = 0.7203538417816162, train/raw-loss = 0.711362361907959, train/logprobs = tensor([[-0.8733, -1.5560],
        [-1.0081, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022478630766272545
Epoch 0, Step 639: train/loss = 0.7115617990493774, train/raw-loss = 0.6984741687774658, train/logprobs = tensor([[-1.0430, -1.7891],
        [-1.1084, -1.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03271898999810219
Epoch 0, Step 640: train/loss = 0.6947324872016907, train/raw-loss = 0.6812210083007812, train/logprobs = tensor([[-1.0546, -2.0676],
        [-1.4581, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033778537064790726
Epoch 0, Step 641: train/loss = 0.7127540707588196, train/raw-loss = 0.707561731338501, train/logprobs = tensor([[-1.2004, -1.6822],
        [-1.2976, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012980739586055279
Epoch 0, Step 642: train/loss = 0.6997827887535095, train/raw-loss = 0.6968263387680054, train/logprobs = tensor([[-0.9999, -1.3492],
        [-0.8653, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007391308434307575
Epoch 0, Step 643: train/loss = 0.6997109651565552, train/raw-loss = 0.6922219395637512, train/logprobs = tensor([[-1.1961, -1.5149],
        [-1.4130, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01872246339917183
Epoch 0, Step 644: train/loss = 0.7107199430465698, train/raw-loss = 0.703067421913147, train/logprobs = tensor([[-1.1049, -1.5916],
        [-1.2204, -1.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019131433218717575
Epoch 0, Step 645: train/loss = 0.7162063121795654, train/raw-loss = 0.7131702899932861, train/logprobs = tensor([[-1.2249, -1.2848],
        [-1.1020, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007590163499116898
Epoch 0, Step 646: train/loss = 0.723529577255249, train/raw-loss = 0.7212232351303101, train/logprobs = tensor([[-0.7628, -1.3632],
        [-0.9376, -1.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005765803158283234
Epoch 0, Step 647: train/loss = 0.7224578857421875, train/raw-loss = 0.7175853252410889, train/logprobs = tensor([[-0.8403, -1.3860],
        [-0.9709, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012181533500552177
Epoch 0, Step 648: train/loss = 0.713840126991272, train/raw-loss = 0.6984020471572876, train/logprobs = tensor([[-1.0686, -1.5316],
        [-1.1749, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03859524056315422
Epoch 0, Step 649: train/loss = 0.7073844075202942, train/raw-loss = 0.7032442092895508, train/logprobs = tensor([[-0.8654, -1.3040],
        [-1.0222, -1.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010350644588470459
Epoch 0, Step 650: train/loss = 0.7110098600387573, train/raw-loss = 0.7092936038970947, train/logprobs = tensor([[-0.8074, -1.1487],
        [-0.8738, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004290636628866196
Epoch 0, Step 651: train/loss = 0.7074580788612366, train/raw-loss = 0.7024211883544922, train/logprobs = tensor([[-1.5700, -1.5503],
        [-1.3555, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012592221610248089
Epoch 0, Step 652: train/loss = 0.7096143960952759, train/raw-loss = 0.7061081528663635, train/logprobs = tensor([[-1.3253, -1.2206],
        [-1.0054, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008765645325183868
Epoch 0, Step 653: train/loss = 0.7151291370391846, train/raw-loss = 0.7120120525360107, train/logprobs = tensor([[-0.9292, -1.2700],
        [-1.0782, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007792777381837368
Epoch 0, Step 654: train/loss = 0.6943904161453247, train/raw-loss = 0.6937249302864075, train/logprobs = tensor([[-0.8921, -0.8757],
        [-0.9433, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016635984648019075
Epoch 0, Step 655: train/loss = 0.7350437045097351, train/raw-loss = 0.7095237970352173, train/logprobs = tensor([[-1.0700, -2.2659],
        [-1.1158, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06379982829093933
Epoch 0, Step 656: train/loss = 0.6917729377746582, train/raw-loss = 0.689826488494873, train/logprobs = tensor([[-1.0817, -1.2330],
        [-1.1793, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004866167902946472
Epoch 0, Step 657: train/loss = 0.696830689907074, train/raw-loss = 0.6835842132568359, train/logprobs = tensor([[-0.9815, -1.4488],
        [-1.2255, -1.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033116187900304794
Epoch 0, Step 658: train/loss = 0.7021071910858154, train/raw-loss = 0.7001168727874756, train/logprobs = tensor([[-1.0766, -1.2907],
        [-1.1587, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004975750111043453
Epoch 0, Step 659: train/loss = 0.6953036785125732, train/raw-loss = 0.6927809715270996, train/logprobs = tensor([[-1.0250, -1.1445],
        [-1.1576, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006306772585958242
Epoch 0, Step 660: train/loss = 0.6907234191894531, train/raw-loss = 0.6878337860107422, train/logprobs = tensor([[-1.5004, -1.5588],
        [-1.4171, -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007224178407341242
Epoch 0, Step 661: train/loss = 0.6915595531463623, train/raw-loss = 0.6821524500846863, train/logprobs = tensor([[-1.4120, -1.5307],
        [-1.3257, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023517783731222153
Epoch 0, Step 662: train/loss = 0.7055906057357788, train/raw-loss = 0.7026640772819519, train/logprobs = tensor([[-1.0236, -0.9088],
        [-1.2014, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007316211238503456
Epoch 0, Step 663: train/loss = 0.7046866416931152, train/raw-loss = 0.6996352672576904, train/logprobs = tensor([[-1.0406, -1.3432],
        [-1.1667, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012628388591110706
Epoch 0, Step 664: train/loss = 0.7080388069152832, train/raw-loss = 0.7074065208435059, train/logprobs = tensor([[-1.1276, -1.4195],
        [-1.1798, -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015806998126208782
Epoch 0, Step 665: train/loss = 0.6976081132888794, train/raw-loss = 0.6951326727867126, train/logprobs = tensor([[-1.0037, -1.1827],
        [-1.3198, -1.2280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006188506260514259
Epoch 0, Step 666: train/loss = 0.7075027823448181, train/raw-loss = 0.706577479839325, train/logprobs = tensor([[-1.2467, -1.0010],
        [-1.4163, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023131093475967646
Epoch 0, Step 667: train/loss = 0.7000465393066406, train/raw-loss = 0.6997777223587036, train/logprobs = tensor([[-1.0826, -0.9675],
        [-1.0712, -0.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006719811353832483
Epoch 0, Step 668: train/loss = 0.7014720439910889, train/raw-loss = 0.6970592737197876, train/logprobs = tensor([[-0.9124, -1.1342],
        [-0.9575, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011031966656446457
Epoch 0, Step 669: train/loss = 0.6949176788330078, train/raw-loss = 0.6825282573699951, train/logprobs = tensor([[-1.0121, -1.4127],
        [-1.1540, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03097359649837017
Epoch 0, Step 670: train/loss = 0.6978003978729248, train/raw-loss = 0.691512942314148, train/logprobs = tensor([[-1.0885, -1.3523],
        [-1.2450, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01571863517165184
Epoch 0, Step 671: train/loss = 0.7008594870567322, train/raw-loss = 0.6995512247085571, train/logprobs = tensor([[-1.0044, -0.8869],
        [-1.1646, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032707839272916317
Epoch 0, Step 672: train/loss = 0.7056426405906677, train/raw-loss = 0.7047340273857117, train/logprobs = tensor([[-0.9272, -1.2529],
        [-1.0159, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002271628938615322
Epoch 0, Step 673: train/loss = 0.6971306800842285, train/raw-loss = 0.693091630935669, train/logprobs = tensor([[-1.0700, -1.2815],
        [-0.9413, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010097727179527283
Epoch 0, Step 674: train/loss = 0.7023679614067078, train/raw-loss = 0.6876599192619324, train/logprobs = tensor([[-0.9763, -1.5404],
        [-0.9608, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036770060658454895
Epoch 0, Step 675: train/loss = 0.696460485458374, train/raw-loss = 0.6963843703269958, train/logprobs = tensor([[-0.9999, -0.9309],
        [-0.9758, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019036777666769922
Epoch 0, Step 676: train/loss = 0.7121649980545044, train/raw-loss = 0.702139139175415, train/logprobs = tensor([[-0.9179, -1.5023],
        [-1.0792, -1.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025064541026949883
Epoch 0, Step 677: train/loss = 0.6987636685371399, train/raw-loss = 0.6911526322364807, train/logprobs = tensor([[-1.1879, -1.6813],
        [-0.9808, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01902763731777668
Epoch 0, Step 678: train/loss = 0.7070720791816711, train/raw-loss = 0.7038629651069641, train/logprobs = tensor([[-1.2189, -1.5777],
        [-1.2829, -1.3606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00802262220531702
Epoch 0, Step 679: train/loss = 0.6995848417282104, train/raw-loss = 0.6955992579460144, train/logprobs = tensor([[-1.0027, -1.1055],
        [-1.1417, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009964151307940483
Epoch 0, Step 680: train/loss = 0.6975544691085815, train/raw-loss = 0.6900067329406738, train/logprobs = tensor([[-1.2519, -2.0154],
        [-1.2903, -1.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018869420513510704
Epoch 0, Step 681: train/loss = 0.701768159866333, train/raw-loss = 0.6986366510391235, train/logprobs = tensor([[-1.3353, -1.5372],
        [-1.3033, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007828803732991219
Epoch 0, Step 682: train/loss = 0.7065902948379517, train/raw-loss = 0.7035311460494995, train/logprobs = tensor([[-1.0832, -1.1765],
        [-1.2144, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007647823542356491
Epoch 0, Step 683: train/loss = 0.7167661190032959, train/raw-loss = 0.7114952206611633, train/logprobs = tensor([[-1.0996, -1.0579],
        [-1.2314, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013177243992686272
Epoch 0, Step 684: train/loss = 0.6965745687484741, train/raw-loss = 0.6955509781837463, train/logprobs = tensor([[-1.1736, -1.5503],
        [-1.2679, -1.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025589526630938053
Epoch 0, Step 685: train/loss = 0.7067583203315735, train/raw-loss = 0.7066711187362671, train/logprobs = tensor([[-1.1729, -1.1737],
        [-1.2244, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002179801231250167
Epoch 0, Step 686: train/loss = 0.6925344467163086, train/raw-loss = 0.6894329190254211, train/logprobs = tensor([[-1.1680, -1.2984],
        [-1.1428, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007753861602395773
Epoch 0, Step 687: train/loss = 0.7024918794631958, train/raw-loss = 0.6947886943817139, train/logprobs = tensor([[-1.0313, -1.6708],
        [-1.2293, -1.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019257906824350357
Epoch 0, Step 688: train/loss = 0.7004191875457764, train/raw-loss = 0.7002622485160828, train/logprobs = tensor([[-1.0020, -1.1829],
        [-1.2402, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039222510531544685
Epoch 0, Step 689: train/loss = 0.7039278745651245, train/raw-loss = 0.700157105922699, train/logprobs = tensor([[-0.9910, -1.1462],
        [-1.1157, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009426879696547985
Epoch 0, Step 690: train/loss = 0.7269667983055115, train/raw-loss = 0.7213754653930664, train/logprobs = tensor([[-1.1155, -1.5492],
        [-1.2378, -1.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013978399336338043
Epoch 0, Step 691: train/loss = 0.6964827179908752, train/raw-loss = 0.6898891925811768, train/logprobs = tensor([[-1.0177, -1.5288],
        [-1.1477, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01648387499153614
Epoch 0, Step 692: train/loss = 0.6908307075500488, train/raw-loss = 0.6847940683364868, train/logprobs = tensor([[-1.0990, -1.4266],
        [-1.3540, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015091562643647194
Epoch 0, Step 693: train/loss = 0.690654456615448, train/raw-loss = 0.6852675676345825, train/logprobs = tensor([[-1.2140, -1.4084],
        [-1.4851, -1.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013467393815517426
Epoch 0, Step 694: train/loss = 0.7180282473564148, train/raw-loss = 0.7177949547767639, train/logprobs = tensor([[-0.9810, -1.0140],
        [-1.0077, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005831274902448058
Epoch 0, Step 695: train/loss = 0.6903538703918457, train/raw-loss = 0.6866037845611572, train/logprobs = tensor([[-0.9340, -1.1527],
        [-1.1031, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00937532540410757
Epoch 0, Step 696: train/loss = 0.6990680694580078, train/raw-loss = 0.695644736289978, train/logprobs = tensor([[-0.7115, -0.8145],
        [-0.9249, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008558446541428566
Epoch 0, Step 697: train/loss = 0.698323130607605, train/raw-loss = 0.6960841417312622, train/logprobs = tensor([[-1.1128, -1.0185],
        [-1.1990, -0.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005597247742116451
Epoch 0, Step 698: train/loss = 0.6930391788482666, train/raw-loss = 0.6901484727859497, train/logprobs = tensor([[-1.0771, -1.2738],
        [-1.3190, -1.1733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007226663175970316
Epoch 0, Step 699: train/loss = 0.7043418884277344, train/raw-loss = 0.7003182768821716, train/logprobs = tensor([[-1.1354, -1.1163],
        [-1.2726, -0.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010058896616101265
Epoch 0, Step 700: train/loss = 0.6993923783302307, train/raw-loss = 0.6931427717208862, train/logprobs = tensor([[-1.0948, -1.3633],
        [-1.1755, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015623974613845348
Epoch 0, Step 701: train/loss = 0.7236782312393188, train/raw-loss = 0.7209208011627197, train/logprobs = tensor([[-1.2194, -1.3897],
        [-1.3133, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006893675308674574
Epoch 0, Step 702: train/loss = 0.7081692218780518, train/raw-loss = 0.7031813859939575, train/logprobs = tensor([[-0.8710, -1.0857],
        [-0.8531, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012469504959881306
Epoch 0, Step 703: train/loss = 0.6966508626937866, train/raw-loss = 0.6940827369689941, train/logprobs = tensor([[-0.9719, -1.0376],
        [-1.0358, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006420261692255735
Epoch 0, Step 704: train/loss = 0.7475910782814026, train/raw-loss = 0.7395433187484741, train/logprobs = tensor([[-1.1434, -1.8350],
        [-1.1356, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020119674503803253
Epoch 0, Step 705: train/loss = 0.7130560278892517, train/raw-loss = 0.706876814365387, train/logprobs = tensor([[-1.0858, -1.4900],
        [-1.2793, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015448134392499924
Epoch 0, Step 706: train/loss = 0.6836810111999512, train/raw-loss = 0.6711703538894653, train/logprobs = tensor([[-0.8435, -1.3803],
        [-1.1298, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03127654269337654
Epoch 0, Step 707: train/loss = 0.6958320736885071, train/raw-loss = 0.6957499980926514, train/logprobs = tensor([[-1.1212, -1.1252],
        [-1.0673, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020516000222414732
Epoch 0, Step 708: train/loss = 0.6947383284568787, train/raw-loss = 0.6901527643203735, train/logprobs = tensor([[-1.0476, -1.4217],
        [-1.1568, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011463947594165802
Epoch 0, Step 709: train/loss = 0.6938351392745972, train/raw-loss = 0.6917127966880798, train/logprobs = tensor([[-1.0631, -1.1723],
        [-1.2743, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005306033417582512
Epoch 0, Step 710: train/loss = 0.6853388547897339, train/raw-loss = 0.6680099368095398, train/logprobs = tensor([[-0.9270, -1.4112],
        [-1.3159, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043322302401065826
Epoch 0, Step 711: train/loss = 0.7144768834114075, train/raw-loss = 0.7123034000396729, train/logprobs = tensor([[-1.2147, -1.1460],
        [-1.5947, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005433805286884308
Epoch 0, Step 712: train/loss = 0.7067729830741882, train/raw-loss = 0.704591691493988, train/logprobs = tensor([[-1.1098, -1.4461],
        [-1.1561, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005453332327306271
Epoch 0, Step 713: train/loss = 0.6995148062705994, train/raw-loss = 0.6992088556289673, train/logprobs = tensor([[-1.1823, -1.1777],
        [-1.2290, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007648556493222713
Epoch 0, Step 714: train/loss = 0.6950843334197998, train/raw-loss = 0.6926077604293823, train/logprobs = tensor([[-1.0309, -1.3121],
        [-1.2496, -1.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006191431079059839
Epoch 0, Step 715: train/loss = 0.7062079310417175, train/raw-loss = 0.7051191329956055, train/logprobs = tensor([[-1.0276, -1.1953],
        [-1.1069, -1.3644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027219534385949373
Epoch 0, Step 716: train/loss = 0.703179657459259, train/raw-loss = 0.6831122040748596, train/logprobs = tensor([[-1.0663, -1.8285],
        [-1.3781, -1.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05016859993338585
Epoch 0, Step 717: train/loss = 0.6950600147247314, train/raw-loss = 0.6844071745872498, train/logprobs = tensor([[-1.0893, -1.1549],
        [-1.3888, -0.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02663210965692997
Epoch 0, Step 718: train/loss = 0.6898238062858582, train/raw-loss = 0.6838593482971191, train/logprobs = tensor([[-0.9137, -1.1563],
        [-1.0806, -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01491108350455761
Epoch 0, Step 719: train/loss = 0.6936435699462891, train/raw-loss = 0.6901311278343201, train/logprobs = tensor([[-1.1911, -1.2335],
        [-1.3723, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008781266398727894
Epoch 0, Step 720: train/loss = 0.6969839930534363, train/raw-loss = 0.6962878704071045, train/logprobs = tensor([[-1.0390, -1.2052],
        [-1.1764, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001740261446684599
Epoch 0, Step 721: train/loss = 0.6974585056304932, train/raw-loss = 0.6958122253417969, train/logprobs = tensor([[-1.0472, -1.3208],
        [-1.1986, -1.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004115826915949583
Epoch 0, Step 722: train/loss = 0.6980831623077393, train/raw-loss = 0.682707667350769, train/logprobs = tensor([[-1.0684, -1.2054],
        [-1.3621, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03843887150287628
Epoch 0, Step 723: train/loss = 0.7098506093025208, train/raw-loss = 0.7095741033554077, train/logprobs = tensor([[-1.2430, -1.0591],
        [-1.3449, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006911336677148938
Epoch 0, Step 724: train/loss = 0.6934567093849182, train/raw-loss = 0.6910601854324341, train/logprobs = tensor([[-0.9845, -1.3070],
        [-1.2600, -1.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005991239100694656
Epoch 0, Step 725: train/loss = 0.6971255540847778, train/raw-loss = 0.6909173727035522, train/logprobs = tensor([[-0.9175, -1.1278],
        [-1.1201, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015520326793193817
Epoch 0, Step 726: train/loss = 0.7005866765975952, train/raw-loss = 0.6989315748214722, train/logprobs = tensor([[-1.0579, -1.0060],
        [-1.2926, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004137746524065733
Epoch 0, Step 727: train/loss = 0.7011569738388062, train/raw-loss = 0.6974984407424927, train/logprobs = tensor([[-1.1036, -1.1212],
        [-1.3780, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00914633646607399
Epoch 0, Step 728: train/loss = 0.7081254720687866, train/raw-loss = 0.707968533039093, train/logprobs = tensor([[-1.3052, -1.2109],
        [-1.4201, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039223197381943464
Epoch 0, Step 729: train/loss = 0.6957305669784546, train/raw-loss = 0.695136308670044, train/logprobs = tensor([[-0.9493, -1.0358],
        [-1.0758, -0.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014855973422527313
Epoch 0, Step 730: train/loss = 0.7002184987068176, train/raw-loss = 0.6971296072006226, train/logprobs = tensor([[-1.1156, -1.2314],
        [-1.2396, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007722427137196064
Epoch 0, Step 731: train/loss = 0.7092228531837463, train/raw-loss = 0.7039920091629028, train/logprobs = tensor([[-1.1419, -1.1069],
        [-1.4479, -0.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013077066279947758
Epoch 0, Step 732: train/loss = 0.6996850371360779, train/raw-loss = 0.6852549314498901, train/logprobs = tensor([[-1.0448, -1.3966],
        [-1.3582, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03607535362243652
Epoch 0, Step 733: train/loss = 0.7162033319473267, train/raw-loss = 0.7151265740394592, train/logprobs = tensor([[-1.1125, -0.9495],
        [-1.4625, -1.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026918447110801935
Epoch 0, Step 734: train/loss = 0.6943393349647522, train/raw-loss = 0.6938033103942871, train/logprobs = tensor([[-0.8371, -0.8283],
        [-0.9812, -0.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013401317410171032
Epoch 0, Step 735: train/loss = 0.706220269203186, train/raw-loss = 0.7039950489997864, train/logprobs = tensor([[-1.2940, -1.3357],
        [-1.4782, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00556303933262825
Epoch 0, Step 736: train/loss = 0.716760516166687, train/raw-loss = 0.7143065929412842, train/logprobs = tensor([[-1.3506, -1.1193],
        [-1.5573, -0.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061348723247647285
Epoch 0, Step 737: train/loss = 0.6944554448127747, train/raw-loss = 0.693073034286499, train/logprobs = tensor([[-1.0486, -1.0339],
        [-1.1277, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034558228217065334
Epoch 0, Step 738: train/loss = 0.6960058808326721, train/raw-loss = 0.6944851875305176, train/logprobs = tensor([[-1.0361, -1.1469],
        [-1.2945, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038017055485397577
Epoch 0, Step 739: train/loss = 0.691824197769165, train/raw-loss = 0.6866468787193298, train/logprobs = tensor([[-1.1676, -1.3034],
        [-1.1931, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012943231500685215
Epoch 0, Step 740: train/loss = 0.7023724317550659, train/raw-loss = 0.7005539536476135, train/logprobs = tensor([[-0.9153, -1.1777],
        [-1.0266, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004546204581856728
Epoch 0, Step 741: train/loss = 0.6892838478088379, train/raw-loss = 0.6833285093307495, train/logprobs = tensor([[-0.8511, -1.2012],
        [-1.1356, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014888457953929901
Epoch 0, Step 742: train/loss = 0.6834421157836914, train/raw-loss = 0.6678627729415894, train/logprobs = tensor([[-1.1699, -1.6368],
        [-1.5839, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03894822299480438
Epoch 0, Step 743: train/loss = 0.6963248252868652, train/raw-loss = 0.6849459409713745, train/logprobs = tensor([[-1.1608, -1.2743],
        [-1.5201, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02844719961285591
Epoch 0, Step 744: train/loss = 0.6956371068954468, train/raw-loss = 0.683366060256958, train/logprobs = tensor([[-0.9113, -1.1839],
        [-1.6162, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030677741393446922
Epoch 0, Step 745: train/loss = 0.6993533968925476, train/raw-loss = 0.6976326107978821, train/logprobs = tensor([[-1.0299, -1.0196],
        [-1.2531, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043021682649850845
Epoch 0, Step 746: train/loss = 0.7066190242767334, train/raw-loss = 0.7065852880477905, train/logprobs = tensor([[-0.9318, -0.7679],
        [-1.0102, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.414367766818032e-05
Epoch 0, Step 747: train/loss = 0.6925603747367859, train/raw-loss = 0.6901243329048157, train/logprobs = tensor([[-1.2821, -1.3957],
        [-1.5539, -1.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006090114824473858
Epoch 0, Step 748: train/loss = 0.6975399255752563, train/raw-loss = 0.6971588134765625, train/logprobs = tensor([[-1.0550, -0.9680],
        [-1.2981, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009529655217193067
Epoch 0, Step 749: train/loss = 0.7091286778450012, train/raw-loss = 0.7050871849060059, train/logprobs = tensor([[-1.1108, -1.0783],
        [-1.5591, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010103688575327396
Epoch 0, Step 750: train/loss = 0.7018876075744629, train/raw-loss = 0.6975066065788269, train/logprobs = tensor([[-0.9294, -0.9769],
        [-1.2044, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010952461510896683
Epoch 0, Step 751: train/loss = 0.6944406032562256, train/raw-loss = 0.6921331882476807, train/logprobs = tensor([[-1.1986, -1.3385],
        [-1.2286, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0057685053907334805
Epoch 0, Step 752: train/loss = 0.6959120631217957, train/raw-loss = 0.6943584680557251, train/logprobs = tensor([[-1.2367, -1.4258],
        [-1.0442, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038838691543787718
Epoch 0, Step 753: train/loss = 0.6968615055084229, train/raw-loss = 0.6911033987998962, train/logprobs = tensor([[-1.1327, -1.4228],
        [-1.2427, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014395210891962051
Epoch 0, Step 754: train/loss = 0.7282470464706421, train/raw-loss = 0.7263778448104858, train/logprobs = tensor([[-1.2174, -0.8658],
        [-1.4657, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004672940820455551
Epoch 0, Step 755: train/loss = 0.6897268295288086, train/raw-loss = 0.6832064390182495, train/logprobs = tensor([[-1.0217, -1.3211],
        [-1.3163, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016300976276397705
Epoch 0, Step 756: train/loss = 0.6928766965866089, train/raw-loss = 0.6907548904418945, train/logprobs = tensor([[-1.1936, -1.3020],
        [-1.3997, -1.2315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005304704420268536
Epoch 0, Step 757: train/loss = 0.6989998817443848, train/raw-loss = 0.698876678943634, train/logprobs = tensor([[-1.1206, -0.9731],
        [-1.4965, -1.3440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030798919033259153
Epoch 0, Step 758: train/loss = 0.6970707178115845, train/raw-loss = 0.6963752508163452, train/logprobs = tensor([[-0.9052, -1.0884],
        [-1.2253, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017385573592036963
Epoch 0, Step 759: train/loss = 0.6793352961540222, train/raw-loss = 0.6614909172058105, train/logprobs = tensor([[-0.9530, -1.3649],
        [-1.4555, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044611088931560516
Epoch 0, Step 760: train/loss = 0.6910622119903564, train/raw-loss = 0.6880891919136047, train/logprobs = tensor([[-1.1140, -1.2785],
        [-1.4106, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007432526908814907
Epoch 0, Step 761: train/loss = 0.7406167984008789, train/raw-loss = 0.7334900498390198, train/logprobs = tensor([[-1.2040, -1.1643],
        [-1.5707, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017816906794905663
Epoch 0, Step 762: train/loss = 0.6921828985214233, train/raw-loss = 0.6891791224479675, train/logprobs = tensor([[-0.8381, -1.1142],
        [-0.9997, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007509383372962475
Epoch 0, Step 763: train/loss = 0.7152611017227173, train/raw-loss = 0.7150821089744568, train/logprobs = tensor([[-1.1517, -0.8289],
        [-1.3014, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044740125304087996
Epoch 0, Step 764: train/loss = 0.698538601398468, train/raw-loss = 0.6924029588699341, train/logprobs = tensor([[-1.2113, -1.1956],
        [-1.3014, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015339222736656666
Epoch 0, Step 765: train/loss = 0.7128649950027466, train/raw-loss = 0.7114448547363281, train/logprobs = tensor([[-1.1623, -0.9567],
        [-1.1982, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003550176741555333
Epoch 0, Step 766: train/loss = 0.7117128372192383, train/raw-loss = 0.7112469673156738, train/logprobs = tensor([[-1.1847, -1.0745],
        [-1.4568, -1.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00116460002027452
Epoch 0, Step 767: train/loss = 0.697744607925415, train/raw-loss = 0.6973601579666138, train/logprobs = tensor([[-0.9188, -0.8138],
        [-1.0573, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009609634871594608
Epoch 0, Step 768: train/loss = 0.6934474110603333, train/raw-loss = 0.6833364963531494, train/logprobs = tensor([[-1.0882, -1.3085],
        [-1.2941, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02527727745473385
Epoch 0, Step 769: train/loss = 0.7261074185371399, train/raw-loss = 0.7171573638916016, train/logprobs = tensor([[-1.0000, -1.6267],
        [-1.3275, -1.2853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02237529493868351
Epoch 0, Step 770: train/loss = 0.6888808012008667, train/raw-loss = 0.6801809668540955, train/logprobs = tensor([[-1.1991, -1.3756],
        [-1.5203, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021749382838606834
Epoch 0, Step 771: train/loss = 0.6871935129165649, train/raw-loss = 0.6815546751022339, train/logprobs = tensor([[-1.1468, -1.2351],
        [-1.4402, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014097272418439388
Epoch 0, Step 772: train/loss = 0.6946266889572144, train/raw-loss = 0.6855294108390808, train/logprobs = tensor([[-0.8643, -1.0543],
        [-1.2526, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022743254899978638
Epoch 0, Step 773: train/loss = 0.6971404552459717, train/raw-loss = 0.6885857582092285, train/logprobs = tensor([[-1.1544, -1.1596],
        [-1.6017, -1.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02138693630695343
Epoch 0, Step 774: train/loss = 0.6972236633300781, train/raw-loss = 0.6945973038673401, train/logprobs = tensor([[-1.0281, -1.1502],
        [-1.3595, -1.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006565879099071026
Epoch 0, Step 775: train/loss = 0.726325511932373, train/raw-loss = 0.7246128916740417, train/logprobs = tensor([[-1.1329, -0.8841],
        [-1.1871, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004281502682715654
Epoch 0, Step 776: train/loss = 0.7352595925331116, train/raw-loss = 0.7344502806663513, train/logprobs = tensor([[-1.2472, -1.0618],
        [-1.4548, -1.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020232233218848705
Epoch 0, Step 777: train/loss = 0.6931074261665344, train/raw-loss = 0.6915690302848816, train/logprobs = tensor([[-0.9183, -1.0036],
        [-1.1170, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038460169453173876
Epoch 0, Step 778: train/loss = 0.6991040110588074, train/raw-loss = 0.6847145557403564, train/logprobs = tensor([[-1.2352, -1.2096],
        [-1.6490, -1.0761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03597363829612732
Epoch 0, Step 779: train/loss = 0.7042984962463379, train/raw-loss = 0.7036529183387756, train/logprobs = tensor([[-0.7959, -0.7743],
        [-0.8281, -0.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016139323124662042
Epoch 0, Step 780: train/loss = 0.6959852576255798, train/raw-loss = 0.6935224533081055, train/logprobs = tensor([[-1.1648, -1.0805],
        [-1.2761, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006157011725008488
Epoch 0, Step 781: train/loss = 0.7040190100669861, train/raw-loss = 0.7023413181304932, train/logprobs = tensor([[-0.9700, -0.8136],
        [-1.0823, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004194407723844051
Epoch 0, Step 782: train/loss = 0.6943860054016113, train/raw-loss = 0.6878063678741455, train/logprobs = tensor([[-0.9972, -0.9984],
        [-1.1315, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016448939219117165
Epoch 0, Step 783: train/loss = 0.7114362716674805, train/raw-loss = 0.708781898021698, train/logprobs = tensor([[-1.0654, -0.8695],
        [-1.2897, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006635825615376234
Epoch 0, Step 784: train/loss = 0.6959116458892822, train/raw-loss = 0.6926984786987305, train/logprobs = tensor([[-0.9179, -0.9706],
        [-1.1036, -1.0542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008032944053411484
Epoch 0, Step 785: train/loss = 0.7034235596656799, train/raw-loss = 0.6990144848823547, train/logprobs = tensor([[-1.1582, -1.5054],
        [-1.5172, -1.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011022720485925674
Epoch 0, Step 786: train/loss = 0.7076436877250671, train/raw-loss = 0.701390266418457, train/logprobs = tensor([[-1.0517, -1.2821],
        [-1.3306, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015633556991815567
Epoch 0, Step 787: train/loss = 0.6930842399597168, train/raw-loss = 0.6918969750404358, train/logprobs = tensor([[-0.9333, -0.9735],
        [-1.1132, -1.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029682095628231764
Epoch 0, Step 788: train/loss = 0.7052708864212036, train/raw-loss = 0.6985250115394592, train/logprobs = tensor([[-0.9543, -0.9867],
        [-1.2694, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016864772886037827
Epoch 0, Step 789: train/loss = 0.7064927816390991, train/raw-loss = 0.7060796022415161, train/logprobs = tensor([[-1.1701, -1.1098],
        [-1.2600, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001032807631418109
Epoch 0, Step 790: train/loss = 0.6933519244194031, train/raw-loss = 0.6867434978485107, train/logprobs = tensor([[-1.0949, -1.2931],
        [-1.2410, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01652117446064949
Epoch 0, Step 791: train/loss = 0.6996903419494629, train/raw-loss = 0.6967697143554688, train/logprobs = tensor([[-1.2434, -1.4885],
        [-1.5407, -1.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007301535923033953
Epoch 0, Step 792: train/loss = 0.7548339366912842, train/raw-loss = 0.749110221862793, train/logprobs = tensor([[-1.3380, -0.9998],
        [-1.7633, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014309410005807877
Epoch 0, Step 793: train/loss = 0.6910513639450073, train/raw-loss = 0.6867483854293823, train/logprobs = tensor([[-0.9942, -1.1361],
        [-1.0513, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010757428593933582
Epoch 0, Step 794: train/loss = 0.6945033073425293, train/raw-loss = 0.6936999559402466, train/logprobs = tensor([[-0.9828, -0.9228],
        [-0.8635, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002008285839110613
Epoch 0, Step 795: train/loss = 0.7011977434158325, train/raw-loss = 0.6879026293754578, train/logprobs = tensor([[-1.3097, -1.3569],
        [-1.8291, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0332377627491951
Epoch 0, Step 796: train/loss = 0.6813284158706665, train/raw-loss = 0.6596476435661316, train/logprobs = tensor([[-1.0772, -1.4041],
        [-1.1016, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054202187806367874
Epoch 0, Step 797: train/loss = 0.694646418094635, train/raw-loss = 0.6892623901367188, train/logprobs = tensor([[-1.2848, -1.3208],
        [-1.4542, -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013460037298500538
Epoch 0, Step 798: train/loss = 0.6966347694396973, train/raw-loss = 0.6956335306167603, train/logprobs = tensor([[-0.8396, -1.0337],
        [-1.0283, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002503274939954281
Epoch 0, Step 799: train/loss = 0.7134004831314087, train/raw-loss = 0.7127408385276794, train/logprobs = tensor([[-0.8185, -0.8424],
        [-0.9446, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016489842673763633
Epoch 0, Step 800: train/loss = 0.6999073028564453, train/raw-loss = 0.6878926157951355, train/logprobs = tensor([[-0.9162, -1.1401],
        [-1.5712, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030036769807338715
Epoch 0, Step 801: train/loss = 0.6957465410232544, train/raw-loss = 0.6950386166572571, train/logprobs = tensor([[-0.8789, -1.0313],
        [-1.1127, -0.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001769908471032977
Epoch 0, Step 802: train/loss = 0.6986225843429565, train/raw-loss = 0.6965315341949463, train/logprobs = tensor([[-1.0642, -1.0191],
        [-1.2287, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052277809008955956
Epoch 0, Step 803: train/loss = 0.6893377304077148, train/raw-loss = 0.6759500503540039, train/logprobs = tensor([[-1.0257, -1.3446],
        [-1.2444, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03346943110227585
Epoch 0, Step 804: train/loss = 0.6950851678848267, train/raw-loss = 0.6949599981307983, train/logprobs = tensor([[-0.8869, -0.8626],
        [-0.8747, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003128076787106693
Epoch 0, Step 805: train/loss = 0.6984779834747314, train/raw-loss = 0.6954758763313293, train/logprobs = tensor([[-1.2212, -1.2144],
        [-1.4044, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007505361922085285
Epoch 0, Step 806: train/loss = 0.6940611600875854, train/raw-loss = 0.6912369728088379, train/logprobs = tensor([[-1.1585, -1.2134],
        [-1.1258, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007060284726321697
Epoch 0, Step 807: train/loss = 0.6922087669372559, train/raw-loss = 0.6859480738639832, train/logprobs = tensor([[-0.9543, -1.1212],
        [-1.3872, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01565185748040676
Epoch 0, Step 808: train/loss = 0.6924768090248108, train/raw-loss = 0.6904479265213013, train/logprobs = tensor([[-0.9122, -1.0984],
        [-1.0706, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0050721606239676476
Epoch 0, Step 809: train/loss = 0.699547529220581, train/raw-loss = 0.69618821144104, train/logprobs = tensor([[-1.0161, -0.9005],
        [-1.2612, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008398172445595264
Epoch 0, Step 810: train/loss = 0.6667268872261047, train/raw-loss = 0.6643661856651306, train/logprobs = tensor([[-0.9711, -1.1909],
        [-1.2129, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005901720374822617
Epoch 0, Step 811: train/loss = 0.6984953880310059, train/raw-loss = 0.6938730478286743, train/logprobs = tensor([[-1.1884, -1.0941],
        [-1.3597, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011555731296539307
Epoch 0, Step 812: train/loss = 0.6913958787918091, train/raw-loss = 0.6842190623283386, train/logprobs = tensor([[-0.8627, -1.0413],
        [-1.1288, -0.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017942029982805252
Epoch 0, Step 813: train/loss = 0.6982777118682861, train/raw-loss = 0.6914293766021729, train/logprobs = tensor([[-1.1181, -1.1332],
        [-1.4284, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01712070032954216
Epoch 0, Step 814: train/loss = 0.6928125619888306, train/raw-loss = 0.6900365352630615, train/logprobs = tensor([[-1.2365, -1.4976],
        [-1.3144, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006939985323697329
Epoch 0, Step 815: train/loss = 0.695465087890625, train/raw-loss = 0.6953481435775757, train/logprobs = tensor([[-1.2742, -1.2327],
        [-1.2981, -1.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029243051540106535
Epoch 0, Step 816: train/loss = 0.7113379240036011, train/raw-loss = 0.7104753255844116, train/logprobs = tensor([[-1.0682, -0.8605],
        [-1.1525, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021565365605056286
Epoch 0, Step 817: train/loss = 0.6870059967041016, train/raw-loss = 0.6790924668312073, train/logprobs = tensor([[-1.0267, -1.2991],
        [-1.3493, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01978364586830139
Epoch 0, Step 818: train/loss = 0.6930955648422241, train/raw-loss = 0.6858230829238892, train/logprobs = tensor([[-0.8732, -1.3752],
        [-1.4073, -1.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01818147674202919
Epoch 0, Step 819: train/loss = 0.6957058906555176, train/raw-loss = 0.6944867968559265, train/logprobs = tensor([[-1.2169, -1.2429],
        [-1.4031, -1.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003047717735171318
Epoch 0, Step 820: train/loss = 0.6946220397949219, train/raw-loss = 0.6917455196380615, train/logprobs = tensor([[-1.0066, -1.1000],
        [-1.1792, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007191272918134928
Epoch 0, Step 821: train/loss = 0.6998546123504639, train/raw-loss = 0.6975165009498596, train/logprobs = tensor([[-1.0770, -1.0332],
        [-1.3760, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00584530271589756
Epoch 0, Step 822: train/loss = 0.6955743432044983, train/raw-loss = 0.693992018699646, train/logprobs = tensor([[-1.0263, -1.0793],
        [-1.0782, -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003955844324082136
Epoch 0, Step 823: train/loss = 0.7045756578445435, train/raw-loss = 0.7000298500061035, train/logprobs = tensor([[-1.2180, -1.1911],
        [-1.5328, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011364556849002838
Epoch 0, Step 824: train/loss = 0.6910325288772583, train/raw-loss = 0.6838610172271729, train/logprobs = tensor([[-0.8877, -1.2296],
        [-1.2021, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017928777262568474
Epoch 0, Step 825: train/loss = 0.6946653127670288, train/raw-loss = 0.692962646484375, train/logprobs = tensor([[-1.2704, -1.5161],
        [-1.6268, -1.5948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004256776068359613
Epoch 0, Step 826: train/loss = 0.6960330009460449, train/raw-loss = 0.6929662823677063, train/logprobs = tensor([[-1.1301, -1.1789],
        [-1.3121, -1.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007666773162782192
Epoch 0, Step 827: train/loss = 0.6967796683311462, train/raw-loss = 0.6930624842643738, train/logprobs = tensor([[-0.9859, -1.0069],
        [-1.2135, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009292864240705967
Epoch 0, Step 828: train/loss = 0.6967755556106567, train/raw-loss = 0.6946582794189453, train/logprobs = tensor([[-0.8468, -1.0376],
        [-0.9777, -0.9715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052933115512132645
Epoch 0, Step 829: train/loss = 0.6993462443351746, train/raw-loss = 0.6946825981140137, train/logprobs = tensor([[-1.0961, -1.1564],
        [-1.5749, -1.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011659091338515282
Epoch 0, Step 830: train/loss = 0.7127628922462463, train/raw-loss = 0.6983929872512817, train/logprobs = tensor([[-0.8150, -1.3162],
        [-1.1558, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03592459112405777
Epoch 0, Step 831: train/loss = 0.6928396224975586, train/raw-loss = 0.6844792366027832, train/logprobs = tensor([[-0.8744, -1.0488],
        [-1.2121, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020900990813970566
Epoch 0, Step 832: train/loss = 0.6875084638595581, train/raw-loss = 0.6827893257141113, train/logprobs = tensor([[-0.9485, -1.2063],
        [-1.1263, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011797918006777763
Epoch 0, Step 833: train/loss = 0.7170699834823608, train/raw-loss = 0.7151709794998169, train/logprobs = tensor([[-1.2735, -1.0896],
        [-1.3772, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004747441504150629
Epoch 0, Step 834: train/loss = 0.7065130472183228, train/raw-loss = 0.7052537202835083, train/logprobs = tensor([[-0.9664, -0.9741],
        [-1.1168, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003148287069052458
Epoch 0, Step 835: train/loss = 0.6895806193351746, train/raw-loss = 0.6856571435928345, train/logprobs = tensor([[-0.9249, -1.0346],
        [-1.1623, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009808615781366825
Epoch 0, Step 836: train/loss = 0.7097582817077637, train/raw-loss = 0.7050220370292664, train/logprobs = tensor([[-1.0911, -1.2999],
        [-1.3806, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011840499006211758
Epoch 0, Step 837: train/loss = 0.7193741798400879, train/raw-loss = 0.709121823310852, train/logprobs = tensor([[-0.9814, -1.3831],
        [-1.4077, -1.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02563079632818699
Epoch 0, Step 838: train/loss = 0.6973621845245361, train/raw-loss = 0.6913940906524658, train/logprobs = tensor([[-1.0798, -1.3807],
        [-1.3534, -1.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014920243993401527
Epoch 0, Step 839: train/loss = 0.681801438331604, train/raw-loss = 0.6761846542358398, train/logprobs = tensor([[-0.9380, -1.2228],
        [-1.3083, -1.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014042070135474205
Epoch 0, Step 840: train/loss = 0.7210710048675537, train/raw-loss = 0.7171016931533813, train/logprobs = tensor([[-1.0514, -1.0379],
        [-1.4079, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009923161938786507
Epoch 0, Step 841: train/loss = 0.6924142837524414, train/raw-loss = 0.6867648363113403, train/logprobs = tensor([[-1.1534, -1.2909],
        [-1.4353, -1.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014123402535915375
Epoch 0, Step 842: train/loss = 0.7382517457008362, train/raw-loss = 0.7257294058799744, train/logprobs = tensor([[-0.8558, -1.0900],
        [-1.2884, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031305860728025436
Epoch 0, Step 843: train/loss = 0.7106771469116211, train/raw-loss = 0.7088065147399902, train/logprobs = tensor([[-1.4346, -1.3161],
        [-1.5727, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004676667507737875
Epoch 0, Step 844: train/loss = 0.7041757106781006, train/raw-loss = 0.6988068222999573, train/logprobs = tensor([[-1.0401, -1.1792],
        [-1.2493, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013422333635389805
Epoch 0, Step 845: train/loss = 0.6930726766586304, train/raw-loss = 0.6806410551071167, train/logprobs = tensor([[-1.0395, -1.5767],
        [-1.3466, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031078750267624855
Epoch 0, Step 846: train/loss = 0.692840576171875, train/raw-loss = 0.6849429607391357, train/logprobs = tensor([[-0.6242, -0.8389],
        [-1.0401, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019743891432881355
Epoch 0, Step 847: train/loss = 0.6927262544631958, train/raw-loss = 0.689531683921814, train/logprobs = tensor([[-1.0024, -1.0836],
        [-1.1553, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007986502721905708
Epoch 0, Step 848: train/loss = 0.695236325263977, train/raw-loss = 0.6950950622558594, train/logprobs = tensor([[-0.9719, -1.0427],
        [-0.8157, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003532881964929402
Epoch 0, Step 849: train/loss = 0.6953458189964294, train/raw-loss = 0.6910739541053772, train/logprobs = tensor([[-0.9822, -1.0600],
        [-1.1693, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01067973580211401
Epoch 0, Step 850: train/loss = 0.6852219700813293, train/raw-loss = 0.6742105484008789, train/logprobs = tensor([[-0.9301, -1.3005],
        [-1.2177, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02752857469022274
Epoch 0, Step 851: train/loss = 0.698693573474884, train/raw-loss = 0.6962991952896118, train/logprobs = tensor([[-0.9357, -1.1542],
        [-1.1390, -1.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005985981319099665
Epoch 0, Step 852: train/loss = 0.6988686919212341, train/raw-loss = 0.6960920095443726, train/logprobs = tensor([[-1.1014, -1.0561],
        [-1.4959, -1.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006941717583686113
Epoch 0, Step 853: train/loss = 0.68785160779953, train/raw-loss = 0.6807676553726196, train/logprobs = tensor([[-1.0584, -1.3284],
        [-1.2296, -1.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017709966748952866
Epoch 0, Step 854: train/loss = 0.7116599082946777, train/raw-loss = 0.7110971212387085, train/logprobs = tensor([[-0.9730, -0.7030],
        [-1.2204, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014069752069190145
Epoch 0, Step 855: train/loss = 0.6998949646949768, train/raw-loss = 0.6912802457809448, train/logprobs = tensor([[-0.9745, -1.1474],
        [-1.4979, -1.1594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021536806598305702
Epoch 0, Step 856: train/loss = 0.6988423466682434, train/raw-loss = 0.6917973160743713, train/logprobs = tensor([[-1.1440, -1.2386],
        [-1.5248, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017612487077713013
Epoch 0, Step 857: train/loss = 0.691478431224823, train/raw-loss = 0.6900516152381897, train/logprobs = tensor([[-0.8991, -1.0004],
        [-0.9402, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035671349614858627
Epoch 0, Step 858: train/loss = 0.6948913335800171, train/raw-loss = 0.6928924918174744, train/logprobs = tensor([[-0.8323, -1.0855],
        [-1.0832, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004996967501938343
Epoch 0, Step 859: train/loss = 0.6988564133644104, train/raw-loss = 0.6960180401802063, train/logprobs = tensor([[-1.1243, -1.1258],
        [-1.3350, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007095830515027046
Epoch 0, Step 860: train/loss = 0.697876513004303, train/raw-loss = 0.6940442323684692, train/logprobs = tensor([[-1.1091, -1.0864],
        [-1.2930, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009580753743648529
Epoch 0, Step 861: train/loss = 0.710139274597168, train/raw-loss = 0.7082204222679138, train/logprobs = tensor([[-1.0873, -1.1381],
        [-1.2683, -0.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00479702465236187
Epoch 0, Step 862: train/loss = 0.6979423761367798, train/raw-loss = 0.6942925453186035, train/logprobs = tensor([[-1.3045, -1.4463],
        [-1.7882, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009124473668634892
Epoch 0, Step 863: train/loss = 0.7758574485778809, train/raw-loss = 0.7377069592475891, train/logprobs = tensor([[-1.2719, -1.6927],
        [-1.7103, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09537610411643982
Epoch 0, Step 864: train/loss = 0.6601729989051819, train/raw-loss = 0.6486181020736694, train/logprobs = tensor([[-0.8364, -1.3877],
        [-1.7575, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02888738363981247
Epoch 0, Step 865: train/loss = 0.7071400880813599, train/raw-loss = 0.7066448926925659, train/logprobs = tensor([[-1.1631, -1.4789],
        [-1.5539, -1.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012381301494315267
Epoch 0, Step 866: train/loss = 0.6942597031593323, train/raw-loss = 0.6885952949523926, train/logprobs = tensor([[-0.8960, -1.0383],
        [-1.1801, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014160921797156334
Epoch 0, Step 867: train/loss = 0.6862634420394897, train/raw-loss = 0.6756954789161682, train/logprobs = tensor([[-1.2799, -1.5088],
        [-1.3114, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026420028880238533
Epoch 0, Step 868: train/loss = 0.6990633010864258, train/raw-loss = 0.6960940361022949, train/logprobs = tensor([[-0.6437, -0.9479],
        [-0.8845, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007423220667988062
Epoch 0, Step 869: train/loss = 0.6971582174301147, train/raw-loss = 0.6891894340515137, train/logprobs = tensor([[-1.0549, -1.2160],
        [-1.1767, -1.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019922032952308655
Epoch 0, Step 870: train/loss = 0.6941636204719543, train/raw-loss = 0.6896461248397827, train/logprobs = tensor([[-1.2577, -1.5633],
        [-1.1487, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011293984949588776
Epoch 0, Step 871: train/loss = 0.6886106729507446, train/raw-loss = 0.6831012964248657, train/logprobs = tensor([[-1.0086, -1.3674],
        [-1.1239, -1.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013773463666439056
Epoch 0, Step 872: train/loss = 0.6996581554412842, train/raw-loss = 0.6986408233642578, train/logprobs = tensor([[-1.2139, -1.1288],
        [-1.0918, -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002543255453929305
Epoch 0, Step 873: train/loss = 0.7161391973495483, train/raw-loss = 0.7115966081619263, train/logprobs = tensor([[-1.0263, -1.1787],
        [-1.1221, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011356296017765999
Epoch 0, Step 874: train/loss = 0.7001755237579346, train/raw-loss = 0.6846634149551392, train/logprobs = tensor([[-1.2557, -1.3601],
        [-1.5694, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03878035396337509
Epoch 0, Step 875: train/loss = 0.7163408994674683, train/raw-loss = 0.7136344909667969, train/logprobs = tensor([[-0.9012, -1.5032],
        [-1.1183, -1.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00676586152985692
Epoch 0, Step 876: train/loss = 0.6989446878433228, train/raw-loss = 0.6985249519348145, train/logprobs = tensor([[-1.1112, -1.3555],
        [-1.2686, -1.3860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010493238223716617
Epoch 0, Step 877: train/loss = 0.7120874524116516, train/raw-loss = 0.6977959871292114, train/logprobs = tensor([[-1.2653, -1.2145],
        [-1.3566, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035728562623262405
Epoch 0, Step 878: train/loss = 0.6901365518569946, train/raw-loss = 0.6792410612106323, train/logprobs = tensor([[-0.8784, -1.0840],
        [-1.2363, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02723873406648636
Epoch 0, Step 879: train/loss = 0.7070264220237732, train/raw-loss = 0.7061790227890015, train/logprobs = tensor([[-0.7669, -0.7677],
        [-1.0149, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002118444535881281
Epoch 0, Step 880: train/loss = 0.6963332295417786, train/raw-loss = 0.6831346154212952, train/logprobs = tensor([[-0.8032, -1.4823],
        [-1.5578, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299630433320999
Epoch 0, Step 881: train/loss = 0.7007836103439331, train/raw-loss = 0.686880886554718, train/logprobs = tensor([[-1.1546, -1.2227],
        [-1.3863, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03475678712129593
Epoch 0, Step 882: train/loss = 0.6829972267150879, train/raw-loss = 0.6689146757125854, train/logprobs = tensor([[-1.0198, -1.3298],
        [-1.3639, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035206250846385956
Epoch 0, Step 883: train/loss = 0.7060180306434631, train/raw-loss = 0.6951514482498169, train/logprobs = tensor([[-1.2523, -1.2494],
        [-1.7490, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027166441082954407
Epoch 0, Step 884: train/loss = 0.688423216342926, train/raw-loss = 0.6807807683944702, train/logprobs = tensor([[-0.8394, -1.0165],
        [-1.0929, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019106224179267883
Epoch 0, Step 885: train/loss = 0.6903043985366821, train/raw-loss = 0.6821043491363525, train/logprobs = tensor([[-0.9576, -1.1764],
        [-1.4007, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020500004291534424
Epoch 0, Step 886: train/loss = 0.7087992429733276, train/raw-loss = 0.7042989134788513, train/logprobs = tensor([[-1.0392, -0.9331],
        [-1.2034, -0.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011250875890254974
Epoch 0, Step 887: train/loss = 0.6938567161560059, train/raw-loss = 0.6934003233909607, train/logprobs = tensor([[-1.2274, -1.2425],
        [-1.1516, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001141026266850531
Epoch 0, Step 888: train/loss = 0.7002326846122742, train/raw-loss = 0.6991762518882751, train/logprobs = tensor([[-1.3076, -1.2092],
        [-1.2308, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026410941500216722
Epoch 0, Step 889: train/loss = 0.7070612907409668, train/raw-loss = 0.6956648230552673, train/logprobs = tensor([[-1.2507, -1.2985],
        [-1.3843, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0284911897033453
Epoch 0, Step 890: train/loss = 0.6934529542922974, train/raw-loss = 0.6934407949447632, train/logprobs = tensor([[-1.0755, -1.0475],
        [-0.9396, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0511815566569567e-05
Epoch 0, Step 891: train/loss = 0.6415773630142212, train/raw-loss = 0.6341744661331177, train/logprobs = tensor([[-0.8780, -1.3993],
        [-1.4376, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01850752905011177
Epoch 0, Step 892: train/loss = 0.6994786262512207, train/raw-loss = 0.698183536529541, train/logprobs = tensor([[-1.2184, -1.2952],
        [-1.1520, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003237666329368949
Epoch 0, Step 893: train/loss = 0.7001895308494568, train/raw-loss = 0.6995953321456909, train/logprobs = tensor([[-1.1053, -0.9666],
        [-1.3037, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014856148045510054
Epoch 0, Step 894: train/loss = 0.7387295961380005, train/raw-loss = 0.730960488319397, train/logprobs = tensor([[-1.2647, -1.0917],
        [-1.7469, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019422831013798714
Epoch 0, Step 895: train/loss = 0.7130569219589233, train/raw-loss = 0.7072492837905884, train/logprobs = tensor([[-0.9316, -0.8237],
        [-1.4657, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014519039541482925
Epoch 0, Step 896: train/loss = 0.6879760026931763, train/raw-loss = 0.6827545762062073, train/logprobs = tensor([[-0.9666, -1.2158],
        [-1.0709, -0.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01305366214364767
Epoch 0, Step 897: train/loss = 0.7031163573265076, train/raw-loss = 0.6943485736846924, train/logprobs = tensor([[-0.9866, -1.0168],
        [-1.2840, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021919529885053635
Epoch 0, Step 898: train/loss = 0.6935515403747559, train/raw-loss = 0.6907297372817993, train/logprobs = tensor([[-1.0119, -1.0519],
        [-1.0949, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0070546395145356655
Epoch 0, Step 899: train/loss = 0.6950526237487793, train/raw-loss = 0.6923303008079529, train/logprobs = tensor([[-0.9271, -1.1717],
        [-0.9163, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006805743090808392
Epoch 0, Step 900: train/loss = 0.6948198080062866, train/raw-loss = 0.6943584680557251, train/logprobs = tensor([[-1.0942, -1.0895],
        [-1.1962, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011533329961821437
Epoch 0, Step 901: train/loss = 0.7126365900039673, train/raw-loss = 0.7023818492889404, train/logprobs = tensor([[-0.8289, -1.6122],
        [-1.2522, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025636853650212288
Epoch 0, Step 902: train/loss = 0.7698763608932495, train/raw-loss = 0.7657154202461243, train/logprobs = tensor([[-1.1328, -1.6006],
        [-1.1912, -1.2704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010402431711554527
Epoch 0, Step 903: train/loss = 0.7160501480102539, train/raw-loss = 0.6991336941719055, train/logprobs = tensor([[-0.9285, -1.5729],
        [-1.2498, -1.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04229123517870903
Epoch 0, Step 904: train/loss = 0.6917265057563782, train/raw-loss = 0.6879379749298096, train/logprobs = tensor([[-0.8860, -0.9087],
        [-1.0867, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009471263736486435
Epoch 0, Step 905: train/loss = 0.6970133781433105, train/raw-loss = 0.6857696771621704, train/logprobs = tensor([[-0.6925, -1.0927],
        [-0.8354, -0.7584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028109079226851463
Epoch 0, Step 906: train/loss = 0.6841331124305725, train/raw-loss = 0.6605008840560913, train/logprobs = tensor([[-1.1333, -1.3813],
        [-1.4683, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05908063054084778
Epoch 0, Step 907: train/loss = 0.6932716369628906, train/raw-loss = 0.6871451139450073, train/logprobs = tensor([[-1.1798, -1.2885],
        [-1.2859, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015316336415708065
Epoch 0, Step 908: train/loss = 0.6955045461654663, train/raw-loss = 0.6948561668395996, train/logprobs = tensor([[-1.1392, -1.1100],
        [-1.5423, -1.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016208200249820948
Epoch 0, Step 909: train/loss = 0.6894531846046448, train/raw-loss = 0.6795433759689331, train/logprobs = tensor([[-1.0832, -1.2365],
        [-1.3442, -0.9007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024774450808763504
Epoch 0, Step 910: train/loss = 0.6891210079193115, train/raw-loss = 0.6733875274658203, train/logprobs = tensor([[-1.1798, -1.2585],
        [-1.3348, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039333537220954895
Epoch 0, Step 911: train/loss = 0.7065020203590393, train/raw-loss = 0.7022225260734558, train/logprobs = tensor([[-0.9131, -1.2670],
        [-1.0374, -1.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01069875992834568
Epoch 0, Step 912: train/loss = 0.6992174386978149, train/raw-loss = 0.6935916543006897, train/logprobs = tensor([[-0.9008, -1.1838],
        [-1.3001, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014064562506973743
Epoch 0, Step 913: train/loss = 0.702610194683075, train/raw-loss = 0.6985853910446167, train/logprobs = tensor([[-0.8720, -1.3036],
        [-1.1332, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010061937384307384
Epoch 0, Step 914: train/loss = 0.6959997415542603, train/raw-loss = 0.6934813857078552, train/logprobs = tensor([[-0.9698, -0.9546],
        [-1.3045, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006295706611126661
Epoch 0, Step 915: train/loss = 0.7077237963676453, train/raw-loss = 0.6959343552589417, train/logprobs = tensor([[-0.9903, -1.5256],
        [-1.0560, -0.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02947363071143627
Epoch 0, Step 916: train/loss = 0.762092649936676, train/raw-loss = 0.7503589391708374, train/logprobs = tensor([[-1.0519, -1.9763],
        [-1.1165, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029334018006920815
Epoch 0, Step 917: train/loss = 0.6984543800354004, train/raw-loss = 0.6960816383361816, train/logprobs = tensor([[-1.1235, -1.2210],
        [-1.1851, -1.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005931856110692024
Epoch 0, Step 918: train/loss = 0.7393421530723572, train/raw-loss = 0.7238303422927856, train/logprobs = tensor([[-0.8777, -1.5314],
        [-1.2799, -1.3038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038779474794864655
Epoch 0, Step 919: train/loss = 0.6883770227432251, train/raw-loss = 0.661684513092041, train/logprobs = tensor([[-1.2046, -1.5691],
        [-1.7409, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0667315274477005
Epoch 0, Step 920: train/loss = 0.6834468245506287, train/raw-loss = 0.6548375487327576, train/logprobs = tensor([[-0.9374, -1.5621],
        [-1.2984, -0.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07152322679758072
Epoch 0, Step 921: train/loss = 0.7079583406448364, train/raw-loss = 0.7067582607269287, train/logprobs = tensor([[-0.8099, -1.1257],
        [-0.9815, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030002230778336525
Epoch 0, Step 922: train/loss = 0.6937936544418335, train/raw-loss = 0.6866909265518188, train/logprobs = tensor([[-1.1262, -1.5004],
        [-1.2575, -1.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017756784334778786
Epoch 0, Step 923: train/loss = 0.6920487880706787, train/raw-loss = 0.6724367737770081, train/logprobs = tensor([[-0.9878, -1.3077],
        [-1.5105, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049029964953660965
Epoch 0, Step 924: train/loss = 0.6884924173355103, train/raw-loss = 0.6506189703941345, train/logprobs = tensor([[-0.8713, -1.6975],
        [-1.4981, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468372166156769
Epoch 0, Step 925: train/loss = 0.7048346400260925, train/raw-loss = 0.6867508888244629, train/logprobs = tensor([[-0.8801, -1.6579],
        [-1.2918, -1.1906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04520929604768753
Epoch 0, Step 926: train/loss = 0.7132819890975952, train/raw-loss = 0.7075232267379761, train/logprobs = tensor([[-1.0126, -1.4244],
        [-1.1738, -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014396841637790203
Epoch 0, Step 927: train/loss = 0.7137314081192017, train/raw-loss = 0.7126835584640503, train/logprobs = tensor([[-1.1544, -1.1137],
        [-1.5194, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002619583159685135
Epoch 0, Step 928: train/loss = 0.7001818418502808, train/raw-loss = 0.6938375234603882, train/logprobs = tensor([[-1.0163, -1.1038],
        [-1.2881, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01586073264479637
Epoch 0, Step 929: train/loss = 0.6913060545921326, train/raw-loss = 0.6846855282783508, train/logprobs = tensor([[-0.9379, -0.9676],
        [-1.2219, -0.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016551468521356583
Epoch 0, Step 930: train/loss = 0.7203336954116821, train/raw-loss = 0.7075240015983582, train/logprobs = tensor([[-0.9009, -1.3884],
        [-1.0463, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032024119049310684
Epoch 0, Step 931: train/loss = 0.6971004605293274, train/raw-loss = 0.6731785535812378, train/logprobs = tensor([[-1.0172, -1.7984],
        [-1.2824, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059804871678352356
Epoch 0, Step 932: train/loss = 0.700957715511322, train/raw-loss = 0.6924389004707336, train/logprobs = tensor([[-1.4265, -1.4142],
        [-1.7739, -1.1765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021296992897987366
Epoch 0, Step 933: train/loss = 0.6995844841003418, train/raw-loss = 0.6975022554397583, train/logprobs = tensor([[-1.1052, -1.2675],
        [-1.2979, -1.2874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052055600099265575
Epoch 0, Step 934: train/loss = 0.7043867111206055, train/raw-loss = 0.70318204164505, train/logprobs = tensor([[-1.2443, -1.3418],
        [-1.1739, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003011678345501423
Epoch 0, Step 935: train/loss = 0.6884087324142456, train/raw-loss = 0.6551549434661865, train/logprobs = tensor([[-0.8722, -1.4833],
        [-1.1945, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08313445746898651
Epoch 0, Step 936: train/loss = 0.6936076283454895, train/raw-loss = 0.6804625988006592, train/logprobs = tensor([[-1.0576, -1.4088],
        [-1.4805, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03286266699433327
Epoch 0, Step 937: train/loss = 0.6968652606010437, train/raw-loss = 0.683936357498169, train/logprobs = tensor([[-1.0576, -1.2484],
        [-1.2528, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032322246581315994
Epoch 0, Step 938: train/loss = 0.6980520486831665, train/raw-loss = 0.6784229874610901, train/logprobs = tensor([[-1.2888, -1.4620],
        [-1.6928, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0490727499127388
Epoch 0, Step 939: train/loss = 0.6923928260803223, train/raw-loss = 0.6728363037109375, train/logprobs = tensor([[-0.8759, -1.2505],
        [-0.9979, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04889124631881714
Epoch 0, Step 940: train/loss = 0.7211514115333557, train/raw-loss = 0.7001734972000122, train/logprobs = tensor([[-0.8739, -1.4373],
        [-1.2384, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05244474858045578
Epoch 0, Step 941: train/loss = 0.6821419596672058, train/raw-loss = 0.6664499640464783, train/logprobs = tensor([[-1.2117, -1.6033],
        [-1.4524, -1.2272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03923006355762482
Epoch 0, Step 942: train/loss = 0.6998944282531738, train/raw-loss = 0.6964402198791504, train/logprobs = tensor([[-1.0755, -1.3305],
        [-1.0057, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008635289967060089
Epoch 0, Step 943: train/loss = 0.740917444229126, train/raw-loss = 0.7293360829353333, train/logprobs = tensor([[-1.3012, -1.1220],
        [-1.5581, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028953345492482185
Epoch 0, Step 944: train/loss = 0.7080013155937195, train/raw-loss = 0.7060308456420898, train/logprobs = tensor([[-1.1960, -1.0742],
        [-1.2279, -0.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004926091060042381
Epoch 0, Step 945: train/loss = 0.7087845802307129, train/raw-loss = 0.703525960445404, train/logprobs = tensor([[-0.9543, -1.1860],
        [-1.1136, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013146499171853065
Epoch 0, Step 946: train/loss = 0.6924246549606323, train/raw-loss = 0.6871045827865601, train/logprobs = tensor([[-0.9688, -1.1046],
        [-1.1406, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013300161808729172
Epoch 0, Step 947: train/loss = 0.6928243637084961, train/raw-loss = 0.6912569999694824, train/logprobs = tensor([[-1.0180, -1.1702],
        [-1.0619, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003918544854968786
Epoch 0, Step 948: train/loss = 0.6951022148132324, train/raw-loss = 0.6942964196205139, train/logprobs = tensor([[-1.0555, -1.1050],
        [-1.0625, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020143589936196804
Epoch 0, Step 949: train/loss = 0.6905403137207031, train/raw-loss = 0.6860781908035278, train/logprobs = tensor([[-0.9633, -1.2799],
        [-1.0647, -0.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011155297048389912
Epoch 0, Step 950: train/loss = 0.6939056515693665, train/raw-loss = 0.6906635761260986, train/logprobs = tensor([[-1.2437, -1.4032],
        [-1.1888, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008105279877781868
Epoch 0, Step 951: train/loss = 0.7082421183586121, train/raw-loss = 0.7053859233856201, train/logprobs = tensor([[-1.1521, -0.9070],
        [-1.2100, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007140396162867546
Epoch 0, Step 952: train/loss = 0.6972441673278809, train/raw-loss = 0.6939898729324341, train/logprobs = tensor([[-0.8013, -0.9626],
        [-1.0537, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008135714568197727
Epoch 0, Step 953: train/loss = 0.678070068359375, train/raw-loss = 0.6473335027694702, train/logprobs = tensor([[-0.9913, -1.6210],
        [-1.4948, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07684126496315002
Epoch 0, Step 954: train/loss = 0.6825202703475952, train/raw-loss = 0.6599950194358826, train/logprobs = tensor([[-1.2007, -1.6466],
        [-1.7662, -1.0784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05631299316883087
Epoch 0, Step 955: train/loss = 0.6653953194618225, train/raw-loss = 0.6407556533813477, train/logprobs = tensor([[-0.8697, -1.5696],
        [-1.4493, -0.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06159920617938042
Epoch 0, Step 956: train/loss = 0.6901774406433105, train/raw-loss = 0.6824168562889099, train/logprobs = tensor([[-1.2968, -1.6153],
        [-1.4161, -1.1882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01940149813890457
Epoch 0, Step 957: train/loss = 0.7185478210449219, train/raw-loss = 0.7135903239250183, train/logprobs = tensor([[-0.8883, -1.3138],
        [-0.8498, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012393766082823277
Epoch 0, Step 958: train/loss = 0.7342534065246582, train/raw-loss = 0.7296360731124878, train/logprobs = tensor([[-0.9553, -1.7059],
        [-0.8978, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01154327392578125
Epoch 0, Step 959: train/loss = 0.7679019570350647, train/raw-loss = 0.7543997168540955, train/logprobs = tensor([[-1.0258, -1.8955],
        [-1.3426, -1.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033755671232938766
Epoch 0, Step 960: train/loss = 0.6909477710723877, train/raw-loss = 0.6741870641708374, train/logprobs = tensor([[-0.9946, -1.5119],
        [-1.4930, -1.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04190194606781006
Epoch 0, Step 961: train/loss = 0.6891598701477051, train/raw-loss = 0.6826058626174927, train/logprobs = tensor([[-1.0843, -1.3242],
        [-1.5378, -1.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016385061666369438
Epoch 0, Step 962: train/loss = 0.6951539516448975, train/raw-loss = 0.6831614971160889, train/logprobs = tensor([[-0.9412, -1.3354],
        [-1.3033, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02998117357492447
Epoch 0, Step 963: train/loss = 0.6977458596229553, train/raw-loss = 0.6791594624519348, train/logprobs = tensor([[-0.9283, -1.5798],
        [-1.2156, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04646597057580948
Epoch 0, Step 964: train/loss = 0.6928605437278748, train/raw-loss = 0.6837706565856934, train/logprobs = tensor([[-0.9367, -1.2364],
        [-1.4679, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02272476814687252
Epoch 0, Step 965: train/loss = 0.6981111168861389, train/raw-loss = 0.6952422857284546, train/logprobs = tensor([[-1.2256, -1.0791],
        [-1.4048, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007172258570790291
Epoch 0, Step 966: train/loss = 0.6895047426223755, train/raw-loss = 0.6733587384223938, train/logprobs = tensor([[-1.2448, -1.4698],
        [-1.3810, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04036511853337288
Epoch 0, Step 967: train/loss = 0.703983724117279, train/raw-loss = 0.7028611898422241, train/logprobs = tensor([[-1.1074, -1.0231],
        [-1.5210, -1.2159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028060763143002987
Epoch 0, Step 968: train/loss = 0.6967282295227051, train/raw-loss = 0.693156898021698, train/logprobs = tensor([[-1.1392, -1.1925],
        [-1.0485, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008928266353905201
Epoch 0, Step 969: train/loss = 0.6905476450920105, train/raw-loss = 0.6844596266746521, train/logprobs = tensor([[-1.0971, -1.2468],
        [-1.2206, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015220087952911854
Epoch 0, Step 970: train/loss = 0.6955193877220154, train/raw-loss = 0.6919294595718384, train/logprobs = tensor([[-0.8301, -0.9605],
        [-1.0635, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008974870666861534
Epoch 0, Step 971: train/loss = 0.6818033456802368, train/raw-loss = 0.6506144404411316, train/logprobs = tensor([[-0.9273, -1.6965],
        [-1.4873, -1.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07797233760356903
Epoch 0, Step 972: train/loss = 0.6943013668060303, train/raw-loss = 0.6888678669929504, train/logprobs = tensor([[-1.0442, -1.3302],
        [-1.1235, -0.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013583805412054062
Epoch 0, Step 973: train/loss = 0.7014935612678528, train/raw-loss = 0.6888685822486877, train/logprobs = tensor([[-1.0181, -1.3935],
        [-1.5467, -1.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031562451273202896
Epoch 0, Step 974: train/loss = 0.696506142616272, train/raw-loss = 0.69307541847229, train/logprobs = tensor([[-1.1079, -1.2478],
        [-0.9531, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008576909080147743
Epoch 0, Step 975: train/loss = 0.6887847781181335, train/raw-loss = 0.682282030582428, train/logprobs = tensor([[-1.1257, -1.2424],
        [-1.3523, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01625693403184414
Epoch 0, Step 976: train/loss = 0.6954441666603088, train/raw-loss = 0.6928732395172119, train/logprobs = tensor([[-1.2358, -1.1151],
        [-1.0928, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006427235901355743
Epoch 0, Step 977: train/loss = 0.6822830438613892, train/raw-loss = 0.6766223907470703, train/logprobs = tensor([[-0.9524, -1.0451],
        [-1.3813, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014151444658637047
Epoch 0, Step 978: train/loss = 0.6856083869934082, train/raw-loss = 0.6682944297790527, train/logprobs = tensor([[-1.0720, -1.5740],
        [-1.3355, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04328492656350136
Epoch 0, Step 979: train/loss = 0.702426552772522, train/raw-loss = 0.6989930868148804, train/logprobs = tensor([[-1.0891, -1.3409],
        [-1.3411, -1.2643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00858357548713684
Epoch 0, Step 980: train/loss = 0.6902806758880615, train/raw-loss = 0.6832796335220337, train/logprobs = tensor([[-1.0802, -1.2108],
        [-1.2708, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01750289462506771
Epoch 0, Step 981: train/loss = 0.7019038200378418, train/raw-loss = 0.6953279376029968, train/logprobs = tensor([[-0.9923, -1.2365],
        [-1.3517, -1.2428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016439560800790787
Epoch 0, Step 982: train/loss = 0.6946111917495728, train/raw-loss = 0.6817150115966797, train/logprobs = tensor([[-0.9830, -1.3327],
        [-1.2414, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032240331172943115
Epoch 0, Step 983: train/loss = 0.705511748790741, train/raw-loss = 0.6984596848487854, train/logprobs = tensor([[-1.0146, -1.1688],
        [-1.0349, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017630156129598618
Epoch 0, Step 984: train/loss = 0.8528351187705994, train/raw-loss = 0.8312529921531677, train/logprobs = tensor([[-0.8333, -1.8533],
        [-1.1860, -1.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05395537614822388
Epoch 0, Step 985: train/loss = 0.6853602528572083, train/raw-loss = 0.6595325469970703, train/logprobs = tensor([[-0.9570, -1.4361],
        [-1.1422, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645691528916359
Epoch 0, Step 986: train/loss = 0.7186510562896729, train/raw-loss = 0.7176067233085632, train/logprobs = tensor([[-0.9505, -1.1308],
        [-1.2279, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002610924653708935
Epoch 0, Step 987: train/loss = 0.6957577466964722, train/raw-loss = 0.6867735385894775, train/logprobs = tensor([[-1.1558, -1.1382],
        [-1.2698, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022460391744971275
Epoch 0, Step 988: train/loss = 0.6851663589477539, train/raw-loss = 0.6577577590942383, train/logprobs = tensor([[-1.0043, -1.4398],
        [-1.1398, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0685214102268219
Epoch 0, Step 989: train/loss = 0.6918300986289978, train/raw-loss = 0.6848938465118408, train/logprobs = tensor([[-1.0930, -1.2100],
        [-1.3302, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01734072156250477
Epoch 0, Step 990: train/loss = 0.7570738792419434, train/raw-loss = 0.7507712244987488, train/logprobs = tensor([[-1.1271, -1.5130],
        [-1.4213, -1.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015756577253341675
Epoch 0, Step 991: train/loss = 0.6965322494506836, train/raw-loss = 0.6801710724830627, train/logprobs = tensor([[-0.9313, -1.4134],
        [-1.3264, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04090294986963272
Epoch 0, Step 992: train/loss = 0.6942998170852661, train/raw-loss = 0.6874117851257324, train/logprobs = tensor([[-0.9610, -1.1175],
        [-1.2709, -0.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01722002774477005
Epoch 0, Step 993: train/loss = 0.7136856317520142, train/raw-loss = 0.7034281492233276, train/logprobs = tensor([[-1.1147, -1.2023],
        [-1.3112, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025643829256296158
Epoch 0, Step 994: train/loss = 0.6825382709503174, train/raw-loss = 0.6553417444229126, train/logprobs = tensor([[-1.0866, -1.6399],
        [-1.1372, -0.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06799117475748062
Epoch 0, Step 995: train/loss = 0.6896843910217285, train/raw-loss = 0.6486387848854065, train/logprobs = tensor([[-0.7407, -1.6347],
        [-1.2597, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10261392593383789
Epoch 0, Step 996: train/loss = 0.6846495270729065, train/raw-loss = 0.6643277406692505, train/logprobs = tensor([[-0.8798, -1.4102],
        [-1.3076, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05080443620681763
Epoch 0, Step 997: train/loss = 0.6899059414863586, train/raw-loss = 0.6761382818222046, train/logprobs = tensor([[-0.8766, -1.1217],
        [-1.2068, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03441914916038513
Epoch 0, Step 998: train/loss = 0.7128115892410278, train/raw-loss = 0.7035964727401733, train/logprobs = tensor([[-1.1784, -1.0868],
        [-1.4282, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023037651553750038
Epoch 0, Step 999: train/loss = 0.6846957206726074, train/raw-loss = 0.6682772636413574, train/logprobs = tensor([[-0.6704, -1.0678],
        [-1.0228, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04104609414935112
eval/loss: 0.6971783638000488
Epoch 0, Step 1000: train/loss = 0.74811190366745, train/raw-loss = 0.7375640869140625, train/logprobs = tensor([[-1.0652, -0.9541],
        [-1.4643, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02636955864727497
Epoch 0, Step 1001: train/loss = 0.6820412278175354, train/raw-loss = 0.6573299169540405, train/logprobs = tensor([[-0.8826, -1.4409],
        [-1.3153, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061778221279382706
Epoch 0, Step 1002: train/loss = 0.7560161352157593, train/raw-loss = 0.7241044640541077, train/logprobs = tensor([[-0.7283, -1.5017],
        [-1.1683, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797792375087738
Epoch 0, Step 1003: train/loss = 0.691144585609436, train/raw-loss = 0.684802234172821, train/logprobs = tensor([[-1.0487, -1.2345],
        [-1.2375, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0158558152616024
Epoch 0, Step 1004: train/loss = 0.6974349617958069, train/raw-loss = 0.6958097219467163, train/logprobs = tensor([[-1.1016, -1.0003],
        [-1.1515, -1.1784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004063014406710863
Epoch 0, Step 1005: train/loss = 0.6894327998161316, train/raw-loss = 0.675767719745636, train/logprobs = tensor([[-1.0004, -1.3211],
        [-1.2110, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03416269272565842
Epoch 0, Step 1006: train/loss = 0.6938127875328064, train/raw-loss = 0.6907444000244141, train/logprobs = tensor([[-1.0346, -1.1967],
        [-1.3663, -1.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007670905441045761
Epoch 0, Step 1007: train/loss = 0.6852506399154663, train/raw-loss = 0.6796845197677612, train/logprobs = tensor([[-0.9643, -1.4139],
        [-1.0939, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01391519419848919
Epoch 0, Step 1008: train/loss = 0.6949406862258911, train/raw-loss = 0.6804369688034058, train/logprobs = tensor([[-1.1279, -1.2063],
        [-1.7166, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036259278655052185
Epoch 0, Step 1009: train/loss = 0.6969475150108337, train/raw-loss = 0.6859617829322815, train/logprobs = tensor([[-1.0940, -1.3880],
        [-1.3047, -0.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027464421465992928
Epoch 0, Step 1010: train/loss = 0.6910452842712402, train/raw-loss = 0.6888705492019653, train/logprobs = tensor([[-1.0501, -1.1877],
        [-0.9343, -0.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005437000654637814
Epoch 0, Step 1011: train/loss = 0.6876957416534424, train/raw-loss = 0.6731977462768555, train/logprobs = tensor([[-1.0509, -1.3920],
        [-1.2632, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03624507784843445
Epoch 0, Step 1012: train/loss = 0.6818042993545532, train/raw-loss = 0.6682779788970947, train/logprobs = tensor([[-1.0992, -1.3875],
        [-1.3238, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03381572663784027
Epoch 0, Step 1013: train/loss = 0.696807861328125, train/raw-loss = 0.681451678276062, train/logprobs = tensor([[-1.1541, -1.4801],
        [-1.3630, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03839060664176941
Epoch 0, Step 1014: train/loss = 0.7009773254394531, train/raw-loss = 0.6785168051719666, train/logprobs = tensor([[-1.1721, -1.0779],
        [-1.5033, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056151315569877625
Epoch 0, Step 1015: train/loss = 0.6765521764755249, train/raw-loss = 0.6462364792823792, train/logprobs = tensor([[-1.0995, -1.6559],
        [-1.3975, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0757891982793808
Epoch 0, Step 1016: train/loss = 0.7013901472091675, train/raw-loss = 0.6965756416320801, train/logprobs = tensor([[-1.0976, -1.2378],
        [-1.5498, -1.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012036232277750969
Epoch 0, Step 1017: train/loss = 0.7966830730438232, train/raw-loss = 0.782828688621521, train/logprobs = tensor([[-0.8789, -1.8125],
        [-1.3326, -1.2652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03463593125343323
Epoch 0, Step 1018: train/loss = 0.6912360191345215, train/raw-loss = 0.68605637550354, train/logprobs = tensor([[-1.3290, -1.3989],
        [-1.2925, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012949185445904732
Epoch 0, Step 1019: train/loss = 0.6859036684036255, train/raw-loss = 0.6688085794448853, train/logprobs = tensor([[-1.0352, -1.5208],
        [-1.5469, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04273754358291626
Epoch 0, Step 1020: train/loss = 0.6898537278175354, train/raw-loss = 0.6841462850570679, train/logprobs = tensor([[-1.2162, -1.3381],
        [-1.2506, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014268716797232628
Epoch 0, Step 1021: train/loss = 0.6951751708984375, train/raw-loss = 0.6875321865081787, train/logprobs = tensor([[-0.9404, -1.1852],
        [-1.1920, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019107339903712273
Epoch 0, Step 1022: train/loss = 0.6728252172470093, train/raw-loss = 0.6552637815475464, train/logprobs = tensor([[-0.9074, -1.4386],
        [-1.2441, -0.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04390343278646469
Epoch 0, Step 1023: train/loss = 0.6980618238449097, train/raw-loss = 0.68858802318573, train/logprobs = tensor([[-0.9040, -1.0498],
        [-1.2541, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02368450164794922
Epoch 0, Step 1024: train/loss = 0.6906982064247131, train/raw-loss = 0.6703060269355774, train/logprobs = tensor([[-0.9686, -1.3052],
        [-1.3129, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05098048597574234
Epoch 0, Step 1025: train/loss = 0.6960872411727905, train/raw-loss = 0.6852965354919434, train/logprobs = tensor([[-0.9884, -1.2747],
        [-1.1308, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026976872235536575
Epoch 0, Step 1026: train/loss = 0.6890722513198853, train/raw-loss = 0.6795831918716431, train/logprobs = tensor([[-1.0689, -1.2940],
        [-1.3449, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023722492158412933
Epoch 0, Step 1027: train/loss = 0.6900920271873474, train/raw-loss = 0.6664834022521973, train/logprobs = tensor([[-1.1811, -1.4985],
        [-1.6106, -1.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05902155488729477
Epoch 0, Step 1028: train/loss = 0.7088210582733154, train/raw-loss = 0.6877871751785278, train/logprobs = tensor([[-1.1848, -1.5564],
        [-1.2844, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052584677934646606
Epoch 0, Step 1029: train/loss = 0.6936340928077698, train/raw-loss = 0.6928414106369019, train/logprobs = tensor([[-0.8788, -0.8576],
        [-1.0159, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001981593668460846
Epoch 0, Step 1030: train/loss = 0.6855215430259705, train/raw-loss = 0.6430259346961975, train/logprobs = tensor([[-1.0095, -2.0969],
        [-1.4747, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10623908042907715
Epoch 0, Step 1031: train/loss = 0.7324737310409546, train/raw-loss = 0.7224518656730652, train/logprobs = tensor([[-1.3570, -1.5459],
        [-1.3171, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025054749101400375
Epoch 0, Step 1032: train/loss = 0.6891528367996216, train/raw-loss = 0.6785606145858765, train/logprobs = tensor([[-1.0502, -1.4349],
        [-1.3624, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026480671018362045
Epoch 0, Step 1033: train/loss = 0.7032790780067444, train/raw-loss = 0.6801408529281616, train/logprobs = tensor([[-1.0552, -1.1726],
        [-1.7453, -0.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05784551799297333
Epoch 0, Step 1034: train/loss = 0.7388851642608643, train/raw-loss = 0.7324157953262329, train/logprobs = tensor([[-1.0270, -1.5172],
        [-0.9959, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01617368869483471
Epoch 0, Step 1035: train/loss = 0.6696233749389648, train/raw-loss = 0.62990403175354, train/logprobs = tensor([[-1.2241, -1.8641],
        [-1.7942, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09929846972227097
Epoch 0, Step 1036: train/loss = 0.681141197681427, train/raw-loss = 0.6630896329879761, train/logprobs = tensor([[-1.1786, -1.5473],
        [-1.2257, -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04512881115078926
Epoch 0, Step 1037: train/loss = 0.7523292303085327, train/raw-loss = 0.7266930341720581, train/logprobs = tensor([[-0.9647, -1.9373],
        [-1.2718, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0640905499458313
Epoch 0, Step 1038: train/loss = 0.7355272173881531, train/raw-loss = 0.7093822360038757, train/logprobs = tensor([[-1.3139, -1.2712],
        [-1.4452, -0.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06536240875720978
Epoch 0, Step 1039: train/loss = 0.6876999139785767, train/raw-loss = 0.6782606244087219, train/logprobs = tensor([[-1.4356, -1.6925],
        [-1.1212, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02359829470515251
Epoch 0, Step 1040: train/loss = 0.695419192314148, train/raw-loss = 0.6848456263542175, train/logprobs = tensor([[-1.3275, -1.5942],
        [-1.2589, -0.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026433996856212616
Epoch 0, Step 1041: train/loss = 0.6905251741409302, train/raw-loss = 0.6764519214630127, train/logprobs = tensor([[-0.9230, -1.2853],
        [-1.2832, -1.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03518311306834221
Epoch 0, Step 1042: train/loss = 0.6931304931640625, train/raw-loss = 0.6930797696113586, train/logprobs = tensor([[-1.2418, -1.2366],
        [-0.8830, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001267993648070842
Epoch 0, Step 1043: train/loss = 0.6789265275001526, train/raw-loss = 0.6533320546150208, train/logprobs = tensor([[-1.2339, -1.6829],
        [-1.4888, -0.9034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06398618221282959
Epoch 0, Step 1044: train/loss = 0.6853243112564087, train/raw-loss = 0.6460033059120178, train/logprobs = tensor([[-1.1206, -1.4106],
        [-1.6082, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09830251336097717
Epoch 0, Step 1045: train/loss = 0.6769822835922241, train/raw-loss = 0.6403716206550598, train/logprobs = tensor([[-1.0560, -1.8432],
        [-1.3613, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09152649343013763
Epoch 0, Step 1046: train/loss = 0.7096896171569824, train/raw-loss = 0.7057831883430481, train/logprobs = tensor([[-1.0726, -0.9501],
        [-1.4862, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009765923954546452
Epoch 0, Step 1047: train/loss = 0.6913766860961914, train/raw-loss = 0.6800476312637329, train/logprobs = tensor([[-0.9983, -1.0941],
        [-1.1873, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02832264080643654
Epoch 0, Step 1048: train/loss = 0.7038916349411011, train/raw-loss = 0.6881246566772461, train/logprobs = tensor([[-0.9997, -1.5804],
        [-1.2310, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03941755369305611
Epoch 0, Step 1049: train/loss = 0.6990587711334229, train/raw-loss = 0.6791138052940369, train/logprobs = tensor([[-0.8214, -1.5222],
        [-1.0272, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04986228793859482
Epoch 0, Step 1050: train/loss = 0.6592293977737427, train/raw-loss = 0.5965472459793091, train/logprobs = tensor([[-1.1530, -2.0124],
        [-1.8308, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15670554339885712
Epoch 0, Step 1051: train/loss = 0.7089250087738037, train/raw-loss = 0.7052067518234253, train/logprobs = tensor([[-0.9440, -0.9745],
        [-1.1544, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009295630268752575
Epoch 0, Step 1052: train/loss = 0.6979026794433594, train/raw-loss = 0.6900679469108582, train/logprobs = tensor([[-1.0160, -1.1629],
        [-1.2708, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01958662085235119
Epoch 0, Step 1053: train/loss = 0.7062178254127502, train/raw-loss = 0.6994911432266235, train/logprobs = tensor([[-0.9479, -1.2204],
        [-1.0060, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01681659370660782
Epoch 0, Step 1054: train/loss = 0.6921699047088623, train/raw-loss = 0.6881894469261169, train/logprobs = tensor([[-1.0271, -1.0697],
        [-1.2016, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009950966574251652
Epoch 0, Step 1055: train/loss = 0.6856208443641663, train/raw-loss = 0.6585436463356018, train/logprobs = tensor([[-0.9918, -1.3060],
        [-1.3623, -1.0072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06769300252199173
Epoch 0, Step 1056: train/loss = 0.6818422079086304, train/raw-loss = 0.6560290455818176, train/logprobs = tensor([[-0.9955, -1.5219],
        [-1.3922, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06453283131122589
Epoch 0, Step 1057: train/loss = 0.6874879598617554, train/raw-loss = 0.6771082878112793, train/logprobs = tensor([[-1.2389, -1.5960],
        [-1.4584, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025949202477931976
Epoch 0, Step 1058: train/loss = 0.7227333784103394, train/raw-loss = 0.7162377834320068, train/logprobs = tensor([[-0.8634, -0.9287],
        [-1.0223, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016238965094089508
Epoch 0, Step 1059: train/loss = 0.6782662272453308, train/raw-loss = 0.6444540023803711, train/logprobs = tensor([[-1.0299, -1.6349],
        [-1.3237, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08453065156936646
Epoch 0, Step 1060: train/loss = 0.6776024699211121, train/raw-loss = 0.6158754229545593, train/logprobs = tensor([[-1.0017, -1.9050],
        [-1.6112, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15431766211986542
Epoch 0, Step 1061: train/loss = 0.7014015913009644, train/raw-loss = 0.6906824111938477, train/logprobs = tensor([[-0.9550, -1.1464],
        [-1.3121, -1.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026797885075211525
Epoch 0, Step 1062: train/loss = 0.6915390491485596, train/raw-loss = 0.686949610710144, train/logprobs = tensor([[-1.0063, -1.2219],
        [-1.0654, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011473698541522026
Epoch 0, Step 1063: train/loss = 0.6986348032951355, train/raw-loss = 0.6871853470802307, train/logprobs = tensor([[-0.9077, -1.0932],
        [-1.2315, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02862364798784256
Epoch 0, Step 1064: train/loss = 0.6760889887809753, train/raw-loss = 0.6356912851333618, train/logprobs = tensor([[-1.0486, -1.6845],
        [-1.6152, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10099433362483978
Epoch 0, Step 1065: train/loss = 0.6901279091835022, train/raw-loss = 0.6824767589569092, train/logprobs = tensor([[-0.9741, -1.0695],
        [-1.5565, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01912793144583702
Epoch 0, Step 1066: train/loss = 0.7117699384689331, train/raw-loss = 0.7086325883865356, train/logprobs = tensor([[-0.9502, -1.0980],
        [-0.9108, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007843530736863613
Epoch 0, Step 1067: train/loss = 0.7410106658935547, train/raw-loss = 0.7381819486618042, train/logprobs = tensor([[-1.2617, -1.6667],
        [-1.3393, -1.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0070716445334255695
Epoch 0, Step 1068: train/loss = 0.6929723620414734, train/raw-loss = 0.6918262839317322, train/logprobs = tensor([[-1.5254, -1.5862],
        [-1.1769, -1.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002865179907530546
Epoch 0, Step 1069: train/loss = 0.6958885192871094, train/raw-loss = 0.6887221932411194, train/logprobs = tensor([[-1.0256, -1.3249],
        [-1.3829, -1.2418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01791568472981453
Epoch 0, Step 1070: train/loss = 0.6788880825042725, train/raw-loss = 0.6498033404350281, train/logprobs = tensor([[-0.8121, -1.1889],
        [-1.4050, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07271180301904678
Epoch 0, Step 1071: train/loss = 0.6902670860290527, train/raw-loss = 0.6849550008773804, train/logprobs = tensor([[-1.3427, -1.4305],
        [-0.9283, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01328024547547102
Epoch 0, Step 1072: train/loss = 0.6986472606658936, train/raw-loss = 0.6683676838874817, train/logprobs = tensor([[-1.1115, -1.8727],
        [-1.3997, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07569889724254608
Epoch 0, Step 1073: train/loss = 0.6714997291564941, train/raw-loss = 0.62753826379776, train/logprobs = tensor([[-0.9393, -1.6647],
        [-1.5069, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10990370810031891
Epoch 0, Step 1074: train/loss = 0.6842213869094849, train/raw-loss = 0.6629291772842407, train/logprobs = tensor([[-1.1882, -1.4654],
        [-1.3324, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053230591118335724
Epoch 0, Step 1075: train/loss = 0.6985619068145752, train/raw-loss = 0.6956629753112793, train/logprobs = tensor([[-1.3253, -1.4958],
        [-1.0885, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007247284986078739
Epoch 0, Step 1076: train/loss = 0.6878571510314941, train/raw-loss = 0.6625338792800903, train/logprobs = tensor([[-1.0305, -1.3379],
        [-1.0525, -0.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330825388431549
Epoch 0, Step 1077: train/loss = 0.6897191405296326, train/raw-loss = 0.6744580268859863, train/logprobs = tensor([[-1.2735, -1.3711],
        [-1.5216, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038152728229761124
Epoch 0, Step 1078: train/loss = 0.6797766089439392, train/raw-loss = 0.668448805809021, train/logprobs = tensor([[-0.8253, -1.1721],
        [-1.2371, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02831954136490822
Epoch 0, Step 1079: train/loss = 0.6914217472076416, train/raw-loss = 0.6826183795928955, train/logprobs = tensor([[-1.2769, -1.3963],
        [-1.1004, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02200840227305889
Epoch 0, Step 1080: train/loss = 0.7249957919120789, train/raw-loss = 0.7050349712371826, train/logprobs = tensor([[-1.1567, -0.9908],
        [-1.7020, -1.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04990195482969284
Epoch 0, Step 1081: train/loss = 0.6974526643753052, train/raw-loss = 0.6907212734222412, train/logprobs = tensor([[-1.4035, -1.5693],
        [-1.5017, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016828589141368866
Epoch 0, Step 1082: train/loss = 0.6916937828063965, train/raw-loss = 0.6894562244415283, train/logprobs = tensor([[-1.2432, -1.4685],
        [-1.4387, -1.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005593935493379831
Epoch 0, Step 1083: train/loss = 0.6940926313400269, train/raw-loss = 0.6809566617012024, train/logprobs = tensor([[-1.0600, -1.3691],
        [-1.0372, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032839901745319366
Epoch 0, Step 1084: train/loss = 0.6964879035949707, train/raw-loss = 0.6913782358169556, train/logprobs = tensor([[-1.1657, -1.1515],
        [-1.2899, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012774107977747917
Epoch 0, Step 1085: train/loss = 0.6958826780319214, train/raw-loss = 0.6936546564102173, train/logprobs = tensor([[-1.0716, -0.9798],
        [-0.9883, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005569848231971264
Epoch 0, Step 1086: train/loss = 0.6879254579544067, train/raw-loss = 0.6728742718696594, train/logprobs = tensor([[-1.0082, -1.4349],
        [-1.3895, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03762798011302948
Epoch 0, Step 1087: train/loss = 0.6699396967887878, train/raw-loss = 0.6261222958564758, train/logprobs = tensor([[-1.0726, -1.9688],
        [-1.3351, -0.6539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954347252845764
Epoch 0, Step 1088: train/loss = 0.6870479583740234, train/raw-loss = 0.6664385199546814, train/logprobs = tensor([[-1.3550, -1.8846],
        [-1.5595, -1.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051523592323064804
Epoch 0, Step 1089: train/loss = 0.688310980796814, train/raw-loss = 0.6621899008750916, train/logprobs = tensor([[-1.0010, -1.3189],
        [-1.6610, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06530251353979111
Epoch 0, Step 1090: train/loss = 0.694129228591919, train/raw-loss = 0.6656152009963989, train/logprobs = tensor([[-0.9335, -1.7652],
        [-1.2525, -1.2668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128505408763885
Epoch 0, Step 1091: train/loss = 0.7387470602989197, train/raw-loss = 0.6733694076538086, train/logprobs = tensor([[-0.9638, -2.1847],
        [-1.1657, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16344423592090607
Epoch 0, Step 1092: train/loss = 0.7090119123458862, train/raw-loss = 0.6667925715446472, train/logprobs = tensor([[-1.1152, -2.0059],
        [-1.2532, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554829239845276
Epoch 0, Step 1093: train/loss = 0.703721284866333, train/raw-loss = 0.6736924052238464, train/logprobs = tensor([[-0.9506, -1.8054],
        [-1.1042, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07507213950157166
Epoch 0, Step 1094: train/loss = 0.6929361820220947, train/raw-loss = 0.6881052255630493, train/logprobs = tensor([[-1.1094, -1.1961],
        [-1.1627, -0.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012077519670128822
Epoch 0, Step 1095: train/loss = 0.677192211151123, train/raw-loss = 0.6511373519897461, train/logprobs = tensor([[-0.8740, -1.4180],
        [-1.1165, -0.7411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06513717770576477
Epoch 0, Step 1096: train/loss = 0.6682435274124146, train/raw-loss = 0.6398141384124756, train/logprobs = tensor([[-1.3867, -1.9112],
        [-1.2291, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107336074113846
Epoch 0, Step 1097: train/loss = 0.6836385726928711, train/raw-loss = 0.6660718321800232, train/logprobs = tensor([[-1.0530, -1.4904],
        [-1.5242, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04391683638095856
Epoch 0, Step 1098: train/loss = 0.6921049356460571, train/raw-loss = 0.6713719367980957, train/logprobs = tensor([[-1.1793, -1.4756],
        [-1.4896, -0.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051832519471645355
Epoch 0, Step 1099: train/loss = 0.6982342004776001, train/raw-loss = 0.6926579475402832, train/logprobs = tensor([[-1.2243, -1.4063],
        [-1.1661, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013940656557679176
Epoch 0, Step 1100: train/loss = 0.6988919377326965, train/raw-loss = 0.6932430267333984, train/logprobs = tensor([[-0.9880, -0.9083],
        [-1.1798, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01412227377295494
Epoch 0, Step 1101: train/loss = 0.7008662223815918, train/raw-loss = 0.6692625284194946, train/logprobs = tensor([[-1.0965, -1.6207],
        [-1.1363, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07900920510292053
Epoch 0, Step 1102: train/loss = 0.6965781450271606, train/raw-loss = 0.6640990376472473, train/logprobs = tensor([[-1.1951, -1.6573],
        [-1.7743, -1.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119771629571915
Epoch 0, Step 1103: train/loss = 0.6957168579101562, train/raw-loss = 0.6956892609596252, train/logprobs = tensor([[-1.3957, -1.3309],
        [-1.5920, -1.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.910890806466341e-05
Epoch 0, Step 1104: train/loss = 0.6927171349525452, train/raw-loss = 0.6708712577819824, train/logprobs = tensor([[-1.3737, -1.5292],
        [-1.5467, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05461473762989044
Epoch 0, Step 1105: train/loss = 0.6741006374359131, train/raw-loss = 0.6558139324188232, train/logprobs = tensor([[-0.8158, -1.3725],
        [-1.6223, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04571671783924103
Epoch 0, Step 1106: train/loss = 0.6589981317520142, train/raw-loss = 0.6342117786407471, train/logprobs = tensor([[-1.0443, -1.5596],
        [-1.3922, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06196596473455429
Epoch 0, Step 1107: train/loss = 0.6988058090209961, train/raw-loss = 0.6945831775665283, train/logprobs = tensor([[-1.2263, -1.3584],
        [-1.2357, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0105565395206213
Epoch 0, Step 1108: train/loss = 0.6893691420555115, train/raw-loss = 0.6693729758262634, train/logprobs = tensor([[-1.1044, -1.6708],
        [-1.2278, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04999049752950668
Epoch 0, Step 1109: train/loss = 0.6944665908813477, train/raw-loss = 0.692531943321228, train/logprobs = tensor([[-1.2587, -1.3852],
        [-1.4991, -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0048366812989115715
Epoch 0, Step 1110: train/loss = 0.6943140029907227, train/raw-loss = 0.6923583745956421, train/logprobs = tensor([[-1.1402, -1.2091],
        [-1.2595, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004888955503702164
Epoch 0, Step 1111: train/loss = 0.6933950781822205, train/raw-loss = 0.6844192147254944, train/logprobs = tensor([[-1.5488, -1.5078],
        [-1.0724, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022439703345298767
Epoch 0, Step 1112: train/loss = 0.697327196598053, train/raw-loss = 0.6931884288787842, train/logprobs = tensor([[-1.1967, -1.2717],
        [-1.5019, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010346840135753155
Epoch 0, Step 1113: train/loss = 0.6786069273948669, train/raw-loss = 0.6242355108261108, train/logprobs = tensor([[-1.1017, -1.5619],
        [-1.6606, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13592851161956787
Epoch 0, Step 1114: train/loss = 0.7169992327690125, train/raw-loss = 0.7155981063842773, train/logprobs = tensor([[-1.8081, -1.6918],
        [-1.3644, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035028872080147266
Epoch 0, Step 1115: train/loss = 0.7192773818969727, train/raw-loss = 0.7070088386535645, train/logprobs = tensor([[-1.0868, -1.5520],
        [-1.2589, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030671341344714165
Epoch 0, Step 1116: train/loss = 0.6954250335693359, train/raw-loss = 0.6885509490966797, train/logprobs = tensor([[-0.8754, -1.0149],
        [-1.0679, -0.7104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017185190692543983
Epoch 0, Step 1117: train/loss = 0.6975987553596497, train/raw-loss = 0.6801676750183105, train/logprobs = tensor([[-1.6275, -1.5938],
        [-1.2847, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04357759654521942
Epoch 0, Step 1118: train/loss = 0.6805047392845154, train/raw-loss = 0.6554685235023499, train/logprobs = tensor([[-1.1847, -1.9422],
        [-1.3172, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06259063631296158
Epoch 0, Step 1119: train/loss = 0.694435715675354, train/raw-loss = 0.6770678758621216, train/logprobs = tensor([[-1.3788, -1.4976],
        [-1.3446, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04341963678598404
Epoch 0, Step 1120: train/loss = 0.6964232325553894, train/raw-loss = 0.6927289962768555, train/logprobs = tensor([[-1.2525, -1.5182],
        [-1.2142, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009235478937625885
Epoch 0, Step 1121: train/loss = 0.7051730155944824, train/raw-loss = 0.6850448846817017, train/logprobs = tensor([[-0.9192, -1.1715],
        [-1.0872, -0.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05032049119472504
Epoch 0, Step 1122: train/loss = 0.6728160381317139, train/raw-loss = 0.639850378036499, train/logprobs = tensor([[-0.9852, -1.7647],
        [-1.4323, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08241426199674606
Epoch 0, Step 1123: train/loss = 0.7000138759613037, train/raw-loss = 0.6988526582717896, train/logprobs = tensor([[-1.4946, -1.4234],
        [-1.2081, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029029285069555044
Epoch 0, Step 1124: train/loss = 0.721720814704895, train/raw-loss = 0.7019577026367188, train/logprobs = tensor([[-1.0612, -2.0801],
        [-1.3247, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04940790683031082
Epoch 0, Step 1125: train/loss = 0.6576390266418457, train/raw-loss = 0.6392048597335815, train/logprobs = tensor([[-0.7620, -1.4253],
        [-1.2009, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04608531296253204
Epoch 0, Step 1126: train/loss = 0.6764714121818542, train/raw-loss = 0.634257435798645, train/logprobs = tensor([[-0.9363, -1.6578],
        [-1.3754, -0.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10553507506847382
Epoch 0, Step 1127: train/loss = 0.7007695436477661, train/raw-loss = 0.6879295110702515, train/logprobs = tensor([[-1.1646, -1.1001],
        [-1.4647, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03210005536675453
Epoch 0, Step 1128: train/loss = 0.6969096064567566, train/raw-loss = 0.6629059910774231, train/logprobs = tensor([[-0.9020, -1.3109],
        [-1.4153, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500921726226807
Epoch 0, Step 1129: train/loss = 0.7123183012008667, train/raw-loss = 0.6988070011138916, train/logprobs = tensor([[-1.1782, -1.4297],
        [-1.1476, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0337783582508564
Epoch 0, Step 1130: train/loss = 0.6867201328277588, train/raw-loss = 0.6412834525108337, train/logprobs = tensor([[-1.0887, -1.4303],
        [-1.7767, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359159648418427
Epoch 0, Step 1131: train/loss = 0.6884280443191528, train/raw-loss = 0.6763954758644104, train/logprobs = tensor([[-0.9024, -1.0998],
        [-1.2271, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03008127585053444
Epoch 0, Step 1132: train/loss = 0.6899265050888062, train/raw-loss = 0.6665748357772827, train/logprobs = tensor([[-0.9038, -1.2408],
        [-1.3809, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05837912857532501
Epoch 0, Step 1133: train/loss = 0.6875646114349365, train/raw-loss = 0.6500603556632996, train/logprobs = tensor([[-1.1881, -1.6638],
        [-1.5685, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09376062452793121
Epoch 0, Step 1134: train/loss = 0.6858523488044739, train/raw-loss = 0.6571028232574463, train/logprobs = tensor([[-1.0023, -1.3303],
        [-1.5246, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07187376171350479
Epoch 0, Step 1135: train/loss = 0.7016997337341309, train/raw-loss = 0.6954153776168823, train/logprobs = tensor([[-1.2224, -1.2909],
        [-1.2505, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015710707753896713
Epoch 0, Step 1136: train/loss = 0.6870344281196594, train/raw-loss = 0.6590372323989868, train/logprobs = tensor([[-0.9499, -1.2952],
        [-1.1078, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06999305635690689
Epoch 0, Step 1137: train/loss = 0.6902061104774475, train/raw-loss = 0.6639622449874878, train/logprobs = tensor([[-1.1090, -1.4844],
        [-1.8286, -1.3494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0656096339225769
Epoch 0, Step 1138: train/loss = 0.686280369758606, train/raw-loss = 0.6512128710746765, train/logprobs = tensor([[-0.9664, -1.3904],
        [-1.6735, -1.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08766866475343704
Epoch 0, Step 1139: train/loss = 0.6855247616767883, train/raw-loss = 0.6780881285667419, train/logprobs = tensor([[-1.5741, -1.7761],
        [-1.3843, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0185915045440197
Epoch 0, Step 1140: train/loss = 0.6963873505592346, train/raw-loss = 0.6856503486633301, train/logprobs = tensor([[-1.0486, -1.3506],
        [-1.2105, -0.8168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026842541992664337
Epoch 0, Step 1141: train/loss = 0.7157230377197266, train/raw-loss = 0.7117050886154175, train/logprobs = tensor([[-1.0016, -0.9164],
        [-1.1840, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010044721886515617
Epoch 0, Step 1142: train/loss = 0.6976327896118164, train/raw-loss = 0.6591445207595825, train/logprobs = tensor([[-0.9292, -1.6810],
        [-1.3374, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622059017419815
Epoch 0, Step 1143: train/loss = 0.7029862999916077, train/raw-loss = 0.7025802135467529, train/logprobs = tensor([[-1.2621, -1.4938],
        [-1.4735, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010151462629437447
Epoch 0, Step 1144: train/loss = 0.6964238882064819, train/raw-loss = 0.6678513884544373, train/logprobs = tensor([[-1.1432, -1.7651],
        [-1.1499, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07143132388591766
Epoch 0, Step 1145: train/loss = 0.7118192315101624, train/raw-loss = 0.7007285952568054, train/logprobs = tensor([[-1.1092, -1.4102],
        [-1.0816, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027726469561457634
Epoch 0, Step 1146: train/loss = 0.6937505006790161, train/raw-loss = 0.6792171597480774, train/logprobs = tensor([[-1.1369, -1.2573],
        [-1.2845, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03633328154683113
Epoch 0, Step 1147: train/loss = 0.6872429251670837, train/raw-loss = 0.6761795282363892, train/logprobs = tensor([[-1.4265, -1.7064],
        [-1.2703, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027658546343445778
Epoch 0, Step 1148: train/loss = 0.6926026940345764, train/raw-loss = 0.6775543689727783, train/logprobs = tensor([[-1.0105, -1.2555],
        [-1.1917, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03762086108326912
Epoch 0, Step 1149: train/loss = 0.7676044702529907, train/raw-loss = 0.6952716112136841, train/logprobs = tensor([[-0.8683, -2.2948],
        [-1.4363, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18083232641220093
Epoch 0, Step 1150: train/loss = 0.6730558276176453, train/raw-loss = 0.636948823928833, train/logprobs = tensor([[-1.1329, -1.7361],
        [-1.2031, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09026748687028885
Epoch 0, Step 1151: train/loss = 0.7035855650901794, train/raw-loss = 0.6753511428833008, train/logprobs = tensor([[-1.1652, -1.2468],
        [-1.7144, -0.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0705859586596489
Epoch 0, Step 1152: train/loss = 0.6669553518295288, train/raw-loss = 0.6336071491241455, train/logprobs = tensor([[-1.0007, -1.6142],
        [-1.3446, -0.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08337048441171646
Epoch 0, Step 1153: train/loss = 0.6803442239761353, train/raw-loss = 0.6342772841453552, train/logprobs = tensor([[-1.1922, -1.9272],
        [-1.8073, -1.2891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1151675209403038
Epoch 0, Step 1154: train/loss = 0.6886439323425293, train/raw-loss = 0.6520891189575195, train/logprobs = tensor([[-0.8284, -1.2844],
        [-1.4527, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09138695895671844
Epoch 0, Step 1155: train/loss = 0.7016962766647339, train/raw-loss = 0.6943029761314392, train/logprobs = tensor([[-1.2423, -1.2517],
        [-1.2851, -0.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0184832401573658
Epoch 0, Step 1156: train/loss = 0.6793463826179504, train/raw-loss = 0.6359943151473999, train/logprobs = tensor([[-1.1105, -1.7387],
        [-1.6001, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838011652231216
Epoch 0, Step 1157: train/loss = 0.6835697293281555, train/raw-loss = 0.6516892910003662, train/logprobs = tensor([[-1.1589, -1.7546],
        [-1.2268, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07970118522644043
Epoch 0, Step 1158: train/loss = 0.6694483757019043, train/raw-loss = 0.6198684573173523, train/logprobs = tensor([[-0.8531, -1.6771],
        [-1.4257, -0.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1239498034119606
Epoch 0, Step 1159: train/loss = 0.6998801231384277, train/raw-loss = 0.6685031652450562, train/logprobs = tensor([[-1.0962, -1.4729],
        [-1.0858, -0.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0784425139427185
Epoch 0, Step 1160: train/loss = 0.6863059997558594, train/raw-loss = 0.6574201583862305, train/logprobs = tensor([[-1.1184, -1.5534],
        [-1.2979, -0.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0722145289182663
Epoch 0, Step 1161: train/loss = 0.6893548965454102, train/raw-loss = 0.672745406627655, train/logprobs = tensor([[-1.1682, -1.3032],
        [-1.3224, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04152369871735573
Epoch 0, Step 1162: train/loss = 0.6798794269561768, train/raw-loss = 0.6304388046264648, train/logprobs = tensor([[-1.3380, -1.7432],
        [-1.6602, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12360155582427979
Epoch 0, Step 1163: train/loss = 0.7167716026306152, train/raw-loss = 0.7007157802581787, train/logprobs = tensor([[-1.0518, -1.4349],
        [-1.5738, -1.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04013937711715698
Epoch 0, Step 1164: train/loss = 0.6905996799468994, train/raw-loss = 0.671380341053009, train/logprobs = tensor([[-1.0990, -1.3110],
        [-1.1276, -0.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048048269003629684
Epoch 0, Step 1165: train/loss = 0.666053295135498, train/raw-loss = 0.6225830316543579, train/logprobs = tensor([[-1.3029, -2.3131],
        [-1.3005, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1086755022406578
Epoch 0, Step 1166: train/loss = 0.6828336715698242, train/raw-loss = 0.6442376375198364, train/logprobs = tensor([[-0.9978, -1.5150],
        [-1.2538, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649010002613068
Epoch 0, Step 1167: train/loss = 0.675686240196228, train/raw-loss = 0.6212096214294434, train/logprobs = tensor([[-1.2030, -1.8186],
        [-1.5889, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361915022134781
Epoch 0, Step 1168: train/loss = 0.6930638551712036, train/raw-loss = 0.6908514499664307, train/logprobs = tensor([[-1.3654, -1.3885],
        [-0.8739, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005530897062271833
Epoch 0, Step 1169: train/loss = 0.6919496059417725, train/raw-loss = 0.6852839589118958, train/logprobs = tensor([[-0.9413, -0.9618],
        [-1.1014, -1.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016664139926433563
Epoch 0, Step 1170: train/loss = 0.6753237843513489, train/raw-loss = 0.6178656816482544, train/logprobs = tensor([[-1.3510, -2.1629],
        [-1.3690, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1436452716588974
Epoch 0, Step 1171: train/loss = 0.6894897222518921, train/raw-loss = 0.6847027540206909, train/logprobs = tensor([[-1.2161, -1.4221],
        [-1.0071, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011967351660132408
Epoch 0, Step 1172: train/loss = 0.6628415584564209, train/raw-loss = 0.6003646850585938, train/logprobs = tensor([[-1.1444, -1.9469],
        [-1.5894, -1.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15619207918643951
Epoch 0, Step 1173: train/loss = 0.6868417263031006, train/raw-loss = 0.626451313495636, train/logprobs = tensor([[-1.2383, -1.8911],
        [-1.7007, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15097613632678986
Epoch 0, Step 1174: train/loss = 0.6438789963722229, train/raw-loss = 0.6156163215637207, train/logprobs = tensor([[-0.9903, -1.4611],
        [-1.8478, -0.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07065661251544952
Epoch 0, Step 1175: train/loss = 0.7059227824211121, train/raw-loss = 0.6854122877120972, train/logprobs = tensor([[-1.1940, -1.6788],
        [-1.3026, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05127611383795738
Epoch 0, Step 1176: train/loss = 0.6829202175140381, train/raw-loss = 0.6368234157562256, train/logprobs = tensor([[-0.8952, -1.7291],
        [-1.3565, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11524195969104767
Epoch 0, Step 1177: train/loss = 0.7017224431037903, train/raw-loss = 0.6854997873306274, train/logprobs = tensor([[-1.1660, -1.4280],
        [-1.6773, -1.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040556542575359344
Epoch 0, Step 1178: train/loss = 0.6898822784423828, train/raw-loss = 0.6828153133392334, train/logprobs = tensor([[-1.0486, -1.2911],
        [-1.2828, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017667284235358238
Epoch 0, Step 1179: train/loss = 0.736735463142395, train/raw-loss = 0.7306204438209534, train/logprobs = tensor([[-1.1795, -1.5795],
        [-1.3511, -1.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015287580899894238
Epoch 0, Step 1180: train/loss = 0.6883253455162048, train/raw-loss = 0.6504783630371094, train/logprobs = tensor([[-0.8861, -1.2861],
        [-1.4598, -0.6708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.094617560505867
Epoch 0, Step 1181: train/loss = 0.6896098852157593, train/raw-loss = 0.6380484700202942, train/logprobs = tensor([[-1.5094, -2.3133],
        [-1.0642, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12890365719795227
Epoch 0, Step 1182: train/loss = 0.6904811263084412, train/raw-loss = 0.6741225719451904, train/logprobs = tensor([[-0.9981, -1.4201],
        [-1.2932, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04089649021625519
Epoch 0, Step 1183: train/loss = 0.7134092450141907, train/raw-loss = 0.6394038200378418, train/logprobs = tensor([[-1.1033, -2.3046],
        [-1.2808, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18501350283622742
Epoch 0, Step 1184: train/loss = 0.7028106451034546, train/raw-loss = 0.6621551513671875, train/logprobs = tensor([[-0.9947, -1.7276],
        [-1.3127, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10163863003253937
Epoch 0, Step 1185: train/loss = 0.6856220960617065, train/raw-loss = 0.6323848962783813, train/logprobs = tensor([[-1.1644, -1.5172],
        [-1.6465, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13309304416179657
Epoch 0, Step 1186: train/loss = 0.6983111500740051, train/raw-loss = 0.646626889705658, train/logprobs = tensor([[-1.3556, -2.3268],
        [-1.2585, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12921075522899628
Epoch 0, Step 1187: train/loss = 0.6948818564414978, train/raw-loss = 0.6903055310249329, train/logprobs = tensor([[-1.2137, -1.3324],
        [-1.0343, -0.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01144078653305769
Epoch 0, Step 1188: train/loss = 0.6790896654129028, train/raw-loss = 0.6190251111984253, train/logprobs = tensor([[-1.0162, -1.7024],
        [-1.2282, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501614898443222
Epoch 0, Step 1189: train/loss = 0.6952042579650879, train/raw-loss = 0.6695311069488525, train/logprobs = tensor([[-1.1387, -1.6759],
        [-1.4369, -1.1554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06418294459581375
Epoch 0, Step 1190: train/loss = 0.6742434501647949, train/raw-loss = 0.5972168445587158, train/logprobs = tensor([[-1.1253, -1.9125],
        [-1.6238, -0.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19256654381752014
Epoch 0, Step 1191: train/loss = 0.6845734715461731, train/raw-loss = 0.6521243453025818, train/logprobs = tensor([[-1.0940, -1.5608],
        [-1.6420, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08112288266420364
Epoch 0, Step 1192: train/loss = 0.6797724962234497, train/raw-loss = 0.6523457169532776, train/logprobs = tensor([[-0.9284, -1.2769],
        [-1.6431, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06856697052717209
Epoch 0, Step 1193: train/loss = 0.6887056231498718, train/raw-loss = 0.6683123111724854, train/logprobs = tensor([[-1.0180, -1.5051],
        [-1.4797, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050983138382434845
Epoch 0, Step 1194: train/loss = 0.6932976841926575, train/raw-loss = 0.6926790475845337, train/logprobs = tensor([[-1.3932, -1.4852],
        [-0.9405, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015464446041733027
Epoch 0, Step 1195: train/loss = 0.7050270438194275, train/raw-loss = 0.703889012336731, train/logprobs = tensor([[-1.3902, -1.2927],
        [-1.3182, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028449990786612034
Epoch 0, Step 1196: train/loss = 0.6973266005516052, train/raw-loss = 0.6926499009132385, train/logprobs = tensor([[-1.0585, -1.3801],
        [-1.1369, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011691771447658539
Epoch 0, Step 1197: train/loss = 0.6893455386161804, train/raw-loss = 0.6746727228164673, train/logprobs = tensor([[-0.9532, -1.2799],
        [-1.2276, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03668215125799179
Epoch 0, Step 1198: train/loss = 0.6951408982276917, train/raw-loss = 0.6648900508880615, train/logprobs = tensor([[-0.8965, -1.6717],
        [-1.4263, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562714070081711
Epoch 0, Step 1199: train/loss = 0.6730949282646179, train/raw-loss = 0.6341864466667175, train/logprobs = tensor([[-1.1166, -1.7490],
        [-1.6348, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09727116674184799
Epoch 0, Step 1200: train/loss = 0.6858246922492981, train/raw-loss = 0.6599491238594055, train/logprobs = tensor([[-0.9370, -1.0479],
        [-1.3440, -1.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06468888372182846
Epoch 0, Step 1201: train/loss = 0.7228412628173828, train/raw-loss = 0.6789818406105042, train/logprobs = tensor([[-1.0806, -1.1813],
        [-1.8443, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10964857041835785
Epoch 0, Step 1202: train/loss = 0.7348247766494751, train/raw-loss = 0.6946253776550293, train/logprobs = tensor([[-1.0776, -2.1986],
        [-1.2748, -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10049845278263092
Epoch 0, Step 1203: train/loss = 0.6893962025642395, train/raw-loss = 0.6784881353378296, train/logprobs = tensor([[-1.0995, -1.3844],
        [-1.2056, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02727038413286209
Epoch 0, Step 1204: train/loss = 0.6955856084823608, train/raw-loss = 0.6796001195907593, train/logprobs = tensor([[-1.1486, -1.4791],
        [-1.1902, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03996383398771286
Epoch 0, Step 1205: train/loss = 0.6852574348449707, train/raw-loss = 0.6443767547607422, train/logprobs = tensor([[-1.1827, -1.8724],
        [-1.2651, -0.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10220165550708771
Epoch 0, Step 1206: train/loss = 0.7037088871002197, train/raw-loss = 0.6909851431846619, train/logprobs = tensor([[-0.8375, -1.0936],
        [-1.1867, -1.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03180930018424988
Epoch 0, Step 1207: train/loss = 0.6847522258758545, train/raw-loss = 0.619074285030365, train/logprobs = tensor([[-1.4276, -2.4190],
        [-1.4715, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16419489681720734
Epoch 0, Step 1208: train/loss = 0.6867090463638306, train/raw-loss = 0.6568344831466675, train/logprobs = tensor([[-1.0552, -1.6201],
        [-1.3499, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07468647509813309
Epoch 0, Step 1209: train/loss = 0.6800780296325684, train/raw-loss = 0.6502162218093872, train/logprobs = tensor([[-1.1472, -1.6057],
        [-1.2030, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07465463131666183
Epoch 0, Step 1210: train/loss = 0.7009972333908081, train/raw-loss = 0.6765286326408386, train/logprobs = tensor([[-0.7893, -1.3448],
        [-1.2371, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06117143854498863
Epoch 0, Step 1211: train/loss = 0.6693205833435059, train/raw-loss = 0.5932694673538208, train/logprobs = tensor([[-0.9477, -1.7790],
        [-1.2300, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19012776017189026
Epoch 0, Step 1212: train/loss = 0.6689822673797607, train/raw-loss = 0.6005074381828308, train/logprobs = tensor([[-1.4500, -2.3862],
        [-1.2178, -0.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1711871474981308
Epoch 0, Step 1213: train/loss = 0.6907371282577515, train/raw-loss = 0.6571651101112366, train/logprobs = tensor([[-1.1510, -1.8387],
        [-1.3700, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08392998576164246
Epoch 0, Step 1214: train/loss = 0.6974883079528809, train/raw-loss = 0.674983561038971, train/logprobs = tensor([[-1.3136, -1.8094],
        [-1.3843, -1.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05626177787780762
Epoch 0, Step 1215: train/loss = 0.6850273013114929, train/raw-loss = 0.6470875144004822, train/logprobs = tensor([[-0.7560, -1.4416],
        [-1.8302, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484948962926865
Epoch 0, Step 1216: train/loss = 0.7239154577255249, train/raw-loss = 0.6267703771591187, train/logprobs = tensor([[-1.0148, -2.1087],
        [-1.6272, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24286268651485443
Epoch 0, Step 1217: train/loss = 0.7114032506942749, train/raw-loss = 0.6661561131477356, train/logprobs = tensor([[-1.2660, -1.7838],
        [-1.9379, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11311763525009155
Epoch 0, Step 1218: train/loss = 0.6675593852996826, train/raw-loss = 0.6078164577484131, train/logprobs = tensor([[-0.9374, -1.9298],
        [-1.4559, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14935731887817383
Epoch 0, Step 1219: train/loss = 0.6812871694564819, train/raw-loss = 0.6081441640853882, train/logprobs = tensor([[-0.8226, -1.7340],
        [-1.5527, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18285775184631348
Epoch 0, Step 1220: train/loss = 0.6836886405944824, train/raw-loss = 0.6538395881652832, train/logprobs = tensor([[-1.5613, -2.2014],
        [-1.3100, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07462265342473984
Epoch 0, Step 1221: train/loss = 0.6833350658416748, train/raw-loss = 0.5869131684303284, train/logprobs = tensor([[-0.9688, -2.1885],
        [-1.6913, -0.9103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24105484783649445
Epoch 0, Step 1222: train/loss = 0.7623658180236816, train/raw-loss = 0.7617542743682861, train/logprobs = tensor([[-1.7753, -1.4692],
        [-1.5171, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001528725610114634
Epoch 0, Step 1223: train/loss = 0.6816074848175049, train/raw-loss = 0.6338275671005249, train/logprobs = tensor([[-1.0825, -1.6837],
        [-1.1731, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1194496676325798
Epoch 0, Step 1224: train/loss = 0.6974169611930847, train/raw-loss = 0.6947609186172485, train/logprobs = tensor([[-1.2615, -1.2880],
        [-0.9481, -1.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006640053819864988
Epoch 0, Step 1225: train/loss = 0.7221221923828125, train/raw-loss = 0.6655029654502869, train/logprobs = tensor([[-1.2661, -2.1262],
        [-1.3337, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14154811203479767
Epoch 0, Step 1226: train/loss = 0.718431293964386, train/raw-loss = 0.7063581943511963, train/logprobs = tensor([[-1.3713, -1.5290],
        [-1.1355, -0.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030182769522070885
Epoch 0, Step 1227: train/loss = 0.682681679725647, train/raw-loss = 0.6567559242248535, train/logprobs = tensor([[-0.6569, -1.2615],
        [-1.3753, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06481440365314484
Epoch 0, Step 1228: train/loss = 0.673992395401001, train/raw-loss = 0.6337587833404541, train/logprobs = tensor([[-0.7696, -1.3747],
        [-1.8388, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10058388859033585
Epoch 0, Step 1229: train/loss = 0.7411918640136719, train/raw-loss = 0.6859915256500244, train/logprobs = tensor([[-0.9037, -2.0032],
        [-1.4234, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13800087571144104
Epoch 0, Step 1230: train/loss = 0.6931988596916199, train/raw-loss = 0.6729870438575745, train/logprobs = tensor([[-1.2828, -1.6222],
        [-1.3506, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050529465079307556
Epoch 0, Step 1231: train/loss = 0.6783931851387024, train/raw-loss = 0.6052520275115967, train/logprobs = tensor([[-0.8856, -1.6236],
        [-1.5771, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182852640748024
Epoch 0, Step 1232: train/loss = 0.7005428671836853, train/raw-loss = 0.68357914686203, train/logprobs = tensor([[-1.1359, -1.3479],
        [-1.5739, -1.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042409300804138184
Epoch 0, Step 1233: train/loss = 0.6456072926521301, train/raw-loss = 0.5359114408493042, train/logprobs = tensor([[-0.9844, -2.1573],
        [-1.9639, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742396295070648
Epoch 0, Step 1234: train/loss = 0.6632401943206787, train/raw-loss = 0.6034064292907715, train/logprobs = tensor([[-1.2838, -2.0466],
        [-1.4800, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14958447217941284
Epoch 0, Step 1235: train/loss = 0.6962641477584839, train/raw-loss = 0.6640150547027588, train/logprobs = tensor([[-1.2042, -2.0312],
        [-1.3425, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08062298595905304
Epoch 0, Step 1236: train/loss = 0.742897093296051, train/raw-loss = 0.6894013285636902, train/logprobs = tensor([[-1.0205, -2.2603],
        [-1.0084, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13373947143554688
Epoch 0, Step 1237: train/loss = 0.6787688732147217, train/raw-loss = 0.6272522807121277, train/logprobs = tensor([[-1.2780, -1.8379],
        [-1.2690, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12879140675067902
Epoch 0, Step 1238: train/loss = 0.6897542476654053, train/raw-loss = 0.6648228168487549, train/logprobs = tensor([[-1.3746, -1.7009],
        [-1.5826, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06232849508523941
Epoch 0, Step 1239: train/loss = 0.6854656934738159, train/raw-loss = 0.6162277460098267, train/logprobs = tensor([[-1.1646, -2.2831],
        [-1.0365, -0.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17309482395648956
Epoch 0, Step 1240: train/loss = 0.6698729395866394, train/raw-loss = 0.6020317077636719, train/logprobs = tensor([[-1.1947, -2.1336],
        [-1.5360, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16960294544696808
Epoch 0, Step 1241: train/loss = 0.6684561371803284, train/raw-loss = 0.5568620562553406, train/logprobs = tensor([[-0.7773, -2.0770],
        [-1.8693, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789851725101471
Epoch 0, Step 1242: train/loss = 0.6763076782226562, train/raw-loss = 0.6279284358024597, train/logprobs = tensor([[-1.5963, -1.8805],
        [-1.5346, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12094796448945999
Epoch 0, Step 1243: train/loss = 0.67259681224823, train/raw-loss = 0.5485419034957886, train/logprobs = tensor([[-1.1696, -2.3814],
        [-1.4423, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31013742089271545
Epoch 0, Step 1244: train/loss = 0.6865002512931824, train/raw-loss = 0.6639252305030823, train/logprobs = tensor([[-1.0045, -1.3745],
        [-1.2174, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056437622755765915
Epoch 0, Step 1245: train/loss = 0.703668475151062, train/raw-loss = 0.6930930614471436, train/logprobs = tensor([[-0.8914, -0.9616],
        [-1.6231, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026438532397150993
Epoch 0, Step 1246: train/loss = 0.6858564615249634, train/raw-loss = 0.6394691467285156, train/logprobs = tensor([[-1.1013, -1.8652],
        [-1.2765, -0.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1159682422876358
Epoch 0, Step 1247: train/loss = 0.6878169178962708, train/raw-loss = 0.6719261407852173, train/logprobs = tensor([[-1.4449, -1.8813],
        [-0.9985, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03972708433866501
Epoch 0, Step 1248: train/loss = 0.6933847665786743, train/raw-loss = 0.6932882070541382, train/logprobs = tensor([[-0.9924, -1.0044],
        [-0.8933, -0.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000241463741986081
Epoch 0, Step 1249: train/loss = 0.6429738402366638, train/raw-loss = 0.5744853019714355, train/logprobs = tensor([[-0.8773, -2.0345],
        [-1.6127, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17122147977352142
Epoch 0, Step 1250: train/loss = 0.6669182181358337, train/raw-loss = 0.6093969345092773, train/logprobs = tensor([[-1.2139, -1.7734],
        [-1.4579, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14380326867103577
Epoch 0, Step 1251: train/loss = 0.6846956014633179, train/raw-loss = 0.6625010371208191, train/logprobs = tensor([[-0.9814, -1.3622],
        [-1.1406, -0.7787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05548633635044098
Epoch 0, Step 1252: train/loss = 0.7318503260612488, train/raw-loss = 0.7058043479919434, train/logprobs = tensor([[-0.9080, -1.2600],
        [-1.3205, -0.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06511477380990982
Epoch 0, Step 1253: train/loss = 0.7043720483779907, train/raw-loss = 0.6985361576080322, train/logprobs = tensor([[-1.4672, -1.1781],
        [-1.2891, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014589669182896614
Epoch 0, Step 1254: train/loss = 0.7113995552062988, train/raw-loss = 0.707705557346344, train/logprobs = tensor([[-1.7866, -1.5203],
        [-1.0041, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009235017001628876
Epoch 0, Step 1255: train/loss = 0.7206428647041321, train/raw-loss = 0.7024180293083191, train/logprobs = tensor([[-1.8843, -2.5708],
        [-1.2790, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04556211084127426
Epoch 0, Step 1256: train/loss = 0.7058373689651489, train/raw-loss = 0.678787112236023, train/logprobs = tensor([[-1.8899, -2.1209],
        [-1.2759, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06762562692165375
Epoch 0, Step 1257: train/loss = 0.73694908618927, train/raw-loss = 0.6975822448730469, train/logprobs = tensor([[-1.0617, -1.5179],
        [-1.9638, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09841702878475189
Epoch 0, Step 1258: train/loss = 0.694707989692688, train/raw-loss = 0.6944864988327026, train/logprobs = tensor([[-1.2181, -1.1873],
        [-1.1500, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005539422854781151
Epoch 0, Step 1259: train/loss = 0.7109512090682983, train/raw-loss = 0.6538448333740234, train/logprobs = tensor([[-1.5791, -1.6438],
        [-1.8619, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14276590943336487
Epoch 0, Step 1260: train/loss = 0.6909167766571045, train/raw-loss = 0.6594086289405823, train/logprobs = tensor([[-1.2979, -1.7174],
        [-1.8492, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877036929130554
Epoch 0, Step 1261: train/loss = 0.7084314227104187, train/raw-loss = 0.6862446665763855, train/logprobs = tensor([[-0.9324, -1.0479],
        [-1.7378, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055466942489147186
Epoch 0, Step 1262: train/loss = 0.6629068851470947, train/raw-loss = 0.6120721697807312, train/logprobs = tensor([[-1.0008, -1.9410],
        [-2.0541, -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270867884159088
Epoch 0, Step 1263: train/loss = 0.7003924250602722, train/raw-loss = 0.6744161248207092, train/logprobs = tensor([[-0.9266, -1.0460],
        [-1.6281, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0649406909942627
Epoch 0, Step 1264: train/loss = 0.7103160619735718, train/raw-loss = 0.6666432023048401, train/logprobs = tensor([[-0.9849, -1.6661],
        [-1.7315, -1.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10918214172124863
Epoch 0, Step 1265: train/loss = 0.6983411312103271, train/raw-loss = 0.693402111530304, train/logprobs = tensor([[-1.0059, -1.1596],
        [-1.9363, -1.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012347526848316193
Epoch 0, Step 1266: train/loss = 0.6582725644111633, train/raw-loss = 0.5884156823158264, train/logprobs = tensor([[-0.9375, -1.7278],
        [-1.9225, -1.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1746421903371811
Epoch 0, Step 1267: train/loss = 0.6740228533744812, train/raw-loss = 0.6227459907531738, train/logprobs = tensor([[-1.1731, -1.5003],
        [-1.6611, -1.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12819209694862366
Epoch 0, Step 1268: train/loss = 0.6759260892868042, train/raw-loss = 0.621353030204773, train/logprobs = tensor([[-0.9959, -1.8048],
        [-1.5384, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13643278181552887
Epoch 0, Step 1269: train/loss = 0.6701496839523315, train/raw-loss = 0.6157348155975342, train/logprobs = tensor([[-1.6404, -1.7838],
        [-1.0769, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13603730499744415
Epoch 0, Step 1270: train/loss = 0.7235771417617798, train/raw-loss = 0.637202262878418, train/logprobs = tensor([[-0.9727, -2.1390],
        [-1.7386, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21593709290027618
Epoch 0, Step 1271: train/loss = 0.685660183429718, train/raw-loss = 0.6380079388618469, train/logprobs = tensor([[-1.6413, -2.0639],
        [-0.9023, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11913052201271057
Epoch 0, Step 1272: train/loss = 0.6760255098342896, train/raw-loss = 0.579034686088562, train/logprobs = tensor([[-1.3811, -2.5539],
        [-1.9524, -1.3607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24247725307941437
Epoch 0, Step 1273: train/loss = 0.6840243339538574, train/raw-loss = 0.6391834020614624, train/logprobs = tensor([[-1.6229, -2.1172],
        [-1.1400, -0.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11210225522518158
Epoch 0, Step 1274: train/loss = 0.6661001443862915, train/raw-loss = 0.5857117772102356, train/logprobs = tensor([[-1.3316, -2.0423],
        [-1.9347, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20097103714942932
Epoch 0, Step 1275: train/loss = 0.6602044701576233, train/raw-loss = 0.5797131061553955, train/logprobs = tensor([[-1.1713, -2.0492],
        [-1.9878, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20122845470905304
Epoch 0, Step 1276: train/loss = 0.6896790266036987, train/raw-loss = 0.663886308670044, train/logprobs = tensor([[-0.9502, -1.0610],
        [-1.8154, -1.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448177248239517
Epoch 0, Step 1277: train/loss = 0.7025526762008667, train/raw-loss = 0.6979435086250305, train/logprobs = tensor([[-0.9662, -1.2646],
        [-1.6019, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01152300089597702
Epoch 0, Step 1278: train/loss = 0.6539971828460693, train/raw-loss = 0.563733696937561, train/logprobs = tensor([[-0.7998, -1.5766],
        [-2.0064, -0.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22565865516662598
Epoch 0, Step 1279: train/loss = 0.6813083291053772, train/raw-loss = 0.572892963886261, train/logprobs = tensor([[-1.3826, -2.6553],
        [-1.7397, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2710384726524353
Epoch 0, Step 1280: train/loss = 0.694511890411377, train/raw-loss = 0.6579177975654602, train/logprobs = tensor([[-0.9754, -1.1667],
        [-2.0287, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09148508310317993
Epoch 0, Step 1281: train/loss = 0.6925934553146362, train/raw-loss = 0.6904483437538147, train/logprobs = tensor([[-1.3336, -1.4708],
        [-1.1415, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005362895783036947
Epoch 0, Step 1282: train/loss = 0.6462961435317993, train/raw-loss = 0.5412998199462891, train/logprobs = tensor([[-1.4579, -2.4009],
        [-1.7558, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26249080896377563
Epoch 0, Step 1283: train/loss = 0.665481686592102, train/raw-loss = 0.5673564672470093, train/logprobs = tensor([[-1.4817, -2.7057],
        [-1.5279, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24531307816505432
Epoch 0, Step 1284: train/loss = 0.6869392395019531, train/raw-loss = 0.5984519720077515, train/logprobs = tensor([[-1.2175, -1.9275],
        [-1.8423, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22121824324131012
Epoch 0, Step 1285: train/loss = 0.7339744567871094, train/raw-loss = 0.7292728424072266, train/logprobs = tensor([[-1.4821, -1.0680],
        [-2.0059, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011753879487514496
Epoch 0, Step 1286: train/loss = 0.7040257453918457, train/raw-loss = 0.6534720659255981, train/logprobs = tensor([[-1.0107, -1.4168],
        [-1.9692, -1.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1263842135667801
Epoch 0, Step 1287: train/loss = 0.6643924713134766, train/raw-loss = 0.5865925550460815, train/logprobs = tensor([[-0.8224, -1.8626],
        [-1.8584, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19449979066848755
Epoch 0, Step 1288: train/loss = 0.688701868057251, train/raw-loss = 0.5944976806640625, train/logprobs = tensor([[-0.9630, -2.0511],
        [-1.7263, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23551052808761597
Epoch 0, Step 1289: train/loss = 0.6348845958709717, train/raw-loss = 0.4810253083705902, train/logprobs = tensor([[-1.0647, -2.6331],
        [-2.2321, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38464832305908203
Epoch 0, Step 1290: train/loss = 0.738120973110199, train/raw-loss = 0.6707265973091125, train/logprobs = tensor([[-1.7607, -3.0493],
        [-1.4684, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16848592460155487
Epoch 0, Step 1291: train/loss = 0.6736409664154053, train/raw-loss = 0.6188516616821289, train/logprobs = tensor([[-0.8480, -1.4925],
        [-2.3557, -1.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13697321712970734
Epoch 0, Step 1292: train/loss = 0.6788867712020874, train/raw-loss = 0.6196311712265015, train/logprobs = tensor([[-0.9422, -1.6613],
        [-1.6590, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14813892543315887
Epoch 0, Step 1293: train/loss = 0.6950821876525879, train/raw-loss = 0.6854044198989868, train/logprobs = tensor([[-1.2577, -1.5917],
        [-1.0862, -1.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024194395169615746
Epoch 0, Step 1294: train/loss = 0.6954361200332642, train/raw-loss = 0.6318347454071045, train/logprobs = tensor([[-1.1439, -2.0213],
        [-1.7106, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1590033918619156
Epoch 0, Step 1295: train/loss = 0.6287899017333984, train/raw-loss = 0.5068202018737793, train/logprobs = tensor([[-1.0712, -2.4387],
        [-2.0826, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049244284629822
Epoch 0, Step 1296: train/loss = 0.6883792281150818, train/raw-loss = 0.651348352432251, train/logprobs = tensor([[-1.2048, -1.4484],
        [-2.0324, -1.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09257717430591583
Epoch 0, Step 1297: train/loss = 0.7075227499008179, train/raw-loss = 0.6533375978469849, train/logprobs = tensor([[-1.0459, -2.0224],
        [-1.6403, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354627013206482
Epoch 0, Step 1298: train/loss = 0.6429780721664429, train/raw-loss = 0.5422120690345764, train/logprobs = tensor([[-1.1117, -2.3550],
        [-1.6815, -0.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519150972366333
Epoch 0, Step 1299: train/loss = 0.6955640316009521, train/raw-loss = 0.6473867893218994, train/logprobs = tensor([[-1.1158, -1.5088],
        [-1.6167, -0.7892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12044332921504974
Epoch 0, Step 1300: train/loss = 0.6931247711181641, train/raw-loss = 0.691155195236206, train/logprobs = tensor([[-1.4106, -1.5327],
        [-1.2566, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004923871252685785
Epoch 0, Step 1301: train/loss = 0.6702847480773926, train/raw-loss = 0.6095999479293823, train/logprobs = tensor([[-0.8970, -1.9219],
        [-2.0395, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15171220898628235
Epoch 0, Step 1302: train/loss = 0.68618243932724, train/raw-loss = 0.5624046325683594, train/logprobs = tensor([[-0.9504, -2.4733],
        [-1.7908, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094443082809448
Epoch 0, Step 1303: train/loss = 0.6432960629463196, train/raw-loss = 0.5176413059234619, train/logprobs = tensor([[-1.3537, -3.0135],
        [-1.6572, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141368627548218
Epoch 0, Step 1304: train/loss = 0.6471741199493408, train/raw-loss = 0.5355646014213562, train/logprobs = tensor([[-0.7712, -2.1917],
        [-1.7396, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27902376651763916
Epoch 0, Step 1305: train/loss = 0.6924093961715698, train/raw-loss = 0.6832817196846008, train/logprobs = tensor([[-1.6942, -1.6866],
        [-1.1402, -1.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022818995639681816
Epoch 0, Step 1306: train/loss = 0.6839879155158997, train/raw-loss = 0.6477352380752563, train/logprobs = tensor([[-0.9513, -1.2718],
        [-1.7602, -1.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09063171595335007
Epoch 0, Step 1307: train/loss = 0.6705250144004822, train/raw-loss = 0.6123812794685364, train/logprobs = tensor([[-1.9175, -2.7146],
        [-1.5183, -0.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14535924792289734
Epoch 0, Step 1308: train/loss = 0.6569792032241821, train/raw-loss = 0.5378190279006958, train/logprobs = tensor([[-0.7790, -2.3682],
        [-1.9938, -1.3448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297900527715683
Epoch 0, Step 1309: train/loss = 0.6984231472015381, train/raw-loss = 0.6329562664031982, train/logprobs = tensor([[-1.2943, -1.5986],
        [-1.9368, -1.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16366711258888245
Epoch 0, Step 1310: train/loss = 0.6859105229377747, train/raw-loss = 0.6329687237739563, train/logprobs = tensor([[-1.7493, -2.2481],
        [-1.1332, -0.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323544979095459
Epoch 0, Step 1311: train/loss = 0.6762762069702148, train/raw-loss = 0.6130881309509277, train/logprobs = tensor([[-1.0626, -1.7508],
        [-1.6705, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797017514705658
Epoch 0, Step 1312: train/loss = 0.684127926826477, train/raw-loss = 0.6545031070709229, train/logprobs = tensor([[-1.1566, -1.6084],
        [-2.2398, -1.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07406194508075714
Epoch 0, Step 1313: train/loss = 0.7099352478981018, train/raw-loss = 0.5602675676345825, train/logprobs = tensor([[-0.7186, -2.1335],
        [-2.4230, -1.4372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37416911125183105
Epoch 0, Step 1314: train/loss = 0.6901061534881592, train/raw-loss = 0.5854878425598145, train/logprobs = tensor([[-1.1163, -2.3158],
        [-2.6414, -1.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26154568791389465
Epoch 0, Step 1315: train/loss = 0.7030234336853027, train/raw-loss = 0.6628067493438721, train/logprobs = tensor([[-1.5320, -1.7539],
        [-1.3973, -0.7577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10054180026054382
Epoch 0, Step 1316: train/loss = 0.6626768112182617, train/raw-loss = 0.4527801275253296, train/logprobs = tensor([[-1.0775, -3.1636],
        [-2.2657, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5247418284416199
Epoch 0, Step 1317: train/loss = 0.687134325504303, train/raw-loss = 0.6671875715255737, train/logprobs = tensor([[-1.7695, -2.0510],
        [-2.0299, -1.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04986674338579178
Epoch 0, Step 1318: train/loss = 0.6540173888206482, train/raw-loss = 0.5750120878219604, train/logprobs = tensor([[-1.0832, -2.0381],
        [-1.4776, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19751326739788055
Epoch 0, Step 1319: train/loss = 0.7192167043685913, train/raw-loss = 0.7103171944618225, train/logprobs = tensor([[-1.1131, -1.0965],
        [-0.8789, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022248754277825356
Epoch 0, Step 1320: train/loss = 0.6823872327804565, train/raw-loss = 0.6300020217895508, train/logprobs = tensor([[-1.1381, -1.6095],
        [-1.8025, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1309630572795868
Epoch 0, Step 1321: train/loss = 0.6511781215667725, train/raw-loss = 0.5497560501098633, train/logprobs = tensor([[-1.2797, -2.6031],
        [-1.9846, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535552680492401
Epoch 0, Step 1322: train/loss = 0.6867186427116394, train/raw-loss = 0.6215187311172485, train/logprobs = tensor([[-1.0048, -2.0206],
        [-1.9587, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16299977898597717
Epoch 0, Step 1323: train/loss = 0.6718799471855164, train/raw-loss = 0.5210300087928772, train/logprobs = tensor([[-0.7296, -1.6017],
        [-2.8211, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37712493538856506
Epoch 0, Step 1324: train/loss = 0.6788548231124878, train/raw-loss = 0.6286720633506775, train/logprobs = tensor([[-1.2569, -2.0047],
        [-1.5294, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12545683979988098
Epoch 0, Step 1325: train/loss = 0.6482134461402893, train/raw-loss = 0.5591042041778564, train/logprobs = tensor([[-1.1651, -1.9698],
        [-1.7606, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2227730005979538
Epoch 0, Step 1326: train/loss = 0.6381098031997681, train/raw-loss = 0.4914635419845581, train/logprobs = tensor([[-0.9162, -2.1076],
        [-2.4208, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3666155934333801
Epoch 0, Step 1327: train/loss = 0.6872496008872986, train/raw-loss = 0.6554059982299805, train/logprobs = tensor([[-1.1688, -1.3321],
        [-1.4078, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07960891723632812
Epoch 0, Step 1328: train/loss = 0.6797146797180176, train/raw-loss = 0.607846736907959, train/logprobs = tensor([[-1.1207, -2.1128],
        [-2.1470, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1796697974205017
Epoch 0, Step 1329: train/loss = 0.6563535928726196, train/raw-loss = 0.5082735419273376, train/logprobs = tensor([[-1.0653, -2.0595],
        [-3.4134, -1.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37020012736320496
Epoch 0, Step 1330: train/loss = 0.6585593223571777, train/raw-loss = 0.5669035911560059, train/logprobs = tensor([[-0.6086, -1.3118],
        [-2.3581, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22913940250873566
Epoch 0, Step 1331: train/loss = 0.675964891910553, train/raw-loss = 0.591659665107727, train/logprobs = tensor([[-1.4909, -2.3397],
        [-1.9117, -1.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21076315641403198
Epoch 0, Step 1332: train/loss = 0.6868703365325928, train/raw-loss = 0.617634654045105, train/logprobs = tensor([[-0.8967, -1.6592],
        [-2.0874, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17308928072452545
Epoch 0, Step 1333: train/loss = 0.7077466249465942, train/raw-loss = 0.6192030906677246, train/logprobs = tensor([[-1.2035, -2.3139],
        [-2.1857, -1.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22135868668556213
Epoch 0, Step 1334: train/loss = 0.6714127659797668, train/raw-loss = 0.6045451164245605, train/logprobs = tensor([[-1.2741, -2.1415],
        [-1.5696, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16716916859149933
Epoch 0, Step 1335: train/loss = 0.6294662356376648, train/raw-loss = 0.4509833753108978, train/logprobs = tensor([[-1.5212, -3.8432],
        [-2.1517, -0.9726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44620704650878906
Epoch 0, Step 1336: train/loss = 0.7105046510696411, train/raw-loss = 0.6664544343948364, train/logprobs = tensor([[-1.5136, -2.2022],
        [-1.3830, -0.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012536287307739
Epoch 0, Step 1337: train/loss = 0.6466427445411682, train/raw-loss = 0.5161219835281372, train/logprobs = tensor([[-1.3709, -2.7096],
        [-2.2093, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3263019919395447
Epoch 0, Step 1338: train/loss = 0.6739147305488586, train/raw-loss = 0.5496104955673218, train/logprobs = tensor([[-1.6708, -2.4192],
        [-2.2523, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107605278491974
Epoch 0, Step 1339: train/loss = 0.6726861000061035, train/raw-loss = 0.6044977903366089, train/logprobs = tensor([[-1.7872, -2.3763],
        [-1.8463, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704709231853485
Epoch 0, Step 1340: train/loss = 0.6514564752578735, train/raw-loss = 0.5207400321960449, train/logprobs = tensor([[-1.2402, -2.2583],
        [-2.1131, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267911672592163
Epoch 0, Step 1341: train/loss = 0.6657900810241699, train/raw-loss = 0.5145602226257324, train/logprobs = tensor([[-1.1450, -2.4298],
        [-2.3843, -0.8797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37807464599609375
Epoch 0, Step 1342: train/loss = 0.7005187273025513, train/raw-loss = 0.6616087555885315, train/logprobs = tensor([[-0.9296, -1.2104],
        [-2.9029, -2.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09727494418621063
Epoch 0, Step 1343: train/loss = 0.674994945526123, train/raw-loss = 0.5979003310203552, train/logprobs = tensor([[-1.0698, -1.6331],
        [-2.3389, -1.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19273647665977478
Epoch 0, Step 1344: train/loss = 0.687751054763794, train/raw-loss = 0.61630779504776, train/logprobs = tensor([[-1.1281, -1.4945],
        [-2.1070, -1.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17860814929008484
Epoch 0, Step 1345: train/loss = 0.6833939552307129, train/raw-loss = 0.5977591276168823, train/logprobs = tensor([[-1.0432, -2.2792],
        [-1.8585, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21408700942993164
Epoch 0, Step 1346: train/loss = 0.6811549663543701, train/raw-loss = 0.5789077877998352, train/logprobs = tensor([[-0.9813, -1.8009],
        [-2.5805, -1.2266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25561806559562683
Epoch 0, Step 1347: train/loss = 0.6457229256629944, train/raw-loss = 0.4940429925918579, train/logprobs = tensor([[-1.0141, -2.5720],
        [-2.5038, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.379199743270874
Epoch 0, Step 1348: train/loss = 0.6624689698219299, train/raw-loss = 0.577034592628479, train/logprobs = tensor([[-1.4059, -2.2676],
        [-1.7695, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2135859727859497
Epoch 0, Step 1349: train/loss = 0.6908166408538818, train/raw-loss = 0.6710942983627319, train/logprobs = tensor([[-2.3437, -2.6128],
        [-1.3146, -0.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04930579662322998
Epoch 0, Step 1350: train/loss = 0.7145551443099976, train/raw-loss = 0.5484533309936523, train/logprobs = tensor([[-1.4213, -3.8180],
        [-2.0856, -1.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4152545928955078
Epoch 0, Step 1351: train/loss = 0.7208309173583984, train/raw-loss = 0.6801328659057617, train/logprobs = tensor([[-1.1781, -2.1861],
        [-1.5423, -1.4186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10174522548913956
Epoch 0, Step 1352: train/loss = 0.5967982411384583, train/raw-loss = 0.31052055954933167, train/logprobs = tensor([[-1.0653, -3.7335],
        [-3.0215, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7156941890716553
Epoch 0, Step 1353: train/loss = 0.6619248390197754, train/raw-loss = 0.46955955028533936, train/logprobs = tensor([[-0.8392, -3.0081],
        [-2.0510, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4809132516384125
Epoch 0, Step 1354: train/loss = 0.6675930023193359, train/raw-loss = 0.576597273349762, train/logprobs = tensor([[-1.5090, -2.4562],
        [-1.7372, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22748933732509613
Epoch 0, Step 1355: train/loss = 0.6963000893592834, train/raw-loss = 0.6211528778076172, train/logprobs = tensor([[-0.9422, -1.4390],
        [-2.0872, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18786798417568207
Epoch 0, Step 1356: train/loss = 0.6632848381996155, train/raw-loss = 0.5475680828094482, train/logprobs = tensor([[-1.6795, -3.3873],
        [-1.7748, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892918288707733
Epoch 0, Step 1357: train/loss = 0.6598736047744751, train/raw-loss = 0.5634271502494812, train/logprobs = tensor([[-1.1849, -2.4869],
        [-1.5444, -1.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24111612141132355
Epoch 0, Step 1358: train/loss = 0.6734439730644226, train/raw-loss = 0.5224766731262207, train/logprobs = tensor([[-0.9222, -2.0301],
        [-2.2961, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37741824984550476
Epoch 0, Step 1359: train/loss = 0.6957637071609497, train/raw-loss = 0.5407618880271912, train/logprobs = tensor([[-1.1621, -1.7917],
        [-2.6612, -0.6435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.387504518032074
Epoch 0, Step 1360: train/loss = 0.6784974932670593, train/raw-loss = 0.6246680021286011, train/logprobs = tensor([[-1.2534, -1.7654],
        [-2.1248, -1.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1345738023519516
Epoch 0, Step 1361: train/loss = 0.6699844598770142, train/raw-loss = 0.5975280404090881, train/logprobs = tensor([[-1.1563, -1.8591],
        [-2.2927, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181141197681427
Epoch 0, Step 1362: train/loss = 0.6770627498626709, train/raw-loss = 0.5698151588439941, train/logprobs = tensor([[-1.3191, -2.8248],
        [-2.1747, -1.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26811888813972473
Epoch 0, Step 1363: train/loss = 0.7400174736976624, train/raw-loss = 0.6648777723312378, train/logprobs = tensor([[-1.3420, -2.6280],
        [-2.5895, -2.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18784938752651215
Epoch 0, Step 1364: train/loss = 0.6423854827880859, train/raw-loss = 0.5284098386764526, train/logprobs = tensor([[-1.4538, -2.5843],
        [-2.7495, -1.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284939169883728
Epoch 0, Step 1365: train/loss = 0.6946738958358765, train/raw-loss = 0.6285368204116821, train/logprobs = tensor([[-0.8785, -1.3785],
        [-2.3213, -1.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16534262895584106
Epoch 0, Step 1366: train/loss = 0.6821876764297485, train/raw-loss = 0.571965217590332, train/logprobs = tensor([[-1.2834, -2.4410],
        [-1.7358, -1.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27555617690086365
Epoch 0, Step 1367: train/loss = 0.8322057127952576, train/raw-loss = 0.7974323034286499, train/logprobs = tensor([[-1.6272, -2.8347],
        [-1.5469, -2.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693355321884155
Epoch 0, Step 1368: train/loss = 0.6394355297088623, train/raw-loss = 0.5075767636299133, train/logprobs = tensor([[-1.1785, -2.4812],
        [-2.9176, -1.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3296467065811157
Epoch 0, Step 1369: train/loss = 0.6198269128799438, train/raw-loss = 0.3940633535385132, train/logprobs = tensor([[-1.1535, -3.9969],
        [-2.8924, -1.3702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5644088983535767
Epoch 0, Step 1370: train/loss = 0.6334041953086853, train/raw-loss = 0.44814014434814453, train/logprobs = tensor([[-1.5296, -3.1842],
        [-2.2410, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46316009759902954
Epoch 0, Step 1371: train/loss = 0.6936484575271606, train/raw-loss = 0.5263397693634033, train/logprobs = tensor([[-0.9913, -2.9985],
        [-1.8235, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41827183961868286
Epoch 0, Step 1372: train/loss = 0.7161355018615723, train/raw-loss = 0.7103205919265747, train/logprobs = tensor([[-1.8516, -1.5301],
        [-1.9036, -1.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014537420123815536
Epoch 0, Step 1373: train/loss = 0.6937465071678162, train/raw-loss = 0.6819840669631958, train/logprobs = tensor([[-2.0164, -2.4895],
        [-2.1504, -1.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02940606325864792
Epoch 0, Step 1374: train/loss = 0.6780575513839722, train/raw-loss = 0.5767236948013306, train/logprobs = tensor([[-1.0954, -1.7320],
        [-2.7220, -1.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25333452224731445
Epoch 0, Step 1375: train/loss = 0.6742619276046753, train/raw-loss = 0.521033525466919, train/logprobs = tensor([[-1.4610, -2.4312],
        [-2.1045, -0.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38307103514671326
Epoch 0, Step 1376: train/loss = 0.6679691076278687, train/raw-loss = 0.5551150441169739, train/logprobs = tensor([[-1.1993, -2.4275],
        [-2.2899, -1.4206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2821350693702698
Epoch 0, Step 1377: train/loss = 0.6929177641868591, train/raw-loss = 0.5603806972503662, train/logprobs = tensor([[-1.2130, -2.9977],
        [-2.2651, -2.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313426077365875
Epoch 0, Step 1378: train/loss = 0.6369777917861938, train/raw-loss = 0.39057108759880066, train/logprobs = tensor([[-1.2701, -3.5608],
        [-2.5645, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.616016685962677
Epoch 0, Step 1379: train/loss = 0.6663016080856323, train/raw-loss = 0.5000618100166321, train/logprobs = tensor([[-2.3236, -1.9668],
        [-2.3742, -1.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155997037887573
Epoch 0, Step 1380: train/loss = 0.6743718385696411, train/raw-loss = 0.6124751567840576, train/logprobs = tensor([[-1.0406, -1.9871],
        [-1.9299, -1.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15474173426628113
Epoch 0, Step 1381: train/loss = 0.691718339920044, train/raw-loss = 0.6333440542221069, train/logprobs = tensor([[-1.7150, -2.7792],
        [-1.4771, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14593563973903656
Epoch 0, Step 1382: train/loss = 0.6542755961418152, train/raw-loss = 0.5269670486450195, train/logprobs = tensor([[-1.2960, -2.6540],
        [-2.0414, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182714283466339
Epoch 0, Step 1383: train/loss = 0.6864166855812073, train/raw-loss = 0.583235502243042, train/logprobs = tensor([[-1.7917, -2.7282],
        [-1.8238, -1.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579529583454132
Epoch 0, Step 1384: train/loss = 0.6831686496734619, train/raw-loss = 0.5907357931137085, train/logprobs = tensor([[-0.9835, -1.9027],
        [-2.2001, -1.5205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23108211159706116
Epoch 0, Step 1385: train/loss = 0.6737892627716064, train/raw-loss = 0.5783184170722961, train/logprobs = tensor([[-2.3725, -3.1294],
        [-2.2681, -1.4015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23867712914943695
Epoch 0, Step 1386: train/loss = 0.627045214176178, train/raw-loss = 0.43209338188171387, train/logprobs = tensor([[-1.0317, -2.9457],
        [-3.3942, -2.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4873795807361603
Epoch 0, Step 1387: train/loss = 0.6564342975616455, train/raw-loss = 0.5220503211021423, train/logprobs = tensor([[-1.1268, -2.2067],
        [-1.8086, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3359599709510803
Epoch 0, Step 1388: train/loss = 0.5968711376190186, train/raw-loss = 0.3411880135536194, train/logprobs = tensor([[-0.8313, -3.9228],
        [-2.7566, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6392077803611755
Epoch 0, Step 1389: train/loss = 0.7316284775733948, train/raw-loss = 0.6800440549850464, train/logprobs = tensor([[-1.9016, -2.7740],
        [-2.1343, -1.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12896087765693665
Epoch 0, Step 1390: train/loss = 0.6956659555435181, train/raw-loss = 0.6825389862060547, train/logprobs = tensor([[-2.2141, -1.9769],
        [-1.2817, -1.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032817404717206955
Epoch 0, Step 1391: train/loss = 0.6681036353111267, train/raw-loss = 0.5746405720710754, train/logprobs = tensor([[-1.7807, -2.6300],
        [-1.7946, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2336576282978058
Epoch 0, Step 1392: train/loss = 0.6886235475540161, train/raw-loss = 0.5640308856964111, train/logprobs = tensor([[-1.9475, -3.5260],
        [-1.9303, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3114815950393677
Epoch 0, Step 1393: train/loss = 0.6882271766662598, train/raw-loss = 0.5791764855384827, train/logprobs = tensor([[-1.6643, -3.1110],
        [-2.0386, -1.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726266384124756
Epoch 0, Step 1394: train/loss = 0.6570736765861511, train/raw-loss = 0.5636419057846069, train/logprobs = tensor([[-1.9842, -3.0846],
        [-1.8880, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23357944190502167
Epoch 0, Step 1395: train/loss = 0.6928266882896423, train/raw-loss = 0.520309329032898, train/logprobs = tensor([[-1.0916, -3.3976],
        [-2.2188, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4312933683395386
Epoch 0, Step 1396: train/loss = 0.6914511919021606, train/raw-loss = 0.6591008901596069, train/logprobs = tensor([[-1.7771, -2.0972],
        [-1.5456, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08087567985057831
Epoch 0, Step 1397: train/loss = 0.7188389897346497, train/raw-loss = 0.6294183135032654, train/logprobs = tensor([[-1.8023, -3.3542],
        [-1.6325, -1.4214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235516905784607
Epoch 0, Step 1398: train/loss = 0.6142210960388184, train/raw-loss = 0.3499838709831238, train/logprobs = tensor([[-1.5933, -4.3001],
        [-2.3759, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6605930924415588
Epoch 0, Step 1399: train/loss = 0.6622703075408936, train/raw-loss = 0.5748084783554077, train/logprobs = tensor([[-1.9300, -2.7786],
        [-1.8083, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21865442395210266
Epoch 0, Step 1400: train/loss = 0.6511268019676208, train/raw-loss = 0.48715782165527344, train/logprobs = tensor([[-1.8498, -3.1381],
        [-1.8650, -0.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40992242097854614
Epoch 0, Step 1401: train/loss = 0.6974587440490723, train/raw-loss = 0.5576417446136475, train/logprobs = tensor([[-1.3923, -2.4670],
        [-2.7051, -1.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3495425581932068
Epoch 0, Step 1402: train/loss = 0.7544243931770325, train/raw-loss = 0.6500185132026672, train/logprobs = tensor([[-2.9548, -4.6397],
        [-1.6579, -1.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610146403312683
Epoch 0, Step 1403: train/loss = 0.6861048936843872, train/raw-loss = 0.5782829523086548, train/logprobs = tensor([[-2.1893, -3.5548],
        [-1.3971, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26955464482307434
Epoch 0, Step 1404: train/loss = 0.6845389008522034, train/raw-loss = 0.6041336059570312, train/logprobs = tensor([[-1.1370, -1.9339],
        [-2.6586, -1.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20101307332515717
Epoch 0, Step 1405: train/loss = 0.6533983945846558, train/raw-loss = 0.4586001932621002, train/logprobs = tensor([[-0.8271, -2.2924],
        [-3.0699, -1.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48699551820755005
Epoch 0, Step 1406: train/loss = 0.6405186653137207, train/raw-loss = 0.48089924454689026, train/logprobs = tensor([[-1.1743, -3.2239],
        [-2.0995, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39904850721359253
Epoch 0, Step 1407: train/loss = 0.6634137630462646, train/raw-loss = 0.44757407903671265, train/logprobs = tensor([[-1.3907, -3.6719],
        [-2.8844, -1.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5395992994308472
Epoch 0, Step 1408: train/loss = 0.6771245002746582, train/raw-loss = 0.555422306060791, train/logprobs = tensor([[-1.6764, -2.6244],
        [-2.4611, -1.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3042553663253784
Epoch 0, Step 1409: train/loss = 0.647437572479248, train/raw-loss = 0.488233745098114, train/logprobs = tensor([[-1.2799, -3.0427],
        [-2.8140, -1.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980094790458679
Epoch 0, Step 1410: train/loss = 0.6836795806884766, train/raw-loss = 0.49598535895347595, train/logprobs = tensor([[-1.0784, -2.8325],
        [-2.9809, -1.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46923550963401794
Epoch 0, Step 1411: train/loss = 0.6069814562797546, train/raw-loss = 0.3594725728034973, train/logprobs = tensor([[-0.9602, -2.8480],
        [-3.4030, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6187721490859985
Epoch 0, Step 1412: train/loss = 0.6973147392272949, train/raw-loss = 0.642475962638855, train/logprobs = tensor([[-1.9795, -2.2672],
        [-1.7522, -1.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13709688186645508
Epoch 0, Step 1413: train/loss = 0.6467808485031128, train/raw-loss = 0.42818111181259155, train/logprobs = tensor([[-1.0204, -2.6615],
        [-3.5275, -2.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5464993715286255
Epoch 0, Step 1414: train/loss = 0.6482963562011719, train/raw-loss = 0.47839295864105225, train/logprobs = tensor([[-1.9058, -3.8047],
        [-2.1854, -1.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42475858330726624
Epoch 0, Step 1415: train/loss = 0.6448348760604858, train/raw-loss = 0.46930992603302, train/logprobs = tensor([[-1.6639, -3.2940],
        [-2.1437, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43881237506866455
Epoch 0, Step 1416: train/loss = 0.6058786511421204, train/raw-loss = 0.38681113719940186, train/logprobs = tensor([[-1.0715, -3.0721],
        [-3.0222, -0.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5476688742637634
Epoch 0, Step 1417: train/loss = 0.6637488603591919, train/raw-loss = 0.5443915128707886, train/logprobs = tensor([[-2.8678, -3.5764],
        [-1.5762, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29839327931404114
Epoch 0, Step 1418: train/loss = 0.6307270526885986, train/raw-loss = 0.45390063524246216, train/logprobs = tensor([[-1.7653, -3.8298],
        [-2.3493, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4420662522315979
Epoch 0, Step 1419: train/loss = 0.738398551940918, train/raw-loss = 0.6444224119186401, train/logprobs = tensor([[-1.5694, -2.8423],
        [-2.9450, -2.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2349403351545334
Epoch 0, Step 1420: train/loss = 0.7115378379821777, train/raw-loss = 0.5391039848327637, train/logprobs = tensor([[-1.2416, -1.9928],
        [-2.7765, -2.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43108469247817993
Epoch 0, Step 1421: train/loss = 0.6693277955055237, train/raw-loss = 0.5703423023223877, train/logprobs = tensor([[-2.0507, -3.6237],
        [-1.9884, -1.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24746368825435638
Epoch 0, Step 1422: train/loss = 0.6642566919326782, train/raw-loss = 0.44448286294937134, train/logprobs = tensor([[-1.9844, -3.7709],
        [-2.4666, -0.8486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5494345426559448
Epoch 0, Step 1423: train/loss = 0.6854708194732666, train/raw-loss = 0.6058080196380615, train/logprobs = tensor([[-1.9749, -3.1897],
        [-1.8961, -1.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19915716350078583
Epoch 0, Step 1424: train/loss = 0.6609789133071899, train/raw-loss = 0.4729396402835846, train/logprobs = tensor([[-1.1468, -3.2717],
        [-2.7666, -1.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4700981080532074
Epoch 0, Step 1425: train/loss = 0.6588128209114075, train/raw-loss = 0.5663289427757263, train/logprobs = tensor([[-2.2324, -3.2103],
        [-1.8699, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23120972514152527
Epoch 0, Step 1426: train/loss = 0.6642443537712097, train/raw-loss = 0.4538990259170532, train/logprobs = tensor([[-2.1784, -3.0781],
        [-1.7043, -1.9743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258631706237793
Epoch 0, Step 1427: train/loss = 0.7218719720840454, train/raw-loss = 0.6993082761764526, train/logprobs = tensor([[-2.7761, -3.5167],
        [-1.7244, -1.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0564093217253685
Epoch 0, Step 1428: train/loss = 0.6430853605270386, train/raw-loss = 0.514330267906189, train/logprobs = tensor([[-0.9927, -3.0765],
        [-4.9380, -3.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218878209590912
Epoch 0, Step 1429: train/loss = 0.6240161061286926, train/raw-loss = 0.44094815850257874, train/logprobs = tensor([[-2.9928, -4.8215],
        [-2.1305, -0.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45766979455947876
Epoch 0, Step 1430: train/loss = 0.7008051872253418, train/raw-loss = 0.597930908203125, train/logprobs = tensor([[-1.9373, -3.7558],
        [-2.4916, -2.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257185697555542
Epoch 0, Step 1431: train/loss = 0.9354007244110107, train/raw-loss = 0.8557095527648926, train/logprobs = tensor([[-2.4862, -2.1722],
        [-3.5156, -2.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19922779500484467
Epoch 0, Step 1432: train/loss = 0.6006555557250977, train/raw-loss = 0.3668268322944641, train/logprobs = tensor([[-2.2491, -4.2738],
        [-3.5729, -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5845718383789062
Epoch 0, Step 1433: train/loss = 0.6339337825775146, train/raw-loss = 0.40272775292396545, train/logprobs = tensor([[-1.4160, -3.4753],
        [-4.2447, -2.2411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.578015148639679
Epoch 0, Step 1434: train/loss = 0.6094536781311035, train/raw-loss = 0.37019649147987366, train/logprobs = tensor([[-0.9565, -3.2041],
        [-4.0792, -2.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5981430411338806
Epoch 0, Step 1435: train/loss = 0.8471885919570923, train/raw-loss = 0.8268731832504272, train/logprobs = tensor([[-3.2488, -3.2588],
        [-1.6818, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05078854411840439
Epoch 0, Step 1436: train/loss = 0.6860909461975098, train/raw-loss = 0.6326748728752136, train/logprobs = tensor([[-1.4558, -1.8657],
        [-2.2639, -1.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335401087999344
Epoch 0, Step 1437: train/loss = 0.596041202545166, train/raw-loss = 0.290263295173645, train/logprobs = tensor([[-1.6180, -4.5337],
        [-3.5550, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7644449472427368
Epoch 0, Step 1438: train/loss = 0.6626555919647217, train/raw-loss = 0.5933760404586792, train/logprobs = tensor([[-2.4226, -3.2006],
        [-1.8298, -1.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17319883406162262
Epoch 0, Step 1439: train/loss = 0.6249287724494934, train/raw-loss = 0.4416965842247009, train/logprobs = tensor([[-1.3668, -3.6208],
        [-2.7593, -1.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4580804705619812
Epoch 0, Step 1440: train/loss = 0.5878691673278809, train/raw-loss = 0.29178255796432495, train/logprobs = tensor([[-0.8852, -3.7212],
        [-3.4400, -1.1551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7402164936065674
Epoch 0, Step 1441: train/loss = 0.6914682388305664, train/raw-loss = 0.6460697650909424, train/logprobs = tensor([[-1.2774, -1.5544],
        [-2.3947, -2.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11349620670080185
Epoch 0, Step 1442: train/loss = 0.6430622339248657, train/raw-loss = 0.3853206932544708, train/logprobs = tensor([[-0.8603, -2.4297],
        [-5.1026, -2.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6443538069725037
Epoch 0, Step 1443: train/loss = 0.6011989116668701, train/raw-loss = 0.3241519331932068, train/logprobs = tensor([[-1.3731, -3.6203],
        [-3.9114, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6926175355911255
Epoch 0, Step 1444: train/loss = 0.7063677906990051, train/raw-loss = 0.7044305205345154, train/logprobs = tensor([[-3.4938, -3.5061],
        [-1.1798, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004843097645789385
Epoch 0, Step 1445: train/loss = 0.6513324975967407, train/raw-loss = 0.5114237070083618, train/logprobs = tensor([[-1.8770, -3.0625],
        [-2.3463, -0.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34977197647094727
Epoch 0, Step 1446: train/loss = 0.5700132846832275, train/raw-loss = 0.17416638135910034, train/logprobs = tensor([[-1.9926, -5.2954],
        [-3.6181, -0.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9896173477172852
Epoch 0, Step 1447: train/loss = 0.7065294981002808, train/raw-loss = 0.6218613386154175, train/logprobs = tensor([[-2.6340, -3.9233],
        [-1.7114, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21167023479938507
Epoch 0, Step 1448: train/loss = 0.6773701310157776, train/raw-loss = 0.5389127731323242, train/logprobs = tensor([[-1.1675, -2.6375],
        [-1.9677, -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461434841156006
Epoch 0, Step 1449: train/loss = 0.6910206079483032, train/raw-loss = 0.5928903222084045, train/logprobs = tensor([[-1.3132, -1.8497],
        [-3.4409, -2.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24532568454742432
Epoch 0, Step 1450: train/loss = 0.6563538908958435, train/raw-loss = 0.5188487768173218, train/logprobs = tensor([[-1.2039, -2.1653],
        [-3.2661, -1.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34376293420791626
Epoch 0, Step 1451: train/loss = 0.6437728404998779, train/raw-loss = 0.4948132634162903, train/logprobs = tensor([[-1.5164, -3.4098],
        [-2.7400, -1.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37239915132522583
Epoch 0, Step 1452: train/loss = 0.6865311861038208, train/raw-loss = 0.5843788981437683, train/logprobs = tensor([[-1.8457, -2.8380],
        [-2.4421, -2.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553807497024536
Epoch 0, Step 1453: train/loss = 0.6520872712135315, train/raw-loss = 0.5373424291610718, train/logprobs = tensor([[-1.5206, -3.0359],
        [-3.1598, -2.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28686222434043884
Epoch 0, Step 1454: train/loss = 0.6099775433540344, train/raw-loss = 0.3029792904853821, train/logprobs = tensor([[-1.6013, -4.4029],
        [-3.1926, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7674956321716309
Epoch 0, Step 1455: train/loss = 0.6229615211486816, train/raw-loss = 0.45297688245773315, train/logprobs = tensor([[-1.4780, -3.4660],
        [-2.9569, -1.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42496174573898315
Epoch 0, Step 1456: train/loss = 0.6773698925971985, train/raw-loss = 0.5164986848831177, train/logprobs = tensor([[-2.1508, -3.4525],
        [-3.6646, -1.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40217792987823486
Epoch 0, Step 1457: train/loss = 0.850956380367279, train/raw-loss = 0.6698755621910095, train/logprobs = tensor([[-2.4740, -5.4873],
        [-2.4246, -2.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45270204544067383
Epoch 0, Step 1458: train/loss = 0.6894508004188538, train/raw-loss = 0.5556251406669617, train/logprobs = tensor([[-1.5427, -3.3894],
        [-3.4597, -2.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33456408977508545
Epoch 0, Step 1459: train/loss = 0.6031849384307861, train/raw-loss = 0.2830057442188263, train/logprobs = tensor([[-0.7600, -2.9474],
        [-4.7350, -2.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.800447940826416
Epoch 0, Step 1460: train/loss = 0.6589892506599426, train/raw-loss = 0.5156390070915222, train/logprobs = tensor([[-1.7537, -3.1130],
        [-2.3278, -1.4221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358375608921051
Epoch 0, Step 1461: train/loss = 0.6266847848892212, train/raw-loss = 0.4646982252597809, train/logprobs = tensor([[-1.9497, -3.2413],
        [-2.9177, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40496647357940674
Epoch 0, Step 1462: train/loss = 0.6579440236091614, train/raw-loss = 0.4716426432132721, train/logprobs = tensor([[-1.9299, -3.6998],
        [-3.4451, -1.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4657534658908844
Epoch 0, Step 1463: train/loss = 0.6567571759223938, train/raw-loss = 0.509095311164856, train/logprobs = tensor([[-3.0598, -4.2243],
        [-2.7643, -1.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691547214984894
Epoch 0, Step 1464: train/loss = 0.6341834664344788, train/raw-loss = 0.40104320645332336, train/logprobs = tensor([[-1.8382, -4.0949],
        [-3.4541, -1.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5828507542610168
Epoch 0, Step 1465: train/loss = 0.6086734533309937, train/raw-loss = 0.33419397473335266, train/logprobs = tensor([[-1.6044, -4.3854],
        [-3.5455, -1.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6861985921859741
Epoch 0, Step 1466: train/loss = 0.5889485478401184, train/raw-loss = 0.2961786985397339, train/logprobs = tensor([[-1.4548, -4.4344],
        [-3.4390, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7319245934486389
Epoch 0, Step 1467: train/loss = 0.734404444694519, train/raw-loss = 0.5374671816825867, train/logprobs = tensor([[-1.6281, -4.2512],
        [-3.4521, -2.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49234315752983093
Epoch 0, Step 1468: train/loss = 0.6640563607215881, train/raw-loss = 0.5456736087799072, train/logprobs = tensor([[-3.0048, -4.7078],
        [-1.5650, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959567606449127
Epoch 0, Step 1469: train/loss = 0.6043176054954529, train/raw-loss = 0.28367897868156433, train/logprobs = tensor([[-1.0663, -4.2084],
        [-3.5826, -1.3798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8015965223312378
Epoch 0, Step 1470: train/loss = 0.644080400466919, train/raw-loss = 0.40013957023620605, train/logprobs = tensor([[-1.3671, -3.2788],
        [-3.5537, -1.3852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6098521947860718
Epoch 0, Step 1471: train/loss = 0.6697200536727905, train/raw-loss = 0.37945759296417236, train/logprobs = tensor([[-2.0063, -3.6119],
        [-2.3385, -3.1130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7256560325622559
Epoch 0, Step 1472: train/loss = 0.66563880443573, train/raw-loss = 0.5554105639457703, train/logprobs = tensor([[-2.2792, -3.1507],
        [-3.5532, -3.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2755705714225769
Epoch 0, Step 1473: train/loss = 0.6269814968109131, train/raw-loss = 0.3623015880584717, train/logprobs = tensor([[-2.1211, -4.3258],
        [-5.1974, -2.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6616997718811035
Epoch 0, Step 1474: train/loss = 0.6709075570106506, train/raw-loss = 0.5757085680961609, train/logprobs = tensor([[-1.7349, -2.5034],
        [-3.6221, -2.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23799732327461243
Epoch 0, Step 1475: train/loss = 0.7214020490646362, train/raw-loss = 0.6417735815048218, train/logprobs = tensor([[-2.7899, -3.7543],
        [-2.5276, -1.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19907119870185852
Epoch 0, Step 1476: train/loss = 0.6392835974693298, train/raw-loss = 0.444320946931839, train/logprobs = tensor([[-1.7738, -3.4567],
        [-4.5427, -3.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48740673065185547
Epoch 0, Step 1477: train/loss = 0.6165986061096191, train/raw-loss = 0.3644750416278839, train/logprobs = tensor([[-1.7007, -3.4621],
        [-2.7917, -1.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6303089261054993
Epoch 0, Step 1478: train/loss = 0.6740075349807739, train/raw-loss = 0.5061696767807007, train/logprobs = tensor([[-1.0009, -2.4321],
        [-3.8634, -2.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41959452629089355
Epoch 0, Step 1479: train/loss = 0.6143603324890137, train/raw-loss = 0.33593350648880005, train/logprobs = tensor([[-1.7383, -4.3918],
        [-4.2954, -1.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6960670351982117
Epoch 0, Step 1480: train/loss = 0.6252111792564392, train/raw-loss = 0.4460958242416382, train/logprobs = tensor([[-3.0768, -5.0443],
        [-3.2143, -1.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477884769439697
Epoch 0, Step 1481: train/loss = 0.6577277183532715, train/raw-loss = 0.47438645362854004, train/logprobs = tensor([[-3.0794, -4.8360],
        [-2.2970, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4583531320095062
Epoch 0, Step 1482: train/loss = 0.6645855903625488, train/raw-loss = 0.5505632162094116, train/logprobs = tensor([[-1.6222, -2.6206],
        [-3.5732, -2.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.285055935382843
Epoch 0, Step 1483: train/loss = 0.6949475407600403, train/raw-loss = 0.49679839611053467, train/logprobs = tensor([[-2.1434, -3.7688],
        [-3.4164, -1.3590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4953727722167969
Epoch 0, Step 1484: train/loss = 0.5804814696311951, train/raw-loss = 0.22396357357501984, train/logprobs = tensor([[-1.5552, -5.5305],
        [-4.2909, -1.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8912947177886963
Epoch 0, Step 1485: train/loss = 0.5941494703292847, train/raw-loss = 0.25525951385498047, train/logprobs = tensor([[-1.0786, -4.4826],
        [-4.8877, -2.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8472249507904053
Epoch 0, Step 1486: train/loss = 0.6527807116508484, train/raw-loss = 0.4857359230518341, train/logprobs = tensor([[-1.4054, -2.8747],
        [-4.0493, -2.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4176120162010193
Epoch 0, Step 1487: train/loss = 0.6853868365287781, train/raw-loss = 0.5821812152862549, train/logprobs = tensor([[-3.3282, -4.7779],
        [-2.1068, -1.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2580142617225647
Epoch 0, Step 1488: train/loss = 0.6545602083206177, train/raw-loss = 0.4902202785015106, train/logprobs = tensor([[-1.8980, -3.2130],
        [-2.7434, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41084977984428406
Epoch 0, Step 1489: train/loss = 0.6201878786087036, train/raw-loss = 0.4300409257411957, train/logprobs = tensor([[-2.2682, -3.7918],
        [-3.2374, -1.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47536736726760864
Epoch 0, Step 1490: train/loss = 0.6188991069793701, train/raw-loss = 0.3054785132408142, train/logprobs = tensor([[-0.8121, -2.6460],
        [-5.3157, -2.4318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7835513353347778
Epoch 0, Step 1491: train/loss = 0.6187025904655457, train/raw-loss = 0.38677653670310974, train/logprobs = tensor([[-2.3085, -4.6096],
        [-3.6656, -1.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.579815149307251
Epoch 0, Step 1492: train/loss = 0.6886345148086548, train/raw-loss = 0.6077568531036377, train/logprobs = tensor([[-1.8007, -2.8559],
        [-2.0267, -1.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021940052509308
Epoch 0, Step 1493: train/loss = 0.5774675607681274, train/raw-loss = 0.2196892499923706, train/logprobs = tensor([[-1.7780, -4.7676],
        [-5.1890, -1.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8944456577301025
Epoch 0, Step 1494: train/loss = 0.6172131299972534, train/raw-loss = 0.3644123375415802, train/logprobs = tensor([[-1.2348, -3.2718],
        [-4.1829, -1.3631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.632002055644989
Epoch 0, Step 1495: train/loss = 0.5920461416244507, train/raw-loss = 0.3052257299423218, train/logprobs = tensor([[-1.6189, -3.8847],
        [-4.4862, -1.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7170510292053223
Epoch 0, Step 1496: train/loss = 0.6515886783599854, train/raw-loss = 0.4714164137840271, train/logprobs = tensor([[-2.0510, -3.9319],
        [-2.7031, -1.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4504307210445404
Epoch 0, Step 1497: train/loss = 0.6368353366851807, train/raw-loss = 0.3619537353515625, train/logprobs = tensor([[-0.9099, -3.0823],
        [-4.0173, -2.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6872040033340454
Epoch 0, Step 1498: train/loss = 0.6181114912033081, train/raw-loss = 0.31609779596328735, train/logprobs = tensor([[-1.1733, -3.3604],
        [-5.4391, -1.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7550342679023743
Epoch 0, Step 1499: train/loss = 0.7245285511016846, train/raw-loss = 0.6860727667808533, train/logprobs = tensor([[-2.2335, -3.2957],
        [-2.4985, -2.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613946825265884
eval/loss: 0.6532902717590332
Epoch 0, Step 1500: train/loss = 0.6215153932571411, train/raw-loss = 0.4402041435241699, train/logprobs = tensor([[-3.0006, -5.1947],
        [-2.3374, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4532780647277832
Epoch 0, Step 1501: train/loss = 0.6545383930206299, train/raw-loss = 0.515529215335846, train/logprobs = tensor([[-2.3979, -3.8657],
        [-3.0840, -1.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3475229740142822
Epoch 0, Step 1502: train/loss = 0.6672531366348267, train/raw-loss = 0.5597000122070312, train/logprobs = tensor([[-1.5642, -2.4604],
        [-2.5882, -2.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26888278126716614
Epoch 0, Step 1503: train/loss = 0.641478955745697, train/raw-loss = 0.4288446009159088, train/logprobs = tensor([[-3.0631, -4.3254],
        [-2.9684, -1.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5315858125686646
Epoch 0, Step 1504: train/loss = 0.6669129729270935, train/raw-loss = 0.5439716577529907, train/logprobs = tensor([[-2.0243, -3.3127],
        [-2.0707, -1.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073533773422241
Epoch 0, Step 1505: train/loss = 0.7310874462127686, train/raw-loss = 0.665764570236206, train/logprobs = tensor([[-1.7430, -2.8857],
        [-3.1564, -2.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16330720484256744
Epoch 0, Step 1506: train/loss = 0.6257457137107849, train/raw-loss = 0.46441662311553955, train/logprobs = tensor([[-2.7846, -4.2390],
        [-2.4531, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40332284569740295
Epoch 0, Step 1507: train/loss = 0.6816632747650146, train/raw-loss = 0.5151544809341431, train/logprobs = tensor([[-1.4845, -2.2636],
        [-3.1917, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4162719249725342
Epoch 0, Step 1508: train/loss = 0.6800246238708496, train/raw-loss = 0.6059908270835876, train/logprobs = tensor([[-1.8703, -2.4909],
        [-2.2633, -1.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18508444726467133
Epoch 0, Step 1509: train/loss = 0.6732176542282104, train/raw-loss = 0.5911997556686401, train/logprobs = tensor([[-1.2988, -1.7578],
        [-3.2517, -2.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20504474639892578
Epoch 0, Step 1510: train/loss = 0.6259905099868774, train/raw-loss = 0.38510948419570923, train/logprobs = tensor([[-1.7560, -3.5519],
        [-3.2612, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6022025346755981
Epoch 0, Step 1511: train/loss = 0.6056020855903625, train/raw-loss = 0.3258436322212219, train/logprobs = tensor([[-1.4695, -3.5750],
        [-3.7708, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6993961334228516
Epoch 0, Step 1512: train/loss = 0.6341205835342407, train/raw-loss = 0.4021724760532379, train/logprobs = tensor([[-1.0724, -2.8854],
        [-4.2283, -1.9611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.579870343208313
Epoch 0, Step 1513: train/loss = 0.6755807399749756, train/raw-loss = 0.6136891841888428, train/logprobs = tensor([[-2.8144, -3.2343],
        [-2.8733, -2.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547289937734604
Epoch 0, Step 1514: train/loss = 0.630669116973877, train/raw-loss = 0.44681400060653687, train/logprobs = tensor([[-1.7874, -3.6821],
        [-2.3471, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4596377909183502
Epoch 0, Step 1515: train/loss = 0.599661111831665, train/raw-loss = 0.2611943185329437, train/logprobs = tensor([[-1.6112, -4.6984],
        [-4.8741, -1.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8461669683456421
Epoch 0, Step 1516: train/loss = 0.6153483390808105, train/raw-loss = 0.30486148595809937, train/logprobs = tensor([[-1.4296, -4.2261],
        [-3.6067, -1.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7762171030044556
Epoch 0, Step 1517: train/loss = 0.6566240787506104, train/raw-loss = 0.5370802879333496, train/logprobs = tensor([[-1.4383, -2.1003],
        [-4.0374, -2.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2988595962524414
Epoch 0, Step 1518: train/loss = 0.6406705379486084, train/raw-loss = 0.43419212102890015, train/logprobs = tensor([[-1.9804, -3.9367],
        [-3.2744, -1.6791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5161960124969482
Epoch 0, Step 1519: train/loss = 0.7049206495285034, train/raw-loss = 0.645267128944397, train/logprobs = tensor([[-1.7736, -1.9006],
        [-2.8797, -2.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14913368225097656
Epoch 0, Step 1520: train/loss = 0.6524653434753418, train/raw-loss = 0.49153146147727966, train/logprobs = tensor([[-2.3759, -3.6607],
        [-3.1402, -1.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40233471989631653
Epoch 0, Step 1521: train/loss = 0.668978214263916, train/raw-loss = 0.55018150806427, train/logprobs = tensor([[-1.6046, -3.0492],
        [-3.0372, -2.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.296991765499115
Epoch 0, Step 1522: train/loss = 0.6176876425743103, train/raw-loss = 0.3932737410068512, train/logprobs = tensor([[-1.2610, -2.7244],
        [-3.2825, -2.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5610346794128418
Epoch 0, Step 1523: train/loss = 0.6026750206947327, train/raw-loss = 0.3031192719936371, train/logprobs = tensor([[-0.9869, -3.4401],
        [-4.3964, -1.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7488893270492554
Epoch 0, Step 1524: train/loss = 0.6284059882164001, train/raw-loss = 0.4164174795150757, train/logprobs = tensor([[-1.8415, -3.7950],
        [-3.3319, -1.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5299712419509888
Epoch 0, Step 1525: train/loss = 0.6878347396850586, train/raw-loss = 0.5730298757553101, train/logprobs = tensor([[-1.5010, -2.8600],
        [-3.5406, -3.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870122790336609
Epoch 0, Step 1526: train/loss = 0.7584958076477051, train/raw-loss = 0.5862827897071838, train/logprobs = tensor([[-1.6756, -3.3258],
        [-3.1037, -2.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43053245544433594
Epoch 0, Step 1527: train/loss = 0.6102758646011353, train/raw-loss = 0.3920249342918396, train/logprobs = tensor([[-1.6539, -3.5771],
        [-3.7069, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.545627236366272
Epoch 0, Step 1528: train/loss = 0.6841228008270264, train/raw-loss = 0.5947135090827942, train/logprobs = tensor([[-2.0557, -3.0537],
        [-3.7043, -3.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22352319955825806
Epoch 0, Step 1529: train/loss = 0.6699106097221375, train/raw-loss = 0.5834225416183472, train/logprobs = tensor([[-3.1023, -4.0495],
        [-3.0633, -2.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21622009575366974
Epoch 0, Step 1530: train/loss = 0.6627070307731628, train/raw-loss = 0.4473429322242737, train/logprobs = tensor([[-2.1147, -3.6010],
        [-2.3171, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5384102463722229
Epoch 0, Step 1531: train/loss = 0.6685610413551331, train/raw-loss = 0.5448203086853027, train/logprobs = tensor([[-1.8958, -2.6855],
        [-3.6780, -2.2708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30935177206993103
Epoch 0, Step 1532: train/loss = 0.8520845770835876, train/raw-loss = 0.7480837106704712, train/logprobs = tensor([[-3.1501, -2.5209],
        [-3.4275, -2.0245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260002076625824
Epoch 0, Step 1533: train/loss = 0.643682599067688, train/raw-loss = 0.45205625891685486, train/logprobs = tensor([[-1.7671, -3.3905],
        [-2.9781, -1.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.479065865278244
Epoch 0, Step 1534: train/loss = 0.6568928956985474, train/raw-loss = 0.41569212079048157, train/logprobs = tensor([[-1.5897, -3.1259],
        [-4.2709, -1.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6030019521713257
Epoch 0, Step 1535: train/loss = 0.6521310210227966, train/raw-loss = 0.5144073367118835, train/logprobs = tensor([[-1.9217, -3.2602],
        [-3.1043, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34430915117263794
Epoch 0, Step 1536: train/loss = 0.732820987701416, train/raw-loss = 0.6237487196922302, train/logprobs = tensor([[-2.1194, -2.0118],
        [-2.3320, -3.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726808786392212
Epoch 0, Step 1537: train/loss = 0.6992945075035095, train/raw-loss = 0.6460332870483398, train/logprobs = tensor([[-2.7835, -3.2677],
        [-2.0468, -2.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13315321505069733
Epoch 0, Step 1538: train/loss = 0.6826737523078918, train/raw-loss = 0.527439534664154, train/logprobs = tensor([[-2.5859, -2.4698],
        [-2.9813, -1.6492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3880854547023773
Epoch 0, Step 1539: train/loss = 0.684364914894104, train/raw-loss = 0.6580215692520142, train/logprobs = tensor([[-2.9056, -3.4771],
        [-1.7517, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06585831940174103
Epoch 0, Step 1540: train/loss = 0.7415366172790527, train/raw-loss = 0.7095726728439331, train/logprobs = tensor([[-3.2857, -3.7503],
        [-2.7316, -2.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07990981638431549
Epoch 0, Step 1541: train/loss = 0.6516497135162354, train/raw-loss = 0.47616079449653625, train/logprobs = tensor([[-1.6338, -2.5502],
        [-4.2927, -3.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43872231245040894
Epoch 0, Step 1542: train/loss = 0.6876037120819092, train/raw-loss = 0.635124921798706, train/logprobs = tensor([[-2.4525, -2.8523],
        [-3.6660, -2.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13119706511497498
Epoch 0, Step 1543: train/loss = 0.6383382678031921, train/raw-loss = 0.4348950684070587, train/logprobs = tensor([[-1.7781, -3.7319],
        [-4.2284, -2.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5086079835891724
Epoch 0, Step 1544: train/loss = 0.6377700567245483, train/raw-loss = 0.41385871171951294, train/logprobs = tensor([[-1.4944, -2.9838],
        [-3.4676, -1.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5597782135009766
Epoch 0, Step 1545: train/loss = 0.5973176956176758, train/raw-loss = 0.3161731958389282, train/logprobs = tensor([[-0.9942, -3.3296],
        [-4.1922, -1.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7028611302375793
Epoch 0, Step 1546: train/loss = 0.7022923827171326, train/raw-loss = 0.6581964492797852, train/logprobs = tensor([[-1.1791, -1.9228],
        [-3.9695, -3.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11023981869220734
Epoch 0, Step 1547: train/loss = 0.6505135297775269, train/raw-loss = 0.4144219756126404, train/logprobs = tensor([[-1.4836, -2.7512],
        [-3.6799, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5902286767959595
Epoch 0, Step 1548: train/loss = 0.6840214729309082, train/raw-loss = 0.6380667090415955, train/logprobs = tensor([[-1.5470, -2.1049],
        [-2.9608, -2.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11488701403141022
Epoch 0, Step 1549: train/loss = 0.5840179920196533, train/raw-loss = 0.34521767497062683, train/logprobs = tensor([[-1.9932, -4.2175],
        [-3.3651, -1.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5970007181167603
Epoch 0, Step 1550: train/loss = 0.6579478979110718, train/raw-loss = 0.5249835252761841, train/logprobs = tensor([[-2.4395, -3.9383],
        [-2.3184, -1.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33241093158721924
Epoch 0, Step 1551: train/loss = 0.6194079518318176, train/raw-loss = 0.38665086030960083, train/logprobs = tensor([[-1.7006, -3.8904],
        [-3.5362, -1.4372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5818926692008972
Epoch 0, Step 1552: train/loss = 0.6272196769714355, train/raw-loss = 0.33288800716400146, train/logprobs = tensor([[-1.4241, -3.5338],
        [-4.5087, -1.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7358289957046509
Epoch 0, Step 1553: train/loss = 0.6305782794952393, train/raw-loss = 0.22670161724090576, train/logprobs = tensor([[-2.0152, -2.5334],
        [-4.3186, -2.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0096914768218994
Epoch 0, Step 1554: train/loss = 0.634227991104126, train/raw-loss = 0.40980297327041626, train/logprobs = tensor([[-2.0126, -3.6750],
        [-3.5384, -1.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5610626339912415
Epoch 0, Step 1555: train/loss = 0.5639917850494385, train/raw-loss = 0.2617458403110504, train/logprobs = tensor([[-1.2114, -4.1580],
        [-4.8937, -1.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7556148767471313
Epoch 0, Step 1556: train/loss = 0.6284788846969604, train/raw-loss = 0.42738765478134155, train/logprobs = tensor([[-2.4322, -4.0242],
        [-3.2780, -1.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5027281641960144
Epoch 0, Step 1557: train/loss = 0.5927436947822571, train/raw-loss = 0.3231295645236969, train/logprobs = tensor([[-1.0513, -3.5210],
        [-4.4718, -2.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6740353107452393
Epoch 0, Step 1558: train/loss = 0.623839259147644, train/raw-loss = 0.25979891419410706, train/logprobs = tensor([[-0.6574, -3.5761],
        [-5.1847, -2.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9101008772850037
Epoch 0, Step 1559: train/loss = 0.5934033393859863, train/raw-loss = 0.3674260377883911, train/logprobs = tensor([[-0.9742, -2.8645],
        [-4.8736, -2.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5649430751800537
Epoch 0, Step 1560: train/loss = 0.6998339891433716, train/raw-loss = 0.5854774117469788, train/logprobs = tensor([[-2.5118, -2.4506],
        [-3.4747, -2.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28589144349098206
Epoch 0, Step 1561: train/loss = 0.6465814709663391, train/raw-loss = 0.42920899391174316, train/logprobs = tensor([[-1.6212, -3.4633],
        [-3.5567, -2.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5434311628341675
Epoch 0, Step 1562: train/loss = 0.7034683227539062, train/raw-loss = 0.6425033807754517, train/logprobs = tensor([[-3.1191, -4.0262],
        [-1.9643, -1.6653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1524122655391693
Epoch 0, Step 1563: train/loss = 0.5918307900428772, train/raw-loss = 0.2729620039463043, train/logprobs = tensor([[-0.8018, -3.2302],
        [-5.8470, -2.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7971720695495605
Epoch 0, Step 1564: train/loss = 0.6270939707756042, train/raw-loss = 0.42097750306129456, train/logprobs = tensor([[-2.7024, -4.9559],
        [-2.6728, -1.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5152912735939026
Epoch 0, Step 1565: train/loss = 0.703578531742096, train/raw-loss = 0.4994489550590515, train/logprobs = tensor([[-2.4948, -4.9500],
        [-2.8388, -2.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5103240013122559
Epoch 0, Step 1566: train/loss = 0.6788344383239746, train/raw-loss = 0.5053552985191345, train/logprobs = tensor([[-2.1099, -2.8205],
        [-2.2213, -2.4036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43369776010513306
Epoch 0, Step 1567: train/loss = 0.693873405456543, train/raw-loss = 0.6507681608200073, train/logprobs = tensor([[-2.5583, -2.7766],
        [-2.3686, -2.2798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776301473379135
Epoch 0, Step 1568: train/loss = 0.6899455785751343, train/raw-loss = 0.41528749465942383, train/logprobs = tensor([[-2.1820, -3.4368],
        [-5.7349, -2.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6866453289985657
Epoch 0, Step 1569: train/loss = 0.6021646857261658, train/raw-loss = 0.27097100019454956, train/logprobs = tensor([[-1.0805, -4.0210],
        [-5.4994, -3.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8279842734336853
Epoch 0, Step 1570: train/loss = 0.6328750848770142, train/raw-loss = 0.42760393023490906, train/logprobs = tensor([[-2.9054, -5.1418],
        [-3.3112, -1.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5131778717041016
Epoch 0, Step 1571: train/loss = 0.6826472282409668, train/raw-loss = 0.58878093957901, train/logprobs = tensor([[-1.6062, -2.0133],
        [-3.8628, -3.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23466579616069794
Epoch 0, Step 1572: train/loss = 0.7148250937461853, train/raw-loss = 0.6402390599250793, train/logprobs = tensor([[-2.8298, -3.3664],
        [-2.6416, -2.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18646518886089325
Epoch 0, Step 1573: train/loss = 0.6470198035240173, train/raw-loss = 0.48783907294273376, train/logprobs = tensor([[-1.7792, -2.9998],
        [-4.7446, -3.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3979519009590149
Epoch 0, Step 1574: train/loss = 0.6550887823104858, train/raw-loss = 0.49302855134010315, train/logprobs = tensor([[-2.9213, -4.6896],
        [-3.3605, -2.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40515053272247314
Epoch 0, Step 1575: train/loss = 0.653454065322876, train/raw-loss = 0.49370524287223816, train/logprobs = tensor([[-1.2803, -2.0906],
        [-5.3810, -5.0801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3993719816207886
Epoch 0, Step 1576: train/loss = 0.6272441148757935, train/raw-loss = 0.3621957004070282, train/logprobs = tensor([[-0.9424, -2.6950],
        [-6.2304, -3.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6626209020614624
Epoch 0, Step 1577: train/loss = 0.6712703704833984, train/raw-loss = 0.563767671585083, train/logprobs = tensor([[-2.2524, -3.3082],
        [-2.8691, -2.3645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26875677704811096
Epoch 0, Step 1578: train/loss = 0.6445980072021484, train/raw-loss = 0.40560466051101685, train/logprobs = tensor([[-1.9521, -4.7071],
        [-5.9279, -3.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5974833965301514
Epoch 0, Step 1579: train/loss = 0.6145582795143127, train/raw-loss = 0.3255321979522705, train/logprobs = tensor([[-1.8014, -4.2387],
        [-4.5294, -1.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7225651741027832
Epoch 0, Step 1580: train/loss = 0.7519764304161072, train/raw-loss = 0.4987114667892456, train/logprobs = tensor([[-1.4608, -3.0316],
        [-4.7104, -2.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.633162260055542
Epoch 0, Step 1581: train/loss = 0.6645048260688782, train/raw-loss = 0.5430968403816223, train/logprobs = tensor([[-2.2821, -2.9736],
        [-3.1533, -1.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035198748111725
Epoch 0, Step 1582: train/loss = 0.6346856951713562, train/raw-loss = 0.4813305139541626, train/logprobs = tensor([[-2.2294, -3.6602],
        [-3.3181, -1.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3833880126476288
Epoch 0, Step 1583: train/loss = 0.5997961759567261, train/raw-loss = 0.24612635374069214, train/logprobs = tensor([[-2.0238, -3.2356],
        [-3.9025, -2.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8841745853424072
Epoch 0, Step 1584: train/loss = 0.6627737283706665, train/raw-loss = 0.3454614281654358, train/logprobs = tensor([[-1.5107, -4.3830],
        [-6.4484, -3.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7932807803153992
Epoch 0, Step 1585: train/loss = 0.586012065410614, train/raw-loss = 0.23497679829597473, train/logprobs = tensor([[-1.5978, -4.8716],
        [-4.8282, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8775882720947266
Epoch 0, Step 1586: train/loss = 0.702722430229187, train/raw-loss = 0.5261899828910828, train/logprobs = tensor([[-2.5531, -4.0138],
        [-4.0408, -2.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4413312077522278
Epoch 0, Step 1587: train/loss = 0.6631007194519043, train/raw-loss = 0.5176029205322266, train/logprobs = tensor([[-1.4601, -2.7839],
        [-4.7611, -3.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36374446749687195
Epoch 0, Step 1588: train/loss = 0.6179766058921814, train/raw-loss = 0.4155709445476532, train/logprobs = tensor([[-3.9774, -5.3945],
        [-4.3719, -2.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5060141682624817
Epoch 0, Step 1589: train/loss = 0.6437148451805115, train/raw-loss = 0.41677671670913696, train/logprobs = tensor([[-2.2370, -4.2913],
        [-3.8713, -2.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.567345380783081
Epoch 0, Step 1590: train/loss = 0.703935980796814, train/raw-loss = 0.6660027503967285, train/logprobs = tensor([[-2.2781, -1.8142],
        [-5.7514, -5.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483306109905243
Epoch 0, Step 1591: train/loss = 0.7464051842689514, train/raw-loss = 0.6574005484580994, train/logprobs = tensor([[-3.0163, -3.1396],
        [-3.5704, -3.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22251154482364655
Epoch 0, Step 1592: train/loss = 0.6301523447036743, train/raw-loss = 0.4027653932571411, train/logprobs = tensor([[-1.1678, -3.4224],
        [-4.7659, -3.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.568467378616333
Epoch 0, Step 1593: train/loss = 0.551270067691803, train/raw-loss = 0.10907819122076035, train/logprobs = tensor([[-1.3751, -5.8946],
        [-5.6396, -1.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1054797172546387
Epoch 0, Step 1594: train/loss = 0.6756502389907837, train/raw-loss = 0.5542854070663452, train/logprobs = tensor([[-2.8581, -3.4059],
        [-3.7359, -2.2924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30341222882270813
Epoch 0, Step 1595: train/loss = 0.6258891224861145, train/raw-loss = 0.27958589792251587, train/logprobs = tensor([[-1.4786, -4.5372],
        [-6.0591, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8657581210136414
Epoch 0, Step 1596: train/loss = 0.606163740158081, train/raw-loss = 0.28193360567092896, train/logprobs = tensor([[-1.6405, -4.5882],
        [-4.6177, -2.0784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8105753064155579
Epoch 0, Step 1597: train/loss = 0.668761670589447, train/raw-loss = 0.5776013731956482, train/logprobs = tensor([[-2.7712, -3.2331],
        [-3.0376, -2.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22790080308914185
Epoch 0, Step 1598: train/loss = 0.6873541474342346, train/raw-loss = 0.5103374719619751, train/logprobs = tensor([[-2.0811, -3.7586],
        [-4.0298, -2.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44254177808761597
Epoch 0, Step 1599: train/loss = 0.6898499727249146, train/raw-loss = 0.5873206257820129, train/logprobs = tensor([[-1.5946, -2.0134],
        [-4.9408, -3.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2563233971595764
Epoch 0, Step 1600: train/loss = 0.7078987956047058, train/raw-loss = 0.5322247743606567, train/logprobs = tensor([[-2.9222, -3.8898],
        [-5.3130, -3.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4391849637031555
Epoch 0, Step 1601: train/loss = 0.6315946578979492, train/raw-loss = 0.4698972702026367, train/logprobs = tensor([[-2.5059, -3.0239],
        [-3.7638, -2.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4042435586452484
Epoch 0, Step 1602: train/loss = 0.6998911499977112, train/raw-loss = 0.6558815240859985, train/logprobs = tensor([[-4.1367, -4.7733],
        [-1.9473, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11002402752637863
Epoch 0, Step 1603: train/loss = 0.6647506952285767, train/raw-loss = 0.5361824035644531, train/logprobs = tensor([[-3.4202, -4.8573],
        [-3.4116, -1.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3214206397533417
Epoch 0, Step 1604: train/loss = 0.6079717874526978, train/raw-loss = 0.32461628317832947, train/logprobs = tensor([[-2.3084, -5.2154],
        [-4.1542, -1.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7083888053894043
Epoch 0, Step 1605: train/loss = 0.6089618802070618, train/raw-loss = 0.41728588938713074, train/logprobs = tensor([[-3.0754, -5.0847],
        [-3.4406, -1.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47918999195098877
Epoch 0, Step 1606: train/loss = 0.6625595688819885, train/raw-loss = 0.5303876399993896, train/logprobs = tensor([[-2.4157, -4.1775],
        [-3.7933, -2.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33042994141578674
Epoch 0, Step 1607: train/loss = 0.6148779988288879, train/raw-loss = 0.26006707549095154, train/logprobs = tensor([[-2.2781, -5.6734],
        [-3.8767, -1.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8870273232460022
Epoch 0, Step 1608: train/loss = 0.6093178987503052, train/raw-loss = 0.2966912090778351, train/logprobs = tensor([[-1.3822, -3.7843],
        [-5.9064, -4.4214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7815666198730469
Epoch 0, Step 1609: train/loss = 0.6472809910774231, train/raw-loss = 0.44623368978500366, train/logprobs = tensor([[-2.1369, -4.1448],
        [-4.5989, -3.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5026183128356934
Epoch 0, Step 1610: train/loss = 0.65729159116745, train/raw-loss = 0.4531453251838684, train/logprobs = tensor([[-2.1071, -3.2251],
        [-4.3445, -2.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5103656649589539
Epoch 0, Step 1611: train/loss = 0.8049871921539307, train/raw-loss = 0.7802908420562744, train/logprobs = tensor([[-4.0877, -4.9723],
        [-1.9795, -2.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061740972101688385
Epoch 0, Step 1612: train/loss = 0.7387217283248901, train/raw-loss = 0.5792701244354248, train/logprobs = tensor([[-3.7641, -5.8582],
        [-2.3329, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3986290693283081
Epoch 0, Step 1613: train/loss = 0.6657990217208862, train/raw-loss = 0.5469556450843811, train/logprobs = tensor([[-2.6730, -3.9691],
        [-3.3676, -2.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2971085011959076
Epoch 0, Step 1614: train/loss = 0.6077777147293091, train/raw-loss = 0.35611405968666077, train/logprobs = tensor([[-2.8230, -5.2442],
        [-4.1972, -1.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6291589736938477
Epoch 0, Step 1615: train/loss = 0.8653894066810608, train/raw-loss = 0.7099854946136475, train/logprobs = tensor([[-1.8331, -2.7314],
        [-4.9170, -4.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885098695755005
Epoch 0, Step 1616: train/loss = 0.6609222888946533, train/raw-loss = 0.5351753234863281, train/logprobs = tensor([[-2.7555, -4.5928],
        [-3.2093, -1.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31436723470687866
Epoch 0, Step 1617: train/loss = 0.6041622161865234, train/raw-loss = 0.3735027015209198, train/logprobs = tensor([[-2.6465, -5.1022],
        [-3.5101, -1.3021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5766487121582031
Epoch 0, Step 1618: train/loss = 0.7039086222648621, train/raw-loss = 0.6260610818862915, train/logprobs = tensor([[-2.6345, -3.7275],
        [-4.0568, -3.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19461891055107117
Epoch 0, Step 1619: train/loss = 0.6369439363479614, train/raw-loss = 0.4704107344150543, train/logprobs = tensor([[-2.9796, -5.1457],
        [-3.3220, -1.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4163331091403961
Epoch 0, Step 1620: train/loss = 0.608005166053772, train/raw-loss = 0.3190193176269531, train/logprobs = tensor([[-1.5491, -3.9208],
        [-4.3460, -2.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7224647998809814
Epoch 0, Step 1621: train/loss = 0.6414353251457214, train/raw-loss = 0.4713898003101349, train/logprobs = tensor([[-4.3146, -5.5517],
        [-2.9347, -1.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42511385679244995
Epoch 0, Step 1622: train/loss = 0.6436026096343994, train/raw-loss = 0.4071826636791229, train/logprobs = tensor([[-2.3476, -5.0673],
        [-3.6562, -1.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.59104984998703
Epoch 0, Step 1623: train/loss = 0.6485844850540161, train/raw-loss = 0.4889638125896454, train/logprobs = tensor([[-2.6908, -3.5635],
        [-3.4366, -3.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990516662597656
Epoch 0, Step 1624: train/loss = 0.6385351419448853, train/raw-loss = 0.412971168756485, train/logprobs = tensor([[-1.3419, -2.7532],
        [-5.0261, -2.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5639099478721619
Epoch 0, Step 1625: train/loss = 0.6202330589294434, train/raw-loss = 0.39116185903549194, train/logprobs = tensor([[-2.5845, -4.4994],
        [-3.9462, -1.7200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5726779103279114
Epoch 0, Step 1626: train/loss = 0.6947964429855347, train/raw-loss = 0.5731583833694458, train/logprobs = tensor([[-2.2678, -2.4569],
        [-4.3481, -5.3734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304095059633255
Epoch 0, Step 1627: train/loss = 0.6146862506866455, train/raw-loss = 0.3955532908439636, train/logprobs = tensor([[-2.3040, -4.3244],
        [-5.0766, -2.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5478323698043823
Epoch 0, Step 1628: train/loss = 0.6845118403434753, train/raw-loss = 0.5917717814445496, train/logprobs = tensor([[-2.1895, -2.9278],
        [-2.7368, -2.3432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23185013234615326
Epoch 0, Step 1629: train/loss = 0.654076099395752, train/raw-loss = 0.5147557258605957, train/logprobs = tensor([[-1.2154, -2.9828],
        [-4.5592, -3.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3483009934425354
Epoch 0, Step 1630: train/loss = 0.6395012140274048, train/raw-loss = 0.33491918444633484, train/logprobs = tensor([[-1.7661, -4.7135],
        [-4.9711, -2.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7614549398422241
Epoch 0, Step 1631: train/loss = 0.6454272270202637, train/raw-loss = 0.4277706444263458, train/logprobs = tensor([[-2.0224, -3.9513],
        [-4.9259, -3.2894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5441415309906006
Epoch 0, Step 1632: train/loss = 0.6504204273223877, train/raw-loss = 0.3770636022090912, train/logprobs = tensor([[-2.3506, -5.2026],
        [-3.6993, -1.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6833920478820801
Epoch 0, Step 1633: train/loss = 0.6360901594161987, train/raw-loss = 0.5000213384628296, train/logprobs = tensor([[-3.1711, -4.2668],
        [-3.2482, -1.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401721715927124
Epoch 0, Step 1634: train/loss = 0.6191447973251343, train/raw-loss = 0.4361927807331085, train/logprobs = tensor([[-2.1310, -3.6529],
        [-3.8271, -2.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4573799967765808
Epoch 0, Step 1635: train/loss = 0.6488974094390869, train/raw-loss = 0.4302986264228821, train/logprobs = tensor([[-2.7461, -4.2760],
        [-4.1471, -2.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5464969873428345
Epoch 0, Step 1636: train/loss = 0.6677627563476562, train/raw-loss = 0.4681229889392853, train/logprobs = tensor([[-2.2826, -3.7677],
        [-4.1498, -3.3821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4990995526313782
Epoch 0, Step 1637: train/loss = 0.634624183177948, train/raw-loss = 0.3771726191043854, train/logprobs = tensor([[-3.4541, -5.6852],
        [-3.6417, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6436289548873901
Epoch 0, Step 1638: train/loss = 0.7116615772247314, train/raw-loss = 0.5865770578384399, train/logprobs = tensor([[-1.7206, -3.5706],
        [-3.0549, -3.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31271108984947205
Epoch 0, Step 1639: train/loss = 0.7097148895263672, train/raw-loss = 0.6989872455596924, train/logprobs = tensor([[-3.3659, -3.1385],
        [-2.8911, -2.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026819268241524696
Epoch 0, Step 1640: train/loss = 0.7417590618133545, train/raw-loss = 0.6133304834365845, train/logprobs = tensor([[-3.0552, -3.8833],
        [-3.2390, -1.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32107147574424744
Epoch 0, Step 1641: train/loss = 0.7049838304519653, train/raw-loss = 0.6314346790313721, train/logprobs = tensor([[-3.1477, -3.3411],
        [-2.5479, -2.2561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838727593421936
Epoch 0, Step 1642: train/loss = 0.617792546749115, train/raw-loss = 0.3206132650375366, train/logprobs = tensor([[-2.9063, -5.4110],
        [-4.1556, -1.6707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7429481744766235
Epoch 0, Step 1643: train/loss = 0.6367632746696472, train/raw-loss = 0.40692588686943054, train/logprobs = tensor([[-3.1464, -5.3724],
        [-3.0723, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5745934247970581
Epoch 0, Step 1644: train/loss = 0.5214881300926208, train/raw-loss = 0.05036119744181633, train/logprobs = tensor([[-1.0481, -6.5706],
        [-5.8817, -1.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1778173446655273
Epoch 0, Step 1645: train/loss = 0.6565996408462524, train/raw-loss = 0.5131632089614868, train/logprobs = tensor([[-2.9331, -4.5139],
        [-3.3373, -2.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3585909605026245
Epoch 0, Step 1646: train/loss = 0.6626535058021545, train/raw-loss = 0.4484631419181824, train/logprobs = tensor([[-2.2974, -4.6569],
        [-3.4877, -2.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.53547602891922
Epoch 0, Step 1647: train/loss = 0.595664381980896, train/raw-loss = 0.2819555401802063, train/logprobs = tensor([[-1.8776, -5.0922],
        [-4.2225, -1.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7842719554901123
Epoch 0, Step 1648: train/loss = 0.6246302127838135, train/raw-loss = 0.39109548926353455, train/logprobs = tensor([[-1.7094, -3.2435],
        [-5.6825, -2.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5838367342948914
Epoch 0, Step 1649: train/loss = 0.5564020872116089, train/raw-loss = 0.11884193122386932, train/logprobs = tensor([[-1.7997, -5.6533],
        [-5.0346, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.093900442123413
Epoch 0, Step 1650: train/loss = 0.6702378988265991, train/raw-loss = 0.5573261976242065, train/logprobs = tensor([[-3.0326, -4.2326],
        [-3.5799, -2.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822791039943695
Epoch 0, Step 1651: train/loss = 0.6286602020263672, train/raw-loss = 0.4069630205631256, train/logprobs = tensor([[-2.5521, -4.5797],
        [-4.4166, -2.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5542429089546204
Epoch 0, Step 1652: train/loss = 0.5978517532348633, train/raw-loss = 0.23515145480632782, train/logprobs = tensor([[-2.2144, -5.8924],
        [-3.8433, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9067506790161133
Epoch 0, Step 1653: train/loss = 0.6816897988319397, train/raw-loss = 0.5911976099014282, train/logprobs = tensor([[-2.5319, -2.8254],
        [-4.0120, -3.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22623062133789062
Epoch 0, Step 1654: train/loss = 0.606150209903717, train/raw-loss = 0.32519403100013733, train/logprobs = tensor([[-2.7732, -6.2624],
        [-4.4405, -1.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7023904919624329
Epoch 0, Step 1655: train/loss = 0.6483723521232605, train/raw-loss = 0.5272899866104126, train/logprobs = tensor([[-4.0227, -5.7568],
        [-2.9650, -1.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3027060031890869
Epoch 0, Step 1656: train/loss = 0.6446848511695862, train/raw-loss = 0.4776551127433777, train/logprobs = tensor([[-2.8719, -4.7236],
        [-3.8693, -2.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.417574405670166
Epoch 0, Step 1657: train/loss = 0.619408369064331, train/raw-loss = 0.38591820001602173, train/logprobs = tensor([[-3.4954, -6.1900],
        [-2.9051, -1.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5837254524230957
Epoch 0, Step 1658: train/loss = 0.6587562561035156, train/raw-loss = 0.47167786955833435, train/logprobs = tensor([[-3.7432, -5.7192],
        [-3.1740, -1.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46769601106643677
Epoch 0, Step 1659: train/loss = 0.5706801414489746, train/raw-loss = 0.20597206056118011, train/logprobs = tensor([[-1.5200, -5.0278],
        [-4.4894, -1.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9117701649665833
Epoch 0, Step 1660: train/loss = 0.6368736624717712, train/raw-loss = 0.396795392036438, train/logprobs = tensor([[-1.5204, -2.9358],
        [-4.3224, -3.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6001957058906555
Epoch 0, Step 1661: train/loss = 0.7408386468887329, train/raw-loss = 0.6889163255691528, train/logprobs = tensor([[-2.7286, -3.7243],
        [-3.5815, -3.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12980586290359497
Epoch 0, Step 1662: train/loss = 0.6378721594810486, train/raw-loss = 0.362978458404541, train/logprobs = tensor([[-2.8005, -5.7774],
        [-3.5944, -1.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6872342824935913
Epoch 0, Step 1663: train/loss = 0.5711944103240967, train/raw-loss = 0.1728171855211258, train/logprobs = tensor([[-2.3380, -6.5762],
        [-4.4856, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9959429502487183
Epoch 0, Step 1664: train/loss = 0.5843405723571777, train/raw-loss = 0.24708229303359985, train/logprobs = tensor([[-1.6301, -5.0257],
        [-5.6474, -2.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8431456685066223
Epoch 0, Step 1665: train/loss = 0.6677473783493042, train/raw-loss = 0.49765413999557495, train/logprobs = tensor([[-3.2346, -5.1035],
        [-3.5980, -2.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4252331256866455
Epoch 0, Step 1666: train/loss = 0.6424793004989624, train/raw-loss = 0.4661310315132141, train/logprobs = tensor([[-3.4059, -4.2412],
        [-3.5855, -3.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44087058305740356
Epoch 0, Step 1667: train/loss = 0.7124402523040771, train/raw-loss = 0.5868628025054932, train/logprobs = tensor([[-4.2721, -5.8980],
        [-2.1787, -1.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313943475484848
Epoch 0, Step 1668: train/loss = 0.6464813947677612, train/raw-loss = 0.44624602794647217, train/logprobs = tensor([[-2.3676, -3.8897],
        [-4.3672, -2.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5005885362625122
Epoch 0, Step 1669: train/loss = 0.6293010115623474, train/raw-loss = 0.43554696440696716, train/logprobs = tensor([[-2.2254, -4.3662],
        [-4.4332, -2.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4843849837779999
Epoch 0, Step 1670: train/loss = 0.5707703232765198, train/raw-loss = 0.18146994709968567, train/logprobs = tensor([[-2.3293, -5.8875],
        [-5.5336, -1.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9732509255409241
Epoch 0, Step 1671: train/loss = 0.595605731010437, train/raw-loss = 0.2533006966114044, train/logprobs = tensor([[-2.5420, -6.3062],
        [-4.8718, -2.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8557624220848083
Epoch 0, Step 1672: train/loss = 0.6393011808395386, train/raw-loss = 0.44455230236053467, train/logprobs = tensor([[-3.3520, -4.7299],
        [-2.8784, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48687222599983215
Epoch 0, Step 1673: train/loss = 0.6723194718360901, train/raw-loss = 0.5637854337692261, train/logprobs = tensor([[-2.7317, -3.1746],
        [-3.9496, -3.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713349461555481
Epoch 0, Step 1674: train/loss = 0.6441456079483032, train/raw-loss = 0.3952196538448334, train/logprobs = tensor([[-2.7058, -5.3819],
        [-3.2575, -1.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6223148703575134
Epoch 0, Step 1675: train/loss = 0.629565417766571, train/raw-loss = 0.3188438415527344, train/logprobs = tensor([[-2.5033, -5.5374],
        [-3.9779, -1.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7768039703369141
Epoch 0, Step 1676: train/loss = 0.6793911457061768, train/raw-loss = 0.4863313138484955, train/logprobs = tensor([[-4.3771, -6.3043],
        [-3.2417, -2.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48264968395233154
Epoch 0, Step 1677: train/loss = 0.6680029630661011, train/raw-loss = 0.5023213624954224, train/logprobs = tensor([[-3.3369, -4.1381],
        [-3.4578, -2.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4142038822174072
Epoch 0, Step 1678: train/loss = 0.654341459274292, train/raw-loss = 0.4817952513694763, train/logprobs = tensor([[-3.0315, -4.4854],
        [-3.6128, -2.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43136540055274963
Epoch 0, Step 1679: train/loss = 0.6677350997924805, train/raw-loss = 0.5561231374740601, train/logprobs = tensor([[-4.0538, -5.3066],
        [-2.5374, -1.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790299355983734
Epoch 0, Step 1680: train/loss = 0.6439239978790283, train/raw-loss = 0.4180416166782379, train/logprobs = tensor([[-2.7224, -4.2846],
        [-4.2915, -2.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5647058486938477
Epoch 0, Step 1681: train/loss = 0.6937950253486633, train/raw-loss = 0.5931118726730347, train/logprobs = tensor([[-4.0040, -5.1519],
        [-2.5913, -1.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25170788168907166
Epoch 0, Step 1682: train/loss = 0.6956570744514465, train/raw-loss = 0.5321043729782104, train/logprobs = tensor([[-3.9262, -5.4488],
        [-3.0078, -1.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40888193249702454
Epoch 0, Step 1683: train/loss = 0.8299307823181152, train/raw-loss = 0.5686302185058594, train/logprobs = tensor([[-3.3692, -5.8455],
        [-3.1391, -2.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6532515287399292
Epoch 0, Step 1684: train/loss = 0.5863760113716125, train/raw-loss = 0.2044963836669922, train/logprobs = tensor([[-2.1282, -6.4726],
        [-5.4946, -1.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.954698920249939
Epoch 0, Step 1685: train/loss = 0.6356313824653625, train/raw-loss = 0.40647098422050476, train/logprobs = tensor([[-1.7780, -3.4642],
        [-4.6437, -2.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5729008913040161
Epoch 0, Step 1686: train/loss = 0.7196690440177917, train/raw-loss = 0.6111024618148804, train/logprobs = tensor([[-4.1076, -5.8018],
        [-2.8011, -2.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27141639590263367
Epoch 0, Step 1687: train/loss = 0.6567912101745605, train/raw-loss = 0.44297921657562256, train/logprobs = tensor([[-3.6547, -5.2905],
        [-3.4987, -1.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5345300436019897
Epoch 0, Step 1688: train/loss = 0.6648133993148804, train/raw-loss = 0.4779292643070221, train/logprobs = tensor([[-4.6429, -6.4179],
        [-3.4013, -1.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46721044182777405
Epoch 0, Step 1689: train/loss = 0.6264503002166748, train/raw-loss = 0.32830703258514404, train/logprobs = tensor([[-2.5854, -6.1245],
        [-4.1298, -2.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7453582286834717
Epoch 0, Step 1690: train/loss = 0.5917191505432129, train/raw-loss = 0.19732201099395752, train/logprobs = tensor([[-1.4435, -5.4265],
        [-6.3842, -2.3862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9859927892684937
Epoch 0, Step 1691: train/loss = 0.5775161385536194, train/raw-loss = 0.09814440459012985, train/logprobs = tensor([[-1.7803, -6.2532],
        [-5.5374, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1984293460845947
Epoch 0, Step 1692: train/loss = 0.6666351556777954, train/raw-loss = 0.5474581718444824, train/logprobs = tensor([[-3.8232, -4.7602],
        [-3.2892, -2.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979426681995392
Epoch 0, Step 1693: train/loss = 0.6978834271430969, train/raw-loss = 0.45090389251708984, train/logprobs = tensor([[-2.5923, -4.9203],
        [-4.7107, -2.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6174488663673401
Epoch 0, Step 1694: train/loss = 0.6648664474487305, train/raw-loss = 0.5531183481216431, train/logprobs = tensor([[-4.0623, -5.0936],
        [-3.3436, -2.3600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2793703079223633
Epoch 0, Step 1695: train/loss = 0.594007134437561, train/raw-loss = 0.1974795162677765, train/logprobs = tensor([[-3.5743, -6.2190],
        [-4.2518, -1.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.991318941116333
Epoch 0, Step 1696: train/loss = 0.6951838731765747, train/raw-loss = 0.6426394581794739, train/logprobs = tensor([[-3.7450, -4.4094],
        [-3.7239, -3.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13136109709739685
Epoch 0, Step 1697: train/loss = 0.6114593744277954, train/raw-loss = 0.3773587942123413, train/logprobs = tensor([[-3.5462, -4.4008],
        [-4.5734, -3.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5852514505386353
Epoch 0, Step 1698: train/loss = 0.6796537637710571, train/raw-loss = 0.6132513284683228, train/logprobs = tensor([[-3.2882, -4.0255],
        [-4.2933, -3.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16600599884986877
Epoch 0, Step 1699: train/loss = 0.6840728521347046, train/raw-loss = 0.6006660461425781, train/logprobs = tensor([[-3.1362, -3.9771],
        [-3.8429, -3.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2085171788930893
Epoch 0, Step 1700: train/loss = 0.6946945190429688, train/raw-loss = 0.6188993453979492, train/logprobs = tensor([[-4.6127, -5.5766],
        [-2.3211, -2.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18948805332183838
Epoch 0, Step 1701: train/loss = 0.5616999864578247, train/raw-loss = 0.20970392227172852, train/logprobs = tensor([[-2.8136, -6.9681],
        [-4.5138, -2.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8799902200698853
Epoch 0, Step 1702: train/loss = 0.8715861439704895, train/raw-loss = 0.6563399434089661, train/logprobs = tensor([[-3.5815, -6.7767],
        [-2.5772, -2.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5381155610084534
Epoch 0, Step 1703: train/loss = 0.602031409740448, train/raw-loss = 0.25948894023895264, train/logprobs = tensor([[-3.0655, -7.1220],
        [-4.5380, -2.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8563560247421265
Epoch 0, Step 1704: train/loss = 0.662061333656311, train/raw-loss = 0.4309726357460022, train/logprobs = tensor([[-2.3456, -4.6439],
        [-4.7399, -3.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5777218341827393
Epoch 0, Step 1705: train/loss = 0.6655635833740234, train/raw-loss = 0.5224452614784241, train/logprobs = tensor([[-3.5119, -4.4521],
        [-4.5379, -2.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35779571533203125
Epoch 0, Step 1706: train/loss = 0.6795852184295654, train/raw-loss = 0.4462096691131592, train/logprobs = tensor([[-2.8138, -5.6715],
        [-5.1537, -3.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5834388136863708
Epoch 0, Step 1707: train/loss = 0.687362551689148, train/raw-loss = 0.5385227203369141, train/logprobs = tensor([[-3.5769, -5.6960],
        [-3.7382, -2.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3720996081829071
Epoch 0, Step 1708: train/loss = 0.7513318061828613, train/raw-loss = 0.47086796164512634, train/logprobs = tensor([[-2.7220, -5.7934],
        [-4.4537, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7011595964431763
Epoch 0, Step 1709: train/loss = 0.6308136582374573, train/raw-loss = 0.2730122208595276, train/logprobs = tensor([[-2.1213, -5.9476],
        [-5.1581, -2.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8945035338401794
Epoch 0, Step 1710: train/loss = 0.569648027420044, train/raw-loss = 0.1846640557050705, train/logprobs = tensor([[-2.8480, -6.8494],
        [-4.5637, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.962459921836853
Epoch 0, Step 1711: train/loss = 0.6320351958274841, train/raw-loss = 0.4120868444442749, train/logprobs = tensor([[-2.8615, -4.5949],
        [-4.6559, -2.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5498708486557007
Epoch 0, Step 1712: train/loss = 0.5997954607009888, train/raw-loss = 0.23405253887176514, train/logprobs = tensor([[-3.1876, -7.2968],
        [-4.3954, -1.4539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9143571853637695
Epoch 0, Step 1713: train/loss = 0.6552407145500183, train/raw-loss = 0.43233054876327515, train/logprobs = tensor([[-3.3685, -6.1701],
        [-5.0862, -2.8470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5572752952575684
Epoch 0, Step 1714: train/loss = 0.6437469720840454, train/raw-loss = 0.3996342420578003, train/logprobs = tensor([[-3.8093, -6.1752],
        [-4.7581, -2.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6102818250656128
Epoch 0, Step 1715: train/loss = 0.6584936380386353, train/raw-loss = 0.5103743076324463, train/logprobs = tensor([[-3.0877, -5.5543],
        [-4.3018, -2.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37029820680618286
Epoch 0, Step 1716: train/loss = 0.5972831845283508, train/raw-loss = 0.2647317945957184, train/logprobs = tensor([[-3.0468, -4.8297],
        [-5.5174, -4.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8313784599304199
Epoch 0, Step 1717: train/loss = 0.5924638509750366, train/raw-loss = 0.24385760724544525, train/logprobs = tensor([[-3.1789, -7.1922],
        [-5.2615, -1.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8715155124664307
Epoch 0, Step 1718: train/loss = 0.655354917049408, train/raw-loss = 0.5423448085784912, train/logprobs = tensor([[-3.8243, -5.0317],
        [-4.7749, -4.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28252527117729187
Epoch 0, Step 1719: train/loss = 0.6092777252197266, train/raw-loss = 0.3722691833972931, train/logprobs = tensor([[-3.5145, -6.1476],
        [-3.9740, -1.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5925211906433105
Epoch 0, Step 1720: train/loss = 0.7005561590194702, train/raw-loss = 0.6715070605278015, train/logprobs = tensor([[-4.7928, -5.0286],
        [-4.1532, -3.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07262258231639862
Epoch 0, Step 1721: train/loss = 0.6542147994041443, train/raw-loss = 0.5188111662864685, train/logprobs = tensor([[-3.6421, -4.7336],
        [-4.9828, -3.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33850905299186707
Epoch 0, Step 1722: train/loss = 0.7489978075027466, train/raw-loss = 0.6189517378807068, train/logprobs = tensor([[-5.0721, -7.3399],
        [-3.4398, -2.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32511502504348755
Epoch 0, Step 1723: train/loss = 0.621672511100769, train/raw-loss = 0.29275593161582947, train/logprobs = tensor([[-2.7161, -4.8490],
        [-4.7657, -4.4293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.822291374206543
Epoch 0, Step 1724: train/loss = 0.6692808270454407, train/raw-loss = 0.4971577823162079, train/logprobs = tensor([[-4.3856, -4.7363],
        [-4.0061, -3.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.430307537317276
Epoch 0, Step 1725: train/loss = 0.591208815574646, train/raw-loss = 0.1811586171388626, train/logprobs = tensor([[-3.4682, -7.5180],
        [-5.7926, -2.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.025125503540039
Epoch 0, Step 1726: train/loss = 0.7077780365943909, train/raw-loss = 0.6308560371398926, train/logprobs = tensor([[-4.0133, -5.1717],
        [-3.6045, -3.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19230495393276215
Epoch 0, Step 1727: train/loss = 0.6600947380065918, train/raw-loss = 0.5301381349563599, train/logprobs = tensor([[-4.5682, -6.4277],
        [-3.6708, -2.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32489144802093506
Epoch 0, Step 1728: train/loss = 0.6253465414047241, train/raw-loss = 0.36628901958465576, train/logprobs = tensor([[-4.8709, -7.0503],
        [-3.9525, -1.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6476438641548157
Epoch 0, Step 1729: train/loss = 0.5047377943992615, train/raw-loss = 0.04895585775375366, train/logprobs = tensor([[-2.1561, -7.4266],
        [-6.5163, -1.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1394548416137695
Epoch 0, Step 1730: train/loss = 0.6240414381027222, train/raw-loss = 0.3851768374443054, train/logprobs = tensor([[-3.4416, -6.8028],
        [-5.4837, -4.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5971615314483643
Epoch 0, Step 1731: train/loss = 0.6266655921936035, train/raw-loss = 0.4389766752719879, train/logprobs = tensor([[-4.3096, -6.4647],
        [-5.5032, -3.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4692222476005554
Epoch 0, Step 1732: train/loss = 0.6188400387763977, train/raw-loss = 0.394655704498291, train/logprobs = tensor([[-3.1269, -5.2451],
        [-5.4459, -3.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5604608654975891
Epoch 0, Step 1733: train/loss = 0.5998243689537048, train/raw-loss = 0.1944856196641922, train/logprobs = tensor([[-2.0052, -6.3793],
        [-5.8387, -3.0056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0133469104766846
Epoch 0, Step 1734: train/loss = 0.688109815120697, train/raw-loss = 0.4569218158721924, train/logprobs = tensor([[-4.9814, -7.4562],
        [-3.4701, -2.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5779699683189392
Epoch 0, Step 1735: train/loss = 0.6403104066848755, train/raw-loss = 0.28374356031417847, train/logprobs = tensor([[-3.4159, -8.3826],
        [-5.3053, -2.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8914170861244202
Epoch 0, Step 1736: train/loss = 0.6753135323524475, train/raw-loss = 0.5352613925933838, train/logprobs = tensor([[-4.9851, -5.9386],
        [-4.1362, -2.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3501303195953369
Epoch 0, Step 1737: train/loss = 0.6112911701202393, train/raw-loss = 0.36125069856643677, train/logprobs = tensor([[-4.0814, -7.1899],
        [-3.9177, -1.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6251012086868286
Epoch 0, Step 1738: train/loss = 0.5660972595214844, train/raw-loss = 0.20116743445396423, train/logprobs = tensor([[-2.8331, -7.0967],
        [-5.6590, -2.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9123245477676392
Epoch 0, Step 1739: train/loss = 0.7229338884353638, train/raw-loss = 0.6846528053283691, train/logprobs = tensor([[-4.2238, -5.2282],
        [-3.1883, -3.3187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09570259600877762
Epoch 0, Step 1740: train/loss = 0.7114032506942749, train/raw-loss = 0.6855951547622681, train/logprobs = tensor([[-4.9547, -4.6346],
        [-4.3257, -4.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06452026218175888
Epoch 0, Step 1741: train/loss = 0.722259521484375, train/raw-loss = 0.6607876420021057, train/logprobs = tensor([[-4.3643, -4.9987],
        [-2.8421, -2.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1536797285079956
Epoch 0, Step 1742: train/loss = 0.6664402484893799, train/raw-loss = 0.46463268995285034, train/logprobs = tensor([[-3.9846, -5.3775],
        [-4.2963, -2.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5045190453529358
Epoch 0, Step 1743: train/loss = 0.6317457556724548, train/raw-loss = 0.23573243618011475, train/logprobs = tensor([[-2.2709, -6.3653],
        [-6.9083, -3.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9900332689285278
Epoch 0, Step 1744: train/loss = 0.689237117767334, train/raw-loss = 0.6384238004684448, train/logprobs = tensor([[-4.2456, -4.0355],
        [-5.7216, -5.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270332634449005
Epoch 0, Step 1745: train/loss = 0.6113097071647644, train/raw-loss = 0.3176652193069458, train/logprobs = tensor([[-3.7653, -6.6463],
        [-5.3639, -2.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7341113090515137
Epoch 0, Step 1746: train/loss = 0.5945941805839539, train/raw-loss = 0.24775461852550507, train/logprobs = tensor([[-2.5393, -5.9309],
        [-6.5273, -3.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8670987486839294
Epoch 0, Step 1747: train/loss = 0.6862677931785583, train/raw-loss = 0.4932733178138733, train/logprobs = tensor([[-3.9401, -6.4992],
        [-4.6378, -3.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48248621821403503
Epoch 0, Step 1748: train/loss = 0.6560354828834534, train/raw-loss = 0.515118420124054, train/logprobs = tensor([[-5.8153, -6.8944],
        [-3.7763, -2.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522927761077881
Epoch 0, Step 1749: train/loss = 0.7455199956893921, train/raw-loss = 0.6128062009811401, train/logprobs = tensor([[-5.7303, -6.4971],
        [-4.2872, -2.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3317846655845642
Epoch 0, Step 1750: train/loss = 0.649022102355957, train/raw-loss = 0.4367569386959076, train/logprobs = tensor([[-4.1552, -5.8778],
        [-4.6551, -3.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5306628942489624
Epoch 0, Step 1751: train/loss = 0.7078917026519775, train/raw-loss = 0.6608544588088989, train/logprobs = tensor([[-5.9689, -6.8545],
        [-4.2167, -3.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1175931990146637
Epoch 0, Step 1752: train/loss = 0.5873441696166992, train/raw-loss = 0.20327062904834747, train/logprobs = tensor([[-2.8765, -5.3348],
        [-6.1737, -3.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9601839780807495
Epoch 0, Step 1753: train/loss = 0.7056479454040527, train/raw-loss = 0.6156750321388245, train/logprobs = tensor([[-6.0623, -5.3126],
        [-3.3440, -4.2451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22493228316307068
Epoch 0, Step 1754: train/loss = 0.5675088167190552, train/raw-loss = 0.18382881581783295, train/logprobs = tensor([[-4.0416, -7.9450],
        [-5.6819, -2.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9591999053955078
Epoch 0, Step 1755: train/loss = 0.6642116904258728, train/raw-loss = 0.5388969779014587, train/logprobs = tensor([[-4.5446, -4.0138],
        [-5.2459, -6.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31328684091567993
Epoch 0, Step 1756: train/loss = 0.7083739638328552, train/raw-loss = 0.6054900288581848, train/logprobs = tensor([[-5.5429, -6.9531],
        [-3.1280, -2.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257209837436676
Epoch 0, Step 1757: train/loss = 0.6557245254516602, train/raw-loss = 0.5229092836380005, train/logprobs = tensor([[-5.1222, -5.9863],
        [-3.9286, -3.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33203810453414917
Epoch 0, Step 1758: train/loss = 0.6094781756401062, train/raw-loss = 0.3775075078010559, train/logprobs = tensor([[-4.8118, -6.8939],
        [-5.0969, -2.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.579926609992981
Epoch 0, Step 1759: train/loss = 0.6605636477470398, train/raw-loss = 0.5003693103790283, train/logprobs = tensor([[-5.1597, -6.9934],
        [-3.9449, -2.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4004858136177063
Epoch 0, Step 1760: train/loss = 0.6098047494888306, train/raw-loss = 0.2570017874240875, train/logprobs = tensor([[-4.4611, -7.3870],
        [-5.9093, -2.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.882007360458374
Epoch 0, Step 1761: train/loss = 0.6198785305023193, train/raw-loss = 0.368559330701828, train/logprobs = tensor([[-4.6663, -7.4866],
        [-4.6731, -1.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6282979249954224
Epoch 0, Step 1762: train/loss = 0.6331281661987305, train/raw-loss = 0.43161439895629883, train/logprobs = tensor([[-4.4115, -6.8099],
        [-5.4240, -3.4031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5037845373153687
Epoch 0, Step 1763: train/loss = 0.5787585377693176, train/raw-loss = 0.291978120803833, train/logprobs = tensor([[-4.0005, -7.1619],
        [-6.9941, -3.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7169511318206787
Epoch 0, Step 1764: train/loss = 0.5708402395248413, train/raw-loss = 0.14130859076976776, train/logprobs = tensor([[-3.3337, -6.0372],
        [-6.5975, -3.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0738290548324585
Epoch 0, Step 1765: train/loss = 0.6975415349006653, train/raw-loss = 0.6898160576820374, train/logprobs = tensor([[-3.9311, -4.0416],
        [-5.2482, -5.2652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019313640892505646
Epoch 0, Step 1766: train/loss = 0.6191921234130859, train/raw-loss = 0.3566858470439911, train/logprobs = tensor([[-4.5015, -6.9131],
        [-4.6498, -2.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6562656760215759
Epoch 0, Step 1767: train/loss = 0.5739972591400146, train/raw-loss = 0.20143210887908936, train/logprobs = tensor([[-4.6883, -8.4833],
        [-6.3803, -1.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9314126968383789
Epoch 0, Step 1768: train/loss = 0.6853300333023071, train/raw-loss = 0.617774486541748, train/logprobs = tensor([[-4.3477, -4.8069],
        [-5.6639, -5.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16888895630836487
Epoch 0, Step 1769: train/loss = 0.6519057750701904, train/raw-loss = 0.3665514588356018, train/logprobs = tensor([[-4.5414, -6.9265],
        [-5.2573, -3.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.713385820388794
Epoch 0, Step 1770: train/loss = 0.6198707818984985, train/raw-loss = 0.2547001838684082, train/logprobs = tensor([[-3.6752, -6.8708],
        [-6.5925, -2.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9129266738891602
Epoch 0, Step 1771: train/loss = 0.6072297096252441, train/raw-loss = 0.32171565294265747, train/logprobs = tensor([[-4.2251, -6.2428],
        [-6.6564, -4.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7137849926948547
Epoch 0, Step 1772: train/loss = 0.9355918169021606, train/raw-loss = 0.9097589254379272, train/logprobs = tensor([[-5.3025, -5.9502],
        [-3.9357, -4.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645822212100029
Epoch 0, Step 1773: train/loss = 0.6593406200408936, train/raw-loss = 0.4808744192123413, train/logprobs = tensor([[-6.5820, -7.9444],
        [-4.4948, -3.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44616538286209106
Epoch 0, Step 1774: train/loss = 0.7024285197257996, train/raw-loss = 0.6281384229660034, train/logprobs = tensor([[-4.9916, -5.3569],
        [-5.6924, -4.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18572527170181274
Epoch 0, Step 1775: train/loss = 0.7034398317337036, train/raw-loss = 0.4870324730873108, train/logprobs = tensor([[-3.8296, -4.2095],
        [-6.6721, -4.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5410183072090149
Epoch 0, Step 1776: train/loss = 0.6209656000137329, train/raw-loss = 0.3865821361541748, train/logprobs = tensor([[-4.9789, -7.8612],
        [-5.9559, -3.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5859586000442505
Epoch 0, Step 1777: train/loss = 0.6542043685913086, train/raw-loss = 0.5191541910171509, train/logprobs = tensor([[-6.2730, -7.8041],
        [-4.2877, -2.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3376253843307495
Epoch 0, Step 1778: train/loss = 0.6136778593063354, train/raw-loss = 0.34670794010162354, train/logprobs = tensor([[-5.4136, -8.1466],
        [-4.6962, -1.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6674247980117798
Epoch 0, Step 1779: train/loss = 0.567650556564331, train/raw-loss = 0.2436046302318573, train/logprobs = tensor([[-2.8693, -6.5678],
        [-6.5422, -3.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8101147413253784
Epoch 0, Step 1780: train/loss = 0.6598234176635742, train/raw-loss = 0.45725587010383606, train/logprobs = tensor([[-3.1912, -5.6489],
        [-6.5649, -4.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5064189434051514
Epoch 0, Step 1781: train/loss = 0.5894067287445068, train/raw-loss = 0.2575770616531372, train/logprobs = tensor([[-5.2230, -7.8942],
        [-6.3810, -2.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8295741081237793
Epoch 0, Step 1782: train/loss = 0.6874952912330627, train/raw-loss = 0.5614850521087646, train/logprobs = tensor([[-5.2402, -6.1916],
        [-5.9459, -4.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150256872177124
Epoch 0, Step 1783: train/loss = 0.6245795488357544, train/raw-loss = 0.33015722036361694, train/logprobs = tensor([[-3.8533, -7.1552],
        [-5.9507, -4.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7360557317733765
Epoch 0, Step 1784: train/loss = 0.6014282703399658, train/raw-loss = 0.3810817301273346, train/logprobs = tensor([[-4.2438, -6.8929],
        [-6.1999, -3.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5508663058280945
Epoch 0, Step 1785: train/loss = 0.6551418304443359, train/raw-loss = 0.5275145769119263, train/logprobs = tensor([[-4.2907, -5.7583],
        [-5.5511, -4.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3190680742263794
Epoch 0, Step 1786: train/loss = 0.6252915859222412, train/raw-loss = 0.38381484150886536, train/logprobs = tensor([[-3.7802, -6.2035],
        [-5.8015, -3.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6036919355392456
Epoch 0, Step 1787: train/loss = 0.6233143210411072, train/raw-loss = 0.40669435262680054, train/logprobs = tensor([[-5.9920, -8.6933],
        [-4.5750, -2.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5415499210357666
Epoch 0, Step 1788: train/loss = 0.6233665347099304, train/raw-loss = 0.42455726861953735, train/logprobs = tensor([[-5.6955, -7.9438],
        [-4.8961, -2.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4970231354236603
Epoch 0, Step 1789: train/loss = 0.5694397687911987, train/raw-loss = 0.20919226109981537, train/logprobs = tensor([[-3.1243, -7.0392],
        [-6.3237, -2.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9006189107894897
Epoch 0, Step 1790: train/loss = 0.6586445569992065, train/raw-loss = 0.5141712427139282, train/logprobs = tensor([[-5.1571, -6.6180],
        [-5.8697, -4.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3611832559108734
Epoch 0, Step 1791: train/loss = 0.6583831310272217, train/raw-loss = 0.4350438714027405, train/logprobs = tensor([[-3.4862, -6.5307],
        [-5.9962, -4.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5583481788635254
Epoch 0, Step 1792: train/loss = 0.5616658329963684, train/raw-loss = 0.22298702597618103, train/logprobs = tensor([[-3.0588, -6.5240],
        [-7.3264, -3.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8466969728469849
Epoch 0, Step 1793: train/loss = 0.8290821313858032, train/raw-loss = 0.6569377779960632, train/logprobs = tensor([[-5.8522, -7.0106],
        [-5.6857, -3.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43036094307899475
Epoch 0, Step 1794: train/loss = 0.6278808116912842, train/raw-loss = 0.3855252265930176, train/logprobs = tensor([[-5.0422, -6.7427],
        [-5.8874, -3.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.605888843536377
Epoch 0, Step 1795: train/loss = 0.6152593493461609, train/raw-loss = 0.369088739156723, train/logprobs = tensor([[-5.6374, -7.9443],
        [-3.8087, -1.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6154264807701111
Epoch 0, Step 1796: train/loss = 0.5989235639572144, train/raw-loss = 0.26917243003845215, train/logprobs = tensor([[-3.1566, -6.2280],
        [-6.8088, -3.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8243777751922607
Epoch 0, Step 1797: train/loss = 0.5631730556488037, train/raw-loss = 0.14786389470100403, train/logprobs = tensor([[-2.5804, -6.7115],
        [-6.3029, -2.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0382728576660156
Epoch 0, Step 1798: train/loss = 0.623656153678894, train/raw-loss = 0.3854484558105469, train/logprobs = tensor([[-2.6011, -4.6080],
        [-6.9595, -4.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5955191850662231
Epoch 0, Step 1799: train/loss = 0.7003781199455261, train/raw-loss = 0.6116381883621216, train/logprobs = tensor([[-5.8178, -7.0606],
        [-4.1738, -3.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22184985876083374
Epoch 0, Step 1800: train/loss = 0.6594254970550537, train/raw-loss = 0.4016706943511963, train/logprobs = tensor([[-4.4578, -6.9397],
        [-5.3667, -3.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6443870067596436
Epoch 0, Step 1801: train/loss = 0.6032524108886719, train/raw-loss = 0.3354337811470032, train/logprobs = tensor([[-3.6385, -6.1643],
        [-5.7822, -3.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6695466041564941
Epoch 0, Step 1802: train/loss = 0.650885820388794, train/raw-loss = 0.39502108097076416, train/logprobs = tensor([[-5.2740, -7.6964],
        [-6.3500, -2.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6396618485450745
Epoch 0, Step 1803: train/loss = 0.621008038520813, train/raw-loss = 0.3762519061565399, train/logprobs = tensor([[-3.8539, -6.3864],
        [-5.8408, -3.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.611890435218811
Epoch 0, Step 1804: train/loss = 0.5601915121078491, train/raw-loss = 0.1996190994977951, train/logprobs = tensor([[-4.5991, -8.1654],
        [-7.2246, -2.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9014309644699097
Epoch 0, Step 1805: train/loss = 0.6156672239303589, train/raw-loss = 0.33069494366645813, train/logprobs = tensor([[-6.1563, -8.5096],
        [-6.0117, -3.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7124307751655579
Epoch 0, Step 1806: train/loss = 0.5883167386054993, train/raw-loss = 0.20484969019889832, train/logprobs = tensor([[-4.1438, -7.7070],
        [-6.0119, -2.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9586677551269531
Epoch 0, Step 1807: train/loss = 0.5904955863952637, train/raw-loss = 0.20204617083072662, train/logprobs = tensor([[-2.3628, -6.6200],
        [-6.7254, -3.6188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9711235761642456
Epoch 0, Step 1808: train/loss = 0.705012321472168, train/raw-loss = 0.5457001328468323, train/logprobs = tensor([[-6.0584, -6.8868],
        [-5.1219, -3.3396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3982805013656616
Epoch 0, Step 1809: train/loss = 0.6003940105438232, train/raw-loss = 0.31832754611968994, train/logprobs = tensor([[-4.4797, -6.9951],
        [-6.0230, -2.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7051662802696228
Epoch 0, Step 1810: train/loss = 0.6778444051742554, train/raw-loss = 0.44691866636276245, train/logprobs = tensor([[-3.9235, -5.2185],
        [-6.3053, -4.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5773144960403442
Epoch 0, Step 1811: train/loss = 0.7640726566314697, train/raw-loss = 0.758830189704895, train/logprobs = tensor([[-4.9215, -5.2698],
        [-4.4847, -4.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013106214813888073
Epoch 0, Step 1812: train/loss = 0.5922300219535828, train/raw-loss = 0.3082793951034546, train/logprobs = tensor([[-3.8288, -7.0308],
        [-6.0423, -3.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.709876537322998
Epoch 0, Step 1813: train/loss = 0.6078408360481262, train/raw-loss = 0.2660987675189972, train/logprobs = tensor([[-4.3521, -7.0688],
        [-6.0650, -2.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8543551564216614
Epoch 0, Step 1814: train/loss = 0.5807653665542603, train/raw-loss = 0.22106023132801056, train/logprobs = tensor([[-3.9578, -7.4673],
        [-6.2275, -3.1805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8992629647254944
Epoch 0, Step 1815: train/loss = 0.5607075691223145, train/raw-loss = 0.21517033874988556, train/logprobs = tensor([[-3.4052, -6.2532],
        [-6.7612, -2.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8638430833816528
Epoch 0, Step 1816: train/loss = 0.5758986473083496, train/raw-loss = 0.25395292043685913, train/logprobs = tensor([[-3.3824, -6.3382],
        [-6.1528, -3.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8048642873764038
Epoch 0, Step 1817: train/loss = 0.6998502016067505, train/raw-loss = 0.6109356880187988, train/logprobs = tensor([[-4.0951, -4.4811],
        [-5.3210, -4.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22228634357452393
Epoch 0, Step 1818: train/loss = 0.6063315272331238, train/raw-loss = 0.36827996373176575, train/logprobs = tensor([[-3.6121, -5.9104],
        [-6.6767, -4.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5951288342475891
Epoch 0, Step 1819: train/loss = 0.6076197028160095, train/raw-loss = 0.2200620174407959, train/logprobs = tensor([[-4.1790, -6.1585],
        [-6.7367, -3.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9688943028450012
Epoch 0, Step 1820: train/loss = 0.714057207107544, train/raw-loss = 0.6624277830123901, train/logprobs = tensor([[-5.4503, -5.5949],
        [-4.1257, -3.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12907350063323975
Epoch 0, Step 1821: train/loss = 0.6739850044250488, train/raw-loss = 0.47355785965919495, train/logprobs = tensor([[-5.5126, -7.2747],
        [-4.2866, -2.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5010678768157959
Epoch 0, Step 1822: train/loss = 0.6044318675994873, train/raw-loss = 0.29260072112083435, train/logprobs = tensor([[-4.7617, -7.8427],
        [-5.9592, -3.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7795778512954712
Epoch 0, Step 1823: train/loss = 0.6574811935424805, train/raw-loss = 0.4172389507293701, train/logprobs = tensor([[-3.7592, -5.1240],
        [-6.3795, -5.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6006056070327759
Epoch 0, Step 1824: train/loss = 0.5792759656906128, train/raw-loss = 0.23745596408843994, train/logprobs = tensor([[-5.2038, -8.0937],
        [-5.5005, -2.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8545500040054321
Epoch 0, Step 1825: train/loss = 0.6494783163070679, train/raw-loss = 0.3954373598098755, train/logprobs = tensor([[-4.1964, -6.4311],
        [-6.0596, -3.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.635102391242981
Epoch 0, Step 1826: train/loss = 0.6151020526885986, train/raw-loss = 0.3548600673675537, train/logprobs = tensor([[-5.6453, -8.3382],
        [-4.5392, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6506050825119019
Epoch 0, Step 1827: train/loss = 0.6524895429611206, train/raw-loss = 0.42930319905281067, train/logprobs = tensor([[-2.8941, -5.9662],
        [-6.4129, -4.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5579659342765808
Epoch 0, Step 1828: train/loss = 0.6012350916862488, train/raw-loss = 0.31141820549964905, train/logprobs = tensor([[-4.6999, -7.1098],
        [-6.3180, -3.1327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7245422005653381
Epoch 0, Step 1829: train/loss = 0.6492002010345459, train/raw-loss = 0.48074012994766235, train/logprobs = tensor([[-5.3650, -7.6206],
        [-3.8329, -2.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42114999890327454
Epoch 0, Step 1830: train/loss = 0.673961341381073, train/raw-loss = 0.5439510345458984, train/logprobs = tensor([[-6.5767, -7.5052],
        [-4.2410, -2.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250258266925812
Epoch 0, Step 1831: train/loss = 0.637680172920227, train/raw-loss = 0.3817485570907593, train/logprobs = tensor([[-3.8170, -5.8881],
        [-6.2051, -4.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6398290991783142
Epoch 0, Step 1832: train/loss = 0.6934621334075928, train/raw-loss = 0.5522853136062622, train/logprobs = tensor([[-4.2729, -5.6904],
        [-6.4672, -4.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3529419004917145
Epoch 0, Step 1833: train/loss = 0.6565746665000916, train/raw-loss = 0.3498132824897766, train/logprobs = tensor([[-3.0788, -5.2871],
        [-6.8739, -3.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7669035196304321
Epoch 0, Step 1834: train/loss = 0.6017123460769653, train/raw-loss = 0.2693454325199127, train/logprobs = tensor([[-5.0532, -7.9155],
        [-6.2790, -2.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8309172987937927
Epoch 0, Step 1835: train/loss = 0.6111760139465332, train/raw-loss = 0.3360403776168823, train/logprobs = tensor([[-4.0806, -6.9392],
        [-6.1230, -3.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6878390908241272
Epoch 0, Step 1836: train/loss = 0.6910995244979858, train/raw-loss = 0.5191340446472168, train/logprobs = tensor([[-4.8058, -6.6488],
        [-4.8209, -3.4023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42991387844085693
Epoch 0, Step 1837: train/loss = 0.5890192985534668, train/raw-loss = 0.25038373470306396, train/logprobs = tensor([[-4.3722, -7.3544],
        [-6.5951, -3.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8465889692306519
Epoch 0, Step 1838: train/loss = 0.6720921993255615, train/raw-loss = 0.48646795749664307, train/logprobs = tensor([[-4.9597, -5.7945],
        [-4.6236, -3.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640606641769409
Epoch 0, Step 1839: train/loss = 0.6645106077194214, train/raw-loss = 0.5287521481513977, train/logprobs = tensor([[-5.6792, -6.6466],
        [-3.9279, -2.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3393961787223816
Epoch 0, Step 1840: train/loss = 0.5876380801200867, train/raw-loss = 0.22205998003482819, train/logprobs = tensor([[-4.1728, -6.8366],
        [-7.8755, -3.3533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.913945198059082
Epoch 0, Step 1841: train/loss = 0.6997791528701782, train/raw-loss = 0.6658124923706055, train/logprobs = tensor([[-6.7925, -7.0406],
        [-3.8758, -3.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08491657674312592
Epoch 0, Step 1842: train/loss = 0.642679750919342, train/raw-loss = 0.3888930678367615, train/logprobs = tensor([[-4.3757, -7.4856],
        [-5.6766, -3.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6344666481018066
Epoch 0, Step 1843: train/loss = 0.6058883666992188, train/raw-loss = 0.34076642990112305, train/logprobs = tensor([[-5.5039, -8.3055],
        [-5.1655, -2.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6628047823905945
Epoch 0, Step 1844: train/loss = 0.6167764663696289, train/raw-loss = 0.42455893754959106, train/logprobs = tensor([[-5.4434, -7.1233],
        [-5.0630, -2.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.480543851852417
Epoch 0, Step 1845: train/loss = 0.6149652600288391, train/raw-loss = 0.33297020196914673, train/logprobs = tensor([[-5.1834, -7.3096],
        [-6.5675, -4.3207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7049877047538757
Epoch 0, Step 1846: train/loss = 0.7184865474700928, train/raw-loss = 0.6568813920021057, train/logprobs = tensor([[-7.3463, -7.3256],
        [-4.8669, -3.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15401293337345123
Epoch 0, Step 1847: train/loss = 0.5965454578399658, train/raw-loss = 0.24523106217384338, train/logprobs = tensor([[-5.1465, -7.7746],
        [-5.6496, -2.1069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8782861232757568
Epoch 0, Step 1848: train/loss = 0.6324077248573303, train/raw-loss = 0.3422854542732239, train/logprobs = tensor([[-3.0353, -4.5092],
        [-7.5400, -3.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7253057956695557
Epoch 0, Step 1849: train/loss = 0.6079970002174377, train/raw-loss = 0.3587533235549927, train/logprobs = tensor([[-2.9503, -4.8998],
        [-7.0624, -4.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6231092214584351
Epoch 0, Step 1850: train/loss = 0.6384937763214111, train/raw-loss = 0.4263952374458313, train/logprobs = tensor([[-4.4298, -7.8145],
        [-5.6121, -3.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5302464365959167
Epoch 0, Step 1851: train/loss = 0.6105138063430786, train/raw-loss = 0.34161195158958435, train/logprobs = tensor([[-4.1605, -7.0449],
        [-6.4523, -3.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6722546815872192
Epoch 0, Step 1852: train/loss = 0.655473530292511, train/raw-loss = 0.4646500051021576, train/logprobs = tensor([[-3.8221, -5.4574],
        [-6.4371, -5.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4770587384700775
Epoch 0, Step 1853: train/loss = 0.5499411225318909, train/raw-loss = 0.19498206675052643, train/logprobs = tensor([[-2.8218, -7.2201],
        [-8.0770, -3.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8873976469039917
Epoch 0, Step 1854: train/loss = 0.5800163745880127, train/raw-loss = 0.24015912413597107, train/logprobs = tensor([[-4.0769, -7.3495],
        [-5.7733, -2.4619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8496431112289429
Epoch 0, Step 1855: train/loss = 0.62628173828125, train/raw-loss = 0.38306573033332825, train/logprobs = tensor([[-5.9000, -8.1080],
        [-5.6905, -2.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6080400943756104
Epoch 0, Step 1856: train/loss = 0.6227667927742004, train/raw-loss = 0.3636707663536072, train/logprobs = tensor([[-4.4430, -7.0693],
        [-6.0962, -3.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6477401256561279
Epoch 0, Step 1857: train/loss = 0.6134548187255859, train/raw-loss = 0.3575863838195801, train/logprobs = tensor([[-5.4805, -7.4436],
        [-6.2582, -3.5479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6396712064743042
Epoch 0, Step 1858: train/loss = 0.6661328077316284, train/raw-loss = 0.4641232490539551, train/logprobs = tensor([[-5.5322, -7.2625],
        [-5.7064, -3.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5050238966941833
Epoch 0, Step 1859: train/loss = 0.6479105949401855, train/raw-loss = 0.38843899965286255, train/logprobs = tensor([[-7.0878, -6.8949],
        [-4.6740, -4.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6486789584159851
Epoch 0, Step 1860: train/loss = 0.6047195792198181, train/raw-loss = 0.4186267852783203, train/logprobs = tensor([[-6.8842, -8.8689],
        [-4.3994, -2.7567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4652319550514221
Epoch 0, Step 1861: train/loss = 0.7990005016326904, train/raw-loss = 0.7409932017326355, train/logprobs = tensor([[-5.9105, -6.6198],
        [-4.6195, -4.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14501821994781494
Epoch 0, Step 1862: train/loss = 0.6800588369369507, train/raw-loss = 0.49383771419525146, train/logprobs = tensor([[-7.1574, -7.7567],
        [-4.1125, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4655528962612152
Epoch 0, Step 1863: train/loss = 0.6085504293441772, train/raw-loss = 0.2730894684791565, train/logprobs = tensor([[-3.1504, -7.0465],
        [-6.9587, -4.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8386524319648743
Epoch 0, Step 1864: train/loss = 0.590296745300293, train/raw-loss = 0.1896325945854187, train/logprobs = tensor([[-2.4009, -7.1802],
        [-7.7847, -3.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0016603469848633
Epoch 0, Step 1865: train/loss = 0.7005738019943237, train/raw-loss = 0.47479715943336487, train/logprobs = tensor([[-5.0048, -7.0527],
        [-6.9951, -4.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5644415616989136
Epoch 0, Step 1866: train/loss = 0.6539061665534973, train/raw-loss = 0.41488727927207947, train/logprobs = tensor([[-2.9713, -6.0627],
        [-7.3770, -5.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5975471138954163
Epoch 0, Step 1867: train/loss = 0.6784241199493408, train/raw-loss = 0.38866403698921204, train/logprobs = tensor([[-5.0038, -7.2633],
        [-6.7265, -3.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7244002223014832
Epoch 0, Step 1868: train/loss = 0.6172792911529541, train/raw-loss = 0.23482421040534973, train/logprobs = tensor([[-5.3342, -8.9809],
        [-5.5912, -2.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9561377763748169
Epoch 0, Step 1869: train/loss = 0.6600441932678223, train/raw-loss = 0.46390241384506226, train/logprobs = tensor([[-4.1252, -6.0446],
        [-6.6488, -6.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4903542995452881
Epoch 0, Step 1870: train/loss = 0.5862529277801514, train/raw-loss = 0.276385635137558, train/logprobs = tensor([[-4.7984, -7.1598],
        [-6.0457, -4.3713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7746681571006775
Epoch 0, Step 1871: train/loss = 0.631423830986023, train/raw-loss = 0.3745935559272766, train/logprobs = tensor([[-4.9593, -6.7100],
        [-5.5179, -4.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.642075777053833
Epoch 0, Step 1872: train/loss = 0.6841626167297363, train/raw-loss = 0.49918806552886963, train/logprobs = tensor([[-4.1119, -5.4733],
        [-6.6771, -5.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46243634819984436
Epoch 0, Step 1873: train/loss = 0.6456173658370972, train/raw-loss = 0.36582741141319275, train/logprobs = tensor([[-5.9638, -7.8733],
        [-6.4847, -3.4205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6994749307632446
Epoch 0, Step 1874: train/loss = 0.5971177816390991, train/raw-loss = 0.24830827116966248, train/logprobs = tensor([[-5.6719, -8.9930],
        [-5.5806, -1.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8720237612724304
Epoch 0, Step 1875: train/loss = 0.6649972200393677, train/raw-loss = 0.46804988384246826, train/logprobs = tensor([[-6.8534, -8.6159],
        [-4.8464, -1.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49236834049224854
Epoch 0, Step 1876: train/loss = 0.6368635892868042, train/raw-loss = 0.43636369705200195, train/logprobs = tensor([[-6.9965, -8.7828],
        [-4.8595, -2.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5012497901916504
Epoch 0, Step 1877: train/loss = 0.6056294441223145, train/raw-loss = 0.24025794863700867, train/logprobs = tensor([[-5.0844, -8.6544],
        [-6.2991, -2.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.913428544998169
Epoch 0, Step 1878: train/loss = 0.6514765024185181, train/raw-loss = 0.5220882296562195, train/logprobs = tensor([[-7.6593, -9.7920],
        [-4.7075, -3.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32347068190574646
Epoch 0, Step 1879: train/loss = 0.5898938179016113, train/raw-loss = 0.25223419070243835, train/logprobs = tensor([[-5.7679, -8.9518],
        [-6.9191, -2.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8441490530967712
Epoch 0, Step 1880: train/loss = 0.6419695019721985, train/raw-loss = 0.5305226445198059, train/logprobs = tensor([[-6.6160, -7.9142],
        [-4.6442, -3.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2786172330379486
Epoch 0, Step 1881: train/loss = 0.6277388334274292, train/raw-loss = 0.43737903237342834, train/logprobs = tensor([[-7.2157, -8.9379],
        [-5.5253, -3.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47589948773384094
Epoch 0, Step 1882: train/loss = 0.6492809653282166, train/raw-loss = 0.5263938903808594, train/logprobs = tensor([[-5.1327, -6.7407],
        [-5.3183, -3.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30721771717071533
Epoch 0, Step 1883: train/loss = 0.5841282606124878, train/raw-loss = 0.23006421327590942, train/logprobs = tensor([[-5.9502, -9.2260],
        [-6.2746, -2.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8851601481437683
Epoch 0, Step 1884: train/loss = 0.6628331542015076, train/raw-loss = 0.5341180562973022, train/logprobs = tensor([[-6.1996, -8.0373],
        [-5.3350, -3.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217877447605133
Epoch 0, Step 1885: train/loss = 0.5497791767120361, train/raw-loss = 0.05819855257868767, train/logprobs = tensor([[-3.8733, -9.9302],
        [-6.8715, -2.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2289516925811768
Epoch 0, Step 1886: train/loss = 0.5482869148254395, train/raw-loss = 0.10757584124803543, train/logprobs = tensor([[-3.5662, -8.1148],
        [-7.0488, -2.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1017776727676392
Epoch 0, Step 1887: train/loss = 0.6941691040992737, train/raw-loss = 0.4640905261039734, train/logprobs = tensor([[-6.4138, -9.2092],
        [-4.6816, -2.3901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.575196385383606
Epoch 0, Step 1888: train/loss = 0.6355420351028442, train/raw-loss = 0.34647005796432495, train/logprobs = tensor([[-6.0086, -8.6940],
        [-6.2940, -2.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7226797938346863
Epoch 0, Step 1889: train/loss = 0.6180951595306396, train/raw-loss = 0.32872939109802246, train/logprobs = tensor([[-6.8607, -9.4291],
        [-5.8598, -4.4108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7234143018722534
Epoch 0, Step 1890: train/loss = 0.6636736392974854, train/raw-loss = 0.4967026710510254, train/logprobs = tensor([[-6.6464, -7.5825],
        [-5.7071, -3.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4174273610115051
Epoch 0, Step 1891: train/loss = 0.6396013498306274, train/raw-loss = 0.4306842088699341, train/logprobs = tensor([[-6.9248, -9.2282],
        [-4.8583, -3.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5222928524017334
Epoch 0, Step 1892: train/loss = 0.568722665309906, train/raw-loss = 0.14000123739242554, train/logprobs = tensor([[-4.7081, -9.2561],
        [-7.1256, -2.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0718035697937012
Epoch 0, Step 1893: train/loss = 0.6683754324913025, train/raw-loss = 0.5609558820724487, train/logprobs = tensor([[-5.9596, -6.9252],
        [-5.8782, -5.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2685488164424896
Epoch 0, Step 1894: train/loss = 0.7496871948242188, train/raw-loss = 0.6458470225334167, train/logprobs = tensor([[-7.8991, -6.5455],
        [-4.3821, -4.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596004009246826
Epoch 0, Step 1895: train/loss = 0.6511136293411255, train/raw-loss = 0.508155882358551, train/logprobs = tensor([[-6.5094, -8.1299],
        [-5.9959, -4.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35739439725875854
Epoch 0, Step 1896: train/loss = 0.8033444881439209, train/raw-loss = 0.5710629224777222, train/logprobs = tensor([[-5.1220, -8.1040],
        [-5.7413, -3.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5807039737701416
Epoch 0, Step 1897: train/loss = 0.6701966524124146, train/raw-loss = 0.4566557705402374, train/logprobs = tensor([[-5.3092, -6.4884],
        [-6.5373, -4.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.533852219581604
Epoch 0, Step 1898: train/loss = 0.6663089990615845, train/raw-loss = 0.5395848155021667, train/logprobs = tensor([[-7.4469, -8.2530],
        [-4.6023, -3.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3168104887008667
Epoch 0, Step 1899: train/loss = 0.5863714218139648, train/raw-loss = 0.2759927809238434, train/logprobs = tensor([[-5.9177, -9.8735],
        [-5.3717, -2.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7759466767311096
Epoch 0, Step 1900: train/loss = 0.5788120627403259, train/raw-loss = 0.18423323333263397, train/logprobs = tensor([[-3.5282, -8.8792],
        [-7.4893, -2.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9864470958709717
Epoch 0, Step 1901: train/loss = 0.7355281114578247, train/raw-loss = 0.7296133637428284, train/logprobs = tensor([[-5.4976, -5.2750],
        [-6.7372, -6.3405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01478694286197424
Epoch 0, Step 1902: train/loss = 0.645578145980835, train/raw-loss = 0.3623434007167816, train/logprobs = tensor([[-7.2456, -7.1052],
        [-4.3963, -4.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7080868482589722
Epoch 0, Step 1903: train/loss = 0.5944976806640625, train/raw-loss = 0.1898864209651947, train/logprobs = tensor([[-5.8613, -9.6122],
        [-6.7466, -1.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0115282535552979
Epoch 0, Step 1904: train/loss = 0.5560891032218933, train/raw-loss = 0.11865009367465973, train/logprobs = tensor([[ -6.7071, -13.4117],
        [ -6.6116,  -2.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.093597650527954
Epoch 0, Step 1905: train/loss = 0.5802479982376099, train/raw-loss = 0.18900159001350403, train/logprobs = tensor([[ -5.3225, -11.3955],
        [ -7.2937,  -3.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9781160354614258
Epoch 0, Step 1906: train/loss = 0.6417849063873291, train/raw-loss = 0.35182300209999084, train/logprobs = tensor([[-5.8097, -9.1436],
        [-6.5282, -4.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7249047160148621
Epoch 0, Step 1907: train/loss = 0.6741862297058105, train/raw-loss = 0.5336707830429077, train/logprobs = tensor([[-8.5668, -7.8261],
        [-4.8812, -5.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35128864645957947
Epoch 0, Step 1908: train/loss = 0.6866168975830078, train/raw-loss = 0.3795079290866852, train/logprobs = tensor([[-4.6272, -8.3847],
        [-9.1153, -5.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7677723169326782
Epoch 0, Step 1909: train/loss = 0.6112664937973022, train/raw-loss = 0.36773520708084106, train/logprobs = tensor([[ -9.4983, -12.3824],
        [ -4.6606,  -2.4544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6088281869888306
Epoch 0, Step 1910: train/loss = 0.7302485704421997, train/raw-loss = 0.5325307846069336, train/logprobs = tensor([[-5.2971, -6.9552],
        [-6.9039, -4.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49429449439048767
Epoch 0, Step 1911: train/loss = 0.6589383482933044, train/raw-loss = 0.4532666802406311, train/logprobs = tensor([[ -7.9642, -10.0491],
        [ -4.9036,  -3.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141791105270386
Epoch 0, Step 1912: train/loss = 0.6541231274604797, train/raw-loss = 0.505645215511322, train/logprobs = tensor([[ -7.7708, -10.1473],
        [ -5.1494,  -3.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37119483947753906
Epoch 0, Step 1913: train/loss = 0.6235864758491516, train/raw-loss = 0.36869174242019653, train/logprobs = tensor([[ -7.3448, -10.3480],
        [ -4.7490,  -2.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6372367739677429
Epoch 0, Step 1914: train/loss = 0.6808080673217773, train/raw-loss = 0.5294727087020874, train/logprobs = tensor([[-7.0099, -9.2103],
        [-6.1368, -5.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37833839654922485
Epoch 0, Step 1915: train/loss = 0.6151884198188782, train/raw-loss = 0.32236331701278687, train/logprobs = tensor([[ -7.5761, -12.1066],
        [ -5.9661,  -3.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7320627570152283
Epoch 0, Step 1916: train/loss = 0.5852632522583008, train/raw-loss = 0.2048705518245697, train/logprobs = tensor([[ -6.6572, -11.0858],
        [ -5.6563,  -2.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.950981616973877
Epoch 0, Step 1917: train/loss = 0.5696197152137756, train/raw-loss = 0.1752796620130539, train/logprobs = tensor([[ -6.5209, -11.7740],
        [ -7.1175,  -2.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9858500957489014
Epoch 0, Step 1918: train/loss = 0.6167376041412354, train/raw-loss = 0.39902088046073914, train/logprobs = tensor([[-7.8611, -9.9826],
        [-5.0569, -2.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5442917943000793
Epoch 0, Step 1919: train/loss = 0.917855978012085, train/raw-loss = 0.6562823057174683, train/logprobs = tensor([[ -8.7708, -12.5572],
        [ -3.8864,  -4.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6539340019226074
Epoch 0, Step 1920: train/loss = 0.5895851254463196, train/raw-loss = 0.29009121656417847, train/logprobs = tensor([[ -8.2025, -11.8510],
        [ -6.0189,  -3.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7487347722053528
Epoch 0, Step 1921: train/loss = 0.7117816209793091, train/raw-loss = 0.7101646661758423, train/logprobs = tensor([[-7.7457, -8.0285],
        [-5.7037, -5.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004042533226311207
Epoch 0, Step 1922: train/loss = 0.5874000787734985, train/raw-loss = 0.358815461397171, train/logprobs = tensor([[ -8.5261, -12.2815],
        [ -6.2915,  -2.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.57146155834198
Epoch 0, Step 1923: train/loss = 0.6284938454627991, train/raw-loss = 0.24468012154102325, train/logprobs = tensor([[ -6.3220, -10.5422],
        [ -8.4853,  -5.0598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9595342874526978
Epoch 0, Step 1924: train/loss = 0.6933238506317139, train/raw-loss = 0.5778436064720154, train/logprobs = tensor([[-12.0044, -13.3833],
        [ -2.9988,  -2.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28870058059692383
Epoch 0, Step 1925: train/loss = 0.6085440516471863, train/raw-loss = 0.2734847664833069, train/logprobs = tensor([[-5.1337, -7.8705],
        [-7.2807, -4.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8376481533050537
Epoch 0, Step 1926: train/loss = 0.605027437210083, train/raw-loss = 0.24548974633216858, train/logprobs = tensor([[-5.1367, -9.3215],
        [-7.9402, -4.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8988441824913025
Epoch 0, Step 1927: train/loss = 0.6307412981987, train/raw-loss = 0.35779932141304016, train/logprobs = tensor([[ -9.6935, -12.0438],
        [ -3.9433,  -1.5780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6823549270629883
Epoch 0, Step 1928: train/loss = 0.5677810907363892, train/raw-loss = 0.1277693808078766, train/logprobs = tensor([[ -5.8734, -10.8729],
        [ -7.1826,  -3.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1000292301177979
Epoch 0, Step 1929: train/loss = 0.6842471361160278, train/raw-loss = 0.5666146278381348, train/logprobs = tensor([[-10.9768, -11.7775],
        [ -4.6766,  -4.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2940811812877655
Epoch 0, Step 1930: train/loss = 0.6280817985534668, train/raw-loss = 0.3934389650821686, train/logprobs = tensor([[ -8.4036, -10.3192],
        [ -5.9998,  -3.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5866069793701172
Epoch 0, Step 1931: train/loss = 0.6734492778778076, train/raw-loss = 0.31589025259017944, train/logprobs = tensor([[ -7.0268, -12.5624],
        [ -6.7205,  -3.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8938975930213928
Epoch 0, Step 1932: train/loss = 0.6488486528396606, train/raw-loss = 0.4846440255641937, train/logprobs = tensor([[ -8.8895, -10.5858],
        [ -5.2793,  -4.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105115830898285
Epoch 0, Step 1933: train/loss = 0.6588466167449951, train/raw-loss = 0.3314267694950104, train/logprobs = tensor([[ -6.5373, -12.0088],
        [ -6.9441,  -2.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8185495734214783
Epoch 0, Step 1934: train/loss = 0.6594952344894409, train/raw-loss = 0.5172727108001709, train/logprobs = tensor([[ -9.2939, -11.3529],
        [ -5.6875,  -4.3484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555564284324646
Epoch 0, Step 1935: train/loss = 0.6516208648681641, train/raw-loss = 0.49100106954574585, train/logprobs = tensor([[-8.5357, -9.6669],
        [-4.8943, -3.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4015495181083679
Epoch 0, Step 1936: train/loss = 0.5932667255401611, train/raw-loss = 0.31230127811431885, train/logprobs = tensor([[ -8.6617, -12.7186],
        [ -5.9641,  -3.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7024135589599609
Epoch 0, Step 1937: train/loss = 0.5957863330841064, train/raw-loss = 0.35531753301620483, train/logprobs = tensor([[ -9.8061, -13.6432],
        [ -5.2742,  -1.4943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6011719703674316
Epoch 0, Step 1938: train/loss = 0.6227580904960632, train/raw-loss = 0.3672378957271576, train/logprobs = tensor([[ -7.8392, -10.1007],
        [ -8.3911,  -5.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6388005018234253
Epoch 0, Step 1939: train/loss = 0.6412879228591919, train/raw-loss = 0.39819803833961487, train/logprobs = tensor([[ -8.6781, -10.7748],
        [ -5.6686,  -3.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.607724666595459
Epoch 0, Step 1940: train/loss = 0.6283894777297974, train/raw-loss = 0.46064767241477966, train/logprobs = tensor([[ -9.5932, -12.2065],
        [ -6.2275,  -3.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41935446858406067
Epoch 0, Step 1941: train/loss = 0.593337893486023, train/raw-loss = 0.2271522730588913, train/logprobs = tensor([[ -8.4293, -13.1076],
        [ -6.5157,  -3.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.915463924407959
Epoch 0, Step 1942: train/loss = 0.5472064018249512, train/raw-loss = 0.07991796731948853, train/logprobs = tensor([[ -6.2836, -13.2709],
        [ -7.4359,  -2.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.168221116065979
Epoch 0, Step 1943: train/loss = 0.6594018936157227, train/raw-loss = 0.5273002982139587, train/logprobs = tensor([[ -9.7565, -10.9933],
        [ -6.2110,  -4.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33025404810905457
Epoch 0, Step 1944: train/loss = 0.5453557968139648, train/raw-loss = 0.01152230054140091, train/logprobs = tensor([[ -4.3388, -12.1875],
        [ -9.6888,  -3.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3345837593078613
Epoch 0, Step 1945: train/loss = 0.6116340756416321, train/raw-loss = 0.37353384494781494, train/logprobs = tensor([[ -8.2031, -11.4001],
        [ -6.3678,  -4.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5952506065368652
Epoch 0, Step 1946: train/loss = 0.5971443057060242, train/raw-loss = 0.35327276587486267, train/logprobs = tensor([[ -7.1243, -10.9394],
        [ -6.4639,  -3.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6096788644790649
Epoch 0, Step 1947: train/loss = 0.5819140672683716, train/raw-loss = 0.23329155147075653, train/logprobs = tensor([[ -8.2189, -13.8374],
        [ -7.1289,  -3.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8715564012527466
Epoch 0, Step 1948: train/loss = 0.5774108171463013, train/raw-loss = 0.2062540352344513, train/logprobs = tensor([[ -7.7275, -11.7741],
        [ -7.1876,  -3.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9278919100761414
Epoch 0, Step 1949: train/loss = 0.5840576887130737, train/raw-loss = 0.20188549160957336, train/logprobs = tensor([[ -5.9441, -11.4679],
        [ -7.2009,  -3.4412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9554303884506226
Epoch 0, Step 1950: train/loss = 0.5341565012931824, train/raw-loss = 0.06879293918609619, train/logprobs = tensor([[ -5.3394, -10.9323],
        [ -7.7698,  -3.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1634089946746826
Epoch 0, Step 1951: train/loss = 0.5532823801040649, train/raw-loss = 0.1917750984430313, train/logprobs = tensor([[ -7.8190, -13.9164],
        [ -6.6946,  -2.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9037681221961975
Epoch 0, Step 1952: train/loss = 0.6995084285736084, train/raw-loss = 0.46098026633262634, train/logprobs = tensor([[-6.1757, -9.3089],
        [-6.9864, -5.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5963202714920044
Epoch 0, Step 1953: train/loss = 0.5786226987838745, train/raw-loss = 0.20973728597164154, train/logprobs = tensor([[ -6.8270, -10.8839],
        [ -8.1689,  -3.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9222135543823242
Epoch 0, Step 1954: train/loss = 0.638565182685852, train/raw-loss = 0.4114835262298584, train/logprobs = tensor([[ -8.6966, -10.3710],
        [ -5.0842,  -3.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5677040219306946
Epoch 0, Step 1955: train/loss = 0.5882954597473145, train/raw-loss = 0.3268364667892456, train/logprobs = tensor([[ -9.8263, -13.6552],
        [ -5.9547,  -3.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6536474823951721
Epoch 0, Step 1956: train/loss = 0.6031597852706909, train/raw-loss = 0.3546023964881897, train/logprobs = tensor([[ -7.4537, -11.4165],
        [ -7.7968,  -4.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6213935613632202
Epoch 0, Step 1957: train/loss = 0.6783721446990967, train/raw-loss = 0.5378590822219849, train/logprobs = tensor([[ -9.9306, -11.3918],
        [ -4.9856,  -4.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35128268599510193
Epoch 0, Step 1958: train/loss = 0.6363855004310608, train/raw-loss = 0.4242485463619232, train/logprobs = tensor([[ -7.6787, -11.8694],
        [ -5.2559,  -4.2144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5303424596786499
Epoch 0, Step 1959: train/loss = 0.6101978421211243, train/raw-loss = 0.3501456379890442, train/logprobs = tensor([[ -7.8468, -10.2898],
        [ -7.5603,  -4.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6501303911209106
Epoch 0, Step 1960: train/loss = 0.5889428853988647, train/raw-loss = 0.2409212589263916, train/logprobs = tensor([[ -7.4615, -12.6288],
        [ -6.5810,  -2.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8700540661811829
Epoch 0, Step 1961: train/loss = 0.5809329748153687, train/raw-loss = 0.18368744850158691, train/logprobs = tensor([[ -8.5751, -13.9422],
        [ -6.4843,  -1.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9931138157844543
Epoch 0, Step 1962: train/loss = 0.7768456935882568, train/raw-loss = 0.43087419867515564, train/logprobs = tensor([[ -8.6939, -12.0046],
        [ -6.2967,  -2.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8649288415908813
Epoch 0, Step 1963: train/loss = 0.7088195085525513, train/raw-loss = 0.47668522596359253, train/logprobs = tensor([[-8.7205, -9.7778],
        [-7.3475, -4.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5803356170654297
Epoch 0, Step 1964: train/loss = 0.7258279919624329, train/raw-loss = 0.7068268060684204, train/logprobs = tensor([[-9.6622, -9.3604],
        [-4.6360, -4.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0475030392408371
Epoch 0, Step 1965: train/loss = 0.673287034034729, train/raw-loss = 0.576996922492981, train/logprobs = tensor([[-10.7042, -11.6793],
        [ -3.7824,  -3.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24072524905204773
Epoch 0, Step 1966: train/loss = 0.5918179750442505, train/raw-loss = 0.24234649538993835, train/logprobs = tensor([[ -8.0329, -12.7803],
        [ -7.0817,  -3.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8736788630485535
Epoch 0, Step 1967: train/loss = 0.589984655380249, train/raw-loss = 0.2581082880496979, train/logprobs = tensor([[ -6.8379, -10.6462],
        [ -7.8632,  -4.8235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8296908140182495
Epoch 0, Step 1968: train/loss = 0.6362830996513367, train/raw-loss = 0.3702937662601471, train/logprobs = tensor([[ -7.4402, -12.1724],
        [ -6.8574,  -3.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6649733781814575
Epoch 0, Step 1969: train/loss = 0.5626131296157837, train/raw-loss = 0.1920301616191864, train/logprobs = tensor([[ -8.2865, -15.5934],
        [ -6.5903,  -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9264573454856873
Epoch 0, Step 1970: train/loss = 0.6339586973190308, train/raw-loss = 0.40810146927833557, train/logprobs = tensor([[ -7.5026, -10.3587],
        [ -6.5318,  -4.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5646430253982544
Epoch 0, Step 1971: train/loss = 0.5600833892822266, train/raw-loss = 0.20198117196559906, train/logprobs = tensor([[ -6.9433, -12.5230],
        [ -7.4056,  -2.2765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.895255446434021
Epoch 0, Step 1972: train/loss = 0.6283425092697144, train/raw-loss = 0.3873559236526489, train/logprobs = tensor([[ -8.6729, -11.3302],
        [ -6.3871,  -4.4118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6024665236473083
Epoch 0, Step 1973: train/loss = 0.6371159553527832, train/raw-loss = 0.32589221000671387, train/logprobs = tensor([[ -8.1403, -10.7272],
        [ -6.9595,  -3.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7780594825744629
Epoch 0, Step 1974: train/loss = 0.606439471244812, train/raw-loss = 0.2547663450241089, train/logprobs = tensor([[ -8.6288, -11.1875],
        [ -6.0466,  -2.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8791828155517578
Epoch 0, Step 1975: train/loss = 0.6234527826309204, train/raw-loss = 0.3174683749675751, train/logprobs = tensor([[ -8.6910, -11.6405],
        [ -6.6960,  -4.6602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7649610638618469
Epoch 0, Step 1976: train/loss = 0.6476097702980042, train/raw-loss = 0.4155631363391876, train/logprobs = tensor([[ -8.2680, -10.4366],
        [ -7.4604,  -5.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5801165699958801
Epoch 0, Step 1977: train/loss = 0.7049134373664856, train/raw-loss = 0.6863675713539124, train/logprobs = tensor([[-11.5273, -11.3328],
        [ -3.7962,  -4.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046364523470401764
Epoch 0, Step 1978: train/loss = 0.6154346466064453, train/raw-loss = 0.3645286560058594, train/logprobs = tensor([[-7.1229, -8.7729],
        [-7.4525, -5.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6272649765014648
Epoch 0, Step 1979: train/loss = 0.5646113753318787, train/raw-loss = 0.0988847091794014, train/logprobs = tensor([[ -6.7622, -11.0873],
        [ -7.6048,  -3.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1643166542053223
Epoch 0, Step 1980: train/loss = 0.6929499506950378, train/raw-loss = 0.5910507440567017, train/logprobs = tensor([[-7.7244, -8.2017],
        [-6.2960, -6.7205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547481060028076
Epoch 0, Step 1981: train/loss = 0.7322657108306885, train/raw-loss = 0.6049240827560425, train/logprobs = tensor([[ -9.3340, -10.2343],
        [ -5.4165,  -3.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3183539807796478
Epoch 0, Step 1982: train/loss = 0.5758424997329712, train/raw-loss = 0.2146422415971756, train/logprobs = tensor([[ -6.5138, -11.0737],
        [ -7.8976,  -3.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9030007123947144
Epoch 0, Step 1983: train/loss = 0.645955502986908, train/raw-loss = 0.3637462854385376, train/logprobs = tensor([[-5.7714, -8.8487],
        [-8.5709, -5.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7055229544639587
Epoch 0, Step 1984: train/loss = 0.581282377243042, train/raw-loss = 0.1627558171749115, train/logprobs = tensor([[ -6.7980, -10.7188],
        [ -7.0769,  -3.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.046316385269165
Epoch 0, Step 1985: train/loss = 0.6604183912277222, train/raw-loss = 0.42746174335479736, train/logprobs = tensor([[ -8.3691, -10.9304],
        [ -5.4698,  -4.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5823916792869568
Epoch 0, Step 1986: train/loss = 0.7647852897644043, train/raw-loss = 0.4892682135105133, train/logprobs = tensor([[-10.3175, -13.1447],
        [ -6.5122,  -2.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6887925863265991
Epoch 0, Step 1987: train/loss = 0.6068046689033508, train/raw-loss = 0.2684028744697571, train/logprobs = tensor([[-10.2962, -12.6348],
        [ -5.3910,  -2.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8460046052932739
Epoch 0, Step 1988: train/loss = 0.6908358931541443, train/raw-loss = 0.5096905827522278, train/logprobs = tensor([[-6.5025, -8.5858],
        [-7.6328, -6.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45286333560943604
Epoch 0, Step 1989: train/loss = 0.6372691988945007, train/raw-loss = 0.3987402319908142, train/logprobs = tensor([[ -8.1834, -10.4331],
        [ -7.2622,  -5.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5963223576545715
Epoch 0, Step 1990: train/loss = 0.6713858842849731, train/raw-loss = 0.40507200360298157, train/logprobs = tensor([[ -9.0296, -12.2220],
        [ -5.9649,  -2.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6657846570014954
Epoch 0, Step 1991: train/loss = 0.6031873822212219, train/raw-loss = 0.2826283276081085, train/logprobs = tensor([[ -9.3040, -12.8501],
        [ -4.9442,  -2.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8013975024223328
Epoch 0, Step 1992: train/loss = 0.6634331941604614, train/raw-loss = 0.5337734818458557, train/logprobs = tensor([[-10.9847, -11.9566],
        [ -2.7941,  -1.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32414937019348145
Epoch 0, Step 1993: train/loss = 0.56841641664505, train/raw-loss = 0.1828695833683014, train/logprobs = tensor([[ -5.9716, -10.4975],
        [ -8.9064,  -3.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9638671278953552
Epoch 0, Step 1994: train/loss = 0.612218976020813, train/raw-loss = 0.2614668309688568, train/logprobs = tensor([[ -7.8470, -11.5981],
        [ -7.2906,  -2.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8768802881240845
Epoch 0, Step 1995: train/loss = 0.5121123790740967, train/raw-loss = 0.018905412405729294, train/logprobs = tensor([[ -5.5511, -12.8630],
        [ -8.3914,  -2.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2330173254013062
Epoch 0, Step 1996: train/loss = 0.6325744390487671, train/raw-loss = 0.40200406312942505, train/logprobs = tensor([[ -9.7750, -12.1650],
        [ -5.4210,  -3.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5764257907867432
Epoch 0, Step 1997: train/loss = 0.6152528524398804, train/raw-loss = 0.30570101737976074, train/logprobs = tensor([[ -7.8654, -10.7387],
        [ -6.7508,  -4.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7738796472549438
Epoch 0, Step 1998: train/loss = 0.5944722294807434, train/raw-loss = 0.20612779259681702, train/logprobs = tensor([[-5.5594, -9.6397],
        [-7.1175, -3.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9708610773086548
Epoch 0, Step 1999: train/loss = 0.6506204605102539, train/raw-loss = 0.4847150444984436, train/logprobs = tensor([[-10.2080, -12.1906],
        [ -4.8943,  -3.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4147634506225586
eval/loss: 0.6279565691947937
Epoch 0, Step 2000: train/loss = 0.6161249279975891, train/raw-loss = 0.3528849184513092, train/logprobs = tensor([[ -7.2660, -11.7338],
        [ -7.0773,  -4.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6581000089645386
Epoch 0, Step 2001: train/loss = 0.6263033151626587, train/raw-loss = 0.3831188380718231, train/logprobs = tensor([[ -9.9476, -12.2241],
        [ -7.1327,  -4.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6079611778259277
Epoch 0, Step 2002: train/loss = 0.6576944589614868, train/raw-loss = 0.5028465986251831, train/logprobs = tensor([[ -9.9076, -11.3066],
        [ -5.7225,  -4.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871196210384369
Epoch 0, Step 2003: train/loss = 0.5753664374351501, train/raw-loss = 0.21045589447021484, train/logprobs = tensor([[ -9.0380, -13.7821],
        [ -7.8089,  -3.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9122763276100159
Epoch 0, Step 2004: train/loss = 0.5891719460487366, train/raw-loss = 0.12562872469425201, train/logprobs = tensor([[ -9.3746, -13.3748],
        [ -7.1741,  -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1588579416275024
Epoch 0, Step 2005: train/loss = 0.6302376389503479, train/raw-loss = 0.3815126419067383, train/logprobs = tensor([[ -7.1714, -11.8962],
        [ -6.3359,  -4.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6218125224113464
Epoch 0, Step 2006: train/loss = 0.6144434809684753, train/raw-loss = 0.34305107593536377, train/logprobs = tensor([[ -9.1432, -12.5312],
        [ -6.5720,  -3.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6784809827804565
Epoch 0, Step 2007: train/loss = 0.667834997177124, train/raw-loss = 0.4895246624946594, train/logprobs = tensor([[-10.2932, -12.5274],
        [ -4.9454,  -2.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4457757771015167
Epoch 0, Step 2008: train/loss = 0.6067100167274475, train/raw-loss = 0.3544907867908478, train/logprobs = tensor([[-10.1082, -14.4775],
        [ -5.2010,  -3.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6305480003356934
Epoch 0, Step 2009: train/loss = 0.6693248748779297, train/raw-loss = 0.35066673159599304, train/logprobs = tensor([[ -8.6065, -12.6436],
        [ -6.5337,  -3.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7966451644897461
Epoch 0, Step 2010: train/loss = 0.5780686736106873, train/raw-loss = 0.17299970984458923, train/logprobs = tensor([[ -7.3183, -11.8151],
        [ -6.3708,  -3.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0126723051071167
Epoch 0, Step 2011: train/loss = 0.618007242679596, train/raw-loss = 0.3692527711391449, train/logprobs = tensor([[ -9.9474, -15.5467],
        [ -6.0650,  -2.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6218861937522888
Epoch 0, Step 2012: train/loss = 0.7002301216125488, train/raw-loss = 0.5320833921432495, train/logprobs = tensor([[-7.9323, -6.4117],
        [-6.4717, -5.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42036694288253784
Epoch 0, Step 2013: train/loss = 0.5976381897926331, train/raw-loss = 0.3632180988788605, train/logprobs = tensor([[ -8.4382, -12.0606],
        [ -6.9496,  -4.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5860502123832703
Epoch 0, Step 2014: train/loss = 0.6259900331497192, train/raw-loss = 0.3443797826766968, train/logprobs = tensor([[ -9.0790, -12.0558],
        [ -5.1809,  -3.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7040255665779114
Epoch 0, Step 2015: train/loss = 0.5906728506088257, train/raw-loss = 0.08856884390115738, train/logprobs = tensor([[ -4.8548, -13.2774],
        [ -9.2847,  -4.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2552599906921387
Epoch 0, Step 2016: train/loss = 0.6235158443450928, train/raw-loss = 0.3246915936470032, train/logprobs = tensor([[ -8.1588, -10.6203],
        [ -8.7259,  -6.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7470605373382568
Epoch 0, Step 2017: train/loss = 0.6225897669792175, train/raw-loss = 0.35043954849243164, train/logprobs = tensor([[ -8.4207, -11.8888],
        [ -6.6843,  -3.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6803755164146423
Epoch 0, Step 2018: train/loss = 0.5695405006408691, train/raw-loss = 0.18090426921844482, train/logprobs = tensor([[ -6.0866, -13.7815],
        [ -8.5309,  -3.3949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.971590518951416
Epoch 0, Step 2019: train/loss = 0.6096750497817993, train/raw-loss = 0.37298277020454407, train/logprobs = tensor([[-10.7106, -13.7574],
        [ -5.9490,  -3.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5917307734489441
Epoch 0, Step 2020: train/loss = 0.6687641739845276, train/raw-loss = 0.533920407295227, train/logprobs = tensor([[ -8.5694, -10.6975],
        [ -6.7780,  -4.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3371094763278961
Epoch 0, Step 2021: train/loss = 0.6018998622894287, train/raw-loss = 0.22717922925949097, train/logprobs = tensor([[ -8.9599, -13.7361],
        [ -6.5675,  -3.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.936801552772522
Epoch 0, Step 2022: train/loss = 0.9282744526863098, train/raw-loss = 0.7931088209152222, train/logprobs = tensor([[-11.4582, -12.4946],
        [ -4.9888,  -3.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33791396021842957
Epoch 0, Step 2023: train/loss = 0.6570106744766235, train/raw-loss = 0.498848021030426, train/logprobs = tensor([[-10.8503, -13.3953],
        [ -5.8497,  -4.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3954066336154938
Epoch 0, Step 2024: train/loss = 0.5362110733985901, train/raw-loss = 0.054530881345272064, train/logprobs = tensor([[ -7.9432, -15.6644],
        [ -9.3116,  -2.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.204200267791748
Epoch 0, Step 2025: train/loss = 0.7563249468803406, train/raw-loss = 0.5929672718048096, train/logprobs = tensor([[-12.9944, -13.8403],
        [ -4.4671,  -1.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4083941578865051
Epoch 0, Step 2026: train/loss = 0.6151720881462097, train/raw-loss = 0.3311794400215149, train/logprobs = tensor([[ -8.7780, -12.8647],
        [ -7.2874,  -3.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7099815607070923
Epoch 0, Step 2027: train/loss = 0.5689190626144409, train/raw-loss = 0.20071357488632202, train/logprobs = tensor([[-10.0115, -17.0973],
        [ -5.5780,  -1.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9205137491226196
Epoch 0, Step 2028: train/loss = 0.723146915435791, train/raw-loss = 0.5719507932662964, train/logprobs = tensor([[ -8.9975, -11.0357],
        [ -5.9501,  -6.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3779902458190918
Epoch 0, Step 2029: train/loss = 0.5701352953910828, train/raw-loss = 0.04562114179134369, train/logprobs = tensor([[ -6.8386, -16.1284],
        [ -7.9936,  -3.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3112854957580566
Epoch 0, Step 2030: train/loss = 0.6558936834335327, train/raw-loss = 0.46496453881263733, train/logprobs = tensor([[-10.0474, -13.0829],
        [ -4.6584,  -2.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4773227274417877
Epoch 0, Step 2031: train/loss = 0.5809787511825562, train/raw-loss = 0.18623371422290802, train/logprobs = tensor([[ -5.5889, -13.3833],
        [ -8.2964,  -4.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9868625402450562
Epoch 0, Step 2032: train/loss = 0.5474936962127686, train/raw-loss = 0.1405567228794098, train/logprobs = tensor([[ -9.3915, -16.2968],
        [ -6.1955,  -2.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0173423290252686
Epoch 0, Step 2033: train/loss = 0.5354942679405212, train/raw-loss = 0.024624386802315712, train/logprobs = tensor([[ -7.8267, -16.7813],
        [ -8.7899,  -2.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.277174711227417
Epoch 0, Step 2034: train/loss = 0.6596341729164124, train/raw-loss = 0.2728351950645447, train/logprobs = tensor([[ -8.8972, -14.9868],
        [ -4.7559,  -2.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9669973254203796
Epoch 0, Step 2035: train/loss = 0.5327906608581543, train/raw-loss = 0.06228618323802948, train/logprobs = tensor([[ -6.4722, -15.3316],
        [ -8.1778,  -3.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1762611865997314
Epoch 0, Step 2036: train/loss = 0.6122220754623413, train/raw-loss = 0.3713172972202301, train/logprobs = tensor([[ -7.1657, -11.0716],
        [ -8.0413,  -5.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.602262020111084
Epoch 0, Step 2037: train/loss = 0.6646511554718018, train/raw-loss = 0.44138872623443604, train/logprobs = tensor([[ -9.9266, -12.8140],
        [ -6.1634,  -5.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5581561923027039
Epoch 0, Step 2038: train/loss = 0.6292653679847717, train/raw-loss = 0.39549943804740906, train/logprobs = tensor([[-13.5689, -16.0024],
        [ -4.5504,  -2.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5844148397445679
Epoch 0, Step 2039: train/loss = 0.6313045620918274, train/raw-loss = 0.3439367115497589, train/logprobs = tensor([[-10.9653, -15.2049],
        [ -5.6543,  -2.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.71841961145401
Epoch 0, Step 2040: train/loss = 0.6380921602249146, train/raw-loss = 0.3758758008480072, train/logprobs = tensor([[-14.0671, -17.9930],
        [ -3.4720,  -2.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6555410623550415
Epoch 0, Step 2041: train/loss = 0.5799598097801208, train/raw-loss = 0.1115197166800499, train/logprobs = tensor([[ -9.3647, -15.2195],
        [ -7.0751,  -3.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1711002588272095
Epoch 0, Step 2042: train/loss = 0.6047394871711731, train/raw-loss = 0.33063921332359314, train/logprobs = tensor([[-10.8067, -16.2281],
        [ -7.0216,  -2.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6852506399154663
Epoch 0, Step 2043: train/loss = 0.5976002216339111, train/raw-loss = 0.2595861256122589, train/logprobs = tensor([[-13.9045, -17.9160],
        [ -5.3135,  -2.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8450353145599365
Epoch 0, Step 2044: train/loss = 0.5854840874671936, train/raw-loss = 0.165651336312294, train/logprobs = tensor([[-10.9881, -15.7494],
        [ -7.2485,  -4.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.04958176612854
Epoch 0, Step 2045: train/loss = 0.58869469165802, train/raw-loss = 0.2435656487941742, train/logprobs = tensor([[-10.3161, -14.1425],
        [ -6.7479,  -3.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8628225326538086
Epoch 0, Step 2046: train/loss = 0.653601348400116, train/raw-loss = 0.3880983293056488, train/logprobs = tensor([[-10.1015, -14.5759],
        [ -6.2542,  -3.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6637575030326843
Epoch 0, Step 2047: train/loss = 0.6663101315498352, train/raw-loss = 0.44021517038345337, train/logprobs = tensor([[-12.8575, -16.1126],
        [ -3.8466,  -2.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5652374625205994
Epoch 0, Step 2048: train/loss = 0.6750844717025757, train/raw-loss = 0.3884879946708679, train/logprobs = tensor([[ -5.8747, -14.1082],
        [ -8.7036,  -5.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.716491162776947
Epoch 0, Step 2049: train/loss = 0.7647089958190918, train/raw-loss = 0.48580706119537354, train/logprobs = tensor([[-12.2401, -16.7423],
        [ -6.3079,  -2.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.69725501537323
Epoch 0, Step 2050: train/loss = 0.6851606369018555, train/raw-loss = 0.56151282787323, train/logprobs = tensor([[-16.2611, -17.6499],
        [ -4.1984,  -3.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.309119313955307
Epoch 0, Step 2051: train/loss = 0.5803980827331543, train/raw-loss = 0.10565424710512161, train/logprobs = tensor([[-10.8651, -11.2474],
        [ -7.1189,  -6.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1868596076965332
Epoch 0, Step 2052: train/loss = 0.6291434168815613, train/raw-loss = 0.4266652464866638, train/logprobs = tensor([[-10.4917, -14.3217],
        [ -7.5862,  -4.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5061953663825989
Epoch 0, Step 2053: train/loss = 0.6829262971878052, train/raw-loss = 0.5222139358520508, train/logprobs = tensor([[ -9.2793, -14.3045],
        [ -7.4538,  -5.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40178099274635315
Epoch 0, Step 2054: train/loss = 0.6522239446640015, train/raw-loss = 0.19983753561973572, train/logprobs = tensor([[ -3.7470, -13.0711],
        [ -9.3234,  -5.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.130966067314148
Epoch 0, Step 2055: train/loss = 0.6619172096252441, train/raw-loss = 0.5418334007263184, train/logprobs = tensor([[-17.5757, -17.8864],
        [ -2.7911,  -2.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002094328403473
Epoch 0, Step 2056: train/loss = 0.5598875880241394, train/raw-loss = 0.18576297163963318, train/logprobs = tensor([[-12.9634, -18.1243],
        [ -6.8550,  -2.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.935311496257782
Epoch 0, Step 2057: train/loss = 0.6455439329147339, train/raw-loss = 0.37530070543289185, train/logprobs = tensor([[-10.5884, -15.4325],
        [ -7.4536,  -4.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.675608217716217
Epoch 0, Step 2058: train/loss = 0.784648060798645, train/raw-loss = 0.5310249328613281, train/logprobs = tensor([[-15.3418, -18.3029],
        [ -3.9340,  -2.5883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6340578198432922
Epoch 0, Step 2059: train/loss = 0.572712242603302, train/raw-loss = 0.18571947515010834, train/logprobs = tensor([[-10.0800, -18.5299],
        [ -7.4764,  -2.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9674819707870483
Epoch 0, Step 2060: train/loss = 0.6051774024963379, train/raw-loss = 0.22069667279720306, train/logprobs = tensor([[-12.6830, -17.2520],
        [ -6.3010,  -2.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9612017869949341
Epoch 0, Step 2061: train/loss = 0.6422539949417114, train/raw-loss = 0.26755082607269287, train/logprobs = tensor([[-13.1729, -17.9008],
        [ -8.1729,  -2.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9367579221725464
Epoch 0, Step 2062: train/loss = 0.6752450466156006, train/raw-loss = 0.5377190113067627, train/logprobs = tensor([[ -9.4470, -10.5386],
        [ -8.8901,  -8.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438151776790619
Epoch 0, Step 2063: train/loss = 0.6993497014045715, train/raw-loss = 0.5930110812187195, train/logprobs = tensor([[-13.7348, -13.4601],
        [ -5.2440,  -6.4182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26584652066230774
Epoch 0, Step 2064: train/loss = 0.60654616355896, train/raw-loss = 0.23602814972400665, train/logprobs = tensor([[-11.1809, -16.9038],
        [ -8.2577,  -4.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9262950420379639
Epoch 0, Step 2065: train/loss = 0.6483614444732666, train/raw-loss = 0.3732534945011139, train/logprobs = tensor([[-15.6227, -20.2151],
        [ -6.4969,  -1.9842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6877698302268982
Epoch 0, Step 2066: train/loss = 0.5832626819610596, train/raw-loss = 0.18053974211215973, train/logprobs = tensor([[-12.2428, -19.8452],
        [ -7.9727,  -2.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0068073272705078
Epoch 0, Step 2067: train/loss = 0.6014169454574585, train/raw-loss = 0.3602706491947174, train/logprobs = tensor([[-17.8117, -20.8948],
        [ -5.2393,  -1.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6028656363487244
Epoch 0, Step 2068: train/loss = 0.5770794749259949, train/raw-loss = 0.1529611498117447, train/logprobs = tensor([[-13.7326, -21.8169],
        [ -9.0481,  -2.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.060295820236206
Epoch 0, Step 2069: train/loss = 0.6422896981239319, train/raw-loss = 0.34906089305877686, train/logprobs = tensor([[-11.8066, -15.7170],
        [ -7.2622,  -3.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7330719828605652
Epoch 0, Step 2070: train/loss = 0.6420974731445312, train/raw-loss = 0.22068089246749878, train/logprobs = tensor([[-13.7104, -17.1529],
        [ -8.6400,  -4.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0535414218902588
Epoch 0, Step 2071: train/loss = 0.6517813205718994, train/raw-loss = 0.28702855110168457, train/logprobs = tensor([[-16.4980, -20.0505],
        [ -7.7530,  -2.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.911881685256958
Epoch 0, Step 2072: train/loss = 0.8435443639755249, train/raw-loss = 0.641177773475647, train/logprobs = tensor([[-15.9536, -17.2484],
        [ -6.6385,  -3.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5059163570404053
Epoch 0, Step 2073: train/loss = 0.5458634495735168, train/raw-loss = 0.07799872010946274, train/logprobs = tensor([[ -9.7353, -16.9836],
        [ -7.1048,  -2.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1696617603302002
Epoch 0, Step 2074: train/loss = 0.5558429956436157, train/raw-loss = 0.05336457118391991, train/logprobs = tensor([[-14.4947, -20.9962],
        [ -9.3938,  -2.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2561960220336914
Epoch 0, Step 2075: train/loss = 0.5756381750106812, train/raw-loss = 0.2175079733133316, train/logprobs = tensor([[-14.2591, -20.6128],
        [ -7.6436,  -3.4363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8953254222869873
Epoch 0, Step 2076: train/loss = 0.6356337070465088, train/raw-loss = 0.35807809233665466, train/logprobs = tensor([[-18.0443, -18.3822],
        [ -5.3051,  -4.3644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6938890814781189
Epoch 0, Step 2077: train/loss = 0.894452691078186, train/raw-loss = 0.5325688719749451, train/logprobs = tensor([[-16.1608, -19.4762],
        [ -6.9681,  -2.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9047093987464905
