[2024-02-22 10:51:41,880][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints$ cd sft-baseline
[2024-02-22 10:51:41,880][root][INFO] - Max seq length: 2048
[2024-02-22 10:51:41,880][root][INFO] - Devices: 4
[2024-02-22 10:51:41,888][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints$ cd sft-baseline
[2024-02-22 10:51:41,888][root][INFO] - Max seq length: 2048
[2024-02-22 10:51:41,888][root][INFO] - Devices: 4
[2024-02-22 10:51:41,900][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints$ cd sft-baseline
[2024-02-22 10:51:41,900][root][INFO] - Max seq length: 2048
[2024-02-22 10:51:41,900][root][INFO] - Devices: 4
[2024-02-22 10:51:41,900][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints$ cd sft-baseline
[2024-02-22 10:51:41,900][root][INFO] - Max seq length: 2048
[2024-02-22 10:51:41,900][root][INFO] - Devices: 4
[2024-02-22 10:53:25,157][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 86370
})
[2024-02-22 10:53:25,277][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 86370
})
[2024-02-22 10:53:25,326][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 86370
})
[2024-02-22 10:53:26,068][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 86370
})
[2024-02-22 10:53:26,083][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 2.0824, 'learning_rate': 3.3333333333333334e-08, 'epoch': 0.01}
{'loss': 2.0795, 'learning_rate': 6.666666666666667e-08, 'epoch': 0.02}
{'loss': 2.0836, 'learning_rate': 1e-07, 'epoch': 0.02}
{'loss': 2.0009, 'learning_rate': 1.3333333333333334e-07, 'epoch': 0.03}
{'loss': 1.9126, 'learning_rate': 1.6666666666666665e-07, 'epoch': 0.04}
{'loss': 1.7784, 'learning_rate': 2e-07, 'epoch': 0.05}
{'loss': 1.7235, 'learning_rate': 2.3333333333333333e-07, 'epoch': 0.05}
{'loss': 1.7162, 'learning_rate': 2.6666666666666667e-07, 'epoch': 0.06}
{'loss': 1.6723, 'learning_rate': 3e-07, 'epoch': 0.07}
{'loss': 1.6468, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.08}
{'loss': 1.6049, 'learning_rate': 3.666666666666666e-07, 'epoch': 0.09}
{'loss': 1.6532, 'learning_rate': 4e-07, 'epoch': 0.09}
{'loss': 1.6455, 'learning_rate': 4.3333333333333335e-07, 'epoch': 0.1}
{'loss': 1.6289, 'learning_rate': 4.6666666666666666e-07, 'epoch': 0.11}
{'loss': 1.6162, 'learning_rate': 5e-07, 'epoch': 0.12}
{'loss': 1.6437, 'learning_rate': 5.333333333333333e-07, 'epoch': 0.12}
{'loss': 1.6042, 'learning_rate': 5.666666666666666e-07, 'epoch': 0.13}
{'loss': 1.6098, 'learning_rate': 6e-07, 'epoch': 0.14}
{'loss': 1.6158, 'learning_rate': 6.333333333333332e-07, 'epoch': 0.15}
{'loss': 1.6377, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.16}
{'loss': 1.6082, 'learning_rate': 7e-07, 'epoch': 0.16}
{'loss': 1.5932, 'learning_rate': 7.333333333333332e-07, 'epoch': 0.17}
{'loss': 1.6239, 'learning_rate': 7.666666666666667e-07, 'epoch': 0.18}
{'loss': 1.6006, 'learning_rate': 8e-07, 'epoch': 0.19}
{'loss': 1.6246, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.19}
{'loss': 1.6195, 'learning_rate': 8.666666666666667e-07, 'epoch': 0.2}
{'loss': 1.653, 'learning_rate': 9e-07, 'epoch': 0.21}
{'loss': 1.6375, 'learning_rate': 9.333333333333333e-07, 'epoch': 0.22}
{'loss': 1.6178, 'learning_rate': 9.666666666666666e-07, 'epoch': 0.23}
