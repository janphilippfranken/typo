[2024-02-26 17:06:38,498][root][INFO] - beta: 0.5
[2024-02-26 17:06:38,499][root][INFO] - loss with_labels
[2024-02-26 17:06:38,499][root][INFO] - max_iter: 0
[2024-02-26 17:06:38,499][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels
clearing gpu cache for all ranks
Model with 214.180352M params prepared
n helpful: 5000
n harmless: 5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-with-labels after each epoch.
Epoch 0, Step 0: train/loss = 0.7773686051368713, train/raw-loss = 0.6935486197471619, train/logprobs = tensor([[-10.4573, -10.5073],
        [-10.4422, -10.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16764001548290253
Epoch 0, Step 1: train/loss = 0.7884273529052734, train/raw-loss = 0.694591760635376, train/logprobs = tensor([[-10.4324, -10.4588],
        [-10.4481, -10.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18767111003398895
Epoch 0, Step 2: train/loss = 0.7767665386199951, train/raw-loss = 0.694462239742279, train/logprobs = tensor([[-10.4195, -10.4799],
        [-10.4487, -10.5020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16460855305194855
Epoch 0, Step 3: train/loss = 0.7946557402610779, train/raw-loss = 0.7119945287704468, train/logprobs = tensor([[-10.4531, -10.4272],
        [-10.4439, -10.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1653224229812622
Epoch 0, Step 4: train/loss = 0.7897357940673828, train/raw-loss = 0.6948099136352539, train/logprobs = tensor([[-10.4569, -10.5106],
        [-10.4500, -10.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18985189497470856
Epoch 0, Step 5: train/loss = 0.8036792278289795, train/raw-loss = 0.6949753165245056, train/logprobs = tensor([[-10.4293, -10.4822],
        [-10.3861, -10.4310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21740779280662537
Epoch 0, Step 6: train/loss = 0.7916070222854614, train/raw-loss = 0.7031717300415039, train/logprobs = tensor([[-10.4254, -10.4468],
        [-10.4316, -10.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17687052488327026
Epoch 0, Step 7: train/loss = 0.8103717565536499, train/raw-loss = 0.6889246106147766, train/logprobs = tensor([[-10.4646, -10.4505],
        [-10.4453, -10.4133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24289430677890778
Epoch 0, Step 8: train/loss = 0.7848244905471802, train/raw-loss = 0.6923255920410156, train/logprobs = tensor([[-10.4654, -10.5337],
        [-10.4645, -10.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1849978268146515
Epoch 0, Step 9: train/loss = 0.8027610778808594, train/raw-loss = 0.7201250791549683, train/logprobs = tensor([[-10.4434, -10.4021],
        [-10.4526, -10.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16527198255062103
Epoch 0, Step 10: train/loss = 0.7805991172790527, train/raw-loss = 0.6974773406982422, train/logprobs = tensor([[-10.4522, -10.4506],
        [-10.4595, -10.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16624343395233154
Epoch 0, Step 11: train/loss = 0.7773721218109131, train/raw-loss = 0.6960716247558594, train/logprobs = tensor([[-10.4474, -10.4852],
        [-10.4377, -10.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16260093450546265
Epoch 0, Step 12: train/loss = 0.8040298223495483, train/raw-loss = 0.7025814056396484, train/logprobs = tensor([[-10.4913, -10.4261],
        [-10.5048, -10.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20289680361747742
Epoch 0, Step 13: train/loss = 0.7858308553695679, train/raw-loss = 0.687181293964386, train/logprobs = tensor([[-10.4559, -10.4340],
        [-10.4802, -10.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19729922711849213
Epoch 0, Step 14: train/loss = 0.7645773887634277, train/raw-loss = 0.6959229707717896, train/logprobs = tensor([[-10.4815, -10.4270],
        [-10.4633, -10.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137308731675148
Epoch 0, Step 15: train/loss = 0.794134259223938, train/raw-loss = 0.6953650712966919, train/logprobs = tensor([[-10.4614, -10.4666],
        [-10.4751, -10.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19753839075565338
Epoch 0, Step 16: train/loss = 0.7991942167282104, train/raw-loss = 0.7172985076904297, train/logprobs = tensor([[-10.4150, -10.5307],
        [-10.4042, -10.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1637912541627884
Epoch 0, Step 17: train/loss = 0.803462028503418, train/raw-loss = 0.7087851762771606, train/logprobs = tensor([[-10.4409, -10.4323],
        [-10.4284, -10.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18935370445251465
Epoch 0, Step 18: train/loss = 0.7895699739456177, train/raw-loss = 0.702856183052063, train/logprobs = tensor([[-10.4679, -10.4481],
        [-10.4530, -10.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17342758178710938
Epoch 0, Step 19: train/loss = 0.7899754643440247, train/raw-loss = 0.7056719660758972, train/logprobs = tensor([[-10.4608, -10.3915],
        [-10.4793, -10.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16860702633857727
Epoch 0, Step 20: train/loss = 0.7759286761283875, train/raw-loss = 0.6975464820861816, train/logprobs = tensor([[-10.4716, -10.4589],
        [-10.4867, -10.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15676426887512207
Epoch 0, Step 21: train/loss = 0.7945976257324219, train/raw-loss = 0.698710024356842, train/logprobs = tensor([[-10.3966, -10.3499],
        [-10.4071, -10.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19177518784999847
Epoch 0, Step 22: train/loss = 0.7692441940307617, train/raw-loss = 0.6886001825332642, train/logprobs = tensor([[-10.4541, -10.4780],
        [-10.4723, -10.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16128796339035034
Epoch 0, Step 23: train/loss = 0.7959526181221008, train/raw-loss = 0.7002555131912231, train/logprobs = tensor([[-10.4502, -10.4849],
        [-10.4355, -10.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19139429926872253
Epoch 0, Step 24: train/loss = 0.7932642698287964, train/raw-loss = 0.700487494468689, train/logprobs = tensor([[-10.4459, -10.4955],
        [-10.4602, -10.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18555359542369843
Epoch 0, Step 25: train/loss = 0.7868690490722656, train/raw-loss = 0.697887122631073, train/logprobs = tensor([[-10.4753, -10.4152],
        [-10.4685, -10.4009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17796382308006287
Epoch 0, Step 26: train/loss = 0.7904675602912903, train/raw-loss = 0.7078809142112732, train/logprobs = tensor([[-10.4424, -10.4371],
        [-10.4228, -10.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16517317295074463
Epoch 0, Step 27: train/loss = 0.7733011245727539, train/raw-loss = 0.6809850931167603, train/logprobs = tensor([[-10.4523, -10.4793],
        [-10.4499, -10.4205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18463212251663208
Epoch 0, Step 28: train/loss = 0.7909034490585327, train/raw-loss = 0.7141047120094299, train/logprobs = tensor([[-10.5077, -10.4845],
        [-10.5053, -10.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15359756350517273
Epoch 0, Step 29: train/loss = 0.7716456055641174, train/raw-loss = 0.6889573931694031, train/logprobs = tensor([[-10.4729, -10.5086],
        [-10.5026, -10.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16537639498710632
Epoch 0, Step 30: train/loss = 0.7744924426078796, train/raw-loss = 0.6811748743057251, train/logprobs = tensor([[-10.4919, -10.4837],
        [-10.5141, -10.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866351068019867
Epoch 0, Step 31: train/loss = 0.7700998783111572, train/raw-loss = 0.6749632358551025, train/logprobs = tensor([[-10.4763, -10.5109],
        [-10.5001, -10.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19027315080165863
Epoch 0, Step 32: train/loss = 0.7847378253936768, train/raw-loss = 0.7035014629364014, train/logprobs = tensor([[-10.5099, -10.4154],
        [-10.4855, -10.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16247278451919556
Epoch 0, Step 33: train/loss = 0.7818742990493774, train/raw-loss = 0.6936241388320923, train/logprobs = tensor([[-10.4302, -10.4288],
        [-10.4485, -10.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17650027573108673
Epoch 0, Step 34: train/loss = 0.773625910282135, train/raw-loss = 0.6878998875617981, train/logprobs = tensor([[-10.4433, -10.3595],
        [-10.4368, -10.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17145201563835144
Epoch 0, Step 35: train/loss = 0.7899570465087891, train/raw-loss = 0.6917125582695007, train/logprobs = tensor([[-10.4659, -10.4229],
        [-10.4952, -10.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19648900628089905
Epoch 0, Step 36: train/loss = 0.7688369750976562, train/raw-loss = 0.6848864555358887, train/logprobs = tensor([[-10.4354, -10.4599],
        [-10.4592, -10.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16790106892585754
Epoch 0, Step 37: train/loss = 0.7844205498695374, train/raw-loss = 0.6996776461601257, train/logprobs = tensor([[-10.4266, -10.4674],
        [-10.4136, -10.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16948571801185608
Epoch 0, Step 38: train/loss = 0.7892402410507202, train/raw-loss = 0.7065526247024536, train/logprobs = tensor([[-10.4729, -10.4860],
        [-10.4738, -10.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16537529230117798
Epoch 0, Step 39: train/loss = 0.7773394584655762, train/raw-loss = 0.6828612685203552, train/logprobs = tensor([[-10.4152, -10.5135],
        [-10.4224, -10.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18895643949508667
Epoch 0, Step 40: train/loss = 0.7752915620803833, train/raw-loss = 0.6921910643577576, train/logprobs = tensor([[-10.5078, -10.5587],
        [-10.5024, -10.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16620109975337982
Epoch 0, Step 41: train/loss = 0.7802830338478088, train/raw-loss = 0.7060619592666626, train/logprobs = tensor([[-10.4185, -10.3703],
        [-10.4007, -10.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484421193599701
Epoch 0, Step 42: train/loss = 0.7884566783905029, train/raw-loss = 0.7008346319198608, train/logprobs = tensor([[-10.4720, -10.5008],
        [-10.4920, -10.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752440333366394
Epoch 0, Step 43: train/loss = 0.7647238969802856, train/raw-loss = 0.6877740621566772, train/logprobs = tensor([[-10.4716, -10.4810],
        [-10.4493, -10.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.153899684548378
Epoch 0, Step 44: train/loss = 0.7916043996810913, train/raw-loss = 0.692202627658844, train/logprobs = tensor([[-10.5202, -10.5023],
        [-10.5399, -10.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19880343973636627
Epoch 0, Step 45: train/loss = 0.7852847576141357, train/raw-loss = 0.7003520131111145, train/logprobs = tensor([[-10.4756, -10.4833],
        [-10.4717, -10.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16986548900604248
Epoch 0, Step 46: train/loss = 0.7716782093048096, train/raw-loss = 0.6936492919921875, train/logprobs = tensor([[-10.4345, -10.5438],
        [-10.4669, -10.5609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15605787932872772
Epoch 0, Step 47: train/loss = 0.7884891033172607, train/raw-loss = 0.712568998336792, train/logprobs = tensor([[-10.4594, -10.4464],
        [-10.4489, -10.5100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518402099609375
Epoch 0, Step 48: train/loss = 0.7928502559661865, train/raw-loss = 0.7100962400436401, train/logprobs = tensor([[-10.4806, -10.4584],
        [-10.4446, -10.4850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1655079424381256
Epoch 0, Step 49: train/loss = 0.7854106426239014, train/raw-loss = 0.6849029064178467, train/logprobs = tensor([[-10.4551, -10.4552],
        [-10.4571, -10.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20101535320281982
Epoch 0, Step 50: train/loss = 0.781843364238739, train/raw-loss = 0.6975854635238647, train/logprobs = tensor([[-10.4818, -10.4839],
        [-10.4955, -10.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16851569712162018
Epoch 0, Step 51: train/loss = 0.7730246186256409, train/raw-loss = 0.6869243383407593, train/logprobs = tensor([[-10.4473, -10.4708],
        [-10.4553, -10.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17220064997673035
Epoch 0, Step 52: train/loss = 0.788288950920105, train/raw-loss = 0.7033055424690247, train/logprobs = tensor([[-10.4625, -10.4893],
        [-10.4262, -10.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16996684670448303
Epoch 0, Step 53: train/loss = 0.7716505527496338, train/raw-loss = 0.6901492476463318, train/logprobs = tensor([[-10.4081, -10.4474],
        [-10.3993, -10.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16300266981124878
Epoch 0, Step 54: train/loss = 0.7895935773849487, train/raw-loss = 0.6920696496963501, train/logprobs = tensor([[-10.3863, -10.3547],
        [-10.4443, -10.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19504785537719727
Epoch 0, Step 55: train/loss = 0.7784731984138489, train/raw-loss = 0.6865798234939575, train/logprobs = tensor([[-10.4915, -10.4086],
        [-10.4995, -10.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18378674983978271
Epoch 0, Step 56: train/loss = 0.7824409604072571, train/raw-loss = 0.6985818147659302, train/logprobs = tensor([[-10.4742, -10.4590],
        [-10.5172, -10.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16771836578845978
Epoch 0, Step 57: train/loss = 0.776538074016571, train/raw-loss = 0.6877453327178955, train/logprobs = tensor([[-10.5137, -10.5126],
        [-10.5288, -10.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17758548259735107
Epoch 0, Step 58: train/loss = 0.7696324586868286, train/raw-loss = 0.6942352056503296, train/logprobs = tensor([[-10.4693, -10.4279],
        [-10.4774, -10.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1507946252822876
Epoch 0, Step 59: train/loss = 0.7949450016021729, train/raw-loss = 0.6987380981445312, train/logprobs = tensor([[-10.4424, -10.4670],
        [-10.4265, -10.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19241365790367126
Epoch 0, Step 60: train/loss = 0.7698721885681152, train/raw-loss = 0.6982039213180542, train/logprobs = tensor([[-10.5467, -10.5220],
        [-10.4912, -10.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14333657920360565
Epoch 0, Step 61: train/loss = 0.753645658493042, train/raw-loss = 0.688862681388855, train/logprobs = tensor([[-10.4803, -10.5149],
        [-10.4981, -10.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12956602871418
Epoch 0, Step 62: train/loss = 0.8120298385620117, train/raw-loss = 0.7116376161575317, train/logprobs = tensor([[-10.4399, -10.3672],
        [-10.4469, -10.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2007845640182495
Epoch 0, Step 63: train/loss = 0.7814993858337402, train/raw-loss = 0.6923778057098389, train/logprobs = tensor([[-10.4758, -10.3850],
        [-10.4800, -10.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17824319005012512
Epoch 0, Step 64: train/loss = 0.7836268544197083, train/raw-loss = 0.6940712928771973, train/logprobs = tensor([[-10.4705, -10.4476],
        [-10.4765, -10.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17911101877689362
Epoch 0, Step 65: train/loss = 0.7852199077606201, train/raw-loss = 0.7085639238357544, train/logprobs = tensor([[-10.4480, -10.4500],
        [-10.4646, -10.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15331190824508667
Epoch 0, Step 66: train/loss = 0.7857250571250916, train/raw-loss = 0.6972274780273438, train/logprobs = tensor([[-10.4628, -10.4155],
        [-10.4585, -10.4049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.176995187997818
Epoch 0, Step 67: train/loss = 0.7877771854400635, train/raw-loss = 0.7133430242538452, train/logprobs = tensor([[-10.4648, -10.3921],
        [-10.4441, -10.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488683968782425
Epoch 0, Step 68: train/loss = 0.79390949010849, train/raw-loss = 0.7030217051506042, train/logprobs = tensor([[-10.4855, -10.5819],
        [-10.4756, -10.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18177556991577148
Epoch 0, Step 69: train/loss = 0.7939655780792236, train/raw-loss = 0.6980236172676086, train/logprobs = tensor([[-10.4586, -10.4842],
        [-10.5125, -10.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19188380241394043
Epoch 0, Step 70: train/loss = 0.7769213914871216, train/raw-loss = 0.6870508193969727, train/logprobs = tensor([[-10.4827, -10.5078],
        [-10.4967, -10.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17974115908145905
Epoch 0, Step 71: train/loss = 0.7749491930007935, train/raw-loss = 0.6881260275840759, train/logprobs = tensor([[-10.4317, -10.4936],
        [-10.4477, -10.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1736464649438858
Epoch 0, Step 72: train/loss = 0.7961534857749939, train/raw-loss = 0.692317008972168, train/logprobs = tensor([[-10.4900, -10.4218],
        [-10.4857, -10.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20767301321029663
Epoch 0, Step 73: train/loss = 0.7841107249259949, train/raw-loss = 0.6938114762306213, train/logprobs = tensor([[-10.4670, -10.4249],
        [-10.4610, -10.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18059849739074707
Epoch 0, Step 74: train/loss = 0.7783290147781372, train/raw-loss = 0.6886123418807983, train/logprobs = tensor([[-10.4365, -10.5402],
        [-10.4601, -10.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17943328619003296
Epoch 0, Step 75: train/loss = 0.7612791061401367, train/raw-loss = 0.6896789073944092, train/logprobs = tensor([[-10.4630, -10.5688],
        [-10.4730, -10.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14320047199726105
Epoch 0, Step 76: train/loss = 0.8219720125198364, train/raw-loss = 0.715595543384552, train/logprobs = tensor([[-10.4994, -10.5054],
        [-10.4746, -10.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21275293827056885
Epoch 0, Step 77: train/loss = 0.8056421279907227, train/raw-loss = 0.701197624206543, train/logprobs = tensor([[-10.5427, -10.5363],
        [-10.5068, -10.5253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20888885855674744
Epoch 0, Step 78: train/loss = 0.7850866317749023, train/raw-loss = 0.698760986328125, train/logprobs = tensor([[-10.4723, -10.5013],
        [-10.4758, -10.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17265132069587708
Epoch 0, Step 79: train/loss = 0.7550113201141357, train/raw-loss = 0.6881142854690552, train/logprobs = tensor([[-10.5045, -10.5674],
        [-10.4843, -10.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13379409909248352
Epoch 0, Step 80: train/loss = 0.8037635684013367, train/raw-loss = 0.7248708009719849, train/logprobs = tensor([[-10.5363, -10.4756],
        [-10.4913, -10.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15778562426567078
Epoch 0, Step 81: train/loss = 0.7712407112121582, train/raw-loss = 0.70002281665802, train/logprobs = tensor([[-10.4678, -10.5239],
        [-10.4189, -10.4943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14243577420711517
Epoch 0, Step 82: train/loss = 0.7404908537864685, train/raw-loss = 0.6757297515869141, train/logprobs = tensor([[-10.4012, -10.4398],
        [-10.4272, -10.3919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12952224910259247
Epoch 0, Step 83: train/loss = 0.7836887240409851, train/raw-loss = 0.703487753868103, train/logprobs = tensor([[-10.4224, -10.4288],
        [-10.4199, -10.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1604020595550537
Epoch 0, Step 84: train/loss = 0.7837931513786316, train/raw-loss = 0.71596759557724, train/logprobs = tensor([[-10.5121, -10.4776],
        [-10.5059, -10.5230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565117120742798
Epoch 0, Step 85: train/loss = 0.7662562131881714, train/raw-loss = 0.6770672798156738, train/logprobs = tensor([[-10.4571, -10.4216],
        [-10.4382, -10.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17837795615196228
Epoch 0, Step 86: train/loss = 0.7940878868103027, train/raw-loss = 0.6945529580116272, train/logprobs = tensor([[-10.4599, -10.4509],
        [-10.4562, -10.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19906963407993317
Epoch 0, Step 87: train/loss = 0.7911642789840698, train/raw-loss = 0.6851526498794556, train/logprobs = tensor([[-10.4184, -10.4765],
        [-10.4559, -10.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21202333271503448
Epoch 0, Step 88: train/loss = 0.776637852191925, train/raw-loss = 0.694024384021759, train/logprobs = tensor([[-10.4811, -10.4688],
        [-10.4174, -10.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16522696614265442
Epoch 0, Step 89: train/loss = 0.8210095167160034, train/raw-loss = 0.7171450257301331, train/logprobs = tensor([[-10.4770, -10.4188],
        [-10.4732, -10.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20772896707057953
Epoch 0, Step 90: train/loss = 0.80279541015625, train/raw-loss = 0.7052184343338013, train/logprobs = tensor([[-10.4437, -10.3942],
        [-10.4354, -10.4217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19515404105186462
Epoch 0, Step 91: train/loss = 0.7741966843605042, train/raw-loss = 0.6838018298149109, train/logprobs = tensor([[-10.4005, -10.4289],
        [-10.4403, -10.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18078961968421936
Epoch 0, Step 92: train/loss = 0.7807233333587646, train/raw-loss = 0.693658709526062, train/logprobs = tensor([[-10.4490, -10.4417],
        [-10.4523, -10.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1741293966770172
Epoch 0, Step 93: train/loss = 0.7833592891693115, train/raw-loss = 0.6834877133369446, train/logprobs = tensor([[-10.4536, -10.4982],
        [-10.4770, -10.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19974319636821747
Epoch 0, Step 94: train/loss = 0.7820934057235718, train/raw-loss = 0.7010518312454224, train/logprobs = tensor([[-10.4575, -10.4527],
        [-10.4513, -10.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16208308935165405
Epoch 0, Step 95: train/loss = 0.78376305103302, train/raw-loss = 0.6856552362442017, train/logprobs = tensor([[-10.5159, -10.4871],
        [-10.5039, -10.4092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19621556997299194
Epoch 0, Step 96: train/loss = 0.7684586048126221, train/raw-loss = 0.7007788419723511, train/logprobs = tensor([[-10.4068, -10.4267],
        [-10.4168, -10.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1353594958782196
Epoch 0, Step 97: train/loss = 0.7955124974250793, train/raw-loss = 0.7098278403282166, train/logprobs = tensor([[-10.5472, -10.5231],
        [-10.5004, -10.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1713692545890808
Epoch 0, Step 98: train/loss = 0.7824750542640686, train/raw-loss = 0.6986458897590637, train/logprobs = tensor([[-10.4564, -10.4642],
        [-10.4278, -10.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16765841841697693
Epoch 0, Step 99: train/loss = 0.7911247611045837, train/raw-loss = 0.699964165687561, train/logprobs = tensor([[-10.4568, -10.4588],
        [-10.4724, -10.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18232113122940063
Epoch 0, Step 100: train/loss = 0.776533842086792, train/raw-loss = 0.6889318823814392, train/logprobs = tensor([[-10.4816, -10.4754],
        [-10.5218, -10.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17520377039909363
Epoch 0, Step 101: train/loss = 0.8108121752738953, train/raw-loss = 0.6961885094642639, train/logprobs = tensor([[-10.4232, -10.3988],
        [-10.4539, -10.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2292473018169403
Epoch 0, Step 102: train/loss = 0.78501296043396, train/raw-loss = 0.7046810388565063, train/logprobs = tensor([[-10.4383, -10.5070],
        [-10.4611, -10.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16066387295722961
Epoch 0, Step 103: train/loss = 0.8012439012527466, train/raw-loss = 0.7052553296089172, train/logprobs = tensor([[-10.5269, -10.3547],
        [-10.5405, -10.4081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1919771134853363
Epoch 0, Step 104: train/loss = 0.7880837917327881, train/raw-loss = 0.7066236734390259, train/logprobs = tensor([[-10.5003, -10.4420],
        [-10.4992, -10.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16292020678520203
Epoch 0, Step 105: train/loss = 0.7844885587692261, train/raw-loss = 0.691203236579895, train/logprobs = tensor([[-10.4281, -10.5099],
        [-10.4438, -10.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18657054007053375
Epoch 0, Step 106: train/loss = 0.8147439956665039, train/raw-loss = 0.7249242663383484, train/logprobs = tensor([[-10.4809, -10.4253],
        [-10.4629, -10.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17963935434818268
Epoch 0, Step 107: train/loss = 0.8031442165374756, train/raw-loss = 0.7090563178062439, train/logprobs = tensor([[-10.4451, -10.4857],
        [-10.4436, -10.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18817569315433502
Epoch 0, Step 108: train/loss = 0.7701244354248047, train/raw-loss = 0.6857956647872925, train/logprobs = tensor([[-10.4552, -10.4910],
        [-10.4806, -10.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16865748167037964
Epoch 0, Step 109: train/loss = 0.7462426424026489, train/raw-loss = 0.6629533767700195, train/logprobs = tensor([[-10.4414, -10.5274],
        [-10.4496, -10.4011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665785163640976
Epoch 0, Step 110: train/loss = 0.7910254001617432, train/raw-loss = 0.7075147032737732, train/logprobs = tensor([[-10.4873, -10.3842],
        [-10.4705, -10.3967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16702145338058472
Epoch 0, Step 111: train/loss = 0.7727101445198059, train/raw-loss = 0.6932733058929443, train/logprobs = tensor([[-10.4909, -10.4087],
        [-10.4893, -10.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15887363255023956
Epoch 0, Step 112: train/loss = 0.7727093696594238, train/raw-loss = 0.6885446906089783, train/logprobs = tensor([[-10.4148, -10.5176],
        [-10.4494, -10.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1683293730020523
Epoch 0, Step 113: train/loss = 0.7723273634910583, train/raw-loss = 0.6810505986213684, train/logprobs = tensor([[-10.4554, -10.3959],
        [-10.4924, -10.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18255352973937988
Epoch 0, Step 114: train/loss = 0.7596389651298523, train/raw-loss = 0.6836137771606445, train/logprobs = tensor([[-10.4398, -10.4154],
        [-10.4431, -10.3679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15205040574073792
Epoch 0, Step 115: train/loss = 0.7689197063446045, train/raw-loss = 0.6872096061706543, train/logprobs = tensor([[-10.4578, -10.5229],
        [-10.4827, -10.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1634202003479004
Epoch 0, Step 116: train/loss = 0.7774379253387451, train/raw-loss = 0.701377809047699, train/logprobs = tensor([[-10.4203, -10.3885],
        [-10.4145, -10.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15212011337280273
Epoch 0, Step 117: train/loss = 0.7753748297691345, train/raw-loss = 0.6944204568862915, train/logprobs = tensor([[-10.4636, -10.5126],
        [-10.4726, -10.5218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190877556800842
Epoch 0, Step 118: train/loss = 0.7931755781173706, train/raw-loss = 0.6998579502105713, train/logprobs = tensor([[-10.4476, -10.4260],
        [-10.4775, -10.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18663521111011505
Epoch 0, Step 119: train/loss = 0.7901215553283691, train/raw-loss = 0.6845816373825073, train/logprobs = tensor([[-10.5217, -10.5443],
        [-10.5563, -10.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2110798954963684
Epoch 0, Step 120: train/loss = 0.8027313947677612, train/raw-loss = 0.6885572671890259, train/logprobs = tensor([[-10.4221, -10.4523],
        [-10.4560, -10.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22834834456443787
Epoch 0, Step 121: train/loss = 0.7750564217567444, train/raw-loss = 0.6897776126861572, train/logprobs = tensor([[-10.4908, -10.4896],
        [-10.4802, -10.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17055760324001312
Epoch 0, Step 122: train/loss = 0.7782464027404785, train/raw-loss = 0.6926895380020142, train/logprobs = tensor([[-10.4907, -10.5485],
        [-10.5018, -10.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111358046531677
Epoch 0, Step 123: train/loss = 0.7802232503890991, train/raw-loss = 0.6999258995056152, train/logprobs = tensor([[-10.4659, -10.4429],
        [-10.4331, -10.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16059480607509613
Epoch 0, Step 124: train/loss = 0.7847411632537842, train/raw-loss = 0.6979671120643616, train/logprobs = tensor([[-10.5135, -10.4713],
        [-10.5300, -10.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17354817688465118
Epoch 0, Step 125: train/loss = 0.8084810972213745, train/raw-loss = 0.6878511905670166, train/logprobs = tensor([[-10.4968, -10.4546],
        [-10.5369, -10.4618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2412598580121994
Epoch 0, Step 126: train/loss = 0.756649911403656, train/raw-loss = 0.6851714849472046, train/logprobs = tensor([[-10.4534, -10.4378],
        [-10.4593, -10.3987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14295688271522522
Epoch 0, Step 127: train/loss = 0.7831858396530151, train/raw-loss = 0.6933094263076782, train/logprobs = tensor([[-10.4632, -10.5173],
        [-10.4838, -10.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17975300550460815
Epoch 0, Step 128: train/loss = 0.7892159819602966, train/raw-loss = 0.6903817057609558, train/logprobs = tensor([[-10.4974, -10.4709],
        [-10.4936, -10.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19766861200332642
Epoch 0, Step 129: train/loss = 0.7941199541091919, train/raw-loss = 0.7031220197677612, train/logprobs = tensor([[-10.4098, -10.4457],
        [-10.4463, -10.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18199586868286133
Epoch 0, Step 130: train/loss = 0.7520036697387695, train/raw-loss = 0.6881701946258545, train/logprobs = tensor([[-10.3947, -10.4325],
        [-10.4151, -10.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12766695022583008
Epoch 0, Step 131: train/loss = 0.7715643644332886, train/raw-loss = 0.6897308826446533, train/logprobs = tensor([[-10.4428, -10.4634],
        [-10.4628, -10.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16366684436798096
Epoch 0, Step 132: train/loss = 0.8033133745193481, train/raw-loss = 0.7059106826782227, train/logprobs = tensor([[-10.4656, -10.4992],
        [-10.4807, -10.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19480544328689575
Epoch 0, Step 133: train/loss = 0.7901692390441895, train/raw-loss = 0.6957891583442688, train/logprobs = tensor([[-10.4019, -10.4589],
        [-10.4432, -10.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18876023590564728
Epoch 0, Step 134: train/loss = 0.786885678768158, train/raw-loss = 0.6892207264900208, train/logprobs = tensor([[-10.4490, -10.5032],
        [-10.4542, -10.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19532990455627441
Epoch 0, Step 135: train/loss = 0.7657855153083801, train/raw-loss = 0.6936779022216797, train/logprobs = tensor([[-10.4837, -10.5095],
        [-10.4636, -10.4887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14421527087688446
Epoch 0, Step 136: train/loss = 0.7690197229385376, train/raw-loss = 0.6767851114273071, train/logprobs = tensor([[-10.4619, -10.5017],
        [-10.4738, -10.4416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18446926772594452
Epoch 0, Step 137: train/loss = 0.7722705602645874, train/raw-loss = 0.6852573156356812, train/logprobs = tensor([[-10.4565, -10.5156],
        [-10.4681, -10.4854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17402660846710205
Epoch 0, Step 138: train/loss = 0.7925263047218323, train/raw-loss = 0.6870648860931396, train/logprobs = tensor([[-10.3699, -10.4604],
        [-10.3862, -10.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21092285215854645
Epoch 0, Step 139: train/loss = 0.7811890244483948, train/raw-loss = 0.6948065161705017, train/logprobs = tensor([[-10.4154, -10.4564],
        [-10.4259, -10.4502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727648824453354
Epoch 0, Step 140: train/loss = 0.7700036764144897, train/raw-loss = 0.6897649765014648, train/logprobs = tensor([[-10.4946, -10.4425],
        [-10.4779, -10.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16047737002372742
Epoch 0, Step 141: train/loss = 0.7697382569313049, train/raw-loss = 0.6866455078125, train/logprobs = tensor([[-10.4743, -10.6379],
        [-10.5158, -10.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1661856770515442
Epoch 0, Step 142: train/loss = 0.7984185814857483, train/raw-loss = 0.7138237357139587, train/logprobs = tensor([[-10.4550, -10.4554],
        [-10.5009, -10.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691897064447403
Epoch 0, Step 143: train/loss = 0.7885640859603882, train/raw-loss = 0.689120888710022, train/logprobs = tensor([[-10.4099, -10.5072],
        [-10.4338, -10.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19888636469841003
Epoch 0, Step 144: train/loss = 0.790916919708252, train/raw-loss = 0.6979700326919556, train/logprobs = tensor([[-10.4797, -10.4473],
        [-10.4742, -10.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.185893714427948
Epoch 0, Step 145: train/loss = 0.7599414587020874, train/raw-loss = 0.6883499622344971, train/logprobs = tensor([[-10.4100, -10.5299],
        [-10.4386, -10.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14318308234214783
Epoch 0, Step 146: train/loss = 0.7847658395767212, train/raw-loss = 0.6985518932342529, train/logprobs = tensor([[-10.4552, -10.5115],
        [-10.4927, -10.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17242787778377533
Epoch 0, Step 147: train/loss = 0.8016034364700317, train/raw-loss = 0.7089429497718811, train/logprobs = tensor([[-10.4561, -10.4257],
        [-10.4373, -10.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18532094359397888
Epoch 0, Step 148: train/loss = 0.8072190880775452, train/raw-loss = 0.7117285132408142, train/logprobs = tensor([[-10.4365, -10.4101],
        [-10.4214, -10.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1909811794757843
Epoch 0, Step 149: train/loss = 0.7795671820640564, train/raw-loss = 0.701421320438385, train/logprobs = tensor([[-10.4733, -10.4822],
        [-10.4696, -10.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15629173815250397
Epoch 0, Step 150: train/loss = 0.7813177704811096, train/raw-loss = 0.6931055784225464, train/logprobs = tensor([[-10.4390, -10.4224],
        [-10.4302, -10.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17642436921596527
Epoch 0, Step 151: train/loss = 0.7816933393478394, train/raw-loss = 0.6890020966529846, train/logprobs = tensor([[-10.4399, -10.4965],
        [-10.4489, -10.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18538248538970947
Epoch 0, Step 152: train/loss = 0.8050404787063599, train/raw-loss = 0.7086243033409119, train/logprobs = tensor([[-10.4365, -10.4849],
        [-10.4603, -10.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19283230602741241
Epoch 0, Step 153: train/loss = 0.7950945496559143, train/raw-loss = 0.6964569687843323, train/logprobs = tensor([[-10.4081, -10.3867],
        [-10.4061, -10.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19727514684200287
Epoch 0, Step 154: train/loss = 0.770179271697998, train/raw-loss = 0.6936438679695129, train/logprobs = tensor([[-10.4637, -10.5245],
        [-10.4478, -10.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15307089686393738
Epoch 0, Step 155: train/loss = 0.7805544137954712, train/raw-loss = 0.6946364641189575, train/logprobs = tensor([[-10.4061, -10.4635],
        [-10.4284, -10.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17183589935302734
Epoch 0, Step 156: train/loss = 0.8031123876571655, train/raw-loss = 0.7136962413787842, train/logprobs = tensor([[-10.4760, -10.3629],
        [-10.4794, -10.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17883215844631195
Epoch 0, Step 157: train/loss = 0.7863671183586121, train/raw-loss = 0.7106121778488159, train/logprobs = tensor([[-10.4463, -10.4611],
        [-10.4647, -10.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15150979161262512
Epoch 0, Step 158: train/loss = 0.7609461545944214, train/raw-loss = 0.6847370862960815, train/logprobs = tensor([[-10.4896, -10.5767],
        [-10.5050, -10.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15241816639900208
Epoch 0, Step 159: train/loss = 0.7623122930526733, train/raw-loss = 0.6852869987487793, train/logprobs = tensor([[-10.4276, -10.4467],
        [-10.4533, -10.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15405058860778809
Epoch 0, Step 160: train/loss = 0.781991183757782, train/raw-loss = 0.6960232853889465, train/logprobs = tensor([[-10.4618, -10.4971],
        [-10.4520, -10.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719357669353485
Epoch 0, Step 161: train/loss = 0.7722402811050415, train/raw-loss = 0.7061600685119629, train/logprobs = tensor([[-10.4492, -10.4384],
        [-10.4841, -10.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13216039538383484
Epoch 0, Step 162: train/loss = 0.7696393728256226, train/raw-loss = 0.6818997859954834, train/logprobs = tensor([[-10.4591, -10.5064],
        [-10.4790, -10.4720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17547917366027832
Epoch 0, Step 163: train/loss = 0.7810965776443481, train/raw-loss = 0.6943550109863281, train/logprobs = tensor([[-10.4708, -10.5049],
        [-10.4629, -10.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17348310351371765
