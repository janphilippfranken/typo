[2024-02-19 16:56:35,072][root][INFO] - beta: 0.3
[2024-02-19 16:56:35,072][root][INFO] - temperature: 1
[2024-02-19 16:56:35,072][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-batch-size-64
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-batch-size-64 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-batch-size-64 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-batch-size-64 after each epoch.
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-batch-size-64 after each epoch.
Epoch 0, Step 0: train/loss = 0.7040798664093018, train/raw-loss = 0.7040798664093018, train/logprobs = tensor([[-0.9533, -0.9948],
        [-0.9302, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7164785265922546, train/raw-loss = 0.7164785265922546, train/logprobs = tensor([[-1.0724, -1.4169],
        [-1.1293, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7007112503051758, train/raw-loss = 0.7007112503051758, train/logprobs = tensor([[-0.8302, -0.9350],
        [-0.7845, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6975338459014893, train/raw-loss = 0.6975338459014893, train/logprobs = tensor([[-0.9099, -0.9087],
        [-0.9060, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6946052312850952, train/raw-loss = 0.6946052312850952, train/logprobs = tensor([[-0.7761, -0.8804],
        [-0.8097, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7074680328369141, train/raw-loss = 0.7074680328369141, train/logprobs = tensor([[-1.2210, -1.1801],
        [-1.2999, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6987193822860718, train/raw-loss = 0.6987193822860718, train/logprobs = tensor([[-1.1771, -1.2348],
        [-1.1741, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.7075663805007935, train/raw-loss = 0.7075663805007935, train/logprobs = tensor([[-0.7880, -0.6978],
        [-0.8163, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.742479681968689, train/raw-loss = 0.742479681968689, train/logprobs = tensor([[-0.9000, -1.5068],
        [-0.8656, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6987901329994202, train/raw-loss = 0.6987901329994202, train/logprobs = tensor([[-0.9074, -1.1629],
        [-0.9010, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7119882702827454, train/raw-loss = 0.7119882702827454, train/logprobs = tensor([[-1.2293, -1.1969],
        [-1.2240, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7207285761833191, train/raw-loss = 0.7207285761833191, train/logprobs = tensor([[-1.0679, -0.9060],
        [-1.0898, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7011242508888245, train/raw-loss = 0.7011242508888245, train/logprobs = tensor([[-0.8549, -1.0949],
        [-0.8891, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.7031682729721069, train/raw-loss = 0.7031682729721069, train/logprobs = tensor([[-0.8906, -1.0827],
        [-0.9134, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7142623662948608, train/raw-loss = 0.7142623662948608, train/logprobs = tensor([[-0.8982, -0.9696],
        [-0.8924, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7054764628410339, train/raw-loss = 0.7054764628410339, train/logprobs = tensor([[-0.5966, -0.8092],
        [-0.5724, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6938965320587158, train/raw-loss = 0.6938965320587158, train/logprobs = tensor([[-1.0988, -1.1515],
        [-1.0541, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7236944437026978, train/raw-loss = 0.7236944437026978, train/logprobs = tensor([[-0.8199, -1.2773],
        [-0.7945, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6943728923797607, train/raw-loss = 0.6943728923797607, train/logprobs = tensor([[-1.0141, -1.0339],
        [-1.0263, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6956578493118286, train/raw-loss = 0.6956578493118286, train/logprobs = tensor([[-1.1737, -1.1441],
        [-1.1765, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7437841296195984, train/raw-loss = 0.7437841296195984, train/logprobs = tensor([[-0.5573, -1.0747],
        [-0.5540, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7071292996406555, train/raw-loss = 0.7071292996406555, train/logprobs = tensor([[-1.0698, -0.9658],
        [-1.0991, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7120579481124878, train/raw-loss = 0.7120579481124878, train/logprobs = tensor([[-1.1177, -1.1496],
        [-1.1588, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7534469962120056, train/raw-loss = 0.7534469962120056, train/logprobs = tensor([[-0.9588, -1.4736],
        [-0.9477, -1.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6944814920425415, train/raw-loss = 0.6944814920425415, train/logprobs = tensor([[-1.3211, -1.4845],
        [-1.2829, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7182225584983826, train/raw-loss = 0.7182225584983826, train/logprobs = tensor([[-0.9310, -0.9236],
        [-0.9353, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7320457696914673, train/raw-loss = 0.7320457696914673, train/logprobs = tensor([[-0.9226, -1.0176],
        [-0.9618, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7064348459243774, train/raw-loss = 0.7064348459243774, train/logprobs = tensor([[-0.9682, -1.0804],
        [-0.9400, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7004761099815369, train/raw-loss = 0.7004761099815369, train/logprobs = tensor([[-1.0793, -1.2677],
        [-1.0354, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7071655988693237, train/raw-loss = 0.7071655988693237, train/logprobs = tensor([[-0.8737, -0.9530],
        [-0.8765, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7233868837356567, train/raw-loss = 0.7233868837356567, train/logprobs = tensor([[-0.9774, -1.2341],
        [-0.9461, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.8921672105789185, train/raw-loss = 0.8921672105789185, train/logprobs = tensor([[-0.7943, -1.4819],
        [-0.8081, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.712089478969574, train/raw-loss = 0.712088942527771, train/logprobs = tensor([[-0.8869, -1.0056],
        [-0.9073, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9964645616710186e-06
Epoch 0, Step 33: train/loss = 0.7010219097137451, train/raw-loss = 0.701019287109375, train/logprobs = tensor([[-0.9851, -0.9311],
        [-0.9676, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.528033504262567e-06
Epoch 0, Step 34: train/loss = 0.7564656734466553, train/raw-loss = 0.7564395070075989, train/logprobs = tensor([[-0.6016, -1.2200],
        [-0.5866, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.731253183213994e-05
Epoch 0, Step 35: train/loss = 0.6850143074989319, train/raw-loss = 0.685012936592102, train/logprobs = tensor([[-0.8444, -1.0261],
        [-1.1836, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.364708729553968e-06
Epoch 0, Step 36: train/loss = 0.6972796320915222, train/raw-loss = 0.6972724199295044, train/logprobs = tensor([[-0.9117, -1.0217],
        [-0.9284, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.398380820523016e-05
Epoch 0, Step 37: train/loss = 0.7978206276893616, train/raw-loss = 0.7978144884109497, train/logprobs = tensor([[-0.6709, -1.2004],
        [-0.6755, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.03110230359016e-05
Epoch 0, Step 38: train/loss = 0.69379723072052, train/raw-loss = 0.6937967538833618, train/logprobs = tensor([[-0.7704, -0.8397],
        [-0.8068, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6755002434365451e-06
Epoch 0, Step 39: train/loss = 0.696683943271637, train/raw-loss = 0.6966814398765564, train/logprobs = tensor([[-0.7973, -0.7414],
        [-0.8082, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.259134119725786e-06
Epoch 0, Step 40: train/loss = 0.6992071866989136, train/raw-loss = 0.6991989612579346, train/logprobs = tensor([[-0.8203, -0.8205],
        [-0.8708, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7404581487644464e-05
Epoch 0, Step 41: train/loss = 0.695595383644104, train/raw-loss = 0.6955914497375488, train/logprobs = tensor([[-1.0475, -0.9800],
        [-1.0721, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2944015907123685e-05
Epoch 0, Step 42: train/loss = 0.6965779662132263, train/raw-loss = 0.6965758204460144, train/logprobs = tensor([[-1.2458, -1.4865],
        [-1.2781, -1.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.171849574660882e-06
Epoch 0, Step 43: train/loss = 0.9550840258598328, train/raw-loss = 0.9550572037696838, train/logprobs = tensor([[-0.7004, -1.9236],
        [-0.8211, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.91951349331066e-05
Epoch 0, Step 44: train/loss = 0.7405298948287964, train/raw-loss = 0.7405191659927368, train/logprobs = tensor([[-0.9471, -1.3785],
        [-0.9688, -1.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6008401366416365e-05
Epoch 0, Step 45: train/loss = 0.7038511633872986, train/raw-loss = 0.7038338780403137, train/logprobs = tensor([[-0.7362, -1.0745],
        [-0.7444, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.768624032498337e-05
Epoch 0, Step 46: train/loss = 0.7072665095329285, train/raw-loss = 0.70725417137146, train/logprobs = tensor([[-1.2158, -1.4737],
        [-1.2533, -1.4460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.134712798986584e-05
Epoch 0, Step 47: train/loss = 0.7040231227874756, train/raw-loss = 0.7040098309516907, train/logprobs = tensor([[-1.0093, -0.8358],
        [-1.0187, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.423211794346571e-05
Epoch 0, Step 48: train/loss = 0.7308599948883057, train/raw-loss = 0.7308274507522583, train/logprobs = tensor([[-0.8481, -1.2675],
        [-0.8170, -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010850199032574892
Epoch 0, Step 49: train/loss = 0.7063823938369751, train/raw-loss = 0.70633864402771, train/logprobs = tensor([[-1.1668, -0.9946],
        [-1.2117, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014582279254682362
Epoch 0, Step 50: train/loss = 0.6978120803833008, train/raw-loss = 0.6977933645248413, train/logprobs = tensor([[-0.9591, -1.1838],
        [-1.0557, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.251729791983962e-05
Epoch 0, Step 51: train/loss = 0.7399669885635376, train/raw-loss = 0.7398579716682434, train/logprobs = tensor([[-0.8906, -1.4039],
        [-0.9206, -1.2787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036348370485939085
Epoch 0, Step 52: train/loss = 0.7306782603263855, train/raw-loss = 0.7305915355682373, train/logprobs = tensor([[-0.7299, -1.0928],
        [-0.8723, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002892415504902601
Epoch 0, Step 53: train/loss = 0.6957425475120544, train/raw-loss = 0.6957213878631592, train/logprobs = tensor([[-0.9992, -1.0997],
        [-1.0385, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.070484571158886e-05
Epoch 0, Step 54: train/loss = 0.7063938975334167, train/raw-loss = 0.7063539624214172, train/logprobs = tensor([[-1.2566, -1.3968],
        [-1.2644, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013302562001626939
Epoch 0, Step 55: train/loss = 0.7244342565536499, train/raw-loss = 0.7244080305099487, train/logprobs = tensor([[-0.9820, -1.5961],
        [-1.0438, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.742463251110166e-05
Epoch 0, Step 56: train/loss = 0.6909627318382263, train/raw-loss = 0.6908837556838989, train/logprobs = tensor([[-1.0101, -1.2003],
        [-1.2056, -1.1831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002634139091242105
Epoch 0, Step 57: train/loss = 0.7226282954216003, train/raw-loss = 0.7226155400276184, train/logprobs = tensor([[-1.0464, -0.8527],
        [-1.0928, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.231956700095907e-05
Epoch 0, Step 58: train/loss = 0.6947500109672546, train/raw-loss = 0.6946597099304199, train/logprobs = tensor([[-0.9207, -1.0141],
        [-0.9934, -0.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000301012652926147
Epoch 0, Step 59: train/loss = 0.7136960625648499, train/raw-loss = 0.7136724591255188, train/logprobs = tensor([[-0.8897, -0.8844],
        [-0.9298, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.851258851587772e-05
Epoch 0, Step 60: train/loss = 0.6979106068611145, train/raw-loss = 0.6978799104690552, train/logprobs = tensor([[-0.6020, -0.6685],
        [-0.6651, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010245959128951654
Epoch 0, Step 61: train/loss = 0.7055491209030151, train/raw-loss = 0.7055376768112183, train/logprobs = tensor([[-0.7942, -0.7774],
        [-0.8721, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7982506910339e-05
Epoch 0, Step 62: train/loss = 0.6993046402931213, train/raw-loss = 0.6993042230606079, train/logprobs = tensor([[-0.7633, -0.9900],
        [-0.7814, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1935662769246846e-06
Epoch 0, Step 63: train/loss = 0.7067729234695435, train/raw-loss = 0.7067220211029053, train/logprobs = tensor([[-1.0801, -0.8872],
        [-1.0620, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016980929649434984
Epoch 0, Step 64: train/loss = 0.7060414552688599, train/raw-loss = 0.7060086727142334, train/logprobs = tensor([[-0.6502, -0.7997],
        [-0.6915, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001092413003789261
Epoch 0, Step 65: train/loss = 0.699739396572113, train/raw-loss = 0.6996788382530212, train/logprobs = tensor([[-0.6589, -0.8636],
        [-0.6884, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020199100254103541
Epoch 0, Step 66: train/loss = 0.69378262758255, train/raw-loss = 0.693769633769989, train/logprobs = tensor([[-0.8262, -0.8056],
        [-0.8938, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.323985194787383e-05
Epoch 0, Step 67: train/loss = 0.6953132748603821, train/raw-loss = 0.6951296329498291, train/logprobs = tensor([[-0.7056, -0.8152],
        [-0.8111, -0.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006120934849604964
Epoch 0, Step 68: train/loss = 0.7392053604125977, train/raw-loss = 0.7391855716705322, train/logprobs = tensor([[-1.0942, -1.0234],
        [-1.0939, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.599811604246497e-05
Epoch 0, Step 69: train/loss = 0.7918360233306885, train/raw-loss = 0.7914098501205444, train/logprobs = tensor([[-1.0983, -1.2513],
        [-1.1631, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001420492073521018
Epoch 0, Step 70: train/loss = 0.701203465461731, train/raw-loss = 0.701189398765564, train/logprobs = tensor([[-0.9105, -0.7884],
        [-0.9575, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7056582843651995e-05
Epoch 0, Step 71: train/loss = 0.7228124141693115, train/raw-loss = 0.722763180732727, train/logprobs = tensor([[-1.0118, -0.8059],
        [-1.0663, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016411501565016806
Epoch 0, Step 72: train/loss = 0.6970192790031433, train/raw-loss = 0.6969572901725769, train/logprobs = tensor([[-0.9413, -0.8891],
        [-1.1032, -0.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002066006709355861
Epoch 0, Step 73: train/loss = 0.6987999081611633, train/raw-loss = 0.6987993717193604, train/logprobs = tensor([[-0.8990, -0.9627],
        [-0.8956, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9564722606446594e-06
Epoch 0, Step 74: train/loss = 0.7421062588691711, train/raw-loss = 0.741671085357666, train/logprobs = tensor([[-0.6788, -0.9357],
        [-0.7472, -0.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014505641302093863
Epoch 0, Step 75: train/loss = 0.6954790353775024, train/raw-loss = 0.6953861713409424, train/logprobs = tensor([[-0.8317, -0.9589],
        [-0.8389, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030966606573201716
Epoch 0, Step 76: train/loss = 0.7411574125289917, train/raw-loss = 0.7411264181137085, train/logprobs = tensor([[-0.7789, -1.0369],
        [-0.8827, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010314300016034395
Epoch 0, Step 77: train/loss = 0.6957533955574036, train/raw-loss = 0.6957504749298096, train/logprobs = tensor([[-0.9139, -0.9507],
        [-0.9875, -0.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.573530405759811e-06
Epoch 0, Step 78: train/loss = 0.7286814451217651, train/raw-loss = 0.7283871173858643, train/logprobs = tensor([[-0.7678, -1.0284],
        [-0.8091, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009808815084397793
Epoch 0, Step 79: train/loss = 0.7031823396682739, train/raw-loss = 0.703021764755249, train/logprobs = tensor([[-0.8398, -0.8704],
        [-0.9008, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005350034916773438
Epoch 0, Step 80: train/loss = 0.6994823813438416, train/raw-loss = 0.6993646025657654, train/logprobs = tensor([[-0.6781, -0.7956],
        [-0.6858, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003925199853256345
Epoch 0, Step 81: train/loss = 0.704761266708374, train/raw-loss = 0.7045661211013794, train/logprobs = tensor([[-1.0100, -1.0474],
        [-1.1290, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000650368514470756
Epoch 0, Step 82: train/loss = 0.6943239569664001, train/raw-loss = 0.69380122423172, train/logprobs = tensor([[-0.9013, -1.0292],
        [-0.9864, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017425562255084515
Epoch 0, Step 83: train/loss = 0.7052397727966309, train/raw-loss = 0.7051759958267212, train/logprobs = tensor([[-0.7902, -0.8888],
        [-0.9631, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002126307226717472
Epoch 0, Step 84: train/loss = 0.698617160320282, train/raw-loss = 0.6986085176467896, train/logprobs = tensor([[-0.9557, -0.7941],
        [-1.3390, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.878281520679593e-05
Epoch 0, Step 85: train/loss = 0.752517819404602, train/raw-loss = 0.7523464560508728, train/logprobs = tensor([[-1.2599, -1.5447],
        [-1.3323, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005710807163268328
Epoch 0, Step 86: train/loss = 0.6930961608886719, train/raw-loss = 0.6930636763572693, train/logprobs = tensor([[-0.7828, -0.8002],
        [-0.8248, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010819768067449331
Epoch 0, Step 87: train/loss = 0.7058818340301514, train/raw-loss = 0.7058508396148682, train/logprobs = tensor([[-0.7417, -0.8123],
        [-0.7899, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010337299318052828
Epoch 0, Step 88: train/loss = 0.7011159062385559, train/raw-loss = 0.7010045051574707, train/logprobs = tensor([[-0.7182, -0.9543],
        [-0.7439, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037137343315407634
Epoch 0, Step 89: train/loss = 0.6942729949951172, train/raw-loss = 0.6942278146743774, train/logprobs = tensor([[-0.8597, -0.9463],
        [-0.9673, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015048091881908476
Epoch 0, Step 90: train/loss = 0.7492895126342773, train/raw-loss = 0.749092698097229, train/logprobs = tensor([[-0.7212, -1.2714],
        [-0.8110, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006560310139320791
Epoch 0, Step 91: train/loss = 0.7119872570037842, train/raw-loss = 0.7119823694229126, train/logprobs = tensor([[-0.8918, -0.9529],
        [-0.9039, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6127320122905076e-05
Epoch 0, Step 92: train/loss = 0.7480467557907104, train/raw-loss = 0.7465353608131409, train/logprobs = tensor([[-0.7220, -1.3115],
        [-0.7640, -1.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005037979688495398
Epoch 0, Step 93: train/loss = 0.7010120153427124, train/raw-loss = 0.7006476521492004, train/logprobs = tensor([[-0.6812, -0.8128],
        [-0.7461, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012144413776695728
Epoch 0, Step 94: train/loss = 0.7122175693511963, train/raw-loss = 0.7121354341506958, train/logprobs = tensor([[-0.9856, -0.8947],
        [-1.0792, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002739800838753581
Epoch 0, Step 95: train/loss = 0.700822114944458, train/raw-loss = 0.7007969617843628, train/logprobs = tensor([[-0.7175, -0.7880],
        [-0.7623, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.390661241719499e-05
Epoch 0, Step 96: train/loss = 0.6980928182601929, train/raw-loss = 0.6977742910385132, train/logprobs = tensor([[-0.7902, -0.9787],
        [-0.8792, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010616738582029939
Epoch 0, Step 97: train/loss = 0.6977806687355042, train/raw-loss = 0.6977637410163879, train/logprobs = tensor([[-0.7184, -0.7948],
        [-0.8144, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6375167332589626e-05
Epoch 0, Step 98: train/loss = 0.6913937330245972, train/raw-loss = 0.6911004781723022, train/logprobs = tensor([[-0.8838, -0.9239],
        [-0.9589, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000977454474195838
Epoch 0, Step 99: train/loss = 0.7146313190460205, train/raw-loss = 0.7146151065826416, train/logprobs = tensor([[-0.8818, -0.8273],
        [-0.9191, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.412864265963435e-05
Epoch 0, Step 100: train/loss = 0.6961897611618042, train/raw-loss = 0.6960081458091736, train/logprobs = tensor([[-0.6939, -0.7364],
        [-0.7413, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006054024561308324
Epoch 0, Step 101: train/loss = 0.6964975595474243, train/raw-loss = 0.6964775919914246, train/logprobs = tensor([[-0.5377, -0.6545],
        [-0.5673, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.645198300248012e-05
Epoch 0, Step 102: train/loss = 0.7199718356132507, train/raw-loss = 0.7198760509490967, train/logprobs = tensor([[-1.0406, -0.8454],
        [-1.0587, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031948357354849577
Epoch 0, Step 103: train/loss = 0.7037507891654968, train/raw-loss = 0.7035422921180725, train/logprobs = tensor([[-0.8824, -0.8214],
        [-0.9578, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006950210081413388
Epoch 0, Step 104: train/loss = 0.714069664478302, train/raw-loss = 0.7140610218048096, train/logprobs = tensor([[-0.7979, -0.5452],
        [-0.8103, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.872373443096876e-05
Epoch 0, Step 105: train/loss = 0.6982530355453491, train/raw-loss = 0.6982475519180298, train/logprobs = tensor([[-0.6392, -0.8497],
        [-0.6861, -0.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8166363588534296e-05
Epoch 0, Step 106: train/loss = 0.7413583993911743, train/raw-loss = 0.7412731647491455, train/logprobs = tensor([[-0.6873, -1.1049],
        [-0.7406, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002842693356797099
Epoch 0, Step 107: train/loss = 0.7008958458900452, train/raw-loss = 0.7008707523345947, train/logprobs = tensor([[-0.6754, -0.6089],
        [-0.7431, -0.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.33994708955288e-05
Epoch 0, Step 108: train/loss = 0.6983339190483093, train/raw-loss = 0.6982074975967407, train/logprobs = tensor([[-0.8328, -1.0043],
        [-0.9080, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004212722706142813
Epoch 0, Step 109: train/loss = 0.6985849738121033, train/raw-loss = 0.697882890701294, train/logprobs = tensor([[-0.7996, -0.9494],
        [-0.8981, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002340418752282858
Epoch 0, Step 110: train/loss = 0.7121159434318542, train/raw-loss = 0.7117724418640137, train/logprobs = tensor([[-0.7285, -0.6159],
        [-0.7810, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001144991721957922
Epoch 0, Step 111: train/loss = 0.7059081196784973, train/raw-loss = 0.705896258354187, train/logprobs = tensor([[-0.6756, -0.9077],
        [-0.7132, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9517290133517236e-05
Epoch 0, Step 112: train/loss = 0.6970753073692322, train/raw-loss = 0.6969931125640869, train/logprobs = tensor([[-0.6512, -0.8326],
        [-0.7361, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027404946740716696
Epoch 0, Step 113: train/loss = 0.7081416845321655, train/raw-loss = 0.7080774307250977, train/logprobs = tensor([[-0.8245, -0.8439],
        [-0.8218, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021413090871647
Epoch 0, Step 114: train/loss = 0.6963573098182678, train/raw-loss = 0.6962997913360596, train/logprobs = tensor([[-0.7695, -0.8491],
        [-0.8464, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019163417164236307
Epoch 0, Step 115: train/loss = 0.7002174258232117, train/raw-loss = 0.6999063491821289, train/logprobs = tensor([[-0.7171, -1.0048],
        [-0.7956, -0.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010368905495852232
Epoch 0, Step 116: train/loss = 0.721777617931366, train/raw-loss = 0.7217450141906738, train/logprobs = tensor([[-0.8506, -0.4950],
        [-1.0473, -0.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001087664277292788
Epoch 0, Step 117: train/loss = 0.7028974294662476, train/raw-loss = 0.7027266025543213, train/logprobs = tensor([[-0.8438, -0.7359],
        [-0.9252, -0.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005696634761989117
Epoch 0, Step 118: train/loss = 0.6996423006057739, train/raw-loss = 0.6995854377746582, train/logprobs = tensor([[-0.5748, -0.7528],
        [-0.6475, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001896344474516809
Epoch 0, Step 119: train/loss = 0.6951929330825806, train/raw-loss = 0.6948056817054749, train/logprobs = tensor([[-0.6280, -0.6858],
        [-0.6557, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012910286895930767
Epoch 0, Step 120: train/loss = 0.7260409593582153, train/raw-loss = 0.7257551550865173, train/logprobs = tensor([[-1.0431, -0.9249],
        [-1.2277, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009526055655442178
Epoch 0, Step 121: train/loss = 0.696230411529541, train/raw-loss = 0.6961841583251953, train/logprobs = tensor([[-0.7059, -0.8255],
        [-0.6877, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001542194513604045
Epoch 0, Step 122: train/loss = 0.7147625684738159, train/raw-loss = 0.7145088315010071, train/logprobs = tensor([[-1.0103, -0.7235],
        [-1.0822, -0.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000845934497192502
Epoch 0, Step 123: train/loss = 0.6938454508781433, train/raw-loss = 0.6938378214836121, train/logprobs = tensor([[-0.7332, -0.7654],
        [-0.7988, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5374116376042366e-05
Epoch 0, Step 124: train/loss = 0.7044868469238281, train/raw-loss = 0.7043716907501221, train/logprobs = tensor([[-0.6765, -0.5712],
        [-0.7243, -0.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003835107199847698
Epoch 0, Step 125: train/loss = 0.7013206481933594, train/raw-loss = 0.701190710067749, train/logprobs = tensor([[-0.8934, -0.8484],
        [-0.9755, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004329549556132406
Epoch 0, Step 126: train/loss = 0.7188923358917236, train/raw-loss = 0.7188205718994141, train/logprobs = tensor([[-0.9158, -1.1509],
        [-0.9831, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023908051662147045
Epoch 0, Step 127: train/loss = 0.7094557881355286, train/raw-loss = 0.7093707323074341, train/logprobs = tensor([[-0.6887, -0.9054],
        [-0.7048, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002835564664565027
Epoch 0, Step 128: train/loss = 0.7460401058197021, train/raw-loss = 0.7458690404891968, train/logprobs = tensor([[-0.9390, -0.4723],
        [-0.9423, -0.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005702036432921886
Epoch 0, Step 129: train/loss = 0.7086096405982971, train/raw-loss = 0.7085305452346802, train/logprobs = tensor([[-0.7932, -0.5850],
        [-0.8124, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026355742011219263
Epoch 0, Step 130: train/loss = 0.7088053226470947, train/raw-loss = 0.7085090279579163, train/logprobs = tensor([[-0.8548, -0.6857],
        [-0.9662, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009874976240098476
Epoch 0, Step 131: train/loss = 0.6967582702636719, train/raw-loss = 0.6966269612312317, train/logprobs = tensor([[-0.6878, -0.7560],
        [-0.7429, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004377000732347369
Epoch 0, Step 132: train/loss = 0.6958649158477783, train/raw-loss = 0.6958154439926147, train/logprobs = tensor([[-0.8276, -0.7713],
        [-0.9116, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016498329932801425
Epoch 0, Step 133: train/loss = 0.6976945400238037, train/raw-loss = 0.6975933313369751, train/logprobs = tensor([[-0.6350, -0.7504],
        [-0.7089, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033747823908925056
Epoch 0, Step 134: train/loss = 0.7731704711914062, train/raw-loss = 0.773098349571228, train/logprobs = tensor([[-0.9559, -0.9074],
        [-1.0438, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024011557979974896
Epoch 0, Step 135: train/loss = 0.6976069808006287, train/raw-loss = 0.6975865364074707, train/logprobs = tensor([[-0.6012, -0.6106],
        [-0.5833, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.812001811340451e-05
Epoch 0, Step 136: train/loss = 0.7032503485679626, train/raw-loss = 0.7032406330108643, train/logprobs = tensor([[-0.7920, -0.7240],
        [-1.0763, -0.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.248488064855337e-05
Epoch 0, Step 137: train/loss = 0.7149927020072937, train/raw-loss = 0.7127819061279297, train/logprobs = tensor([[-0.5393, -0.8790],
        [-0.5981, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073691788129508495
Epoch 0, Step 138: train/loss = 0.7019177675247192, train/raw-loss = 0.7018797993659973, train/logprobs = tensor([[-0.5574, -0.4694],
        [-0.6006, -0.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001265627215616405
Epoch 0, Step 139: train/loss = 0.7100142240524292, train/raw-loss = 0.7098872065544128, train/logprobs = tensor([[-0.5297, -0.7131],
        [-0.5584, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004234348889440298
Epoch 0, Step 140: train/loss = 0.7170431613922119, train/raw-loss = 0.7169988751411438, train/logprobs = tensor([[-0.6007, -0.8312],
        [-0.5979, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014761774218641222
Epoch 0, Step 141: train/loss = 0.7198868989944458, train/raw-loss = 0.7197598218917847, train/logprobs = tensor([[-0.5090, -0.8329],
        [-0.5554, -0.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004236229578964412
Epoch 0, Step 142: train/loss = 0.7001736760139465, train/raw-loss = 0.7000390291213989, train/logprobs = tensor([[-0.7525, -0.6404],
        [-0.8477, -0.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004489724524319172
Epoch 0, Step 143: train/loss = 0.6870719194412231, train/raw-loss = 0.6863335371017456, train/logprobs = tensor([[-0.8299, -0.7939],
        [-1.3154, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024613356217741966
Epoch 0, Step 144: train/loss = 0.7203385233879089, train/raw-loss = 0.7198454141616821, train/logprobs = tensor([[-0.7852, -0.7609],
        [-0.8648, -0.7744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016436880687251687
Epoch 0, Step 145: train/loss = 0.7071443200111389, train/raw-loss = 0.7071143984794617, train/logprobs = tensor([[-0.7979, -0.6479],
        [-0.8357, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.968461381504312e-05
Epoch 0, Step 146: train/loss = 0.7659755945205688, train/raw-loss = 0.7658097743988037, train/logprobs = tensor([[-0.8517, -0.5499],
        [-0.9245, -0.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005528344190679491
Epoch 0, Step 147: train/loss = 0.7035880088806152, train/raw-loss = 0.7034617066383362, train/logprobs = tensor([[-0.6277, -0.7290],
        [-0.7219, -0.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042111199581995606
Epoch 0, Step 148: train/loss = 0.7071534991264343, train/raw-loss = 0.7071502208709717, train/logprobs = tensor([[-0.6685, -0.4897],
        [-0.6698, -0.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0908202966675162e-05
Epoch 0, Step 149: train/loss = 0.6975424885749817, train/raw-loss = 0.697453498840332, train/logprobs = tensor([[-0.7244, -0.7026],
        [-0.7939, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029660004656761885
Epoch 0, Step 150: train/loss = 0.6959127187728882, train/raw-loss = 0.6958988904953003, train/logprobs = tensor([[-0.6855, -0.6601],
        [-0.7052, -0.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.617602098733187e-05
Epoch 0, Step 151: train/loss = 0.69620680809021, train/raw-loss = 0.6962009072303772, train/logprobs = tensor([[-0.7193, -0.7315],
        [-0.7458, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9669634639285505e-05
Epoch 0, Step 152: train/loss = 0.7116811275482178, train/raw-loss = 0.7115107178688049, train/logprobs = tensor([[-0.7579, -0.5690],
        [-0.8491, -0.5445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005682085175067186
Epoch 0, Step 153: train/loss = 0.6958659887313843, train/raw-loss = 0.6958460807800293, train/logprobs = tensor([[-0.5512, -0.6704],
        [-0.6097, -0.5946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.629656854784116e-05
Epoch 0, Step 154: train/loss = 0.6960178017616272, train/raw-loss = 0.6958574652671814, train/logprobs = tensor([[-0.6761, -0.6309],
        [-0.7828, -0.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005345424870029092
Epoch 0, Step 155: train/loss = 0.710783839225769, train/raw-loss = 0.7106762528419495, train/logprobs = tensor([[-0.5533, -0.7794],
        [-0.5701, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003586226375773549
Epoch 0, Step 156: train/loss = 0.7082491517066956, train/raw-loss = 0.7082206010818481, train/logprobs = tensor([[-0.5037, -0.6560],
        [-0.5316, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.503081673756242e-05
Epoch 0, Step 157: train/loss = 0.7328035831451416, train/raw-loss = 0.7308886051177979, train/logprobs = tensor([[-0.9215, -0.6475],
        [-0.9635, -0.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006383243948221207
Epoch 0, Step 158: train/loss = 0.7456321716308594, train/raw-loss = 0.7455234527587891, train/logprobs = tensor([[-0.9953, -0.5932],
        [-0.9967, -0.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003623652155511081
Epoch 0, Step 159: train/loss = 0.7051679491996765, train/raw-loss = 0.7051020264625549, train/logprobs = tensor([[-0.5820, -0.8724],
        [-0.5789, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021966500207781792
Epoch 0, Step 160: train/loss = 0.6955075860023499, train/raw-loss = 0.6952745914459229, train/logprobs = tensor([[-0.7806, -0.7256],
        [-0.8480, -0.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007765754708088934
Epoch 0, Step 161: train/loss = 0.6919831037521362, train/raw-loss = 0.6911509037017822, train/logprobs = tensor([[-0.6105, -0.6826],
        [-0.6739, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027739231009036303
Epoch 0, Step 162: train/loss = 0.7035112977027893, train/raw-loss = 0.7029719352722168, train/logprobs = tensor([[-0.7995, -0.8124],
        [-0.9003, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001797939999960363
Epoch 0, Step 163: train/loss = 0.7013144493103027, train/raw-loss = 0.7012501358985901, train/logprobs = tensor([[-0.8481, -0.7192],
        [-0.9953, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021444473532028496
Epoch 0, Step 164: train/loss = 0.7101725339889526, train/raw-loss = 0.7100405097007751, train/logprobs = tensor([[-0.6789, -0.9564],
        [-0.7556, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004398814053274691
Epoch 0, Step 165: train/loss = 0.8071184158325195, train/raw-loss = 0.8070268034934998, train/logprobs = tensor([[-0.8526, -1.3744],
        [-0.9374, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003053836990147829
Epoch 0, Step 166: train/loss = 0.7085285186767578, train/raw-loss = 0.7084319591522217, train/logprobs = tensor([[-0.7878, -0.8420],
        [-0.8206, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003221214283257723
Epoch 0, Step 167: train/loss = 0.699948251247406, train/raw-loss = 0.6997019052505493, train/logprobs = tensor([[-0.6635, -0.7676],
        [-0.7026, -0.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000821112422272563
Epoch 0, Step 168: train/loss = 0.6951150298118591, train/raw-loss = 0.695087730884552, train/logprobs = tensor([[-0.6710, -0.7339],
        [-0.7128, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.084719931706786e-05
Epoch 0, Step 169: train/loss = 0.6944527626037598, train/raw-loss = 0.69439297914505, train/logprobs = tensor([[-0.5317, -0.5027],
        [-0.5521, -0.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019948225235566497
Epoch 0, Step 170: train/loss = 0.694908082485199, train/raw-loss = 0.6948543787002563, train/logprobs = tensor([[-0.7204, -0.6911],
        [-0.7563, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001790727546904236
Epoch 0, Step 171: train/loss = 0.6977090835571289, train/raw-loss = 0.6973648071289062, train/logprobs = tensor([[-0.6009, -0.7250],
        [-0.6332, -0.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011476825457066298
Epoch 0, Step 172: train/loss = 0.7252813577651978, train/raw-loss = 0.7252696752548218, train/logprobs = tensor([[-0.9625, -0.7798],
        [-1.0403, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.891138476319611e-05
Epoch 0, Step 173: train/loss = 0.7029146552085876, train/raw-loss = 0.7002676725387573, train/logprobs = tensor([[-0.6823, -0.9864],
        [-0.6445, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008823280222713947
Epoch 0, Step 174: train/loss = 0.6888560056686401, train/raw-loss = 0.6867612600326538, train/logprobs = tensor([[-0.6146, -0.7518],
        [-0.7026, -0.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006982417311519384
Epoch 0, Step 175: train/loss = 0.699248194694519, train/raw-loss = 0.6987845301628113, train/logprobs = tensor([[-0.9014, -0.8958],
        [-1.0041, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015455014072358608
Epoch 0, Step 176: train/loss = 0.6991221904754639, train/raw-loss = 0.6987663507461548, train/logprobs = tensor([[-0.7973, -0.8123],
        [-0.8558, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001186477136798203
Epoch 0, Step 177: train/loss = 0.6963940858840942, train/raw-loss = 0.6963099241256714, train/logprobs = tensor([[-0.8384, -0.8162],
        [-0.9565, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002805482945404947
Epoch 0, Step 178: train/loss = 0.6837029457092285, train/raw-loss = 0.674828290939331, train/logprobs = tensor([[-0.7041, -1.3678],
        [-0.8430, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029582282528281212
Epoch 0, Step 179: train/loss = 0.6988362073898315, train/raw-loss = 0.6987646818161011, train/logprobs = tensor([[-0.6091, -0.5576],
        [-0.5970, -0.4703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023848493583500385
Epoch 0, Step 180: train/loss = 0.7169800400733948, train/raw-loss = 0.7164296507835388, train/logprobs = tensor([[-0.7252, -0.6352],
        [-0.8261, -0.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018347156001254916
Epoch 0, Step 181: train/loss = 0.7028478384017944, train/raw-loss = 0.70232093334198, train/logprobs = tensor([[-0.6853, -0.7473],
        [-0.7153, -0.6247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017560397973284125
Epoch 0, Step 182: train/loss = 0.7082470655441284, train/raw-loss = 0.7081855535507202, train/logprobs = tensor([[-0.8091, -0.9825],
        [-0.8267, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002049971662927419
Epoch 0, Step 183: train/loss = 0.6993287801742554, train/raw-loss = 0.6987810134887695, train/logprobs = tensor([[-0.7169, -0.8299],
        [-0.7778, -0.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018260304350405931
Epoch 0, Step 184: train/loss = 0.7006706595420837, train/raw-loss = 0.7005857229232788, train/logprobs = tensor([[-0.7947, -0.7014],
        [-0.8410, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028331915382295847
Epoch 0, Step 185: train/loss = 0.6938177347183228, train/raw-loss = 0.6934688687324524, train/logprobs = tensor([[-0.7717, -1.0947],
        [-0.8010, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011628532083705068
Epoch 0, Step 186: train/loss = 0.7035099267959595, train/raw-loss = 0.7034048438072205, train/logprobs = tensor([[-0.8937, -0.7626],
        [-0.9079, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035029230639338493
Epoch 0, Step 187: train/loss = 0.6941220760345459, train/raw-loss = 0.693423867225647, train/logprobs = tensor([[-0.6625, -0.7525],
        [-0.7340, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023273108527064323
Epoch 0, Step 188: train/loss = 0.703241229057312, train/raw-loss = 0.7031961679458618, train/logprobs = tensor([[-0.7191, -0.8044],
        [-0.7589, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015034496027510613
Epoch 0, Step 189: train/loss = 0.7057191133499146, train/raw-loss = 0.7056362628936768, train/logprobs = tensor([[-0.5362, -0.6690],
        [-0.6827, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027612101985141635
Epoch 0, Step 190: train/loss = 0.6934099197387695, train/raw-loss = 0.693077802658081, train/logprobs = tensor([[-0.5609, -0.6616],
        [-0.6512, -0.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011069421889260411
Epoch 0, Step 191: train/loss = 0.6949602365493774, train/raw-loss = 0.6949596405029297, train/logprobs = tensor([[-0.7719, -0.7129],
        [-0.7448, -0.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.082504579448141e-06
Epoch 0, Step 192: train/loss = 0.6938232183456421, train/raw-loss = 0.693698525428772, train/logprobs = tensor([[-0.6335, -0.6065],
        [-0.6821, -0.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004155116621404886
Epoch 0, Step 193: train/loss = 0.7048139572143555, train/raw-loss = 0.7043758630752563, train/logprobs = tensor([[-0.5715, -0.9420],
        [-0.7058, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014602297451347113
Epoch 0, Step 194: train/loss = 0.7196454405784607, train/raw-loss = 0.7162907123565674, train/logprobs = tensor([[-0.7538, -1.1688],
        [-0.9143, -0.7817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011182494461536407
Epoch 0, Step 195: train/loss = 0.7440446019172668, train/raw-loss = 0.7439433336257935, train/logprobs = tensor([[-1.0350, -0.8400],
        [-1.1065, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033764925319701433
Epoch 0, Step 196: train/loss = 0.6938951015472412, train/raw-loss = 0.6925073862075806, train/logprobs = tensor([[-0.9828, -0.9703],
        [-1.0269, -0.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004625496454536915
Epoch 0, Step 197: train/loss = 0.7224805951118469, train/raw-loss = 0.7221696376800537, train/logprobs = tensor([[-0.6167, -0.9503],
        [-0.6637, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001036516623571515
Epoch 0, Step 198: train/loss = 0.7275500297546387, train/raw-loss = 0.7267919182777405, train/logprobs = tensor([[-1.2962, -1.1710],
        [-1.3125, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00252689141780138
Epoch 0, Step 199: train/loss = 0.7038629055023193, train/raw-loss = 0.7029821872711182, train/logprobs = tensor([[-0.8443, -0.8725],
        [-0.9012, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029358379542827606
Epoch 0, Step 200: train/loss = 0.6952263116836548, train/raw-loss = 0.694969117641449, train/logprobs = tensor([[-0.7844, -0.8289],
        [-0.8033, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000857406877912581
Epoch 0, Step 201: train/loss = 0.7005434632301331, train/raw-loss = 0.6978591680526733, train/logprobs = tensor([[-0.7652, -1.2571],
        [-0.9407, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008947453461587429
Epoch 0, Step 202: train/loss = 0.6965184807777405, train/raw-loss = 0.6963099241256714, train/logprobs = tensor([[-0.9952, -0.9114],
        [-1.0045, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006953057600185275
Epoch 0, Step 203: train/loss = 0.6984607577323914, train/raw-loss = 0.6971539258956909, train/logprobs = tensor([[-0.7092, -0.9184],
        [-0.8082, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004356081131845713
Epoch 0, Step 204: train/loss = 0.7036652565002441, train/raw-loss = 0.7019965648651123, train/logprobs = tensor([[-0.8154, -1.0554],
        [-0.8563, -0.8228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005562460981309414
Epoch 0, Step 205: train/loss = 0.7005733251571655, train/raw-loss = 0.7005330920219421, train/logprobs = tensor([[-0.8338, -0.6941],
        [-0.8840, -0.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013417079753708094
Epoch 0, Step 206: train/loss = 0.697697103023529, train/raw-loss = 0.6976684331893921, train/logprobs = tensor([[-0.6214, -0.5085],
        [-0.6936, -0.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.548642992740497e-05
Epoch 0, Step 207: train/loss = 0.6973193883895874, train/raw-loss = 0.697009801864624, train/logprobs = tensor([[-0.7012, -0.9436],
        [-0.7447, -0.8149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010321795707568526
Epoch 0, Step 208: train/loss = 0.6959718465805054, train/raw-loss = 0.6957356333732605, train/logprobs = tensor([[-0.6711, -0.6948],
        [-0.6542, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007873829454183578
Epoch 0, Step 209: train/loss = 0.7583181858062744, train/raw-loss = 0.7579622268676758, train/logprobs = tensor([[-0.7990, -1.1367],
        [-0.8037, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011865276610478759
Epoch 0, Step 210: train/loss = 0.6940164566040039, train/raw-loss = 0.694006621837616, train/logprobs = tensor([[-0.6641, -0.6981],
        [-0.6733, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.288105654064566e-05
Epoch 0, Step 211: train/loss = 0.7000828981399536, train/raw-loss = 0.6999417543411255, train/logprobs = tensor([[-0.7309, -0.7123],
        [-0.7670, -0.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047037098556756973
Epoch 0, Step 212: train/loss = 0.7085400819778442, train/raw-loss = 0.707260012626648, train/logprobs = tensor([[-0.7179, -0.9387],
        [-0.7887, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004267118871212006
Epoch 0, Step 213: train/loss = 0.7952932119369507, train/raw-loss = 0.7914637327194214, train/logprobs = tensor([[-0.8180, -1.3294],
        [-0.9303, -1.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012765059247612953
Epoch 0, Step 214: train/loss = 0.6967286467552185, train/raw-loss = 0.6966948509216309, train/logprobs = tensor([[-0.6117, -0.5248],
        [-0.7280, -0.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011245565838180482
Epoch 0, Step 215: train/loss = 0.7026753425598145, train/raw-loss = 0.7022963762283325, train/logprobs = tensor([[-0.6444, -0.8590],
        [-0.6478, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012634831946343184
Epoch 0, Step 216: train/loss = 0.7149820923805237, train/raw-loss = 0.7131867408752441, train/logprobs = tensor([[-0.8278, -1.0516],
        [-0.8211, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005984392482787371
Epoch 0, Step 217: train/loss = 0.6946195363998413, train/raw-loss = 0.6943461298942566, train/logprobs = tensor([[-0.6867, -0.6595],
        [-0.8287, -0.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009113744017668068
Epoch 0, Step 218: train/loss = 0.7107821702957153, train/raw-loss = 0.7103681564331055, train/logprobs = tensor([[-0.9394, -0.7844],
        [-1.0033, -0.6123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013801716268062592
Epoch 0, Step 219: train/loss = 0.7148114442825317, train/raw-loss = 0.7144365906715393, train/logprobs = tensor([[-0.6621, -0.9636],
        [-0.8336, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012496225535869598
Epoch 0, Step 220: train/loss = 0.7003151178359985, train/raw-loss = 0.6988597512245178, train/logprobs = tensor([[-0.7989, -1.0396],
        [-0.8344, -0.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004851259291172028
Epoch 0, Step 221: train/loss = 0.6952906847000122, train/raw-loss = 0.6942572593688965, train/logprobs = tensor([[-0.7924, -0.7802],
        [-0.7998, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003444671630859375
Epoch 0, Step 222: train/loss = 0.6941673159599304, train/raw-loss = 0.6937568187713623, train/logprobs = tensor([[-0.6984, -0.7150],
        [-0.8012, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013685476733371615
Epoch 0, Step 223: train/loss = 0.7043022513389587, train/raw-loss = 0.7039709687232971, train/logprobs = tensor([[-0.7396, -0.6207],
        [-0.8086, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001104022259823978
Epoch 0, Step 224: train/loss = 0.737957239151001, train/raw-loss = 0.7364394068717957, train/logprobs = tensor([[-1.1840, -1.1525],
        [-1.2868, -1.0008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005059336312115192
Epoch 0, Step 225: train/loss = 0.7256327271461487, train/raw-loss = 0.7244560718536377, train/logprobs = tensor([[-0.9048, -1.2055],
        [-1.0683, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039220890030264854
Epoch 0, Step 226: train/loss = 0.7157199382781982, train/raw-loss = 0.7151482701301575, train/logprobs = tensor([[-0.9535, -0.8440],
        [-1.0432, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001905412063933909
Epoch 0, Step 227: train/loss = 0.7098367810249329, train/raw-loss = 0.7062563896179199, train/logprobs = tensor([[-0.6611, -1.2861],
        [-0.7279, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011934732086956501
Epoch 0, Step 228: train/loss = 0.6861569285392761, train/raw-loss = 0.6792964935302734, train/logprobs = tensor([[-1.0338, -1.4630],
        [-0.9301, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022867998108267784
Epoch 0, Step 229: train/loss = 0.7003201246261597, train/raw-loss = 0.6998274326324463, train/logprobs = tensor([[-0.7218, -1.0120],
        [-0.7170, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016423261258751154
Epoch 0, Step 230: train/loss = 0.7302341461181641, train/raw-loss = 0.7267005443572998, train/logprobs = tensor([[-0.6176, -1.3590],
        [-0.6351, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011778783053159714
Epoch 0, Step 231: train/loss = 0.6962724924087524, train/raw-loss = 0.6959337592124939, train/logprobs = tensor([[-0.5785, -0.6934],
        [-0.6048, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011291466653347015
Epoch 0, Step 232: train/loss = 0.7058661580085754, train/raw-loss = 0.7056784629821777, train/logprobs = tensor([[-0.7531, -0.9122],
        [-0.7853, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006256833439692855
Epoch 0, Step 233: train/loss = 0.6914841532707214, train/raw-loss = 0.6847119331359863, train/logprobs = tensor([[-0.7664, -1.1729],
        [-0.8349, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02257383242249489
Epoch 0, Step 234: train/loss = 0.7088754177093506, train/raw-loss = 0.7085232138633728, train/logprobs = tensor([[-0.9500, -0.7731],
        [-1.0331, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001173960161395371
Epoch 0, Step 235: train/loss = 0.6937251091003418, train/raw-loss = 0.6931913495063782, train/logprobs = tensor([[-0.7376, -0.7746],
        [-0.8125, -0.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017791250720620155
Epoch 0, Step 236: train/loss = 0.7133947014808655, train/raw-loss = 0.7029523849487305, train/logprobs = tensor([[-1.1086, -1.8467],
        [-0.9394, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03480753302574158
Epoch 0, Step 237: train/loss = 0.6956758499145508, train/raw-loss = 0.6937519311904907, train/logprobs = tensor([[-0.8187, -0.9286],
        [-0.8051, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006413068622350693
Epoch 0, Step 238: train/loss = 0.7097374200820923, train/raw-loss = 0.7075649499893188, train/logprobs = tensor([[-0.6478, -0.8384],
        [-0.6746, -0.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007241742219775915
Epoch 0, Step 239: train/loss = 0.7046480774879456, train/raw-loss = 0.7042906880378723, train/logprobs = tensor([[-0.8003, -0.7679],
        [-0.8501, -0.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011912521440535784
Epoch 0, Step 240: train/loss = 0.6984169483184814, train/raw-loss = 0.6983627080917358, train/logprobs = tensor([[-0.9349, -0.8494],
        [-0.8921, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000180660659680143
Epoch 0, Step 241: train/loss = 0.7560603618621826, train/raw-loss = 0.7536354064941406, train/logprobs = tensor([[-1.0038, -1.2064],
        [-1.0902, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008083446882665157
Epoch 0, Step 242: train/loss = 0.6977862119674683, train/raw-loss = 0.6863820552825928, train/logprobs = tensor([[-0.8597, -1.4834],
        [-1.0158, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03801403567194939
Epoch 0, Step 243: train/loss = 0.7053797245025635, train/raw-loss = 0.7029658555984497, train/logprobs = tensor([[-0.9843, -1.4476],
        [-1.0652, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00804629735648632
Epoch 0, Step 244: train/loss = 0.6945883631706238, train/raw-loss = 0.6929367780685425, train/logprobs = tensor([[-0.8608, -1.1117],
        [-0.8291, -0.8035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005505366250872612
Epoch 0, Step 245: train/loss = 0.7414119839668274, train/raw-loss = 0.7410731911659241, train/logprobs = tensor([[-0.7266, -1.1651],
        [-0.7783, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011293720453977585
Epoch 0, Step 246: train/loss = 0.7240262031555176, train/raw-loss = 0.7217418551445007, train/logprobs = tensor([[-1.0240, -0.7237],
        [-1.2440, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007614506408572197
Epoch 0, Step 247: train/loss = 0.7091550827026367, train/raw-loss = 0.7088668346405029, train/logprobs = tensor([[-0.6859, -0.9039],
        [-0.7352, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000960620935074985
Epoch 0, Step 248: train/loss = 0.7200947999954224, train/raw-loss = 0.7192515134811401, train/logprobs = tensor([[-0.9793, -1.5082],
        [-0.9453, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002811165526509285
Epoch 0, Step 249: train/loss = 0.6955568790435791, train/raw-loss = 0.6955441832542419, train/logprobs = tensor([[-0.6388, -0.8012],
        [-0.6252, -0.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.243614966981113e-05
Epoch 0, Step 250: train/loss = 0.6949013471603394, train/raw-loss = 0.6941909790039062, train/logprobs = tensor([[-0.6883, -0.8642],
        [-0.8200, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023678408470004797
Epoch 0, Step 251: train/loss = 0.7219702005386353, train/raw-loss = 0.7188878059387207, train/logprobs = tensor([[-0.8709, -1.3948],
        [-0.9421, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010274550877511501
Epoch 0, Step 252: train/loss = 0.7143760919570923, train/raw-loss = 0.7143216133117676, train/logprobs = tensor([[-0.7221, -0.9285],
        [-0.7599, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018157975864596665
Epoch 0, Step 253: train/loss = 0.7041734457015991, train/raw-loss = 0.7017601728439331, train/logprobs = tensor([[-0.9598, -0.8579],
        [-1.0522, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00804431177675724
Epoch 0, Step 254: train/loss = 0.7162868976593018, train/raw-loss = 0.7145159840583801, train/logprobs = tensor([[-0.8302, -1.3788],
        [-0.9185, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005903088487684727
Epoch 0, Step 255: train/loss = 0.7136643528938293, train/raw-loss = 0.7124302983283997, train/logprobs = tensor([[-0.6084, -0.7632],
        [-0.8414, -0.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004113542847335339
Epoch 0, Step 256: train/loss = 0.6962700486183167, train/raw-loss = 0.695905327796936, train/logprobs = tensor([[-1.1098, -1.0679],
        [-0.9910, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001215689000673592
Epoch 0, Step 257: train/loss = 0.6919609904289246, train/raw-loss = 0.689431369304657, train/logprobs = tensor([[-0.9936, -1.3088],
        [-0.9421, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008432090282440186
Epoch 0, Step 258: train/loss = 0.6898661851882935, train/raw-loss = 0.6818827986717224, train/logprobs = tensor([[-0.8339, -1.4106],
        [-1.1636, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026611261069774628
Epoch 0, Step 259: train/loss = 0.6954508423805237, train/raw-loss = 0.6944714784622192, train/logprobs = tensor([[-0.7132, -0.9538],
        [-0.7002, -0.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032644819002598524
Epoch 0, Step 260: train/loss = 0.7133854627609253, train/raw-loss = 0.7086129188537598, train/logprobs = tensor([[-0.8294, -1.3194],
        [-0.8768, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01590859144926071
Epoch 0, Step 261: train/loss = 0.7109804153442383, train/raw-loss = 0.7104918956756592, train/logprobs = tensor([[-0.8311, -1.1882],
        [-0.8552, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016280299751088023
Epoch 0, Step 262: train/loss = 0.7154542207717896, train/raw-loss = 0.7124637365341187, train/logprobs = tensor([[-1.1133, -1.1990],
        [-1.1488, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009968597441911697
Epoch 0, Step 263: train/loss = 0.694420576095581, train/raw-loss = 0.6944167613983154, train/logprobs = tensor([[-0.5641, -0.5636],
        [-0.5703, -0.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2717024219455197e-05
Epoch 0, Step 264: train/loss = 0.7312402725219727, train/raw-loss = 0.7285798192024231, train/logprobs = tensor([[-0.7322, -1.3720],
        [-0.7676, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008868313394486904
Epoch 0, Step 265: train/loss = 0.7219030857086182, train/raw-loss = 0.719588041305542, train/logprobs = tensor([[-0.9545, -1.5072],
        [-0.9236, -1.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007716948166489601
Epoch 0, Step 266: train/loss = 0.7339726686477661, train/raw-loss = 0.7310760021209717, train/logprobs = tensor([[-1.0592, -1.2198],
        [-1.0822, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009655584581196308
Epoch 0, Step 267: train/loss = 0.6999998092651367, train/raw-loss = 0.699495792388916, train/logprobs = tensor([[-0.7744, -0.9786],
        [-0.7043, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016801295569166541
Epoch 0, Step 268: train/loss = 0.82028728723526, train/raw-loss = 0.8198986053466797, train/logprobs = tensor([[-0.9713, -1.7909],
        [-0.7214, -1.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012956146383658051
Epoch 0, Step 269: train/loss = 0.697437047958374, train/raw-loss = 0.6951038241386414, train/logprobs = tensor([[-0.8059, -1.1773],
        [-0.8080, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007777589373290539
Epoch 0, Step 270: train/loss = 0.716842532157898, train/raw-loss = 0.714732825756073, train/logprobs = tensor([[-0.6180, -1.1824],
        [-0.6059, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007032260298728943
Epoch 0, Step 271: train/loss = 0.701163649559021, train/raw-loss = 0.7009570598602295, train/logprobs = tensor([[-1.1048, -1.0160],
        [-1.1296, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000688621774315834
Epoch 0, Step 272: train/loss = 0.6977620720863342, train/raw-loss = 0.697361946105957, train/logprobs = tensor([[-0.9452, -0.8170],
        [-1.0002, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001333694439381361
Epoch 0, Step 273: train/loss = 0.6928489208221436, train/raw-loss = 0.6903612613677979, train/logprobs = tensor([[-0.8174, -1.0454],
        [-0.8555, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008292174898087978
Epoch 0, Step 274: train/loss = 0.8189446926116943, train/raw-loss = 0.8100903034210205, train/logprobs = tensor([[-0.8281, -1.7940],
        [-0.8273, -1.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029514731839299202
Epoch 0, Step 275: train/loss = 0.6995247602462769, train/raw-loss = 0.6991562247276306, train/logprobs = tensor([[-0.7235, -0.9226],
        [-0.7223, -0.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012284405529499054
Epoch 0, Step 276: train/loss = 0.7143557071685791, train/raw-loss = 0.7129616737365723, train/logprobs = tensor([[-0.8277, -1.0171],
        [-0.8271, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004646917339414358
Epoch 0, Step 277: train/loss = 0.6929242610931396, train/raw-loss = 0.6925979256629944, train/logprobs = tensor([[-1.0775, -1.1754],
        [-0.8342, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010876754531636834
Epoch 0, Step 278: train/loss = 0.6970579028129578, train/raw-loss = 0.6939815282821655, train/logprobs = tensor([[-0.8167, -1.2091],
        [-0.7722, -0.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010254457592964172
Epoch 0, Step 279: train/loss = 0.6939103603363037, train/raw-loss = 0.6936922669410706, train/logprobs = tensor([[-1.0937, -1.2770],
        [-1.1673, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007268825429491699
Epoch 0, Step 280: train/loss = 0.7161121368408203, train/raw-loss = 0.7145811915397644, train/logprobs = tensor([[-0.7505, -1.0268],
        [-0.9086, -0.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005103191826492548
Epoch 0, Step 281: train/loss = 0.6936751008033752, train/raw-loss = 0.6920819282531738, train/logprobs = tensor([[-1.1812, -1.4695],
        [-1.0491, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005310540087521076
Epoch 0, Step 282: train/loss = 0.6997292041778564, train/raw-loss = 0.6997038125991821, train/logprobs = tensor([[-0.9477, -0.8764],
        [-0.8065, -0.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.458429510938004e-05
Epoch 0, Step 283: train/loss = 0.6852284669876099, train/raw-loss = 0.6824140548706055, train/logprobs = tensor([[-1.0026, -1.1892],
        [-1.1711, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009381287731230259
Epoch 0, Step 284: train/loss = 0.7004885673522949, train/raw-loss = 0.7004202604293823, train/logprobs = tensor([[-0.7898, -0.6310],
        [-0.7444, -0.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002276930317748338
Epoch 0, Step 285: train/loss = 0.7070099115371704, train/raw-loss = 0.7059065103530884, train/logprobs = tensor([[-1.4064, -1.3250],
        [-1.3086, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036779753863811493
Epoch 0, Step 286: train/loss = 0.6942430138587952, train/raw-loss = 0.6941894292831421, train/logprobs = tensor([[-0.6553, -0.6484],
        [-0.5162, -0.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001786070060916245
Epoch 0, Step 287: train/loss = 0.728610634803772, train/raw-loss = 0.7209943532943726, train/logprobs = tensor([[-0.9358, -1.5106],
        [-0.8580, -0.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025387508794665337
Epoch 0, Step 288: train/loss = 0.6916142702102661, train/raw-loss = 0.6815167665481567, train/logprobs = tensor([[-0.9343, -1.5075],
        [-1.0749, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03365834429860115
Epoch 0, Step 289: train/loss = 0.6972969174385071, train/raw-loss = 0.69571453332901, train/logprobs = tensor([[-0.8766, -1.1073],
        [-0.9917, -0.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005274614784866571
Epoch 0, Step 290: train/loss = 0.7211811542510986, train/raw-loss = 0.7205848693847656, train/logprobs = tensor([[-1.1370, -0.8749],
        [-1.1264, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019879289902746677
Epoch 0, Step 291: train/loss = 0.6955167651176453, train/raw-loss = 0.6940209865570068, train/logprobs = tensor([[-0.9258, -1.2008],
        [-0.9217, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004985806066542864
Epoch 0, Step 292: train/loss = 0.700614333152771, train/raw-loss = 0.6992748379707336, train/logprobs = tensor([[-0.6042, -0.8778],
        [-0.6519, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004464997909963131
Epoch 0, Step 293: train/loss = 0.6880978345870972, train/raw-loss = 0.6834824085235596, train/logprobs = tensor([[-0.8199, -0.9585],
        [-0.8801, -0.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015385124832391739
Epoch 0, Step 294: train/loss = 0.7003782987594604, train/raw-loss = 0.6967347860336304, train/logprobs = tensor([[-0.9534, -1.4071],
        [-0.9706, -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01214524544775486
Epoch 0, Step 295: train/loss = 0.705265998840332, train/raw-loss = 0.7050075531005859, train/logprobs = tensor([[-0.8115, -0.7248],
        [-0.8192, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008616565610282123
Epoch 0, Step 296: train/loss = 0.693766176700592, train/raw-loss = 0.6927700638771057, train/logprobs = tensor([[-0.9131, -0.9856],
        [-0.9899, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003320605494081974
Epoch 0, Step 297: train/loss = 0.7068045735359192, train/raw-loss = 0.7059434652328491, train/logprobs = tensor([[-1.0151, -1.2298],
        [-1.1821, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028703983407467604
Epoch 0, Step 298: train/loss = 0.6832720041275024, train/raw-loss = 0.673635721206665, train/logprobs = tensor([[-0.8632, -1.4495],
        [-0.9744, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03212098032236099
Epoch 0, Step 299: train/loss = 0.6948144435882568, train/raw-loss = 0.6941976547241211, train/logprobs = tensor([[-0.6895, -0.7339],
        [-0.7334, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020559667609632015
Epoch 0, Step 300: train/loss = 0.725105881690979, train/raw-loss = 0.7043782472610474, train/logprobs = tensor([[-0.7954, -1.7049],
        [-0.9646, -0.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06909190118312836
Epoch 0, Step 301: train/loss = 0.6996596455574036, train/raw-loss = 0.6993142366409302, train/logprobs = tensor([[-0.8498, -0.9125],
        [-0.7868, -0.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011510857148095965
Epoch 0, Step 302: train/loss = 0.6979833245277405, train/raw-loss = 0.6968307495117188, train/logprobs = tensor([[-0.9310, -0.8822],
        [-1.0331, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003841858822852373
Epoch 0, Step 303: train/loss = 0.694132387638092, train/raw-loss = 0.6931523084640503, train/logprobs = tensor([[-0.8898, -1.1373],
        [-0.9361, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032668127678334713
Epoch 0, Step 304: train/loss = 0.7070071697235107, train/raw-loss = 0.7020167112350464, train/logprobs = tensor([[-0.8969, -1.2860],
        [-0.9934, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016634929925203323
Epoch 0, Step 305: train/loss = 0.7184375524520874, train/raw-loss = 0.7179181575775146, train/logprobs = tensor([[-1.0187, -1.2135],
        [-0.9744, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017312432173639536
Epoch 0, Step 306: train/loss = 0.6958004236221313, train/raw-loss = 0.6949106454849243, train/logprobs = tensor([[-0.8179, -0.9000],
        [-0.9398, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002965977881103754
Epoch 0, Step 307: train/loss = 0.6987801194190979, train/raw-loss = 0.6969332098960876, train/logprobs = tensor([[-0.8256, -0.9558],
        [-0.9443, -0.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006156439892947674
Epoch 0, Step 308: train/loss = 0.6916923522949219, train/raw-loss = 0.6899654269218445, train/logprobs = tensor([[-0.6656, -0.8545],
        [-0.7587, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00575660914182663
Epoch 0, Step 309: train/loss = 0.7010736465454102, train/raw-loss = 0.6752597093582153, train/logprobs = tensor([[-0.9794, -1.9298],
        [-1.1136, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08604655414819717
Epoch 0, Step 310: train/loss = 0.6950693130493164, train/raw-loss = 0.6924291253089905, train/logprobs = tensor([[-0.7710, -1.0475],
        [-0.9054, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008800671435892582
Epoch 0, Step 311: train/loss = 0.6987451910972595, train/raw-loss = 0.6979677677154541, train/logprobs = tensor([[-0.8143, -0.7668],
        [-0.7975, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025913571007549763
Epoch 0, Step 312: train/loss = 0.7048895359039307, train/raw-loss = 0.6981334686279297, train/logprobs = tensor([[-0.8464, -1.3876],
        [-0.9152, -0.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022520501166582108
Epoch 0, Step 313: train/loss = 0.6967107653617859, train/raw-loss = 0.6965375542640686, train/logprobs = tensor([[-0.7436, -0.7281],
        [-0.9023, -0.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005773006123490632
Epoch 0, Step 314: train/loss = 0.7017771005630493, train/raw-loss = 0.6993181109428406, train/logprobs = tensor([[-1.1060, -1.3301],
        [-1.2148, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008196710608899593
Epoch 0, Step 315: train/loss = 0.7078261375427246, train/raw-loss = 0.7067227363586426, train/logprobs = tensor([[-0.7862, -1.1341],
        [-1.0252, -1.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003678009146824479
Epoch 0, Step 316: train/loss = 0.7221336364746094, train/raw-loss = 0.7204873561859131, train/logprobs = tensor([[-1.1224, -0.9028],
        [-1.3131, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005487517453730106
Epoch 0, Step 317: train/loss = 0.6944760084152222, train/raw-loss = 0.6937496662139893, train/logprobs = tensor([[-0.9164, -0.9995],
        [-0.9764, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002421180484816432
Epoch 0, Step 318: train/loss = 0.6859904527664185, train/raw-loss = 0.6813573837280273, train/logprobs = tensor([[-0.8707, -1.1362],
        [-1.0155, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015443525277078152
Epoch 0, Step 319: train/loss = 0.7056498527526855, train/raw-loss = 0.7014036178588867, train/logprobs = tensor([[-1.2553, -1.6556],
        [-0.9960, -1.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014154157601296902
Epoch 0, Step 320: train/loss = 0.7051103115081787, train/raw-loss = 0.703217625617981, train/logprobs = tensor([[-0.9786, -1.2689],
        [-1.0240, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006309087388217449
Epoch 0, Step 321: train/loss = 0.6927414536476135, train/raw-loss = 0.6893733739852905, train/logprobs = tensor([[-0.8161, -0.9084],
        [-0.8719, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011226808652281761
Epoch 0, Step 322: train/loss = 0.7020252346992493, train/raw-loss = 0.7009710669517517, train/logprobs = tensor([[-1.0296, -1.2034],
        [-1.0207, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003513761330395937
Epoch 0, Step 323: train/loss = 0.6967214345932007, train/raw-loss = 0.6952986121177673, train/logprobs = tensor([[-0.8398, -0.8447],
        [-0.9587, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004743011202663183
Epoch 0, Step 324: train/loss = 0.746894121170044, train/raw-loss = 0.7444217205047607, train/logprobs = tensor([[-0.9990, -1.1543],
        [-1.2611, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008241264149546623
Epoch 0, Step 325: train/loss = 0.6946660876274109, train/raw-loss = 0.6943446397781372, train/logprobs = tensor([[-0.9074, -0.9324],
        [-1.0787, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010717363329604268
Epoch 0, Step 326: train/loss = 0.6881929039955139, train/raw-loss = 0.6794147491455078, train/logprobs = tensor([[-1.3246, -1.7648],
        [-1.5042, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02926057204604149
Epoch 0, Step 327: train/loss = 0.6999764442443848, train/raw-loss = 0.6993188858032227, train/logprobs = tensor([[-0.9394, -0.9259],
        [-1.0084, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002191924024373293
Epoch 0, Step 328: train/loss = 0.7217617034912109, train/raw-loss = 0.7107123732566833, train/logprobs = tensor([[-1.0805, -1.3497],
        [-1.4527, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03683087229728699
Epoch 0, Step 329: train/loss = 0.6957687139511108, train/raw-loss = 0.6941843628883362, train/logprobs = tensor([[-0.7701, -0.7775],
        [-0.7895, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005281088873744011
Epoch 0, Step 330: train/loss = 0.7210462093353271, train/raw-loss = 0.7188100814819336, train/logprobs = tensor([[-0.7775, -1.2762],
        [-0.9793, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007454093545675278
Epoch 0, Step 331: train/loss = 0.7166429758071899, train/raw-loss = 0.7140339016914368, train/logprobs = tensor([[-0.9776, -0.8110],
        [-1.0510, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008696934208273888
Epoch 0, Step 332: train/loss = 0.6887651681900024, train/raw-loss = 0.6868948936462402, train/logprobs = tensor([[-0.9934, -1.0847],
        [-1.1519, -0.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006234435364603996
Epoch 0, Step 333: train/loss = 0.7014073133468628, train/raw-loss = 0.7004376649856567, train/logprobs = tensor([[-0.8287, -0.9960],
        [-0.8309, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032320863101631403
Epoch 0, Step 334: train/loss = 0.7018604874610901, train/raw-loss = 0.7011770009994507, train/logprobs = tensor([[-0.9653, -1.2833],
        [-1.1680, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022782336454838514
Epoch 0, Step 335: train/loss = 0.6896575093269348, train/raw-loss = 0.6853958964347839, train/logprobs = tensor([[-1.0742, -1.2206],
        [-1.3315, -0.9984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014205561019480228
Epoch 0, Step 336: train/loss = 0.7005999088287354, train/raw-loss = 0.6888695359230042, train/logprobs = tensor([[-0.9013, -1.4182],
        [-1.0487, -0.8249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039101339876651764
Epoch 0, Step 337: train/loss = 0.6986736059188843, train/raw-loss = 0.697354257106781, train/logprobs = tensor([[-0.9932, -1.3295],
        [-1.1522, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043978444300591946
Epoch 0, Step 338: train/loss = 0.6870964765548706, train/raw-loss = 0.6818222999572754, train/logprobs = tensor([[-0.9827, -1.1488],
        [-1.3039, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017580462619662285
Epoch 0, Step 339: train/loss = 0.7150585651397705, train/raw-loss = 0.7145904898643494, train/logprobs = tensor([[-0.9592, -0.8135],
        [-1.0757, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015603055944666266
Epoch 0, Step 340: train/loss = 0.6943885684013367, train/raw-loss = 0.6942311525344849, train/logprobs = tensor([[-0.9796, -0.9136],
        [-0.9866, -0.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005248237866908312
Epoch 0, Step 341: train/loss = 0.684859037399292, train/raw-loss = 0.6818360090255737, train/logprobs = tensor([[-0.8458, -1.0235],
        [-1.2143, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010076716542243958
Epoch 0, Step 342: train/loss = 0.7076729536056519, train/raw-loss = 0.7047501802444458, train/logprobs = tensor([[-1.1129, -1.0868],
        [-1.2064, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00974283367395401
Epoch 0, Step 343: train/loss = 0.6977182626724243, train/raw-loss = 0.6969159841537476, train/logprobs = tensor([[-0.9399, -0.9084],
        [-1.0838, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026741712354123592
Epoch 0, Step 344: train/loss = 0.7003880739212036, train/raw-loss = 0.6984184980392456, train/logprobs = tensor([[-1.0946, -1.1311],
        [-1.2646, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006565262097865343
Epoch 0, Step 345: train/loss = 0.6942335367202759, train/raw-loss = 0.6923258304595947, train/logprobs = tensor([[-1.1279, -1.1648],
        [-1.3849, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006358915474265814
Epoch 0, Step 346: train/loss = 0.7451945543289185, train/raw-loss = 0.7418110370635986, train/logprobs = tensor([[-0.9347, -1.1018],
        [-1.0936, -0.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011278636753559113
Epoch 0, Step 347: train/loss = 0.7127977013587952, train/raw-loss = 0.7078531384468079, train/logprobs = tensor([[-1.0087, -0.9554],
        [-1.3788, -0.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016482003033161163
Epoch 0, Step 348: train/loss = 0.6938963532447815, train/raw-loss = 0.6936411261558533, train/logprobs = tensor([[-1.2438, -1.2209],
        [-1.2872, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008508684113621712
Epoch 0, Step 349: train/loss = 0.6976445317268372, train/raw-loss = 0.6970381140708923, train/logprobs = tensor([[-0.8791, -0.8179],
        [-0.9164, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00202159583568573
Epoch 0, Step 350: train/loss = 0.6973216533660889, train/raw-loss = 0.6971849203109741, train/logprobs = tensor([[-0.9548, -0.8958],
        [-1.0345, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004558065556921065
Epoch 0, Step 351: train/loss = 0.6990147829055786, train/raw-loss = 0.696567952632904, train/logprobs = tensor([[-1.0665, -1.0346],
        [-1.2952, -0.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008155880495905876
Epoch 0, Step 352: train/loss = 0.6944388747215271, train/raw-loss = 0.6892281770706177, train/logprobs = tensor([[-1.2641, -1.4641],
        [-1.3096, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01736924797296524
Epoch 0, Step 353: train/loss = 0.6707522869110107, train/raw-loss = 0.6484799981117249, train/logprobs = tensor([[-0.8412, -1.5262],
        [-1.0684, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07424093037843704
Epoch 0, Step 354: train/loss = 0.7208032608032227, train/raw-loss = 0.7183104753494263, train/logprobs = tensor([[-1.0601, -1.1922],
        [-1.3183, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008309181779623032
Epoch 0, Step 355: train/loss = 0.7149600982666016, train/raw-loss = 0.7094809412956238, train/logprobs = tensor([[-1.6127, -1.7941],
        [-1.2442, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01826382614672184
Epoch 0, Step 356: train/loss = 0.7075185179710388, train/raw-loss = 0.7050783634185791, train/logprobs = tensor([[-1.4014, -1.4788],
        [-1.4523, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008133960887789726
Epoch 0, Step 357: train/loss = 0.6961027383804321, train/raw-loss = 0.6882063746452332, train/logprobs = tensor([[-0.9242, -1.5101],
        [-0.9594, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026321331039071083
Epoch 0, Step 358: train/loss = 0.7086787223815918, train/raw-loss = 0.7047096490859985, train/logprobs = tensor([[-0.7530, -1.1984],
        [-1.0219, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013230112381279469
Epoch 0, Step 359: train/loss = 0.696194589138031, train/raw-loss = 0.6897149682044983, train/logprobs = tensor([[-0.8627, -1.3642],
        [-1.1655, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021598752588033676
Epoch 0, Step 360: train/loss = 0.7261490225791931, train/raw-loss = 0.7169827222824097, train/logprobs = tensor([[-1.1462, -2.0384],
        [-1.4511, -1.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030554361641407013
Epoch 0, Step 361: train/loss = 0.7164636850357056, train/raw-loss = 0.7130299806594849, train/logprobs = tensor([[-1.3413, -1.0627],
        [-1.0909, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011445649899542332
Epoch 0, Step 362: train/loss = 0.6937698721885681, train/raw-loss = 0.6933785676956177, train/logprobs = tensor([[-1.0229, -1.0823],
        [-1.1001, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013045823434367776
Epoch 0, Step 363: train/loss = 0.7035073637962341, train/raw-loss = 0.7007378339767456, train/logprobs = tensor([[-0.9390, -1.3936],
        [-0.8903, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009231951087713242
Epoch 0, Step 364: train/loss = 0.6976291537284851, train/raw-loss = 0.6934792995452881, train/logprobs = tensor([[-1.0062, -0.9258],
        [-1.4542, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013832887634634972
Epoch 0, Step 365: train/loss = 0.6914690732955933, train/raw-loss = 0.6890062689781189, train/logprobs = tensor([[-0.8577, -1.0440],
        [-0.9049, -0.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008209426887333393
Epoch 0, Step 366: train/loss = 0.7025302052497864, train/raw-loss = 0.699394166469574, train/logprobs = tensor([[-1.1090, -1.1733],
        [-1.2613, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010453490540385246
Epoch 0, Step 367: train/loss = 0.6920076608657837, train/raw-loss = 0.6865789890289307, train/logprobs = tensor([[-0.8093, -1.2774],
        [-0.8635, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01809569261968136
Epoch 0, Step 368: train/loss = 0.6905878782272339, train/raw-loss = 0.6862003207206726, train/logprobs = tensor([[-1.2021, -1.4925],
        [-1.0340, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014625295996665955
Epoch 0, Step 369: train/loss = 0.6920039653778076, train/raw-loss = 0.6894026398658752, train/logprobs = tensor([[-0.9462, -1.0114],
        [-1.0628, -0.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008671224117279053
Epoch 0, Step 370: train/loss = 0.6932329535484314, train/raw-loss = 0.6928693652153015, train/logprobs = tensor([[-1.0444, -1.0460],
        [-1.0921, -0.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012120823375880718
Epoch 0, Step 371: train/loss = 0.7046935558319092, train/raw-loss = 0.7004193067550659, train/logprobs = tensor([[-1.1634, -1.3779],
        [-1.1487, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014247702434659004
Epoch 0, Step 372: train/loss = 0.6993856430053711, train/raw-loss = 0.6983153820037842, train/logprobs = tensor([[-1.3731, -1.4083],
        [-0.9252, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035677135456353426
Epoch 0, Step 373: train/loss = 0.7087271213531494, train/raw-loss = 0.7032140493392944, train/logprobs = tensor([[-0.9901, -1.1995],
        [-1.2645, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018376898020505905
Epoch 0, Step 374: train/loss = 0.7450469732284546, train/raw-loss = 0.7433562278747559, train/logprobs = tensor([[-1.1282, -0.8973],
        [-1.1803, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005635748617351055
Epoch 0, Step 375: train/loss = 0.697594165802002, train/raw-loss = 0.6966598629951477, train/logprobs = tensor([[-1.0653, -1.0605],
        [-1.0965, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031144737731665373
Epoch 0, Step 376: train/loss = 0.6916961669921875, train/raw-loss = 0.6835932731628418, train/logprobs = tensor([[-1.0837, -1.5691],
        [-1.1107, -0.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027009621262550354
Epoch 0, Step 377: train/loss = 0.6988296508789062, train/raw-loss = 0.6956422328948975, train/logprobs = tensor([[-1.0228, -1.0371],
        [-1.1070, -0.6478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01062469370663166
Epoch 0, Step 378: train/loss = 0.7366060018539429, train/raw-loss = 0.7232694029808044, train/logprobs = tensor([[-0.9005, -1.5696],
        [-1.0675, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044455453753471375
Epoch 0, Step 379: train/loss = 0.7031776309013367, train/raw-loss = 0.7023863792419434, train/logprobs = tensor([[-0.8819, -1.2362],
        [-0.8936, -1.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002637532539665699
Epoch 0, Step 380: train/loss = 0.7043247222900391, train/raw-loss = 0.7021065354347229, train/logprobs = tensor([[-1.0545, -1.0200],
        [-1.1445, -0.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007394187618046999
Epoch 0, Step 381: train/loss = 0.7039023637771606, train/raw-loss = 0.7027965188026428, train/logprobs = tensor([[-1.2627, -1.1437],
        [-1.0463, -0.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003685910487547517
Epoch 0, Step 382: train/loss = 0.6775393486022949, train/raw-loss = 0.663521409034729, train/logprobs = tensor([[-1.0805, -1.5495],
        [-1.3030, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046726472675800323
Epoch 0, Step 383: train/loss = 0.6929925680160522, train/raw-loss = 0.6893640756607056, train/logprobs = tensor([[-0.9759, -1.0325],
        [-1.2727, -0.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012094938196241856
Epoch 0, Step 384: train/loss = 0.6929733753204346, train/raw-loss = 0.6922899484634399, train/logprobs = tensor([[-0.8489, -0.9584],
        [-0.8271, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022781267762184143
Epoch 0, Step 385: train/loss = 0.689180850982666, train/raw-loss = 0.6812220811843872, train/logprobs = tensor([[-1.1090, -1.4375],
        [-1.0378, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026529358699917793
Epoch 0, Step 386: train/loss = 0.7079935073852539, train/raw-loss = 0.7073149085044861, train/logprobs = tensor([[-1.0453, -1.1000],
        [-1.1063, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022621110547333956
Epoch 0, Step 387: train/loss = 0.6937480568885803, train/raw-loss = 0.6901887059211731, train/logprobs = tensor([[-1.0711, -1.4029],
        [-1.2055, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011864622123539448
Epoch 0, Step 388: train/loss = 0.7001668810844421, train/raw-loss = 0.6942548751831055, train/logprobs = tensor([[-1.4319, -1.7280],
        [-1.4370, -1.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01970675215125084
Epoch 0, Step 389: train/loss = 0.7125942707061768, train/raw-loss = 0.7082307934761047, train/logprobs = tensor([[-1.1033, -1.4058],
        [-1.1638, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014544661156833172
Epoch 0, Step 390: train/loss = 0.6833012700080872, train/raw-loss = 0.6704720258712769, train/logprobs = tensor([[-1.0469, -1.5520],
        [-1.3534, -1.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042764343321323395
Epoch 0, Step 391: train/loss = 0.7133321166038513, train/raw-loss = 0.7117531895637512, train/logprobs = tensor([[-1.0071, -1.0753],
        [-1.1003, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005263018887490034
Epoch 0, Step 392: train/loss = 0.7151528596878052, train/raw-loss = 0.7108657360076904, train/logprobs = tensor([[-1.0311, -1.4980],
        [-1.2306, -1.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014290593564510345
Epoch 0, Step 393: train/loss = 0.704210638999939, train/raw-loss = 0.7041101455688477, train/logprobs = tensor([[-0.9248, -0.8869],
        [-1.0133, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033484186860732734
Epoch 0, Step 394: train/loss = 0.6922114491462708, train/raw-loss = 0.6895819902420044, train/logprobs = tensor([[-0.8259, -0.9086],
        [-1.0233, -0.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008764953352510929
Epoch 0, Step 395: train/loss = 0.6933444738388062, train/raw-loss = 0.6918432712554932, train/logprobs = tensor([[-1.0723, -1.3613],
        [-1.1682, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005003910977393389
Epoch 0, Step 396: train/loss = 0.7036440372467041, train/raw-loss = 0.695620596408844, train/logprobs = tensor([[-1.1904, -1.9240],
        [-1.0186, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026745028793811798
Epoch 0, Step 397: train/loss = 0.6992442011833191, train/raw-loss = 0.6781948804855347, train/logprobs = tensor([[-1.2228, -1.8244],
        [-1.3276, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07016446441411972
Epoch 0, Step 398: train/loss = 0.7096256017684937, train/raw-loss = 0.709477424621582, train/logprobs = tensor([[-1.0081, -0.7452],
        [-1.0624, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004939729114994407
Epoch 0, Step 399: train/loss = 0.6844769716262817, train/raw-loss = 0.6774430871009827, train/logprobs = tensor([[-1.1921, -1.4119],
        [-1.3273, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02344619110226631
Epoch 0, Step 400: train/loss = 0.6953158378601074, train/raw-loss = 0.6949772238731384, train/logprobs = tensor([[-1.1523, -1.2084],
        [-0.7975, -0.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011288949754089117
Epoch 0, Step 401: train/loss = 0.7127814292907715, train/raw-loss = 0.7064628601074219, train/logprobs = tensor([[-1.0340, -1.5179],
        [-0.9779, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02106219157576561
Epoch 0, Step 402: train/loss = 0.7144637107849121, train/raw-loss = 0.7139202356338501, train/logprobs = tensor([[-1.2455, -1.0375],
        [-1.3928, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018116263672709465
Epoch 0, Step 403: train/loss = 0.73581862449646, train/raw-loss = 0.7319824695587158, train/logprobs = tensor([[-0.9051, -1.2883],
        [-0.9253, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012787222862243652
Epoch 0, Step 404: train/loss = 0.678976833820343, train/raw-loss = 0.6456916928291321, train/logprobs = tensor([[-0.9534, -1.7649],
        [-1.1982, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095041036605835
Epoch 0, Step 405: train/loss = 0.6868877410888672, train/raw-loss = 0.678696870803833, train/logprobs = tensor([[-1.0049, -1.3945],
        [-1.2662, -0.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027303170412778854
Epoch 0, Step 406: train/loss = 0.7532080411911011, train/raw-loss = 0.7411056756973267, train/logprobs = tensor([[-1.2629, -1.8133],
        [-1.2922, -0.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04034104943275452
Epoch 0, Step 407: train/loss = 0.7054412961006165, train/raw-loss = 0.7010555863380432, train/logprobs = tensor([[-1.0191, -1.6276],
        [-1.1137, -1.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01461896114051342
Epoch 0, Step 408: train/loss = 0.6988517045974731, train/raw-loss = 0.6800880432128906, train/logprobs = tensor([[-0.9171, -1.6096],
        [-1.1899, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0625455304980278
Epoch 0, Step 409: train/loss = 0.6942705512046814, train/raw-loss = 0.6913257837295532, train/logprobs = tensor([[-1.1378, -1.2019],
        [-1.3512, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009815849363803864
Epoch 0, Step 410: train/loss = 0.7090622186660767, train/raw-loss = 0.6861246824264526, train/logprobs = tensor([[-0.8323, -1.7725],
        [-0.9866, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07645842432975769
Epoch 0, Step 411: train/loss = 0.6873234510421753, train/raw-loss = 0.6837502717971802, train/logprobs = tensor([[-1.1863, -1.3365],
        [-1.1130, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011910615488886833
Epoch 0, Step 412: train/loss = 0.7013422250747681, train/raw-loss = 0.6992252469062805, train/logprobs = tensor([[-1.4887, -1.4226],
        [-1.3833, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007056393660604954
Epoch 0, Step 413: train/loss = 0.6949448585510254, train/raw-loss = 0.692714512348175, train/logprobs = tensor([[-1.2171, -1.2500],
        [-1.0372, -0.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007434319704771042
Epoch 0, Step 414: train/loss = 0.708119809627533, train/raw-loss = 0.702998161315918, train/logprobs = tensor([[-0.8960, -1.1423],
        [-1.1285, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017072424292564392
Epoch 0, Step 415: train/loss = 0.6877318620681763, train/raw-loss = 0.6836546659469604, train/logprobs = tensor([[-0.9014, -1.1780],
        [-0.9422, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013590769842267036
Epoch 0, Step 416: train/loss = 0.7387309670448303, train/raw-loss = 0.714719831943512, train/logprobs = tensor([[-1.3074, -2.3137],
        [-1.3946, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08003700524568558
Epoch 0, Step 417: train/loss = 0.748206615447998, train/raw-loss = 0.7419031858444214, train/logprobs = tensor([[-0.9928, -0.9789],
        [-1.1964, -0.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021011296659708023
Epoch 0, Step 418: train/loss = 0.6988458633422852, train/raw-loss = 0.6965745687484741, train/logprobs = tensor([[-1.8443, -1.8933],
        [-1.3377, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007570987567305565
Epoch 0, Step 419: train/loss = 0.6953219175338745, train/raw-loss = 0.6940479874610901, train/logprobs = tensor([[-1.3534, -1.5079],
        [-1.1295, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004246559925377369
Epoch 0, Step 420: train/loss = 0.6936235427856445, train/raw-loss = 0.6752790808677673, train/logprobs = tensor([[-1.0263, -1.5913],
        [-1.0469, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06114834174513817
Epoch 0, Step 421: train/loss = 0.6980257034301758, train/raw-loss = 0.6848543286323547, train/logprobs = tensor([[-1.3124, -1.9801],
        [-1.2798, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04390445351600647
Epoch 0, Step 422: train/loss = 0.6938228011131287, train/raw-loss = 0.6899182796478271, train/logprobs = tensor([[-1.1418, -1.4538],
        [-1.1896, -1.1941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013015002943575382
Epoch 0, Step 423: train/loss = 0.7007063627243042, train/raw-loss = 0.6958171129226685, train/logprobs = tensor([[-1.3525, -1.3894],
        [-1.5308, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016297217458486557
Epoch 0, Step 424: train/loss = 0.7055743932723999, train/raw-loss = 0.702022135257721, train/logprobs = tensor([[-1.1395, -1.1295],
        [-1.1890, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011841109953820705
Epoch 0, Step 425: train/loss = 0.6816354393959045, train/raw-loss = 0.6724841594696045, train/logprobs = tensor([[-0.9468, -1.5371],
        [-1.0666, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0305042527616024
Epoch 0, Step 426: train/loss = 0.7156529426574707, train/raw-loss = 0.7097131013870239, train/logprobs = tensor([[-1.4234, -1.2212],
        [-1.5298, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019799329340457916
Epoch 0, Step 427: train/loss = 0.7077564597129822, train/raw-loss = 0.7031686305999756, train/logprobs = tensor([[-1.0221, -1.2207],
        [-1.1491, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015292934142053127
Epoch 0, Step 428: train/loss = 0.7084593772888184, train/raw-loss = 0.704791247844696, train/logprobs = tensor([[-1.0983, -1.0614],
        [-1.1981, -0.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012227272614836693
Epoch 0, Step 429: train/loss = 0.6998195648193359, train/raw-loss = 0.6972686648368835, train/logprobs = tensor([[-0.9571, -1.0487],
        [-1.1574, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008503075689077377
Epoch 0, Step 430: train/loss = 0.7097206115722656, train/raw-loss = 0.7042380571365356, train/logprobs = tensor([[-0.9034, -1.4293],
        [-0.9514, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01827527955174446
Epoch 0, Step 431: train/loss = 0.7120981216430664, train/raw-loss = 0.7115907669067383, train/logprobs = tensor([[-1.2438, -1.6413],
        [-1.3235, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016911306884139776
Epoch 0, Step 432: train/loss = 0.6958302855491638, train/raw-loss = 0.690720796585083, train/logprobs = tensor([[-1.2918, -1.4541],
        [-1.2552, -0.9648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01703152433037758
Epoch 0, Step 433: train/loss = 0.7060327529907227, train/raw-loss = 0.699737548828125, train/logprobs = tensor([[-0.9827, -1.1865],
        [-0.9683, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02098388969898224
Epoch 0, Step 434: train/loss = 0.6923155784606934, train/raw-loss = 0.6897177696228027, train/logprobs = tensor([[-1.4678, -1.5923],
        [-1.2285, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00865938700735569
Epoch 0, Step 435: train/loss = 0.7586844563484192, train/raw-loss = 0.7464727759361267, train/logprobs = tensor([[-1.3813, -2.0442],
        [-1.3945, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04070562869310379
Epoch 0, Step 436: train/loss = 0.6987436413764954, train/raw-loss = 0.6871178150177002, train/logprobs = tensor([[-0.9450, -1.5867],
        [-0.9074, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03875269740819931
Epoch 0, Step 437: train/loss = 0.7059900760650635, train/raw-loss = 0.696730375289917, train/logprobs = tensor([[-1.4774, -1.4325],
        [-1.2550, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03086565062403679
Epoch 0, Step 438: train/loss = 0.6867860555648804, train/raw-loss = 0.6734872460365295, train/logprobs = tensor([[-0.9334, -1.3077],
        [-1.2415, -0.6138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044329214841127396
Epoch 0, Step 439: train/loss = 0.71428382396698, train/raw-loss = 0.7080835103988647, train/logprobs = tensor([[-1.4097, -1.6981],
        [-1.4652, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020667528733611107
Epoch 0, Step 440: train/loss = 0.6998713612556458, train/raw-loss = 0.6966875791549683, train/logprobs = tensor([[-1.2405, -1.4927],
        [-1.3979, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010612488724291325
Epoch 0, Step 441: train/loss = 0.6853487491607666, train/raw-loss = 0.6701211929321289, train/logprobs = tensor([[-1.2047, -1.6055],
        [-1.4569, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05075833946466446
Epoch 0, Step 442: train/loss = 0.6954364776611328, train/raw-loss = 0.6902800798416138, train/logprobs = tensor([[-0.9214, -0.9416],
        [-1.1060, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017187954857945442
Epoch 0, Step 443: train/loss = 0.71519935131073, train/raw-loss = 0.7148745656013489, train/logprobs = tensor([[-1.1142, -0.8643],
        [-0.8792, -0.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010824276832863688
Epoch 0, Step 444: train/loss = 0.7103367447853088, train/raw-loss = 0.6746118068695068, train/logprobs = tensor([[-0.8662, -2.1449],
        [-1.1075, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11908310651779175
Epoch 0, Step 445: train/loss = 0.7198541164398193, train/raw-loss = 0.703629195690155, train/logprobs = tensor([[-1.0223, -1.6986],
        [-1.1318, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05408289656043053
Epoch 0, Step 446: train/loss = 0.6834493279457092, train/raw-loss = 0.6678807735443115, train/logprobs = tensor([[-0.9476, -1.5807],
        [-0.9211, -0.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05189509317278862
Epoch 0, Step 447: train/loss = 0.6910821199417114, train/raw-loss = 0.6856429576873779, train/logprobs = tensor([[-1.0681, -1.3716],
        [-0.9556, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018130654469132423
Epoch 0, Step 448: train/loss = 0.7318171262741089, train/raw-loss = 0.7250454425811768, train/logprobs = tensor([[-1.2185, -1.7203],
        [-1.0539, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022572241723537445
Epoch 0, Step 449: train/loss = 0.6825994253158569, train/raw-loss = 0.6769598126411438, train/logprobs = tensor([[-1.3363, -1.5531],
        [-1.5049, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018798712641000748
Epoch 0, Step 450: train/loss = 0.7247650623321533, train/raw-loss = 0.7244810461997986, train/logprobs = tensor([[-1.4836, -1.2617],
        [-1.2654, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009468200732953846
Epoch 0, Step 451: train/loss = 0.6908748149871826, train/raw-loss = 0.6584688425064087, train/logprobs = tensor([[-0.9103, -1.9195],
        [-1.1774, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1080198884010315
Epoch 0, Step 452: train/loss = 0.6998232007026672, train/raw-loss = 0.694082498550415, train/logprobs = tensor([[-1.3884, -1.9700],
        [-0.8009, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019135572016239166
Epoch 0, Step 453: train/loss = 0.7032269239425659, train/raw-loss = 0.6889408826828003, train/logprobs = tensor([[-1.0881, -1.6562],
        [-1.0863, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04762028902769089
Epoch 0, Step 454: train/loss = 0.6811147332191467, train/raw-loss = 0.6695407629013062, train/logprobs = tensor([[-1.1086, -1.4206],
        [-1.2612, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03857996687293053
Epoch 0, Step 455: train/loss = 0.7046693563461304, train/raw-loss = 0.6916418075561523, train/logprobs = tensor([[-1.1910, -1.5893],
        [-1.1387, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043425317853689194
Epoch 0, Step 456: train/loss = 0.6936855316162109, train/raw-loss = 0.6929981708526611, train/logprobs = tensor([[-0.9352, -1.0283],
        [-0.8633, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00229146471247077
Epoch 0, Step 457: train/loss = 0.7086809873580933, train/raw-loss = 0.6910958290100098, train/logprobs = tensor([[-0.9552, -1.5993],
        [-1.2026, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05861726775765419
Epoch 0, Step 458: train/loss = 0.7510796189308167, train/raw-loss = 0.7439751625061035, train/logprobs = tensor([[-1.0270, -1.8145],
        [-1.0330, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023681439459323883
Epoch 0, Step 459: train/loss = 0.7172439098358154, train/raw-loss = 0.711152195930481, train/logprobs = tensor([[-1.6990, -1.8421],
        [-1.3282, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020305555313825607
Epoch 0, Step 460: train/loss = 0.6994301676750183, train/raw-loss = 0.692990779876709, train/logprobs = tensor([[-1.1707, -1.4213],
        [-1.4811, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021464761346578598
Epoch 0, Step 461: train/loss = 0.6830475330352783, train/raw-loss = 0.6819400191307068, train/logprobs = tensor([[-1.4227, -1.5968],
        [-1.0050, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036917387042194605
Epoch 0, Step 462: train/loss = 0.6683962345123291, train/raw-loss = 0.6642476320266724, train/logprobs = tensor([[-1.3396, -1.8737],
        [-1.3190, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013828479684889317
Epoch 0, Step 463: train/loss = 0.7480466365814209, train/raw-loss = 0.7014496326446533, train/logprobs = tensor([[-1.3200, -2.5807],
        [-1.1458, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15532340109348297
Epoch 0, Step 464: train/loss = 0.6864908933639526, train/raw-loss = 0.6779500246047974, train/logprobs = tensor([[-1.4079, -1.6630],
        [-1.2446, -1.1433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028469569981098175
Epoch 0, Step 465: train/loss = 0.7125545740127563, train/raw-loss = 0.7099389433860779, train/logprobs = tensor([[-1.0532, -1.2836],
        [-1.0769, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008718808181583881
Epoch 0, Step 466: train/loss = 0.7002602815628052, train/raw-loss = 0.6999322175979614, train/logprobs = tensor([[-1.0665, -1.2116],
        [-1.0277, -1.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010935295140370727
Epoch 0, Step 467: train/loss = 0.6958702802658081, train/raw-loss = 0.6913983821868896, train/logprobs = tensor([[-1.3621, -1.7821],
        [-1.5106, -1.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014906137250363827
Epoch 0, Step 468: train/loss = 0.7036895155906677, train/raw-loss = 0.6922497749328613, train/logprobs = tensor([[-0.9112, -1.5792],
        [-0.8924, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03813234344124794
Epoch 0, Step 469: train/loss = 0.6963518261909485, train/raw-loss = 0.693822979927063, train/logprobs = tensor([[-1.0695, -1.0476],
        [-1.1387, -0.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0084296315908432
Epoch 0, Step 470: train/loss = 0.7010824084281921, train/raw-loss = 0.6970843076705933, train/logprobs = tensor([[-0.9997, -1.4056],
        [-1.1455, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013326889835298061
Epoch 0, Step 471: train/loss = 0.7062150835990906, train/raw-loss = 0.7031376957893372, train/logprobs = tensor([[-1.0839, -1.4699],
        [-1.3709, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010257931426167488
Epoch 0, Step 472: train/loss = 0.6698306798934937, train/raw-loss = 0.6391866207122803, train/logprobs = tensor([[-1.2505, -2.0285],
        [-1.3198, -0.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1021469235420227
Epoch 0, Step 473: train/loss = 0.6927248239517212, train/raw-loss = 0.6905062198638916, train/logprobs = tensor([[-1.6025, -1.7712],
        [-1.6708, -1.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007395321503281593
Epoch 0, Step 474: train/loss = 0.7065298557281494, train/raw-loss = 0.6954777240753174, train/logprobs = tensor([[-1.0325, -1.6554],
        [-1.1458, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03684022277593613
Epoch 0, Step 475: train/loss = 0.705445408821106, train/raw-loss = 0.7016099691390991, train/logprobs = tensor([[-0.9266, -1.3271],
        [-1.1117, -1.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012785137630999088
Epoch 0, Step 476: train/loss = 0.739519476890564, train/raw-loss = 0.7325525879859924, train/logprobs = tensor([[-1.5715, -1.5330],
        [-1.8791, -1.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023223161697387695
Epoch 0, Step 477: train/loss = 0.6783069968223572, train/raw-loss = 0.661900520324707, train/logprobs = tensor([[-1.3821, -1.7725],
        [-1.4344, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05468832328915596
Epoch 0, Step 478: train/loss = 0.7035067677497864, train/raw-loss = 0.6948084831237793, train/logprobs = tensor([[-0.9131, -1.3357],
        [-1.1422, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028994271531701088
Epoch 0, Step 479: train/loss = 0.6966396570205688, train/raw-loss = 0.6965581178665161, train/logprobs = tensor([[-1.2125, -1.1443],
        [-1.4078, -1.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002720777702052146
Epoch 0, Step 480: train/loss = 0.695069432258606, train/raw-loss = 0.6930893659591675, train/logprobs = tensor([[-1.1211, -1.1216],
        [-1.0081, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006600555963814259
Epoch 0, Step 481: train/loss = 0.6846065521240234, train/raw-loss = 0.6647257804870605, train/logprobs = tensor([[-1.2205, -1.7290],
        [-1.3115, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0662691742181778
Epoch 0, Step 482: train/loss = 0.6932766437530518, train/raw-loss = 0.6784659624099731, train/logprobs = tensor([[-1.4434, -1.6368],
        [-1.4172, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04936857521533966
Epoch 0, Step 483: train/loss = 0.6890149712562561, train/raw-loss = 0.6692123413085938, train/logprobs = tensor([[-1.2425, -1.7479],
        [-1.0680, -0.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06600897759199142
Epoch 0, Step 484: train/loss = 0.7132025957107544, train/raw-loss = 0.7037994861602783, train/logprobs = tensor([[-1.0831, -1.8745],
        [-1.3505, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03134358674287796
Epoch 0, Step 485: train/loss = 0.6785048842430115, train/raw-loss = 0.6634652614593506, train/logprobs = tensor([[-1.0801, -1.6114],
        [-1.0141, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05013188347220421
Epoch 0, Step 486: train/loss = 0.7200677990913391, train/raw-loss = 0.7190530300140381, train/logprobs = tensor([[-1.1511, -1.3221],
        [-1.2018, -1.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003382521215826273
Epoch 0, Step 487: train/loss = 0.6930660605430603, train/raw-loss = 0.691493809223175, train/logprobs = tensor([[-1.2041, -1.2897],
        [-0.9894, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005240764003247023
Epoch 0, Step 488: train/loss = 0.6870836019515991, train/raw-loss = 0.6727036833763123, train/logprobs = tensor([[-1.3742, -1.8402],
        [-1.2473, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04793310537934303
Epoch 0, Step 489: train/loss = 0.7217394709587097, train/raw-loss = 0.7111064195632935, train/logprobs = tensor([[-0.9375, -1.6926],
        [-1.0684, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03544335812330246
Epoch 0, Step 490: train/loss = 0.6859974265098572, train/raw-loss = 0.6744898557662964, train/logprobs = tensor([[-1.0157, -1.4861],
        [-1.1095, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038358669728040695
Epoch 0, Step 491: train/loss = 0.6869460344314575, train/raw-loss = 0.6759644150733948, train/logprobs = tensor([[-1.0830, -1.3321],
        [-1.2357, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03660562261939049
Epoch 0, Step 492: train/loss = 0.6960080862045288, train/raw-loss = 0.6913355588912964, train/logprobs = tensor([[-0.9932, -1.2030],
        [-1.0506, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01557515561580658
Epoch 0, Step 493: train/loss = 0.7695741653442383, train/raw-loss = 0.7455036044120789, train/logprobs = tensor([[-0.9918, -2.1510],
        [-1.1460, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0802353098988533
Epoch 0, Step 494: train/loss = 0.6880084872245789, train/raw-loss = 0.6818209886550903, train/logprobs = tensor([[-1.4278, -1.3797],
        [-1.1388, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020625244826078415
Epoch 0, Step 495: train/loss = 0.695396363735199, train/raw-loss = 0.6863512396812439, train/logprobs = tensor([[-0.9071, -1.2561],
        [-1.0865, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030150407925248146
Epoch 0, Step 496: train/loss = 0.6900347471237183, train/raw-loss = 0.6853767037391663, train/logprobs = tensor([[-1.0595, -1.2140],
        [-1.2772, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015526815317571163
Epoch 0, Step 497: train/loss = 0.7247982621192932, train/raw-loss = 0.7232720851898193, train/logprobs = tensor([[-1.3185, -1.1687],
        [-1.0693, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005087398923933506
Epoch 0, Step 498: train/loss = 0.6997362375259399, train/raw-loss = 0.6636534929275513, train/logprobs = tensor([[-1.0634, -2.4675],
        [-1.0710, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12027599662542343
Epoch 0, Step 499: train/loss = 0.6875684857368469, train/raw-loss = 0.6712706089019775, train/logprobs = tensor([[-0.8753, -1.2811],
        [-0.9737, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05432634800672531
eval/loss: 0.7027060985565186
Epoch 0, Step 500: train/loss = 0.7179896831512451, train/raw-loss = 0.7111730575561523, train/logprobs = tensor([[-1.4696, -1.6085],
        [-1.1116, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02272208034992218
Epoch 0, Step 501: train/loss = 0.7251495718955994, train/raw-loss = 0.7190069556236267, train/logprobs = tensor([[-1.4377, -1.7376],
        [-1.4700, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020475268363952637
Epoch 0, Step 502: train/loss = 0.71589595079422, train/raw-loss = 0.7030588388442993, train/logprobs = tensor([[-1.4930, -2.0312],
        [-1.3037, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04279053956270218
Epoch 0, Step 503: train/loss = 0.7444992065429688, train/raw-loss = 0.7322620749473572, train/logprobs = tensor([[-1.5319, -1.6273],
        [-1.3862, -1.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040790289640426636
Epoch 0, Step 504: train/loss = 0.7271989583969116, train/raw-loss = 0.7260841727256775, train/logprobs = tensor([[-1.3246, -1.1553],
        [-1.4018, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037159956991672516
Epoch 0, Step 505: train/loss = 0.7091696858406067, train/raw-loss = 0.7046935558319092, train/logprobs = tensor([[-0.9782, -1.0924],
        [-1.0573, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014920661225914955
Epoch 0, Step 506: train/loss = 0.7193612456321716, train/raw-loss = 0.7121093273162842, train/logprobs = tensor([[-0.8237, -1.3585],
        [-0.9232, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024173205718398094
Epoch 0, Step 507: train/loss = 0.6922883987426758, train/raw-loss = 0.6756094098091125, train/logprobs = tensor([[-1.2815, -1.8263],
        [-1.4398, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05559661611914635
Epoch 0, Step 508: train/loss = 0.7006703019142151, train/raw-loss = 0.6993589401245117, train/logprobs = tensor([[-0.9988, -0.9607],
        [-1.0888, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004371375776827335
Epoch 0, Step 509: train/loss = 0.6941199898719788, train/raw-loss = 0.6888110637664795, train/logprobs = tensor([[-0.8765, -1.2925],
        [-1.0026, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01769622229039669
Epoch 0, Step 510: train/loss = 0.6739506721496582, train/raw-loss = 0.6568218469619751, train/logprobs = tensor([[-1.0616, -1.5433],
        [-1.2298, -1.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057096388190984726
Epoch 0, Step 511: train/loss = 0.6630488634109497, train/raw-loss = 0.6353477239608765, train/logprobs = tensor([[-1.3235, -2.1228],
        [-1.2314, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09233713150024414
Epoch 0, Step 512: train/loss = 0.6919320821762085, train/raw-loss = 0.6825841069221497, train/logprobs = tensor([[-1.0541, -1.4241],
        [-1.0798, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03115985170006752
Epoch 0, Step 513: train/loss = 0.7267489433288574, train/raw-loss = 0.7246984243392944, train/logprobs = tensor([[-0.9619, -0.6905],
        [-0.9586, -0.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006835061125457287
Epoch 0, Step 514: train/loss = 0.6926054954528809, train/raw-loss = 0.674404501914978, train/logprobs = tensor([[-1.1743, -1.4708],
        [-1.3999, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06067017838358879
Epoch 0, Step 515: train/loss = 0.7044453024864197, train/raw-loss = 0.6719447374343872, train/logprobs = tensor([[-1.2197, -2.2386],
        [-1.0420, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10833528637886047
Epoch 0, Step 516: train/loss = 0.7337939143180847, train/raw-loss = 0.7167820334434509, train/logprobs = tensor([[-0.8837, -1.4643],
        [-1.0801, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05670648068189621
Epoch 0, Step 517: train/loss = 0.6825896501541138, train/raw-loss = 0.670474648475647, train/logprobs = tensor([[-1.0661, -1.5462],
        [-1.3022, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04038330912590027
Epoch 0, Step 518: train/loss = 0.7019444108009338, train/raw-loss = 0.6587060689926147, train/logprobs = tensor([[-0.9876, -2.1599],
        [-1.2125, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441277116537094
Epoch 0, Step 519: train/loss = 0.688030481338501, train/raw-loss = 0.6786693334579468, train/logprobs = tensor([[-1.1385, -1.4766],
        [-1.1152, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031204013153910637
Epoch 0, Step 520: train/loss = 0.7200333476066589, train/raw-loss = 0.703130304813385, train/logprobs = tensor([[-1.3661, -1.5391],
        [-1.4480, -0.4945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056343529373407364
Epoch 0, Step 521: train/loss = 0.7406408190727234, train/raw-loss = 0.7231125831604004, train/logprobs = tensor([[-1.0174, -2.0109],
        [-1.1234, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05842761695384979
Epoch 0, Step 522: train/loss = 0.6810527443885803, train/raw-loss = 0.6278047561645508, train/logprobs = tensor([[-0.8989, -2.3294],
        [-1.2113, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17749327421188354
Epoch 0, Step 523: train/loss = 0.6953459978103638, train/raw-loss = 0.6817963719367981, train/logprobs = tensor([[-1.2322, -2.0843],
        [-1.0738, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04516548290848732
Epoch 0, Step 524: train/loss = 0.6950191259384155, train/raw-loss = 0.6947634220123291, train/logprobs = tensor([[-1.2970, -1.2900],
        [-1.2282, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008522339630872011
Epoch 0, Step 525: train/loss = 0.7284495830535889, train/raw-loss = 0.7137235403060913, train/logprobs = tensor([[-0.8204, -1.4937],
        [-0.9930, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0490868017077446
Epoch 0, Step 526: train/loss = 0.6831632256507874, train/raw-loss = 0.6716651916503906, train/logprobs = tensor([[-1.0960, -1.4792],
        [-1.1261, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03832685202360153
Epoch 0, Step 527: train/loss = 0.727389931678772, train/raw-loss = 0.7163315415382385, train/logprobs = tensor([[-1.2581, -1.3059],
        [-1.7643, -0.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03686143830418587
Epoch 0, Step 528: train/loss = 0.6593752503395081, train/raw-loss = 0.6237934827804565, train/logprobs = tensor([[-1.4007, -2.0357],
        [-1.5077, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11860601603984833
Epoch 0, Step 529: train/loss = 0.6808146238327026, train/raw-loss = 0.6569246053695679, train/logprobs = tensor([[-1.0132, -1.3548],
        [-1.2717, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07963357120752335
Epoch 0, Step 530: train/loss = 0.7264546751976013, train/raw-loss = 0.7242133021354675, train/logprobs = tensor([[-1.1307, -1.0761],
        [-1.1853, -0.8733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007471325341612101
Epoch 0, Step 531: train/loss = 0.6958348751068115, train/raw-loss = 0.69216388463974, train/logprobs = tensor([[-1.3066, -1.3558],
        [-1.3452, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012236636132001877
Epoch 0, Step 532: train/loss = 0.7153892517089844, train/raw-loss = 0.7124021649360657, train/logprobs = tensor([[-1.5168, -1.9340],
        [-1.3840, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009956947527825832
Epoch 0, Step 533: train/loss = 0.7435998916625977, train/raw-loss = 0.7381070852279663, train/logprobs = tensor([[-1.1168, -1.6039],
        [-1.2428, -1.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018309209495782852
Epoch 0, Step 534: train/loss = 0.6843075752258301, train/raw-loss = 0.6745944619178772, train/logprobs = tensor([[-0.9543, -1.1663],
        [-0.9813, -0.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03237731754779816
Epoch 0, Step 535: train/loss = 0.6753197312355042, train/raw-loss = 0.6383739709854126, train/logprobs = tensor([[-1.3695, -2.1904],
        [-1.5252, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12315259128808975
Epoch 0, Step 536: train/loss = 0.6853904128074646, train/raw-loss = 0.6563366651535034, train/logprobs = tensor([[-1.2994, -1.9473],
        [-1.3119, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09684595465660095
Epoch 0, Step 537: train/loss = 0.6567524075508118, train/raw-loss = 0.5992756485939026, train/logprobs = tensor([[-1.0840, -2.2211],
        [-1.1935, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19158907234668732
Epoch 0, Step 538: train/loss = 0.6953808069229126, train/raw-loss = 0.6938793659210205, train/logprobs = tensor([[-0.8472, -0.9142],
        [-0.9214, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005005027167499065
Epoch 0, Step 539: train/loss = 0.673822820186615, train/raw-loss = 0.6099129915237427, train/logprobs = tensor([[-1.4025, -2.8996],
        [-1.6803, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21303284168243408
Epoch 0, Step 540: train/loss = 0.6956288814544678, train/raw-loss = 0.6881075501441956, train/logprobs = tensor([[-0.9523, -1.1154],
        [-1.2396, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025071213021874428
Epoch 0, Step 541: train/loss = 0.6958879828453064, train/raw-loss = 0.6900637149810791, train/logprobs = tensor([[-1.1394, -1.3031],
        [-1.2542, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01941431686282158
Epoch 0, Step 542: train/loss = 0.6888983845710754, train/raw-loss = 0.666681170463562, train/logprobs = tensor([[-1.4026, -1.7562],
        [-1.0929, -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07405728846788406
Epoch 0, Step 543: train/loss = 0.7145214080810547, train/raw-loss = 0.6960740089416504, train/logprobs = tensor([[-1.1958, -1.1567],
        [-1.6452, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06149102374911308
Epoch 0, Step 544: train/loss = 0.6781718134880066, train/raw-loss = 0.6577569246292114, train/logprobs = tensor([[-1.6230, -2.0823],
        [-1.6911, -1.2887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0680493637919426
Epoch 0, Step 545: train/loss = 0.7017139792442322, train/raw-loss = 0.7012362480163574, train/logprobs = tensor([[-2.2173, -2.1645],
        [-1.3176, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015922916354611516
Epoch 0, Step 546: train/loss = 0.7037617564201355, train/raw-loss = 0.666742205619812, train/logprobs = tensor([[-1.7520, -2.7950],
        [-1.4199, -1.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12339849770069122
Epoch 0, Step 547: train/loss = 0.7106705904006958, train/raw-loss = 0.7031362056732178, train/logprobs = tensor([[-1.4893, -1.8009],
        [-0.8426, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025114446878433228
Epoch 0, Step 548: train/loss = 0.6765741109848022, train/raw-loss = 0.6371699571609497, train/logprobs = tensor([[-0.9920, -1.8894],
        [-1.4969, -1.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13134726881980896
Epoch 0, Step 549: train/loss = 0.684759259223938, train/raw-loss = 0.6696533560752869, train/logprobs = tensor([[-1.1462, -1.7282],
        [-1.3359, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05035301297903061
Epoch 0, Step 550: train/loss = 0.6735159158706665, train/raw-loss = 0.6614824533462524, train/logprobs = tensor([[-1.3284, -1.6175],
        [-1.2670, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040111642330884933
Epoch 0, Step 551: train/loss = 0.6915201544761658, train/raw-loss = 0.6578196287155151, train/logprobs = tensor([[-1.1562, -2.1338],
        [-1.0427, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11233512312173843
Epoch 0, Step 552: train/loss = 0.7928972244262695, train/raw-loss = 0.756598949432373, train/logprobs = tensor([[-0.9284, -2.4322],
        [-1.5159, -1.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12099438905715942
Epoch 0, Step 553: train/loss = 0.6866482496261597, train/raw-loss = 0.6523221731185913, train/logprobs = tensor([[-1.7566, -2.6625],
        [-1.2541, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11442038416862488
Epoch 0, Step 554: train/loss = 0.7267540693283081, train/raw-loss = 0.7138935327529907, train/logprobs = tensor([[-1.1914, -1.8767],
        [-1.2368, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04286827892065048
Epoch 0, Step 555: train/loss = 0.6957617402076721, train/raw-loss = 0.6942024827003479, train/logprobs = tensor([[-1.4863, -1.6273],
        [-1.4514, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005197639111429453
Epoch 0, Step 556: train/loss = 0.695145845413208, train/raw-loss = 0.6719340682029724, train/logprobs = tensor([[-1.3986, -1.9119],
        [-1.0846, -1.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773724913597107
Epoch 0, Step 557: train/loss = 0.6945369839668274, train/raw-loss = 0.6937378644943237, train/logprobs = tensor([[-0.9446, -1.0056],
        [-0.9363, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002663635415956378
Epoch 0, Step 558: train/loss = 0.6732458472251892, train/raw-loss = 0.6286242008209229, train/logprobs = tensor([[-1.3193, -2.2144],
        [-1.1173, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14873898029327393
Epoch 0, Step 559: train/loss = 0.7154083251953125, train/raw-loss = 0.7130303978919983, train/logprobs = tensor([[-1.4306, -1.8736],
        [-1.2853, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007926525548100471
Epoch 0, Step 560: train/loss = 0.6895228624343872, train/raw-loss = 0.6804497241973877, train/logprobs = tensor([[-0.9830, -1.2054],
        [-1.0087, -0.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030243922024965286
Epoch 0, Step 561: train/loss = 0.7516179084777832, train/raw-loss = 0.7175674438476562, train/logprobs = tensor([[-1.3164, -1.9403],
        [-1.2929, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11350154876708984
Epoch 0, Step 562: train/loss = 0.6927496194839478, train/raw-loss = 0.6258754134178162, train/logprobs = tensor([[-0.9882, -2.2383],
        [-1.0508, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.222913920879364
Epoch 0, Step 563: train/loss = 0.7039958238601685, train/raw-loss = 0.6892521381378174, train/logprobs = tensor([[-1.2024, -1.6557],
        [-1.3850, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04914556071162224
Epoch 0, Step 564: train/loss = 0.6937142610549927, train/raw-loss = 0.6199377775192261, train/logprobs = tensor([[-0.8335, -2.6074],
        [-1.2624, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24592162668704987
Epoch 0, Step 565: train/loss = 0.7116451859474182, train/raw-loss = 0.6605719327926636, train/logprobs = tensor([[-1.1521, -2.8387],
        [-1.3292, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1702442318201065
Epoch 0, Step 566: train/loss = 0.694177508354187, train/raw-loss = 0.6938067674636841, train/logprobs = tensor([[-1.3942, -1.4843],
        [-1.0402, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012359591200947762
Epoch 0, Step 567: train/loss = 0.6898365020751953, train/raw-loss = 0.654004693031311, train/logprobs = tensor([[-1.1452, -2.4378],
        [-1.4468, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11943933367729187
Epoch 0, Step 568: train/loss = 0.6931031346321106, train/raw-loss = 0.6920253038406372, train/logprobs = tensor([[-1.2958, -1.3334],
        [-1.3244, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035928015131503344
Epoch 0, Step 569: train/loss = 0.7211194634437561, train/raw-loss = 0.7066522240638733, train/logprobs = tensor([[-1.5904, -1.7701],
        [-1.3293, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04822413623332977
Epoch 0, Step 570: train/loss = 0.7365403771400452, train/raw-loss = 0.7237987518310547, train/logprobs = tensor([[-1.5553, -2.2985],
        [-1.0563, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04247201979160309
Epoch 0, Step 571: train/loss = 0.6814515590667725, train/raw-loss = 0.6478261351585388, train/logprobs = tensor([[-1.0661, -1.8841],
        [-1.3952, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11208482086658478
Epoch 0, Step 572: train/loss = 0.6974365711212158, train/raw-loss = 0.6562298536300659, train/logprobs = tensor([[-0.9978, -2.3945],
        [-1.1874, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137355774641037
Epoch 0, Step 573: train/loss = 0.7025753855705261, train/raw-loss = 0.701016902923584, train/logprobs = tensor([[-1.2649, -1.2446],
        [-1.0539, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005194873083382845
Epoch 0, Step 574: train/loss = 0.7287856340408325, train/raw-loss = 0.692986011505127, train/logprobs = tensor([[-0.8723, -2.4496],
        [-0.9446, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11933235079050064
Epoch 0, Step 575: train/loss = 0.7059659361839294, train/raw-loss = 0.6937596201896667, train/logprobs = tensor([[-1.0910, -1.1494],
        [-1.4069, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04068763926625252
Epoch 0, Step 576: train/loss = 0.7371974587440491, train/raw-loss = 0.7169456481933594, train/logprobs = tensor([[-1.3608, -1.9802],
        [-1.6933, -1.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750603020191193
Epoch 0, Step 577: train/loss = 0.6932789087295532, train/raw-loss = 0.6725400686264038, train/logprobs = tensor([[-1.2192, -1.6347],
        [-1.2317, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06912972778081894
Epoch 0, Step 578: train/loss = 0.6834279298782349, train/raw-loss = 0.6496706604957581, train/logprobs = tensor([[-1.4679, -2.6229],
        [-1.2152, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11252415180206299
Epoch 0, Step 579: train/loss = 0.678833544254303, train/raw-loss = 0.6593483090400696, train/logprobs = tensor([[-1.5001, -2.0795],
        [-1.3207, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06495076417922974
Epoch 0, Step 580: train/loss = 0.6803016662597656, train/raw-loss = 0.6127843856811523, train/logprobs = tensor([[-1.0035, -2.7603],
        [-1.3740, -0.9737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22505785524845123
Epoch 0, Step 581: train/loss = 0.6901237964630127, train/raw-loss = 0.6859089732170105, train/logprobs = tensor([[-1.0468, -1.3239],
        [-0.9276, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01404978521168232
Epoch 0, Step 582: train/loss = 0.701687216758728, train/raw-loss = 0.6662113070487976, train/logprobs = tensor([[-0.9556, -1.9233],
        [-1.2821, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182531863451004
Epoch 0, Step 583: train/loss = 0.6799694299697876, train/raw-loss = 0.6525173187255859, train/logprobs = tensor([[-1.1182, -2.0155],
        [-1.1844, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150698035955429
Epoch 0, Step 584: train/loss = 0.6855549216270447, train/raw-loss = 0.6737017631530762, train/logprobs = tensor([[-1.9797, -2.3549],
        [-1.2447, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039510633796453476
Epoch 0, Step 585: train/loss = 0.7769689559936523, train/raw-loss = 0.776319146156311, train/logprobs = tensor([[-1.0000, -1.3112],
        [-0.7198, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002166161546483636
Epoch 0, Step 586: train/loss = 0.6962006092071533, train/raw-loss = 0.6940162181854248, train/logprobs = tensor([[-1.3146, -1.3023],
        [-1.3184, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007281262427568436
Epoch 0, Step 587: train/loss = 0.6957404613494873, train/raw-loss = 0.6908894777297974, train/logprobs = tensor([[-2.2680, -2.3322],
        [-1.4868, -1.3358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01616973802447319
Epoch 0, Step 588: train/loss = 0.7360361814498901, train/raw-loss = 0.671116828918457, train/logprobs = tensor([[-0.8710, -2.8190],
        [-1.2525, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21639780700206757
Epoch 0, Step 589: train/loss = 0.7077972888946533, train/raw-loss = 0.6748114824295044, train/logprobs = tensor([[-1.2032, -2.3278],
        [-1.2780, -1.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099523976445198
Epoch 0, Step 590: train/loss = 0.6890113949775696, train/raw-loss = 0.6768627166748047, train/logprobs = tensor([[-1.5498, -2.0324],
        [-0.9587, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04049547016620636
Epoch 0, Step 591: train/loss = 0.7056574821472168, train/raw-loss = 0.6962090730667114, train/logprobs = tensor([[-1.1656, -1.6737],
        [-1.0809, -1.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0314948670566082
Epoch 0, Step 592: train/loss = 0.6772899627685547, train/raw-loss = 0.6390138864517212, train/logprobs = tensor([[-1.1436, -2.5774],
        [-1.2062, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12758666276931763
Epoch 0, Step 593: train/loss = 0.6582105755805969, train/raw-loss = 0.6200160980224609, train/logprobs = tensor([[-1.7275, -2.7103],
        [-1.3022, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12731480598449707
Epoch 0, Step 594: train/loss = 0.6558140516281128, train/raw-loss = 0.6123956441879272, train/logprobs = tensor([[-1.6803, -2.9003],
        [-1.3991, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14472807943820953
Epoch 0, Step 595: train/loss = 0.6588406562805176, train/raw-loss = 0.6010392308235168, train/logprobs = tensor([[-1.2292, -2.9770],
        [-2.4740, -1.6168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19267158210277557
Epoch 0, Step 596: train/loss = 0.6890949606895447, train/raw-loss = 0.6807674169540405, train/logprobs = tensor([[-1.1687, -1.6086],
        [-1.5489, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027758613228797913
Epoch 0, Step 597: train/loss = 0.6557721495628357, train/raw-loss = 0.6156131625175476, train/logprobs = tensor([[-1.0980, -2.2817],
        [-1.2404, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338631808757782
Epoch 0, Step 598: train/loss = 0.6792160272598267, train/raw-loss = 0.6625553965568542, train/logprobs = tensor([[-1.1154, -1.6387],
        [-1.0201, -0.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05553525686264038
Epoch 0, Step 599: train/loss = 0.6945186257362366, train/raw-loss = 0.69449782371521, train/logprobs = tensor([[-1.0451, -1.1190],
        [-0.8154, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.899620348121971e-05
Epoch 0, Step 600: train/loss = 0.6977772116661072, train/raw-loss = 0.6819573044776917, train/logprobs = tensor([[-1.0658, -1.5611],
        [-1.2087, -1.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05273306369781494
Epoch 0, Step 601: train/loss = 0.6961597800254822, train/raw-loss = 0.6958997845649719, train/logprobs = tensor([[-1.0828, -0.9950],
        [-0.9880, -0.9574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008666592184454203
Epoch 0, Step 602: train/loss = 0.697698712348938, train/raw-loss = 0.6947174072265625, train/logprobs = tensor([[-1.1591, -1.2949],
        [-0.8772, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009937861002981663
Epoch 0, Step 603: train/loss = 0.6893525123596191, train/raw-loss = 0.6532992720603943, train/logprobs = tensor([[-0.8622, -2.3001],
        [-1.2691, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12017747759819031
Epoch 0, Step 604: train/loss = 0.7051123380661011, train/raw-loss = 0.6926606893539429, train/logprobs = tensor([[-1.3185, -1.5391],
        [-1.2151, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04150557145476341
Epoch 0, Step 605: train/loss = 0.690925657749176, train/raw-loss = 0.664402961730957, train/logprobs = tensor([[-0.9058, -1.6805],
        [-1.0018, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884091854095459
Epoch 0, Step 606: train/loss = 0.6959691047668457, train/raw-loss = 0.6941357254981995, train/logprobs = tensor([[-1.4268, -1.4092],
        [-1.1091, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006111293565481901
Epoch 0, Step 607: train/loss = 0.7248007655143738, train/raw-loss = 0.6630930304527283, train/logprobs = tensor([[-0.8870, -2.5175],
        [-0.9306, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20569241046905518
Epoch 0, Step 608: train/loss = 0.6951266527175903, train/raw-loss = 0.6946460008621216, train/logprobs = tensor([[-1.0616, -1.1615],
        [-0.9621, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016019975300878286
Epoch 0, Step 609: train/loss = 0.6677447557449341, train/raw-loss = 0.6159514784812927, train/logprobs = tensor([[-1.0032, -2.1190],
        [-1.5500, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17264437675476074
Epoch 0, Step 610: train/loss = 0.745177686214447, train/raw-loss = 0.7449750304222107, train/logprobs = tensor([[-1.0049, -1.3339],
        [-1.3501, -1.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006753592751920223
Epoch 0, Step 611: train/loss = 0.8298934698104858, train/raw-loss = 0.7991465330123901, train/logprobs = tensor([[-1.9201, -1.5030],
        [-1.7752, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249001532793045
Epoch 0, Step 612: train/loss = 0.7022340297698975, train/raw-loss = 0.6995013952255249, train/logprobs = tensor([[-0.9287, -0.9145],
        [-1.2119, -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00910877250134945
Epoch 0, Step 613: train/loss = 0.7047897577285767, train/raw-loss = 0.6881968975067139, train/logprobs = tensor([[-0.9252, -1.4261],
        [-1.3207, -1.0874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05530954524874687
Epoch 0, Step 614: train/loss = 0.711498498916626, train/raw-loss = 0.7062671184539795, train/logprobs = tensor([[-1.5923, -1.4319],
        [-1.3298, -1.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017438096925616264
Epoch 0, Step 615: train/loss = 0.7017809748649597, train/raw-loss = 0.6978523135185242, train/logprobs = tensor([[-1.8133, -1.9552],
        [-1.2027, -0.9873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013095501810312271
Epoch 0, Step 616: train/loss = 0.7399598956108093, train/raw-loss = 0.6746519804000854, train/logprobs = tensor([[-1.3582, -3.0344],
        [-1.3451, -1.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21769309043884277
Epoch 0, Step 617: train/loss = 0.7130928039550781, train/raw-loss = 0.6820669174194336, train/logprobs = tensor([[-0.7995, -2.0520],
        [-1.0613, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10341963171958923
Epoch 0, Step 618: train/loss = 0.7254524827003479, train/raw-loss = 0.7133550643920898, train/logprobs = tensor([[-1.7704, -1.7191],
        [-1.4200, -1.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040324896574020386
Epoch 0, Step 619: train/loss = 0.6910665035247803, train/raw-loss = 0.6773874759674072, train/logprobs = tensor([[-1.3421, -1.7187],
        [-1.6563, -1.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04559674859046936
Epoch 0, Step 620: train/loss = 0.7366706132888794, train/raw-loss = 0.7080087065696716, train/logprobs = tensor([[-0.9932, -2.1650],
        [-1.2230, -1.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0955398753285408
Epoch 0, Step 621: train/loss = 0.7185669541358948, train/raw-loss = 0.7103432416915894, train/logprobs = tensor([[-1.0190, -1.2179],
        [-1.2437, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027412403374910355
Epoch 0, Step 622: train/loss = 0.6557813286781311, train/raw-loss = 0.5887292623519897, train/logprobs = tensor([[-1.2127, -2.5408],
        [-1.3609, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22350701689720154
Epoch 0, Step 623: train/loss = 0.7840867638587952, train/raw-loss = 0.7755254507064819, train/logprobs = tensor([[-1.5776, -1.6348],
        [-1.5456, -0.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028537511825561523
Epoch 0, Step 624: train/loss = 0.7048234939575195, train/raw-loss = 0.6645954251289368, train/logprobs = tensor([[-1.0652, -2.1479],
        [-1.2454, -1.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1340935230255127
Epoch 0, Step 625: train/loss = 0.7425425052642822, train/raw-loss = 0.7271127104759216, train/logprobs = tensor([[-0.6871, -1.7612],
        [-0.8643, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05143279954791069
Epoch 0, Step 626: train/loss = 0.6795971393585205, train/raw-loss = 0.6661957502365112, train/logprobs = tensor([[-1.3441, -1.5599],
        [-1.4857, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044671088457107544
Epoch 0, Step 627: train/loss = 0.7080259919166565, train/raw-loss = 0.7039828300476074, train/logprobs = tensor([[-2.1215, -1.9712],
        [-1.3226, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013477342203259468
Epoch 0, Step 628: train/loss = 0.6850485801696777, train/raw-loss = 0.6548112034797668, train/logprobs = tensor([[-1.2908, -1.8100],
        [-1.6141, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10079138725996017
Epoch 0, Step 629: train/loss = 0.6583201289176941, train/raw-loss = 0.5999631881713867, train/logprobs = tensor([[-1.4034, -2.5424],
        [-1.3570, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19452336430549622
Epoch 0, Step 630: train/loss = 0.7079485654830933, train/raw-loss = 0.6749940514564514, train/logprobs = tensor([[-0.8337, -1.4670],
        [-1.3150, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10984833538532257
Epoch 0, Step 631: train/loss = 0.6517494320869446, train/raw-loss = 0.5798709392547607, train/logprobs = tensor([[-0.9798, -2.8167],
        [-1.3805, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23959484696388245
Epoch 0, Step 632: train/loss = 0.6961795091629028, train/raw-loss = 0.6638301610946655, train/logprobs = tensor([[-1.6013, -2.5248],
        [-1.5090, -1.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10783125460147858
Epoch 0, Step 633: train/loss = 0.6908363699913025, train/raw-loss = 0.6881051063537598, train/logprobs = tensor([[-1.9689, -2.1184],
        [-1.0899, -1.0165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009104115888476372
Epoch 0, Step 634: train/loss = 0.6646751165390015, train/raw-loss = 0.6134419441223145, train/logprobs = tensor([[-1.8216, -2.9052],
        [-1.4187, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17077717185020447
Epoch 0, Step 635: train/loss = 0.6882278919219971, train/raw-loss = 0.6789835691452026, train/logprobs = tensor([[-2.0428, -2.2751],
        [-0.8712, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030814513564109802
Epoch 0, Step 636: train/loss = 0.6864797472953796, train/raw-loss = 0.6261240243911743, train/logprobs = tensor([[-1.2799, -2.6581],
        [-1.3519, -1.0170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20118549466133118
Epoch 0, Step 637: train/loss = 0.6689451932907104, train/raw-loss = 0.6445857286453247, train/logprobs = tensor([[-0.9157, -1.4856],
        [-1.4218, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119834959506989
Epoch 0, Step 638: train/loss = 0.6509727835655212, train/raw-loss = 0.6024198532104492, train/logprobs = tensor([[-0.8552, -2.3574],
        [-1.4082, -1.1029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16184325516223907
Epoch 0, Step 639: train/loss = 0.6843500137329102, train/raw-loss = 0.6174166798591614, train/logprobs = tensor([[-1.0423, -2.5935],
        [-1.3209, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2231111377477646
Epoch 0, Step 640: train/loss = 0.6109882593154907, train/raw-loss = 0.5428852438926697, train/logprobs = tensor([[-1.5534, -3.4300],
        [-1.8486, -1.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22701016068458557
Epoch 0, Step 641: train/loss = 0.6776140332221985, train/raw-loss = 0.629690408706665, train/logprobs = tensor([[-1.3536, -2.5545],
        [-1.6248, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15974554419517517
Epoch 0, Step 642: train/loss = 0.6806515455245972, train/raw-loss = 0.6567836999893188, train/logprobs = tensor([[-1.2638, -1.9382],
        [-0.9049, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07955949008464813
Epoch 0, Step 643: train/loss = 0.6690202355384827, train/raw-loss = 0.6251287460327148, train/logprobs = tensor([[-1.2433, -2.0983],
        [-1.7531, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14630499482154846
Epoch 0, Step 644: train/loss = 0.6913056373596191, train/raw-loss = 0.6432752013206482, train/logprobs = tensor([[-1.1963, -2.4100],
        [-1.2819, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16010166704654694
Epoch 0, Step 645: train/loss = 0.7111325263977051, train/raw-loss = 0.6990565061569214, train/logprobs = tensor([[-1.9938, -1.9351],
        [-1.1329, -1.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04025324806571007
Epoch 0, Step 646: train/loss = 0.7314683794975281, train/raw-loss = 0.7182788848876953, train/logprobs = tensor([[-0.7673, -1.5364],
        [-1.4952, -1.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04396472126245499
Epoch 0, Step 647: train/loss = 0.6798543334007263, train/raw-loss = 0.6280550360679626, train/logprobs = tensor([[-0.8000, -2.1209],
        [-1.3297, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17266422510147095
Epoch 0, Step 648: train/loss = 0.6841048002243042, train/raw-loss = 0.6201819777488708, train/logprobs = tensor([[-1.1680, -2.3795],
        [-1.5280, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21307609975337982
Epoch 0, Step 649: train/loss = 0.6845784187316895, train/raw-loss = 0.6500435471534729, train/logprobs = tensor([[-0.7622, -1.7027],
        [-1.4810, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11511620134115219
Epoch 0, Step 650: train/loss = 0.7025582790374756, train/raw-loss = 0.6822969913482666, train/logprobs = tensor([[-0.7223, -1.4064],
        [-1.1272, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06753761321306229
Epoch 0, Step 651: train/loss = 0.701004683971405, train/raw-loss = 0.6803203821182251, train/logprobs = tensor([[-1.8521, -2.0316],
        [-1.4605, -0.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06894753873348236
Epoch 0, Step 652: train/loss = 0.7059968113899231, train/raw-loss = 0.7003114223480225, train/logprobs = tensor([[-1.9625, -1.9025],
        [-1.1143, -0.8489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018951157107949257
Epoch 0, Step 653: train/loss = 0.6859015226364136, train/raw-loss = 0.6528066396713257, train/logprobs = tensor([[-0.9200, -1.8200],
        [-1.4432, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11031640321016312
Epoch 0, Step 654: train/loss = 0.6875631809234619, train/raw-loss = 0.6762959957122803, train/logprobs = tensor([[-0.9842, -1.1782],
        [-1.1579, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037557270377874374
Epoch 0, Step 655: train/loss = 0.6800351142883301, train/raw-loss = 0.6033205986022949, train/logprobs = tensor([[-1.2715, -3.3957],
        [-1.2895, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25571495294570923
Epoch 0, Step 656: train/loss = 0.6653551459312439, train/raw-loss = 0.6334067583084106, train/logprobs = tensor([[-1.1747, -1.8557],
        [-1.4121, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10649476200342178
Epoch 0, Step 657: train/loss = 0.652764618396759, train/raw-loss = 0.5635766386985779, train/logprobs = tensor([[-1.4237, -2.9218],
        [-2.0709, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29729318618774414
Epoch 0, Step 658: train/loss = 0.6809729337692261, train/raw-loss = 0.6507558822631836, train/logprobs = tensor([[-1.1859, -1.9305],
        [-1.4205, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10072347521781921
Epoch 0, Step 659: train/loss = 0.6775032877922058, train/raw-loss = 0.655003547668457, train/logprobs = tensor([[-1.2632, -1.7335],
        [-1.5308, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07499895244836807
Epoch 0, Step 660: train/loss = 0.6668624877929688, train/raw-loss = 0.638177752494812, train/logprobs = tensor([[-1.9940, -2.3502],
        [-1.5643, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09561584889888763
Epoch 0, Step 661: train/loss = 0.6600316166877747, train/raw-loss = 0.6115413904190063, train/logprobs = tensor([[-1.8889, -2.6768],
        [-1.3350, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16163410246372223
Epoch 0, Step 662: train/loss = 0.6970854997634888, train/raw-loss = 0.6675734519958496, train/logprobs = tensor([[-0.9956, -1.1829],
        [-1.6641, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09837370365858078
Epoch 0, Step 663: train/loss = 0.6564832925796509, train/raw-loss = 0.6024585366249084, train/logprobs = tensor([[-1.2252, -1.9445],
        [-1.6560, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18008258938789368
Epoch 0, Step 664: train/loss = 0.696916937828064, train/raw-loss = 0.6874529719352722, train/logprobs = tensor([[-1.2951, -1.6895],
        [-1.2647, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03154648840427399
Epoch 0, Step 665: train/loss = 0.6765719652175903, train/raw-loss = 0.6539791822433472, train/logprobs = tensor([[-1.1238, -1.7607],
        [-1.8349, -1.5029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07530926167964935
Epoch 0, Step 666: train/loss = 0.6978851556777954, train/raw-loss = 0.6863672733306885, train/logprobs = tensor([[-1.2845, -1.2575],
        [-1.6267, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0383930504322052
Epoch 0, Step 667: train/loss = 0.6918444037437439, train/raw-loss = 0.6850907802581787, train/logprobs = tensor([[-1.1851, -1.3659],
        [-1.1759, -0.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02251221053302288
Epoch 0, Step 668: train/loss = 0.6622830629348755, train/raw-loss = 0.6072553396224976, train/logprobs = tensor([[-1.3312, -2.2049],
        [-1.3424, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183425635099411
Epoch 0, Step 669: train/loss = 0.6757973432540894, train/raw-loss = 0.5976681113243103, train/logprobs = tensor([[-1.1883, -2.4712],
        [-1.6625, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26043078303337097
Epoch 0, Step 670: train/loss = 0.652553379535675, train/raw-loss = 0.5830087661743164, train/logprobs = tensor([[-1.2394, -2.3672],
        [-1.6721, -0.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.231815367937088
Epoch 0, Step 671: train/loss = 0.7035996317863464, train/raw-loss = 0.6938391327857971, train/logprobs = tensor([[-0.9887, -1.1428],
        [-1.7513, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03253499045968056
Epoch 0, Step 672: train/loss = 0.6840488910675049, train/raw-loss = 0.6630951762199402, train/logprobs = tensor([[-1.0987, -1.6739],
        [-1.5002, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06984579563140869
Epoch 0, Step 673: train/loss = 0.6946350336074829, train/raw-loss = 0.6647336483001709, train/logprobs = tensor([[-1.6672, -2.2911],
        [-1.0036, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09967143833637238
Epoch 0, Step 674: train/loss = 0.6539162397384644, train/raw-loss = 0.5958686470985413, train/logprobs = tensor([[-1.2036, -2.4275],
        [-1.3850, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1934918463230133
Epoch 0, Step 675: train/loss = 0.688552737236023, train/raw-loss = 0.683418869972229, train/logprobs = tensor([[-1.3682, -1.6186],
        [-0.9153, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017112817615270615
Epoch 0, Step 676: train/loss = 0.6304380893707275, train/raw-loss = 0.5228281617164612, train/logprobs = tensor([[-0.9481, -2.3877],
        [-1.7632, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358699768781662
Epoch 0, Step 677: train/loss = 0.6836428046226501, train/raw-loss = 0.649272084236145, train/logprobs = tensor([[-2.3034, -3.2871],
        [-1.0574, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456894874572754
Epoch 0, Step 678: train/loss = 0.6923223733901978, train/raw-loss = 0.667454183101654, train/logprobs = tensor([[-1.5699, -2.4089],
        [-1.7219, -1.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08289394527673721
Epoch 0, Step 679: train/loss = 0.6608725786209106, train/raw-loss = 0.6099117994308472, train/logprobs = tensor([[-1.1346, -1.9191],
        [-1.7758, -1.4832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16986915469169617
Epoch 0, Step 680: train/loss = 0.6366778612136841, train/raw-loss = 0.5473943948745728, train/logprobs = tensor([[-1.5562, -3.5582],
        [-1.5845, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29761138558387756
Epoch 0, Step 681: train/loss = 0.6586003303527832, train/raw-loss = 0.6103286147117615, train/logprobs = tensor([[-1.7777, -2.7215],
        [-1.6039, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16090571880340576
Epoch 0, Step 682: train/loss = 0.6879420280456543, train/raw-loss = 0.6741263270378113, train/logprobs = tensor([[-1.2116, -1.8451],
        [-1.6602, -1.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04605254530906677
Epoch 0, Step 683: train/loss = 0.629970908164978, train/raw-loss = 0.544223964214325, train/logprobs = tensor([[-1.2358, -2.6193],
        [-1.6403, -0.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28582313656806946
Epoch 0, Step 684: train/loss = 0.6824709177017212, train/raw-loss = 0.655672550201416, train/logprobs = tensor([[-1.3601, -2.3997],
        [-1.5763, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08932806551456451
Epoch 0, Step 685: train/loss = 0.7037771940231323, train/raw-loss = 0.7016608715057373, train/logprobs = tensor([[-1.5422, -1.5712],
        [-1.3583, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007054441142827272
Epoch 0, Step 686: train/loss = 0.6598542928695679, train/raw-loss = 0.6187788844108582, train/logprobs = tensor([[-1.5439, -2.1983],
        [-1.4542, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1369178295135498
Epoch 0, Step 687: train/loss = 0.6484265327453613, train/raw-loss = 0.5660269260406494, train/logprobs = tensor([[-1.0405, -2.8385],
        [-1.8966, -1.2846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27466532588005066
Epoch 0, Step 688: train/loss = 0.681066632270813, train/raw-loss = 0.6573777794837952, train/logprobs = tensor([[-1.1513, -1.6642],
        [-1.9293, -1.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07896284013986588
Epoch 0, Step 689: train/loss = 0.6357587575912476, train/raw-loss = 0.5599431991577148, train/logprobs = tensor([[-1.0779, -1.8865],
        [-1.7275, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527184784412384
Epoch 0, Step 690: train/loss = 0.762405514717102, train/raw-loss = 0.6930809020996094, train/logprobs = tensor([[-1.3740, -2.8574],
        [-1.9463, -1.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23108215630054474
Epoch 0, Step 691: train/loss = 0.6402588486671448, train/raw-loss = 0.5528348088264465, train/logprobs = tensor([[-1.1189, -2.8259],
        [-1.6676, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29141342639923096
Epoch 0, Step 692: train/loss = 0.6340627670288086, train/raw-loss = 0.5619257688522339, train/logprobs = tensor([[-1.2888, -2.7147],
        [-1.7171, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24045643210411072
Epoch 0, Step 693: train/loss = 0.601292610168457, train/raw-loss = 0.49003881216049194, train/logprobs = tensor([[-1.2216, -2.4886],
        [-2.6019, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37084609270095825
Epoch 0, Step 694: train/loss = 0.710309624671936, train/raw-loss = 0.705004870891571, train/logprobs = tensor([[-1.3415, -1.4160],
        [-1.3938, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01768260821700096
Epoch 0, Step 695: train/loss = 0.6543927192687988, train/raw-loss = 0.6167774200439453, train/logprobs = tensor([[-1.4619, -2.0254],
        [-1.6802, -1.2537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1253841668367386
Epoch 0, Step 696: train/loss = 0.6675195693969727, train/raw-loss = 0.6216811537742615, train/logprobs = tensor([[-0.7428, -1.4511],
        [-1.4621, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15279461443424225
Epoch 0, Step 697: train/loss = 0.6880227327346802, train/raw-loss = 0.6669372320175171, train/logprobs = tensor([[-1.5562, -1.8935],
        [-1.6040, -1.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07028499245643616
Epoch 0, Step 698: train/loss = 0.6568147540092468, train/raw-loss = 0.6015845537185669, train/logprobs = tensor([[-1.5916, -2.1706],
        [-2.1309, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18410071730613708
Epoch 0, Step 699: train/loss = 0.654731273651123, train/raw-loss = 0.603907585144043, train/logprobs = tensor([[-1.2772, -2.1630],
        [-1.5949, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16941237449645996
Epoch 0, Step 700: train/loss = 0.6810451745986938, train/raw-loss = 0.6279325485229492, train/logprobs = tensor([[-1.4617, -2.5176],
        [-1.5562, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17704233527183533
Epoch 0, Step 701: train/loss = 0.7428320646286011, train/raw-loss = 0.7022261619567871, train/logprobs = tensor([[-1.7994, -2.3433],
        [-1.9423, -1.5192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13535290956497192
Epoch 0, Step 702: train/loss = 0.6635693907737732, train/raw-loss = 0.608108639717102, train/logprobs = tensor([[-1.3271, -1.8104],
        [-1.2110, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1848691701889038
Epoch 0, Step 703: train/loss = 0.6873993873596191, train/raw-loss = 0.6459558010101318, train/logprobs = tensor([[-1.1657, -2.3050],
        [-1.2882, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13814543187618256
Epoch 0, Step 704: train/loss = 0.6317116618156433, train/raw-loss = 0.5316781997680664, train/logprobs = tensor([[-1.8088, -3.2334],
        [-1.9383, -1.3114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334450125694275
Epoch 0, Step 705: train/loss = 0.6507876515388489, train/raw-loss = 0.5893709659576416, train/logprobs = tensor([[-1.4544, -2.4473],
        [-1.8025, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20472201704978943
Epoch 0, Step 706: train/loss = 0.5697571039199829, train/raw-loss = 0.42246347665786743, train/logprobs = tensor([[-0.7981, -2.9092],
        [-2.2264, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49097874760627747
Epoch 0, Step 707: train/loss = 0.6935815811157227, train/raw-loss = 0.692931056022644, train/logprobs = tensor([[-1.6154, -1.6377],
        [-1.1331, -1.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021683366503566504
Epoch 0, Step 708: train/loss = 0.6546084880828857, train/raw-loss = 0.5758217573165894, train/logprobs = tensor([[-1.2721, -3.0516],
        [-1.4441, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626224458217621
Epoch 0, Step 709: train/loss = 0.6394181251525879, train/raw-loss = 0.543255090713501, train/logprobs = tensor([[-1.1067, -2.1927],
        [-2.5069, -1.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32054340839385986
Epoch 0, Step 710: train/loss = 0.5489099025726318, train/raw-loss = 0.3841565251350403, train/logprobs = tensor([[-0.8646, -2.7468],
        [-2.7065, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5491777658462524
Epoch 0, Step 711: train/loss = 0.6709696054458618, train/raw-loss = 0.6027631759643555, train/logprobs = tensor([[-1.0757, -1.7002],
        [-2.4591, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22735466063022614
Epoch 0, Step 712: train/loss = 0.6557852625846863, train/raw-loss = 0.6060577630996704, train/logprobs = tensor([[-1.2910, -1.9888],
        [-1.6847, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16575837135314941
Epoch 0, Step 713: train/loss = 0.6722285151481628, train/raw-loss = 0.6422191858291626, train/logprobs = tensor([[-1.5375, -2.1685],
        [-1.5634, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10003107786178589
Epoch 0, Step 714: train/loss = 0.6290753483772278, train/raw-loss = 0.55128413438797, train/logprobs = tensor([[-1.2675, -2.3477],
        [-2.5220, -1.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25930407643318176
Epoch 0, Step 715: train/loss = 0.7015012502670288, train/raw-loss = 0.6782236099243164, train/logprobs = tensor([[-1.1380, -1.2759],
        [-1.8078, -2.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07759176194667816
Epoch 0, Step 716: train/loss = 0.5826641321182251, train/raw-loss = 0.43790197372436523, train/logprobs = tensor([[-1.0674, -3.4610],
        [-2.6300, -1.4216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4825403690338135
Epoch 0, Step 717: train/loss = 0.6465688347816467, train/raw-loss = 0.5674132704734802, train/logprobs = tensor([[-1.0952, -2.1625],
        [-2.2306, -1.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26385194063186646
Epoch 0, Step 718: train/loss = 0.599960446357727, train/raw-loss = 0.47627291083335876, train/logprobs = tensor([[-1.1721, -2.8118],
        [-1.9069, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122917652130127
Epoch 0, Step 719: train/loss = 0.6183990240097046, train/raw-loss = 0.5199506282806396, train/logprobs = tensor([[-1.3300, -2.7668],
        [-1.9839, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32816147804260254
Epoch 0, Step 720: train/loss = 0.7248306274414062, train/raw-loss = 0.7057338953018188, train/logprobs = tensor([[-1.3932, -1.9330],
        [-2.2788, -2.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365577131509781
Epoch 0, Step 721: train/loss = 0.6384918689727783, train/raw-loss = 0.5510222911834717, train/logprobs = tensor([[-1.3137, -2.5514],
        [-2.0495, -1.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29156532883644104
Epoch 0, Step 722: train/loss = 0.6024006605148315, train/raw-loss = 0.47314342856407166, train/logprobs = tensor([[-1.1104, -2.5111],
        [-2.7465, -1.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4308575391769409
Epoch 0, Step 723: train/loss = 0.684639036655426, train/raw-loss = 0.6602705121040344, train/logprobs = tensor([[-1.6895, -1.8922],
        [-1.8661, -1.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0812283307313919
Epoch 0, Step 724: train/loss = 0.6211538910865784, train/raw-loss = 0.5371566414833069, train/logprobs = tensor([[-0.9624, -1.9739],
        [-2.4706, -1.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27999070286750793
Epoch 0, Step 725: train/loss = 0.6406044960021973, train/raw-loss = 0.5621321201324463, train/logprobs = tensor([[-1.0423, -1.9853],
        [-1.8459, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615746259689331
Epoch 0, Step 726: train/loss = 0.6711245775222778, train/raw-loss = 0.6379369497299194, train/logprobs = tensor([[-1.4012, -1.6983],
        [-2.1564, -1.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062537133693695
Epoch 0, Step 727: train/loss = 0.62093186378479, train/raw-loss = 0.49829763174057007, train/logprobs = tensor([[-1.0258, -2.2067],
        [-2.8262, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.408780962228775
Epoch 0, Step 728: train/loss = 0.7046334743499756, train/raw-loss = 0.7036259174346924, train/logprobs = tensor([[-1.5022, -1.4112],
        [-1.8209, -1.6616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033585538621991873
Epoch 0, Step 729: train/loss = 0.6709402203559875, train/raw-loss = 0.6419233083724976, train/logprobs = tensor([[-1.1408, -1.6670],
        [-1.4095, -0.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09672295302152634
Epoch 0, Step 730: train/loss = 0.677045464515686, train/raw-loss = 0.6331194639205933, train/logprobs = tensor([[-1.7983, -2.5327],
        [-1.8751, -1.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14641979336738586
Epoch 0, Step 731: train/loss = 0.6333579421043396, train/raw-loss = 0.5202847123146057, train/logprobs = tensor([[-1.1577, -1.9004],
        [-2.9441, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37691089510917664
Epoch 0, Step 732: train/loss = 0.5723802447319031, train/raw-loss = 0.397113561630249, train/logprobs = tensor([[-1.2748, -3.6433],
        [-2.5657, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5842222571372986
Epoch 0, Step 733: train/loss = 0.6617052555084229, train/raw-loss = 0.5984603762626648, train/logprobs = tensor([[-1.0112, -1.6071],
        [-2.8076, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21081604063510895
Epoch 0, Step 734: train/loss = 0.6984083652496338, train/raw-loss = 0.6819601058959961, train/logprobs = tensor([[-1.2769, -1.1922],
        [-1.8779, -1.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0548277422785759
Epoch 0, Step 735: train/loss = 0.6607187986373901, train/raw-loss = 0.602994441986084, train/logprobs = tensor([[-1.7131, -2.6926],
        [-2.0323, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19241443276405334
Epoch 0, Step 736: train/loss = 0.6445397734642029, train/raw-loss = 0.5532076358795166, train/logprobs = tensor([[-1.5849, -2.3849],
        [-2.7456, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304440438747406
Epoch 0, Step 737: train/loss = 0.6725082993507385, train/raw-loss = 0.6307376623153687, train/logprobs = tensor([[-1.5699, -2.0552],
        [-1.7417, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392355114221573
Epoch 0, Step 738: train/loss = 0.6791935563087463, train/raw-loss = 0.6569068431854248, train/logprobs = tensor([[-1.5814, -1.9604],
        [-1.5829, -1.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0742890015244484
Epoch 0, Step 739: train/loss = 0.6337335109710693, train/raw-loss = 0.5655713677406311, train/logprobs = tensor([[-1.7128, -2.7928],
        [-1.8860, -1.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22720691561698914
Epoch 0, Step 740: train/loss = 0.6792004108428955, train/raw-loss = 0.6420279741287231, train/logprobs = tensor([[-1.1677, -1.6897],
        [-1.7312, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12390803545713425
Epoch 0, Step 741: train/loss = 0.6012792587280273, train/raw-loss = 0.47647833824157715, train/logprobs = tensor([[-0.9715, -2.7157],
        [-2.2558, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4160032272338867
Epoch 0, Step 742: train/loss = 0.5254331827163696, train/raw-loss = 0.33388590812683105, train/logprobs = tensor([[-1.1918, -3.6271],
        [-3.2647, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6384909749031067
Epoch 0, Step 743: train/loss = 0.567936360836029, train/raw-loss = 0.38697153329849243, train/logprobs = tensor([[-1.1097, -2.6829],
        [-3.0116, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6032160520553589
Epoch 0, Step 744: train/loss = 0.6212894916534424, train/raw-loss = 0.5142073631286621, train/logprobs = tensor([[-0.9715, -3.2176],
        [-2.7346, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3569403290748596
Epoch 0, Step 745: train/loss = 0.7004669308662415, train/raw-loss = 0.648619532585144, train/logprobs = tensor([[-1.1274, -1.3816],
        [-2.6613, -2.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17282459139823914
Epoch 0, Step 746: train/loss = 0.6932112574577332, train/raw-loss = 0.6862080097198486, train/logprobs = tensor([[-1.2827, -1.2424],
        [-1.5842, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023344162851572037
Epoch 0, Step 747: train/loss = 0.6405309438705444, train/raw-loss = 0.5704085826873779, train/logprobs = tensor([[-1.3677, -2.0974],
        [-3.0703, -2.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2337411344051361
Epoch 0, Step 748: train/loss = 0.695415735244751, train/raw-loss = 0.6874430775642395, train/logprobs = tensor([[-1.1813, -1.1933],
        [-2.5821, -2.2621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026575585827231407
Epoch 0, Step 749: train/loss = 0.5787069797515869, train/raw-loss = 0.4241091012954712, train/logprobs = tensor([[-1.0181, -2.3895],
        [-3.6627, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5153260827064514
Epoch 0, Step 750: train/loss = 0.682474672794342, train/raw-loss = 0.5781406760215759, train/logprobs = tensor([[-1.0825, -1.9806],
        [-2.5639, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34777992963790894
Epoch 0, Step 751: train/loss = 0.6890749931335449, train/raw-loss = 0.6764783263206482, train/logprobs = tensor([[-1.6296, -2.0402],
        [-1.8500, -1.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04198871925473213
Epoch 0, Step 752: train/loss = 0.6797802448272705, train/raw-loss = 0.6577668190002441, train/logprobs = tensor([[-2.4929, -3.0610],
        [-1.3185, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07337823510169983
Epoch 0, Step 753: train/loss = 0.6329540014266968, train/raw-loss = 0.5614131689071655, train/logprobs = tensor([[-1.3810, -2.2833],
        [-2.1281, -1.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384694665670395
Epoch 0, Step 754: train/loss = 0.7096313238143921, train/raw-loss = 0.636454701423645, train/logprobs = tensor([[-1.3134, -1.4524],
        [-3.2204, -1.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24392195045948029
Epoch 0, Step 755: train/loss = 0.5534059405326843, train/raw-loss = 0.3924548029899597, train/logprobs = tensor([[-1.2519, -3.3228],
        [-2.6901, -0.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5365036725997925
Epoch 0, Step 756: train/loss = 0.6451916098594666, train/raw-loss = 0.5670258402824402, train/logprobs = tensor([[-1.5302, -2.2112],
        [-2.6767, -1.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605525255203247
Epoch 0, Step 757: train/loss = 0.6950746774673462, train/raw-loss = 0.6932021379470825, train/logprobs = tensor([[-1.0774, -1.0781],
        [-3.5452, -3.5813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006241918075829744
Epoch 0, Step 758: train/loss = 0.6759695410728455, train/raw-loss = 0.6529099345207214, train/logprobs = tensor([[-1.0878, -1.5743],
        [-2.6626, -2.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07686536014080048
Epoch 0, Step 759: train/loss = 0.5561044812202454, train/raw-loss = 0.39965322613716125, train/logprobs = tensor([[-1.1511, -3.0604],
        [-2.6978, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5215041637420654
Epoch 0, Step 760: train/loss = 0.6413875818252563, train/raw-loss = 0.5794034004211426, train/logprobs = tensor([[-1.2488, -2.0845],
        [-2.7252, -1.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066137194633484
Epoch 0, Step 761: train/loss = 0.6384751796722412, train/raw-loss = 0.547330379486084, train/logprobs = tensor([[-1.6387, -2.5484],
        [-2.7159, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30381613969802856
Epoch 0, Step 762: train/loss = 0.681128203868866, train/raw-loss = 0.6418808102607727, train/logprobs = tensor([[-1.6321, -2.5861],
        [-1.4916, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13082458078861237
Epoch 0, Step 763: train/loss = 0.7158363461494446, train/raw-loss = 0.7002794146537781, train/logprobs = tensor([[-1.3448, -1.2118],
        [-2.3774, -1.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05185643583536148
Epoch 0, Step 764: train/loss = 0.6187652349472046, train/raw-loss = 0.5090826749801636, train/logprobs = tensor([[-1.8053, -3.0608],
        [-2.3251, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3656083345413208
Epoch 0, Step 765: train/loss = 0.6753882765769958, train/raw-loss = 0.6497892141342163, train/logprobs = tensor([[-1.6266, -1.9502],
        [-1.5774, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08533014357089996
Epoch 0, Step 766: train/loss = 0.7059759497642517, train/raw-loss = 0.6805112361907959, train/logprobs = tensor([[-1.3035, -1.3147],
        [-2.5532, -1.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0848824679851532
Epoch 0, Step 767: train/loss = 0.692534327507019, train/raw-loss = 0.6846393346786499, train/logprobs = tensor([[-1.1128, -1.2412],
        [-1.9308, -1.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02631654217839241
Epoch 0, Step 768: train/loss = 0.6416015028953552, train/raw-loss = 0.565988302230835, train/logprobs = tensor([[-1.3500, -2.3889],
        [-2.2251, -1.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520439922809601
Epoch 0, Step 769: train/loss = 0.5548880100250244, train/raw-loss = 0.38409823179244995, train/logprobs = tensor([[-1.0725, -3.1046],
        [-3.5146, -1.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5692993402481079
Epoch 0, Step 770: train/loss = 0.6081812381744385, train/raw-loss = 0.47812458872795105, train/logprobs = tensor([[-1.3218, -2.7850],
        [-3.0907, -1.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335220158100128
Epoch 0, Step 771: train/loss = 0.5983385443687439, train/raw-loss = 0.5028603076934814, train/logprobs = tensor([[-1.6935, -2.5648],
        [-2.7173, -1.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182608485221863
Epoch 0, Step 772: train/loss = 0.543680727481842, train/raw-loss = 0.3192634582519531, train/logprobs = tensor([[-0.9527, -2.7699],
        [-3.6346, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7480576038360596
Epoch 0, Step 773: train/loss = 0.6156978011131287, train/raw-loss = 0.49792417883872986, train/logprobs = tensor([[-1.1302, -2.0048],
        [-3.8497, -2.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39257872104644775
Epoch 0, Step 774: train/loss = 0.6234304904937744, train/raw-loss = 0.5203994512557983, train/logprobs = tensor([[-1.1976, -2.3872],
        [-2.9785, -1.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434368371963501
Epoch 0, Step 775: train/loss = 0.6553487777709961, train/raw-loss = 0.569171667098999, train/logprobs = tensor([[-1.5484, -1.9634],
        [-2.3464, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28725698590278625
Epoch 0, Step 776: train/loss = 0.6562615633010864, train/raw-loss = 0.5785704255104065, train/logprobs = tensor([[-1.4313, -1.9488],
        [-2.5054, -1.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25897035002708435
Epoch 0, Step 777: train/loss = 0.66650390625, train/raw-loss = 0.6172534227371216, train/logprobs = tensor([[-1.2011, -1.6597],
        [-2.0071, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16416841745376587
Epoch 0, Step 778: train/loss = 0.5714502930641174, train/raw-loss = 0.3919910490512848, train/logprobs = tensor([[-1.4673, -2.8501],
        [-3.6541, -1.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5981974601745605
Epoch 0, Step 779: train/loss = 0.6745626926422119, train/raw-loss = 0.624545156955719, train/logprobs = tensor([[-1.2449, -1.5702],
        [-1.5412, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1667250245809555
Epoch 0, Step 780: train/loss = 0.6548672914505005, train/raw-loss = 0.6006957292556763, train/logprobs = tensor([[-1.4967, -1.9741],
        [-2.2145, -1.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18057188391685486
Epoch 0, Step 781: train/loss = 0.6934208869934082, train/raw-loss = 0.6675328016281128, train/logprobs = tensor([[-1.3265, -1.1735],
        [-1.9756, -1.8578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08629373461008072
Epoch 0, Step 782: train/loss = 0.6476068496704102, train/raw-loss = 0.5713541507720947, train/logprobs = tensor([[-1.3384, -1.9445],
        [-1.9854, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2541755735874176
Epoch 0, Step 783: train/loss = 0.682448148727417, train/raw-loss = 0.5859746932983398, train/logprobs = tensor([[-1.1164, -1.8157],
        [-2.6829, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32157814502716064
Epoch 0, Step 784: train/loss = 0.6605410575866699, train/raw-loss = 0.633007287979126, train/logprobs = tensor([[-1.3538, -1.7945],
        [-2.6299, -2.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177930653095245
Epoch 0, Step 785: train/loss = 0.5903828740119934, train/raw-loss = 0.44630688428878784, train/logprobs = tensor([[-1.3895, -3.3736],
        [-3.2411, -1.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48025330901145935
Epoch 0, Step 786: train/loss = 0.5897241234779358, train/raw-loss = 0.4568374752998352, train/logprobs = tensor([[-1.2943, -2.9513],
        [-3.2699, -2.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44295552372932434
Epoch 0, Step 787: train/loss = 0.6526769399642944, train/raw-loss = 0.587675929069519, train/logprobs = tensor([[-1.5977, -2.1167],
        [-2.5731, -1.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21667003631591797
Epoch 0, Step 788: train/loss = 0.57554030418396, train/raw-loss = 0.37270545959472656, train/logprobs = tensor([[-1.1701, -2.6606],
        [-3.6614, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6761162281036377
Epoch 0, Step 789: train/loss = 0.7258058190345764, train/raw-loss = 0.7197927832603455, train/logprobs = tensor([[-1.9301, -1.8755],
        [-2.0948, -2.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020043212920427322
Epoch 0, Step 790: train/loss = 0.5857720375061035, train/raw-loss = 0.43542590737342834, train/logprobs = tensor([[-1.8874, -3.0743],
        [-2.5429, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5011539459228516
Epoch 0, Step 791: train/loss = 0.6016433238983154, train/raw-loss = 0.46482813358306885, train/logprobs = tensor([[-1.5243, -2.7928],
        [-3.7255, -1.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4560506045818329
Epoch 0, Step 792: train/loss = 0.6662106513977051, train/raw-loss = 0.4635637104511261, train/logprobs = tensor([[-1.5431, -2.9885],
        [-4.1124, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6754896640777588
Epoch 0, Step 793: train/loss = 0.6209789514541626, train/raw-loss = 0.528433620929718, train/logprobs = tensor([[-1.4989, -2.5141],
        [-2.5070, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30848443508148193
Epoch 0, Step 794: train/loss = 0.676988959312439, train/raw-loss = 0.6228656768798828, train/logprobs = tensor([[-1.8677, -1.8959],
        [-2.2882, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18041075766086578
Epoch 0, Step 795: train/loss = 0.49803510308265686, train/raw-loss = 0.2418009340763092, train/logprobs = tensor([[-1.4220, -3.9072],
        [-5.5491, -2.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8541138768196106
Epoch 0, Step 796: train/loss = 0.6136825680732727, train/raw-loss = 0.47622957825660706, train/logprobs = tensor([[-1.9159, -3.4853],
        [-2.5280, -0.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4581766426563263
Epoch 0, Step 797: train/loss = 0.668393611907959, train/raw-loss = 0.5634613633155823, train/logprobs = tensor([[-2.1438, -3.2456],
        [-3.4304, -2.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34977424144744873
Epoch 0, Step 798: train/loss = 0.6667729020118713, train/raw-loss = 0.6056485176086426, train/logprobs = tensor([[-1.2875, -1.9673],
        [-2.3111, -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20374804735183716
Epoch 0, Step 799: train/loss = 0.7339729070663452, train/raw-loss = 0.6944528222084045, train/logprobs = tensor([[-1.4080, -1.3415],
        [-1.8433, -2.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13173353672027588
Epoch 0, Step 800: train/loss = 0.5187945365905762, train/raw-loss = 0.25622373819351196, train/logprobs = tensor([[-0.7636, -2.9693],
        [-4.9819, -1.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.875235915184021
Epoch 0, Step 801: train/loss = 0.6519052386283875, train/raw-loss = 0.5885173678398132, train/logprobs = tensor([[-1.2690, -2.0282],
        [-2.5005, -1.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21129275858402252
Epoch 0, Step 802: train/loss = 0.6316166520118713, train/raw-loss = 0.542279839515686, train/logprobs = tensor([[-1.9252, -2.7749],
        [-2.5709, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29778939485549927
Epoch 0, Step 803: train/loss = 0.6076147556304932, train/raw-loss = 0.49416249990463257, train/logprobs = tensor([[-1.5264, -3.1248],
        [-2.9054, -1.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3781742453575134
Epoch 0, Step 804: train/loss = 0.6900283098220825, train/raw-loss = 0.6858553290367126, train/logprobs = tensor([[-2.0691, -2.1772],
        [-1.5045, -1.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013909959234297276
Epoch 0, Step 805: train/loss = 0.6391300559043884, train/raw-loss = 0.5473736524581909, train/logprobs = tensor([[-2.1761, -3.0023],
        [-3.0458, -1.6564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30585452914237976
Epoch 0, Step 806: train/loss = 0.6823384761810303, train/raw-loss = 0.6594672203063965, train/logprobs = tensor([[-1.9875, -2.2173],
        [-1.6725, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07623744755983353
Epoch 0, Step 807: train/loss = 0.5558701753616333, train/raw-loss = 0.37440651655197144, train/logprobs = tensor([[-0.9818, -2.7981],
        [-3.8377, -1.7919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6048787832260132
Epoch 0, Step 808: train/loss = 0.6388615965843201, train/raw-loss = 0.5686107873916626, train/logprobs = tensor([[-1.6972, -2.7056],
        [-1.8791, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23416952788829803
Epoch 0, Step 809: train/loss = 0.5723034739494324, train/raw-loss = 0.41914302110671997, train/logprobs = tensor([[-1.4926, -3.0702],
        [-2.7558, -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5105348229408264
Epoch 0, Step 810: train/loss = 0.6008105278015137, train/raw-loss = 0.556740939617157, train/logprobs = tensor([[-1.9539, -3.0119],
        [-1.6056, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14689864218235016
Epoch 0, Step 811: train/loss = 0.6256148815155029, train/raw-loss = 0.5171899199485779, train/logprobs = tensor([[-1.8137, -2.7371],
        [-3.5772, -1.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36141645908355713
Epoch 0, Step 812: train/loss = 0.6075327396392822, train/raw-loss = 0.48920291662216187, train/logprobs = tensor([[-1.2118, -2.4518],
        [-3.4389, -2.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39443281292915344
Epoch 0, Step 813: train/loss = 0.6167880892753601, train/raw-loss = 0.4875119626522064, train/logprobs = tensor([[-1.6199, -2.8833],
        [-3.0411, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4309203624725342
Epoch 0, Step 814: train/loss = 0.6208438873291016, train/raw-loss = 0.5147404074668884, train/logprobs = tensor([[-2.1605, -3.4056],
        [-2.3927, -1.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536781370639801
Epoch 0, Step 815: train/loss = 0.6655296087265015, train/raw-loss = 0.6328614950180054, train/logprobs = tensor([[-2.9621, -3.4054],
        [-1.8803, -1.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889358073472977
Epoch 0, Step 816: train/loss = 0.6040247678756714, train/raw-loss = 0.4799567759037018, train/logprobs = tensor([[-2.0590, -3.4072],
        [-2.4352, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41356000304222107
Epoch 0, Step 817: train/loss = 0.5586789846420288, train/raw-loss = 0.38524994254112244, train/logprobs = tensor([[-1.3904, -3.2649],
        [-3.2016, -1.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.578096866607666
Epoch 0, Step 818: train/loss = 0.5471762418746948, train/raw-loss = 0.343688428401947, train/logprobs = tensor([[-1.1220, -3.5686],
        [-4.1656, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6782927513122559
Epoch 0, Step 819: train/loss = 0.6607446670532227, train/raw-loss = 0.5781897306442261, train/logprobs = tensor([[-1.8452, -1.5736],
        [-3.1353, -3.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2751830220222473
Epoch 0, Step 820: train/loss = 0.6221209168434143, train/raw-loss = 0.5087879300117493, train/logprobs = tensor([[-1.7126, -2.7608],
        [-2.8781, -1.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37777671217918396
Epoch 0, Step 821: train/loss = 0.6021071076393127, train/raw-loss = 0.48841482400894165, train/logprobs = tensor([[-1.5156, -2.8165],
        [-3.1077, -1.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37897437810897827
Epoch 0, Step 822: train/loss = 0.6489120721817017, train/raw-loss = 0.5863664746284485, train/logprobs = tensor([[-2.1921, -2.5090],
        [-1.9023, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2084854394197464
Epoch 0, Step 823: train/loss = 0.6074243187904358, train/raw-loss = 0.4787949323654175, train/logprobs = tensor([[-1.6178, -2.6892],
        [-3.5508, -2.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42876458168029785
Epoch 0, Step 824: train/loss = 0.6370431184768677, train/raw-loss = 0.5588833093643188, train/logprobs = tensor([[-1.6718, -2.2081],
        [-2.6054, -1.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605326771736145
Epoch 0, Step 825: train/loss = 0.5762578845024109, train/raw-loss = 0.44055861234664917, train/logprobs = tensor([[-1.3914, -2.8883],
        [-4.5354, -2.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4523307681083679
Epoch 0, Step 826: train/loss = 0.6852254867553711, train/raw-loss = 0.6617106199264526, train/logprobs = tensor([[-1.8807, -2.0829],
        [-2.1736, -2.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07838291674852371
Epoch 0, Step 827: train/loss = 0.6509515643119812, train/raw-loss = 0.5882691144943237, train/logprobs = tensor([[-2.1731, -2.9854],
        [-1.7774, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20894142985343933
Epoch 0, Step 828: train/loss = 0.6598965525627136, train/raw-loss = 0.5906449556350708, train/logprobs = tensor([[-1.7677, -2.4404],
        [-2.1991, -1.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23083867132663727
Epoch 0, Step 829: train/loss = 0.5083280205726624, train/raw-loss = 0.2839674949645996, train/logprobs = tensor([[-1.1325, -3.8997],
        [-4.1648, -1.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7478684186935425
Epoch 0, Step 830: train/loss = 0.6057462692260742, train/raw-loss = 0.39397966861724854, train/logprobs = tensor([[-0.9638, -3.5255],
        [-3.6295, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7058888077735901
Epoch 0, Step 831: train/loss = 0.5987356305122375, train/raw-loss = 0.4122448265552521, train/logprobs = tensor([[-1.5265, -2.6280],
        [-3.9357, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6216359734535217
Epoch 0, Step 832: train/loss = 0.5782051086425781, train/raw-loss = 0.43340104818344116, train/logprobs = tensor([[-1.3579, -3.2983],
        [-2.5220, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4826802611351013
Epoch 0, Step 833: train/loss = 0.6147335767745972, train/raw-loss = 0.5150954723358154, train/logprobs = tensor([[-2.2653, -3.4108],
        [-2.9691, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33212679624557495
Epoch 0, Step 834: train/loss = 0.6514072418212891, train/raw-loss = 0.5464718341827393, train/logprobs = tensor([[-1.5018, -2.4551],
        [-2.9030, -2.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497844934463501
Epoch 0, Step 835: train/loss = 0.5794404149055481, train/raw-loss = 0.4307599663734436, train/logprobs = tensor([[-2.0452, -3.4558],
        [-2.7947, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4956014156341553
Epoch 0, Step 836: train/loss = 0.554230809211731, train/raw-loss = 0.3294079303741455, train/logprobs = tensor([[-1.6346, -3.6181],
        [-3.9940, -2.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7494097948074341
Epoch 0, Step 837: train/loss = 1.1867449283599854, train/raw-loss = 1.1039756536483765, train/logprobs = tensor([[-1.2812, -3.7852],
        [-3.3136, -3.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758979797363281
Epoch 0, Step 838: train/loss = 0.6121751666069031, train/raw-loss = 0.45730316638946533, train/logprobs = tensor([[-1.6923, -3.4871],
        [-3.3192, -2.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5162400007247925
Epoch 0, Step 839: train/loss = 0.5688718557357788, train/raw-loss = 0.43872007727622986, train/logprobs = tensor([[-1.5094, -3.2503],
        [-3.2074, -1.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43383923172950745
Epoch 0, Step 840: train/loss = 0.5926721096038818, train/raw-loss = 0.38831621408462524, train/logprobs = tensor([[-1.2120, -2.8212],
        [-4.1781, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6811862587928772
Epoch 0, Step 841: train/loss = 0.5266771912574768, train/raw-loss = 0.2803999185562134, train/logprobs = tensor([[-1.5741, -3.7841],
        [-4.0403, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8209242224693298
Epoch 0, Step 842: train/loss = 0.8841593265533447, train/raw-loss = 0.7674015164375305, train/logprobs = tensor([[-0.9744, -2.9074],
        [-2.8491, -2.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891926407814026
Epoch 0, Step 843: train/loss = 0.5893853902816772, train/raw-loss = 0.44557225704193115, train/logprobs = tensor([[-2.3606, -3.5054],
        [-4.0915, -1.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4793771803379059
Epoch 0, Step 844: train/loss = 0.5987110733985901, train/raw-loss = 0.44974902272224426, train/logprobs = tensor([[-2.5972, -4.6332],
        [-2.9387, -1.0787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4965401887893677
Epoch 0, Step 845: train/loss = 0.5023676753044128, train/raw-loss = 0.25871217250823975, train/logprobs = tensor([[-1.2255, -4.3534],
        [-3.8948, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8121848702430725
Epoch 0, Step 846: train/loss = 0.5733564496040344, train/raw-loss = 0.366682767868042, train/logprobs = tensor([[-0.5962, -2.3548],
        [-4.5417, -1.7551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6889122724533081
Epoch 0, Step 847: train/loss = 0.5679963231086731, train/raw-loss = 0.39527228474617004, train/logprobs = tensor([[-2.1883, -4.4961],
        [-2.5057, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5757467746734619
Epoch 0, Step 848: train/loss = 0.694197416305542, train/raw-loss = 0.6941718459129333, train/logprobs = tensor([[-4.1604, -4.2325],
        [-1.1419, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.522509597241879e-05
Epoch 0, Step 849: train/loss = 0.5996631979942322, train/raw-loss = 0.46343886852264404, train/logprobs = tensor([[-2.6889, -4.8128],
        [-2.5290, -1.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540810286998749
Epoch 0, Step 850: train/loss = 0.6365211009979248, train/raw-loss = 0.5308137536048889, train/logprobs = tensor([[-1.4085, -3.1140],
        [-3.9485, -3.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523576557636261
Epoch 0, Step 851: train/loss = 0.6992641687393188, train/raw-loss = 0.6578024625778198, train/logprobs = tensor([[-2.4274, -3.3806],
        [-2.1771, -1.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13820596039295197
Epoch 0, Step 852: train/loss = 0.6323404908180237, train/raw-loss = 0.5404834747314453, train/logprobs = tensor([[-1.9297, -3.3244],
        [-3.9987, -3.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061900734901428
Epoch 0, Step 853: train/loss = 0.616894006729126, train/raw-loss = 0.5092750787734985, train/logprobs = tensor([[-2.0279, -3.4513],
        [-2.4909, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35872966051101685
Epoch 0, Step 854: train/loss = 0.6896562576293945, train/raw-loss = 0.6160461902618408, train/logprobs = tensor([[-1.3954, -1.3818],
        [-3.7500, -2.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2453671246767044
Epoch 0, Step 855: train/loss = 0.5774243474006653, train/raw-loss = 0.40499597787857056, train/logprobs = tensor([[-0.9690, -2.8305],
        [-5.6799, -3.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.574761152267456
Epoch 0, Step 856: train/loss = 0.516642153263092, train/raw-loss = 0.2679794430732727, train/logprobs = tensor([[-1.7516, -4.7967],
        [-4.2599, -1.3042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8288756608963013
Epoch 0, Step 857: train/loss = 0.633918285369873, train/raw-loss = 0.5517587065696716, train/logprobs = tensor([[-3.9832, -5.1703],
        [-2.0132, -1.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27386534214019775
Epoch 0, Step 858: train/loss = 0.6266195774078369, train/raw-loss = 0.5470298528671265, train/logprobs = tensor([[-1.2141, -2.1936],
        [-3.2145, -2.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26529884338378906
Epoch 0, Step 859: train/loss = 0.567953884601593, train/raw-loss = 0.3886115550994873, train/logprobs = tensor([[-1.8163, -4.5104],
        [-3.3285, -1.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5978076457977295
Epoch 0, Step 860: train/loss = 0.6156598329544067, train/raw-loss = 0.49727386236190796, train/logprobs = tensor([[-2.0446, -3.2688],
        [-2.7753, -1.2282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39461976289749146
Epoch 0, Step 861: train/loss = 0.8323742747306824, train/raw-loss = 0.7441062331199646, train/logprobs = tensor([[-2.0684, -3.9689],
        [-3.1069, -2.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29422688484191895
Epoch 0, Step 862: train/loss = 0.5033703446388245, train/raw-loss = 0.25557318329811096, train/logprobs = tensor([[-1.5299, -4.5979],
        [-5.1281, -2.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8259904980659485
Epoch 0, Step 863: train/loss = 0.5169107913970947, train/raw-loss = 0.2633378505706787, train/logprobs = tensor([[-2.4235, -5.7969],
        [-4.3680, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8452429175376892
Epoch 0, Step 864: train/loss = 0.4532761871814728, train/raw-loss = 0.212234765291214, train/logprobs = tensor([[-1.1167, -4.9389],
        [-5.6845, -1.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8034713268280029
Epoch 0, Step 865: train/loss = 0.5999612808227539, train/raw-loss = 0.4855618476867676, train/logprobs = tensor([[-1.9366, -4.7798],
        [-4.3256, -3.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3813314437866211
Epoch 0, Step 866: train/loss = 0.5553495287895203, train/raw-loss = 0.3576328158378601, train/logprobs = tensor([[-1.7415, -4.0619],
        [-3.7070, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6590557098388672
Epoch 0, Step 867: train/loss = 0.5810788869857788, train/raw-loss = 0.4315953850746155, train/logprobs = tensor([[-4.5681, -7.0978],
        [-2.7242, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49827826023101807
Epoch 0, Step 868: train/loss = 0.5958666801452637, train/raw-loss = 0.4427650570869446, train/logprobs = tensor([[-1.3926, -3.2058],
        [-4.3416, -2.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5103387832641602
Epoch 0, Step 869: train/loss = 0.6392871141433716, train/raw-loss = 0.545694887638092, train/logprobs = tensor([[-2.7691, -4.0299],
        [-3.1855, -1.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119741380214691
Epoch 0, Step 870: train/loss = 0.6279562711715698, train/raw-loss = 0.5314534902572632, train/logprobs = tensor([[-4.2059, -5.8834],
        [-2.6169, -1.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32167568802833557
Epoch 0, Step 871: train/loss = 0.6253904700279236, train/raw-loss = 0.4838906526565552, train/logprobs = tensor([[-3.2462, -5.6013],
        [-2.8855, -1.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4716659188270569
Epoch 0, Step 872: train/loss = 0.6330627202987671, train/raw-loss = 0.5432020425796509, train/logprobs = tensor([[-3.9874, -5.1474],
        [-2.5888, -1.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2995355427265167
Epoch 0, Step 873: train/loss = 0.7046748399734497, train/raw-loss = 0.5537634491920471, train/logprobs = tensor([[-2.7213, -5.2983],
        [-2.2593, -1.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5030380487442017
Epoch 0, Step 874: train/loss = 0.44962355494499207, train/raw-loss = 0.11408603936433792, train/logprobs = tensor([[-1.8098, -7.0397],
        [-4.1805, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1184583902359009
Epoch 0, Step 875: train/loss = 0.6150197982788086, train/raw-loss = 0.47495245933532715, train/logprobs = tensor([[-2.6109, -4.7919],
        [-3.0066, -1.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46689096093177795
Epoch 0, Step 876: train/loss = 0.9333131313323975, train/raw-loss = 0.9193368554115295, train/logprobs = tensor([[-2.2173, -3.7905],
        [-3.6569, -4.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04658737778663635
Epoch 0, Step 877: train/loss = 0.6348932385444641, train/raw-loss = 0.4648277759552002, train/logprobs = tensor([[-2.8001, -4.5641],
        [-4.1769, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5668848752975464
Epoch 0, Step 878: train/loss = 0.5467846989631653, train/raw-loss = 0.34111738204956055, train/logprobs = tensor([[-1.9312, -5.1254],
        [-3.9577, -1.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6855577826499939
Epoch 0, Step 879: train/loss = 0.602240800857544, train/raw-loss = 0.47850915789604187, train/logprobs = tensor([[-1.5369, -2.8036],
        [-3.8432, -2.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4124389886856079
Epoch 0, Step 880: train/loss = 0.4348527789115906, train/raw-loss = 0.08893012255430222, train/logprobs = tensor([[-1.1367, -6.9214],
        [-7.1506, -3.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1530754566192627
Epoch 0, Step 881: train/loss = 0.8413005471229553, train/raw-loss = 0.647902250289917, train/logprobs = tensor([[-2.8692, -6.2367],
        [-4.8220, -2.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6446609497070312
Epoch 0, Step 882: train/loss = 0.6356558203697205, train/raw-loss = 0.5424730777740479, train/logprobs = tensor([[-2.1415, -4.7764],
        [-3.6775, -1.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31060901284217834
Epoch 0, Step 883: train/loss = 0.5780844688415527, train/raw-loss = 0.41951003670692444, train/logprobs = tensor([[-3.6214, -6.1294],
        [-4.9409, -2.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.528581440448761
Epoch 0, Step 884: train/loss = 0.5297341346740723, train/raw-loss = 0.3051636219024658, train/logprobs = tensor([[-2.4005, -6.0847],
        [-3.9655, -1.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7485684156417847
Epoch 0, Step 885: train/loss = 0.5234634876251221, train/raw-loss = 0.21914304792881012, train/logprobs = tensor([[-1.0073, -7.2618],
        [-6.3433, -2.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0144015550613403
Epoch 0, Step 886: train/loss = 0.594306468963623, train/raw-loss = 0.399721622467041, train/logprobs = tensor([[-2.6429, -4.1139],
        [-4.3934, -2.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6486161947250366
Epoch 0, Step 887: train/loss = 0.6633463501930237, train/raw-loss = 0.6003999710083008, train/logprobs = tensor([[-4.5741, -5.5326],
        [-1.9901, -1.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2098214030265808
Epoch 0, Step 888: train/loss = 0.6227490901947021, train/raw-loss = 0.5206887125968933, train/logprobs = tensor([[-5.8114, -7.2742],
        [-3.2166, -1.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34020140767097473
Epoch 0, Step 889: train/loss = 0.6376043558120728, train/raw-loss = 0.46762168407440186, train/logprobs = tensor([[-4.0149, -6.0141],
        [-3.7779, -1.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5666090846061707
Epoch 0, Step 890: train/loss = 0.7158034443855286, train/raw-loss = 0.6986215114593506, train/logprobs = tensor([[-6.1308, -5.8620],
        [-1.6899, -1.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057273223996162415
Epoch 0, Step 891: train/loss = 0.45598599314689636, train/raw-loss = 0.26417815685272217, train/logprobs = tensor([[-2.1866, -6.3772],
        [-4.6715, -1.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6393594145774841
Epoch 0, Step 892: train/loss = 0.6767945289611816, train/raw-loss = 0.5593101978302002, train/logprobs = tensor([[-4.1035, -6.0677],
        [-2.0365, -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39161446690559387
Epoch 0, Step 893: train/loss = 0.5863922238349915, train/raw-loss = 0.41533830761909485, train/logprobs = tensor([[-3.1176, -5.2982],
        [-3.1174, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5701797604560852
Epoch 0, Step 894: train/loss = 0.6908471584320068, train/raw-loss = 0.4505763053894043, train/logprobs = tensor([[-2.3571, -5.1752],
        [-5.8160, -1.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8009026646614075
Epoch 0, Step 895: train/loss = 0.5897103548049927, train/raw-loss = 0.3937058448791504, train/logprobs = tensor([[-2.1335, -4.5858],
        [-5.0547, -1.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.653348445892334
Epoch 0, Step 896: train/loss = 0.6941136717796326, train/raw-loss = 0.5955546498298645, train/logprobs = tensor([[-4.9645, -6.9189],
        [-4.3885, -2.3186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32853007316589355
Epoch 0, Step 897: train/loss = 0.5763599872589111, train/raw-loss = 0.3320736885070801, train/logprobs = tensor([[-1.9992, -5.5160],
        [-5.2490, -2.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8142874836921692
Epoch 0, Step 898: train/loss = 0.6453163027763367, train/raw-loss = 0.5389413833618164, train/logprobs = tensor([[-4.1315, -5.4927],
        [-3.9376, -2.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35458284616470337
Epoch 0, Step 899: train/loss = 1.3809491395950317, train/raw-loss = 1.3164595365524292, train/logprobs = tensor([[-3.4063, -6.5979],
        [-1.9009, -3.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21496541798114777
Epoch 0, Step 900: train/loss = 0.7389002442359924, train/raw-loss = 0.6890857815742493, train/logprobs = tensor([[-4.3454, -5.4763],
        [-2.2861, -2.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16604822874069214
Epoch 0, Step 901: train/loss = 0.5053049921989441, train/raw-loss = 0.22401657700538635, train/logprobs = tensor([[-1.4969, -6.5234],
        [-6.3856, -3.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.937627911567688
Epoch 0, Step 902: train/loss = 1.2049952745437622, train/raw-loss = 1.1104075908660889, train/logprobs = tensor([[-3.9867, -6.8374],
        [-2.9499, -3.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152921497821808
Epoch 0, Step 903: train/loss = 0.5694342851638794, train/raw-loss = 0.3473304212093353, train/logprobs = tensor([[-3.5865, -7.5534],
        [-4.3851, -3.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7403460741043091
Epoch 0, Step 904: train/loss = 0.6153621673583984, train/raw-loss = 0.47920680046081543, train/logprobs = tensor([[-2.7424, -5.7649],
        [-4.1196, -2.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45385128259658813
Epoch 0, Step 905: train/loss = 0.6850824952125549, train/raw-loss = 0.5162076950073242, train/logprobs = tensor([[-2.9870, -6.5821],
        [-3.1394, -2.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.562916100025177
Epoch 0, Step 906: train/loss = 0.6014515161514282, train/raw-loss = 0.3966538906097412, train/logprobs = tensor([[-3.4285, -6.5193],
        [-5.0407, -1.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6826586723327637
Epoch 0, Step 907: train/loss = 0.533851146697998, train/raw-loss = 0.30899184942245483, train/logprobs = tensor([[-5.5832, -8.3953],
        [-3.8659, -1.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7495309114456177
Epoch 0, Step 908: train/loss = 0.7016682028770447, train/raw-loss = 0.6771745681762695, train/logprobs = tensor([[-4.8036, -4.7151],
        [-5.0228, -4.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08164547383785248
Epoch 0, Step 909: train/loss = 0.48733165860176086, train/raw-loss = 0.21182946860790253, train/logprobs = tensor([[-3.0775, -7.5531],
        [-5.1017, -1.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9183406233787537
Epoch 0, Step 910: train/loss = 0.659191906452179, train/raw-loss = 0.46776556968688965, train/logprobs = tensor([[-4.6152, -7.9375],
        [-4.6036, -1.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6380877494812012
Epoch 0, Step 911: train/loss = 0.6085780262947083, train/raw-loss = 0.3822197914123535, train/logprobs = tensor([[-2.0782, -5.5706],
        [-4.8341, -2.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7545273900032043
Epoch 0, Step 912: train/loss = 0.8097999095916748, train/raw-loss = 0.5384660363197327, train/logprobs = tensor([[-1.5551, -5.7838],
        [-5.7209, -3.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.904446005821228
Epoch 0, Step 913: train/loss = 0.4977265000343323, train/raw-loss = 0.21633654832839966, train/logprobs = tensor([[-2.6772, -6.2195],
        [-4.5641, -2.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9379665851593018
Epoch 0, Step 914: train/loss = 0.7561237812042236, train/raw-loss = 0.634348452091217, train/logprobs = tensor([[-2.9159, -5.1653],
        [-3.8219, -3.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4059177041053772
Epoch 0, Step 915: train/loss = 0.5467895269393921, train/raw-loss = 0.32477307319641113, train/logprobs = tensor([[-3.2828, -7.6827],
        [-2.7845, -1.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7400548458099365
Epoch 0, Step 916: train/loss = 0.709267795085907, train/raw-loss = 0.46868932247161865, train/logprobs = tensor([[ -5.0656, -10.3780],
        [ -3.3286,  -2.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8019282817840576
Epoch 0, Step 917: train/loss = 0.6684024333953857, train/raw-loss = 0.5402030348777771, train/logprobs = tensor([[-4.6169, -7.4660],
        [-3.5401, -2.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42733141779899597
Epoch 0, Step 918: train/loss = 0.5615823864936829, train/raw-loss = 0.3620418608188629, train/logprobs = tensor([[-3.0472, -6.2505],
        [-6.7385, -4.2026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6651351451873779
Epoch 0, Step 919: train/loss = 0.5109053254127502, train/raw-loss = 0.22539731860160828, train/logprobs = tensor([[-2.4788, -8.1634],
        [-5.7460, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9516931772232056
Epoch 0, Step 920: train/loss = 0.4396820366382599, train/raw-loss = 0.08527301996946335, train/logprobs = tensor([[-2.0775, -8.9428],
        [-5.8457, -1.3309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1813633441925049
Epoch 0, Step 921: train/loss = 0.6859840750694275, train/raw-loss = 0.537612795829773, train/logprobs = tensor([[-2.7715, -6.0353],
        [-3.6480, -2.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4945712387561798
Epoch 0, Step 922: train/loss = 0.6081805229187012, train/raw-loss = 0.4953908324241638, train/logprobs = tensor([[-4.9172, -7.0471],
        [-3.7891, -2.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37596559524536133
Epoch 0, Step 923: train/loss = 0.43384820222854614, train/raw-loss = 0.04319304972887039, train/logprobs = tensor([[-1.7031, -8.1532],
        [-7.5425, -1.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3021836280822754
Epoch 0, Step 924: train/loss = 0.49056804180145264, train/raw-loss = 0.21714356541633606, train/logprobs = tensor([[-3.1200, -7.8368],
        [-6.3119, -2.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9114148020744324
Epoch 0, Step 925: train/loss = 1.5829367637634277, train/raw-loss = 1.395397663116455, train/logprobs = tensor([[-1.4422, -8.0157],
        [-5.1719, -4.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6251300573348999
Epoch 0, Step 926: train/loss = 0.6385398507118225, train/raw-loss = 0.5349975228309631, train/logprobs = tensor([[-2.9023, -4.8767],
        [-5.1495, -4.4265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3451409339904785
Epoch 0, Step 927: train/loss = 0.5444214940071106, train/raw-loss = 0.3624999225139618, train/logprobs = tensor([[-4.3702, -6.8594],
        [-5.3676, -2.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6064050793647766
Epoch 0, Step 928: train/loss = 0.5313341617584229, train/raw-loss = 0.3130011558532715, train/logprobs = tensor([[-2.8287, -6.4401],
        [-5.2642, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7277766466140747
Epoch 0, Step 929: train/loss = 0.6156278848648071, train/raw-loss = 0.47689661383628845, train/logprobs = tensor([[-2.7758, -5.3284],
        [-4.9426, -1.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4624375104904175
Epoch 0, Step 930: train/loss = 0.8122334480285645, train/raw-loss = 0.6806329488754272, train/logprobs = tensor([[-3.7961, -7.5783],
        [-3.8606, -2.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4386683404445648
Epoch 0, Step 931: train/loss = 1.6541193723678589, train/raw-loss = 1.4533334970474243, train/logprobs = tensor([[ -3.3639, -10.4045],
        [ -4.0689,  -3.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6692860722541809
Epoch 0, Step 932: train/loss = 0.5821852684020996, train/raw-loss = 0.40306854248046875, train/logprobs = tensor([[-4.8406, -6.6844],
        [-6.1333, -3.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5970557928085327
Epoch 0, Step 933: train/loss = 0.6564208269119263, train/raw-loss = 0.5615707039833069, train/logprobs = tensor([[-3.3524, -4.7847],
        [-3.3873, -2.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31616687774658203
Epoch 0, Step 934: train/loss = 0.6976897716522217, train/raw-loss = 0.5882245302200317, train/logprobs = tensor([[-6.3270, -6.9679],
        [-2.8173, -2.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3648841083049774
Epoch 0, Step 935: train/loss = 0.5668502449989319, train/raw-loss = 0.39559081196784973, train/logprobs = tensor([[-3.9443, -6.6611],
        [-4.8820, -2.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5708648562431335
Epoch 0, Step 936: train/loss = 0.4977516233921051, train/raw-loss = 0.24689196050167084, train/logprobs = tensor([[-2.9222, -7.5598],
        [-5.9388, -2.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8361989259719849
Epoch 0, Step 937: train/loss = 0.5409573912620544, train/raw-loss = 0.3097166419029236, train/logprobs = tensor([[-4.5512, -9.4498],
        [-4.8588, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.77080237865448
Epoch 0, Step 938: train/loss = 0.45659905672073364, train/raw-loss = 0.1249670535326004, train/logprobs = tensor([[-3.0701, -8.0330],
        [-7.1051, -2.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1054399013519287
Epoch 0, Step 939: train/loss = 0.5510096549987793, train/raw-loss = 0.35508933663368225, train/logprobs = tensor([[-3.4660, -8.1815],
        [-4.0366, -0.8490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6530675292015076
Epoch 0, Step 940: train/loss = 0.5760632753372192, train/raw-loss = 0.412566602230072, train/logprobs = tensor([[-3.5768, -6.5452],
        [-6.4361, -4.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5449889898300171
Epoch 0, Step 941: train/loss = 0.5578266382217407, train/raw-loss = 0.3952665627002716, train/logprobs = tensor([[-4.4612, -8.3460],
        [-5.2550, -2.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5418667197227478
Epoch 0, Step 942: train/loss = 0.538603663444519, train/raw-loss = 0.2636674642562866, train/logprobs = tensor([[-4.6436, -8.9601],
        [-3.4524, -2.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9164538979530334
Epoch 0, Step 943: train/loss = 0.7144608497619629, train/raw-loss = 0.4460808038711548, train/logprobs = tensor([[-4.1665, -6.1169],
        [-5.3164, -2.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8946002721786499
Epoch 0, Step 944: train/loss = 0.6906403303146362, train/raw-loss = 0.6228982210159302, train/logprobs = tensor([[-4.9608, -6.1715],
        [-1.6679, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22580690681934357
Epoch 0, Step 945: train/loss = 1.6490464210510254, train/raw-loss = 1.5250022411346436, train/logprobs = tensor([[-2.3523, -7.4016],
        [-2.7785, -4.3681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41348037123680115
Epoch 0, Step 946: train/loss = 0.6224322319030762, train/raw-loss = 0.4967959225177765, train/logprobs = tensor([[-5.9916, -7.9323],
        [-2.3483, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41878756880760193
Epoch 0, Step 947: train/loss = 0.6260998845100403, train/raw-loss = 0.43001246452331543, train/logprobs = tensor([[-3.8290, -7.9156],
        [-3.1087, -2.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6536246538162231
Epoch 0, Step 948: train/loss = 0.5920635461807251, train/raw-loss = 0.3936607241630554, train/logprobs = tensor([[-4.3629, -7.9140],
        [-2.8388, -1.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6613426208496094
Epoch 0, Step 949: train/loss = 0.5693507194519043, train/raw-loss = 0.3915867805480957, train/logprobs = tensor([[-4.2004, -8.0287],
        [-3.4766, -1.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5925463438034058
Epoch 0, Step 950: train/loss = 0.6354809999465942, train/raw-loss = 0.4817102253437042, train/logprobs = tensor([[-5.3828, -7.5952],
        [-2.7896, -1.3335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5125690698623657
Epoch 0, Step 951: train/loss = 0.5750320553779602, train/raw-loss = 0.3808358609676361, train/logprobs = tensor([[-3.3654, -6.6601],
        [-3.9047, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6473206281661987
Epoch 0, Step 952: train/loss = 0.6330432891845703, train/raw-loss = 0.5319063663482666, train/logprobs = tensor([[-3.1028, -4.4903],
        [-2.8977, -1.7441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33712294697761536
Epoch 0, Step 953: train/loss = 0.4024879038333893, train/raw-loss = 0.02179059386253357, train/logprobs = tensor([[ -1.8803, -10.0656],
        [ -6.8936,  -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2689911127090454
Epoch 0, Step 954: train/loss = 0.41010910272598267, train/raw-loss = 0.04441625624895096, train/logprobs = tensor([[-2.3974, -9.6107],
        [-7.0812, -2.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2189760208129883
Epoch 0, Step 955: train/loss = 0.4239163100719452, train/raw-loss = 0.11002303659915924, train/logprobs = tensor([[ -2.3189, -10.0479],
        [ -5.7030,  -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0463107824325562
Epoch 0, Step 956: train/loss = 0.614176869392395, train/raw-loss = 0.5236963033676147, train/logprobs = tensor([[-5.8020, -8.6969],
        [-4.5985, -2.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30160197615623474
Epoch 0, Step 957: train/loss = 0.5627370476722717, train/raw-loss = 0.36526215076446533, train/logprobs = tensor([[ -5.7035, -10.4586],
        [ -3.2596,  -1.4538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6582497358322144
Epoch 0, Step 958: train/loss = 1.5669515132904053, train/raw-loss = 1.4687538146972656, train/logprobs = tensor([[-4.1699, -8.2824],
        [-2.7675, -4.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273256719112396
Epoch 0, Step 959: train/loss = 0.42492011189460754, train/raw-loss = 0.054579537361860275, train/logprobs = tensor([[-1.9640, -9.4395],
        [-6.0335, -1.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2344684600830078
Epoch 0, Step 960: train/loss = 0.4547475278377533, train/raw-loss = 0.07572703063488007, train/logprobs = tensor([[-1.2620, -8.0957],
        [-7.8638, -4.7056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2634015083312988
Epoch 0, Step 961: train/loss = 0.5627973675727844, train/raw-loss = 0.3735589385032654, train/logprobs = tensor([[-2.9098, -6.4067],
        [-6.2440, -3.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.630794882774353
Epoch 0, Step 962: train/loss = 0.9742079973220825, train/raw-loss = 0.7652547955513, train/logprobs = tensor([[-2.1755, -7.9164],
        [-5.7897, -2.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6965106129646301
Epoch 0, Step 963: train/loss = 0.4971039891242981, train/raw-loss = 0.21223148703575134, train/logprobs = tensor([[-3.8966, -8.5935],
        [-5.0935, -2.2391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9495749473571777
Epoch 0, Step 964: train/loss = 0.5318118333816528, train/raw-loss = 0.2969246804714203, train/logprobs = tensor([[-1.5861, -5.4413],
        [-7.7536, -3.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7829570770263672
Epoch 0, Step 965: train/loss = 0.6744645237922668, train/raw-loss = 0.5022929906845093, train/logprobs = tensor([[-4.7028, -4.7100],
        [-4.9287, -4.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5739052295684814
Epoch 0, Step 966: train/loss = 0.5605451464653015, train/raw-loss = 0.3641301095485687, train/logprobs = tensor([[-5.0163, -7.9299],
        [-6.0567, -2.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6547168493270874
Epoch 0, Step 967: train/loss = 0.6018649339675903, train/raw-loss = 0.4620412588119507, train/logprobs = tensor([[-3.0513, -4.7765],
        [-5.4413, -3.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660789668560028
Epoch 0, Step 968: train/loss = 0.7009639143943787, train/raw-loss = 0.6103429794311523, train/logprobs = tensor([[-4.9418, -7.1977],
        [-2.4212, -2.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020695745944977
Epoch 0, Step 969: train/loss = 0.754754364490509, train/raw-loss = 0.6576037406921387, train/logprobs = tensor([[-4.6217, -5.4572],
        [-4.2146, -4.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32383543252944946
Epoch 0, Step 970: train/loss = 0.5614132285118103, train/raw-loss = 0.35037410259246826, train/logprobs = tensor([[-3.0665, -6.2294],
        [-5.3166, -2.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7034636735916138
Epoch 0, Step 971: train/loss = 0.5261149406433105, train/raw-loss = 0.30479180812835693, train/logprobs = tensor([[-1.0537, -6.6439],
        [-8.8872, -5.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7377437949180603
Epoch 0, Step 972: train/loss = 0.565613329410553, train/raw-loss = 0.3268546760082245, train/logprobs = tensor([[-5.8163, -9.8776],
        [-2.6684, -1.2552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7958621978759766
Epoch 0, Step 973: train/loss = 1.561402678489685, train/raw-loss = 1.4249753952026367, train/logprobs = tensor([[-4.0398, -9.4169],
        [-4.2014, -4.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4547576308250427
Epoch 0, Step 974: train/loss = 0.779333233833313, train/raw-loss = 0.7386132478713989, train/logprobs = tensor([[-7.5084, -8.5415],
        [-2.2923, -2.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13573352992534637
Epoch 0, Step 975: train/loss = 0.6000553369522095, train/raw-loss = 0.5078823566436768, train/logprobs = tensor([[-4.5229, -6.9352],
        [-3.8002, -1.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30724307894706726
Epoch 0, Step 976: train/loss = 0.698914647102356, train/raw-loss = 0.6090291738510132, train/logprobs = tensor([[-5.1137, -4.4604],
        [-3.2555, -4.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29961830377578735
Epoch 0, Step 977: train/loss = 0.582804799079895, train/raw-loss = 0.43500852584838867, train/logprobs = tensor([[-3.8275, -7.4073],
        [-5.1984, -2.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4926541745662689
Epoch 0, Step 978: train/loss = 0.49833178520202637, train/raw-loss = 0.23809503018856049, train/logprobs = tensor([[ -5.6652, -11.4779],
        [ -4.9554,  -1.3261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8674558997154236
Epoch 0, Step 979: train/loss = 0.5599784851074219, train/raw-loss = 0.3444821536540985, train/logprobs = tensor([[-4.3799, -8.1605],
        [-4.8916, -3.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7183209657669067
Epoch 0, Step 980: train/loss = 0.6563822627067566, train/raw-loss = 0.4838632345199585, train/logprobs = tensor([[-3.9595, -7.2631],
        [-4.3933, -2.3506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5750632882118225
Epoch 0, Step 981: train/loss = 0.5423785448074341, train/raw-loss = 0.32192930579185486, train/logprobs = tensor([[-2.0800, -5.7276],
        [-4.7023, -2.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7348306179046631
Epoch 0, Step 982: train/loss = 0.5621826648712158, train/raw-loss = 0.3483189046382904, train/logprobs = tensor([[-3.4921, -6.4976],
        [-5.3023, -3.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7128793001174927
Epoch 0, Step 983: train/loss = 0.5886766910552979, train/raw-loss = 0.428317129611969, train/logprobs = tensor([[-4.9016, -7.0255],
        [-5.8808, -4.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5345319509506226
Epoch 0, Step 984: train/loss = 1.3229126930236816, train/raw-loss = 1.314276099205017, train/logprobs = tensor([[-4.1343, -6.0831],
        [-5.3628, -6.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02878904901444912
Epoch 0, Step 985: train/loss = 0.5350283980369568, train/raw-loss = 0.2588200569152832, train/logprobs = tensor([[-2.9057, -7.0191],
        [-4.9510, -3.4120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9206944704055786
Epoch 0, Step 986: train/loss = 0.6161994934082031, train/raw-loss = 0.4427318572998047, train/logprobs = tensor([[-2.9406, -6.2458],
        [-5.0482, -4.2466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5782254338264465
Epoch 0, Step 987: train/loss = 0.6346349716186523, train/raw-loss = 0.5282096862792969, train/logprobs = tensor([[-4.3123, -6.7824],
        [-5.1193, -3.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547509014606476
Epoch 0, Step 988: train/loss = 0.5629861354827881, train/raw-loss = 0.38135936856269836, train/logprobs = tensor([[-4.6053, -7.4912],
        [-2.9479, -0.9016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6054226160049438
Epoch 0, Step 989: train/loss = 0.6109648942947388, train/raw-loss = 0.4729014039039612, train/logprobs = tensor([[-4.3603, -6.7095],
        [-5.5779, -3.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4602116346359253
Epoch 0, Step 990: train/loss = 0.7645364999771118, train/raw-loss = 0.5517428517341614, train/logprobs = tensor([[-2.5780, -6.6695],
        [-4.1608, -3.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7093121409416199
Epoch 0, Step 991: train/loss = 0.4866793155670166, train/raw-loss = 0.18928171694278717, train/logprobs = tensor([[-1.9820, -8.6432],
        [-5.5546, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9913252592086792
Epoch 0, Step 992: train/loss = 0.5306612253189087, train/raw-loss = 0.19666656851768494, train/logprobs = tensor([[-2.7156, -9.2365],
        [-4.8517, -2.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1133155822753906
Epoch 0, Step 993: train/loss = 0.5507384538650513, train/raw-loss = 0.31995126605033875, train/logprobs = tensor([[-3.9742, -7.9357],
        [-4.2032, -1.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7692906856536865
Epoch 0, Step 994: train/loss = 0.5091136693954468, train/raw-loss = 0.23271067440509796, train/logprobs = tensor([[ -4.4828, -10.3040],
        [ -3.4982,  -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9213433265686035
Epoch 0, Step 995: train/loss = 0.47540631890296936, train/raw-loss = 0.18250149488449097, train/logprobs = tensor([[-1.4534, -7.6027],
        [-6.5294, -2.3412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9763492941856384
Epoch 0, Step 996: train/loss = 0.6334060430526733, train/raw-loss = 0.4333932399749756, train/logprobs = tensor([[-1.9635, -6.2100],
        [-5.0061, -3.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6667093634605408
Epoch 0, Step 997: train/loss = 0.4913882613182068, train/raw-loss = 0.20460966229438782, train/logprobs = tensor([[-3.7931, -8.5428],
        [-4.7458, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9559285640716553
Epoch 0, Step 998: train/loss = 0.5315318703651428, train/raw-loss = 0.24555492401123047, train/logprobs = tensor([[-3.1806, -6.7570],
        [-4.8675, -1.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9532566070556641
Epoch 0, Step 999: train/loss = 0.5263947248458862, train/raw-loss = 0.2597385346889496, train/logprobs = tensor([[-4.0951, -9.3638],
        [-4.3501, -1.1029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8888537287712097
eval/loss: 0.6942005157470703
Epoch 0, Step 1000: train/loss = 0.4903583526611328, train/raw-loss = 0.14589142799377441, train/logprobs = tensor([[-2.3463, -6.6766],
        [-5.3490, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1482230424880981
Epoch 0, Step 1001: train/loss = 0.4746829569339752, train/raw-loss = 0.17857268452644348, train/logprobs = tensor([[-2.0065, -8.5019],
        [-5.8611, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9870342016220093
Epoch 0, Step 1002: train/loss = 0.5552798509597778, train/raw-loss = 0.25395411252975464, train/logprobs = tensor([[-1.2267, -6.1440],
        [-7.2587, -2.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0044190883636475
Epoch 0, Step 1003: train/loss = 0.6000098586082458, train/raw-loss = 0.35424304008483887, train/logprobs = tensor([[-3.2163, -7.2189],
        [-3.7497, -1.6680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8192226886749268
Epoch 0, Step 1004: train/loss = 0.6633685827255249, train/raw-loss = 0.5736188292503357, train/logprobs = tensor([[-3.7207, -3.1374],
        [-2.8788, -4.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991657257080078
Epoch 0, Step 1005: train/loss = 0.6020776033401489, train/raw-loss = 0.4774576425552368, train/logprobs = tensor([[-3.1911, -5.3500],
        [-4.9843, -3.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41539981961250305
Epoch 0, Step 1006: train/loss = 0.6388047933578491, train/raw-loss = 0.47951120138168335, train/logprobs = tensor([[-3.0892, -5.3586],
        [-5.2091, -4.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.530978798866272
Epoch 0, Step 1007: train/loss = 1.31259024143219, train/raw-loss = 1.1404567956924438, train/logprobs = tensor([[-2.1406, -7.8724],
        [-3.9344, -3.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5737779140472412
Epoch 0, Step 1008: train/loss = 0.5662766695022583, train/raw-loss = 0.33182477951049805, train/logprobs = tensor([[-2.1413, -5.5669],
        [-5.5703, -3.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7815062999725342
Epoch 0, Step 1009: train/loss = 0.5552692413330078, train/raw-loss = 0.34661173820495605, train/logprobs = tensor([[-2.1638, -5.2898],
        [-3.7587, -1.2242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6955248713493347
Epoch 0, Step 1010: train/loss = 1.2865902185440063, train/raw-loss = 1.236290693283081, train/logprobs = tensor([[-4.4267, -7.1835],
        [-2.1411, -3.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1676652580499649
Epoch 0, Step 1011: train/loss = 0.55727618932724, train/raw-loss = 0.36748945713043213, train/logprobs = tensor([[-3.2334, -6.2868],
        [-3.0437, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.632622480392456
Epoch 0, Step 1012: train/loss = 0.633135974407196, train/raw-loss = 0.5426111817359924, train/logprobs = tensor([[-3.2364, -5.3010],
        [-3.0764, -2.3059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30174916982650757
Epoch 0, Step 1013: train/loss = 0.5017967224121094, train/raw-loss = 0.19848757982254028, train/logprobs = tensor([[-2.6618, -7.6908],
        [-4.2064, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0110304355621338
Epoch 0, Step 1014: train/loss = 0.5239095091819763, train/raw-loss = 0.25160929560661316, train/logprobs = tensor([[-2.8318, -4.6954],
        [-4.5723, -3.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9076674580574036
Epoch 0, Step 1015: train/loss = 0.5384828448295593, train/raw-loss = 0.3461144268512726, train/logprobs = tensor([[-2.0158, -6.7818],
        [-4.1579, -1.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6412280797958374
Epoch 0, Step 1016: train/loss = 0.7204618453979492, train/raw-loss = 0.6063604354858398, train/logprobs = tensor([[-1.7776, -4.0143],
        [-5.3753, -6.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.380338191986084
Epoch 0, Step 1017: train/loss = 0.4860660433769226, train/raw-loss = 0.1710277795791626, train/logprobs = tensor([[-2.3506, -8.8297],
        [-5.0628, -1.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.050127387046814
Epoch 0, Step 1018: train/loss = 0.6727375984191895, train/raw-loss = 0.6380038857460022, train/logprobs = tensor([[-5.8316, -5.9838],
        [-1.6392, -1.3589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577893048524857
Epoch 0, Step 1019: train/loss = 0.4358373284339905, train/raw-loss = 0.08448123186826706, train/logprobs = tensor([[-1.7756, -7.3528],
        [-5.1805, -1.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.171186923980713
Epoch 0, Step 1020: train/loss = 0.6026104688644409, train/raw-loss = 0.4844478964805603, train/logprobs = tensor([[-5.3099, -6.3235],
        [-4.3358, -3.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3938751220703125
Epoch 0, Step 1021: train/loss = 0.7064072489738464, train/raw-loss = 0.6035261154174805, train/logprobs = tensor([[-2.7556, -4.4827],
        [-3.0119, -2.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429372310638428
Epoch 0, Step 1022: train/loss = 0.4723413586616516, train/raw-loss = 0.16147446632385254, train/logprobs = tensor([[-2.4082, -7.7174],
        [-4.0640, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0362228155136108
Epoch 0, Step 1023: train/loss = 0.5579954385757446, train/raw-loss = 0.31402847170829773, train/logprobs = tensor([[-1.6547, -4.1320],
        [-4.4795, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8132233619689941
Epoch 0, Step 1024: train/loss = 1.4477125406265259, train/raw-loss = 1.3217719793319702, train/logprobs = tensor([[-2.3026, -6.5851],
        [-2.8986, -3.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4198017716407776
Epoch 0, Step 1025: train/loss = 0.658720850944519, train/raw-loss = 0.5843127369880676, train/logprobs = tensor([[-3.4314, -4.7654],
        [-1.8457, -1.2651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.248027041554451
Epoch 0, Step 1026: train/loss = 0.5910587310791016, train/raw-loss = 0.44498321413993835, train/logprobs = tensor([[-3.9475, -6.1772],
        [-3.9973, -2.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48691824078559875
Epoch 0, Step 1027: train/loss = 0.6148535013198853, train/raw-loss = 0.41846054792404175, train/logprobs = tensor([[-1.8936, -4.7531],
        [-5.6025, -2.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6546429991722107
Epoch 0, Step 1028: train/loss = 0.578646183013916, train/raw-loss = 0.3700842261314392, train/logprobs = tensor([[-3.2684, -6.7765],
        [-2.3313, -0.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6952066421508789
Epoch 0, Step 1029: train/loss = 0.6315063238143921, train/raw-loss = 0.5197802186012268, train/logprobs = tensor([[-1.6333, -3.0293],
        [-3.2776, -2.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3724202811717987
Epoch 0, Step 1030: train/loss = 0.416057825088501, train/raw-loss = 0.051994383335113525, train/logprobs = tensor([[-1.8095, -9.6460],
        [-6.0530, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2135447263717651
Epoch 0, Step 1031: train/loss = 0.6643568873405457, train/raw-loss = 0.5286076664924622, train/logprobs = tensor([[-4.7745, -4.4345],
        [-2.9820, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45249736309051514
Epoch 0, Step 1032: train/loss = 0.5931607484817505, train/raw-loss = 0.3395153880119324, train/logprobs = tensor([[-1.9873, -6.8183],
        [-4.5173, -1.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8454843759536743
Epoch 0, Step 1033: train/loss = 0.4423297643661499, train/raw-loss = 0.09872934222221375, train/logprobs = tensor([[-1.5001, -6.5952],
        [-6.3657, -1.3522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1453347206115723
Epoch 0, Step 1034: train/loss = 0.6803982853889465, train/raw-loss = 0.5906365513801575, train/logprobs = tensor([[-3.1923, -4.9325],
        [-1.2544, -0.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992056608200073
Epoch 0, Step 1035: train/loss = 0.4677547812461853, train/raw-loss = 0.19908538460731506, train/logprobs = tensor([[-1.6701, -6.6426],
        [-5.8507, -1.2451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8955645561218262
Epoch 0, Step 1036: train/loss = 0.5982643365859985, train/raw-loss = 0.448618084192276, train/logprobs = tensor([[-4.0815, -7.4700],
        [-2.7549, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4988209307193756
Epoch 0, Step 1037: train/loss = 0.5583999156951904, train/raw-loss = 0.3672448396682739, train/logprobs = tensor([[-2.9251, -7.3128],
        [-4.9388, -2.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.637183666229248
Epoch 0, Step 1038: train/loss = 0.5469447374343872, train/raw-loss = 0.25074073672294617, train/logprobs = tensor([[-2.9926, -6.9156],
        [-4.4262, -1.2996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9873465299606323
Epoch 0, Step 1039: train/loss = 0.6063153743743896, train/raw-loss = 0.46997129917144775, train/logprobs = tensor([[-5.1524, -7.7761],
        [-2.1850, -1.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4544803202152252
Epoch 0, Step 1040: train/loss = 0.5520532727241516, train/raw-loss = 0.28438493609428406, train/logprobs = tensor([[-4.1841, -8.5939],
        [-4.4288, -1.2834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8922277688980103
Epoch 0, Step 1041: train/loss = 0.6375463008880615, train/raw-loss = 0.49184054136276245, train/logprobs = tensor([[-3.5430, -5.3890],
        [-3.0312, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48568591475486755
Epoch 0, Step 1042: train/loss = 0.6945214867591858, train/raw-loss = 0.6916310787200928, train/logprobs = tensor([[-6.5005, -6.2912],
        [-1.1155, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009634743444621563
Epoch 0, Step 1043: train/loss = 0.49911853671073914, train/raw-loss = 0.20353496074676514, train/logprobs = tensor([[-2.9374, -8.2588],
        [-4.9373, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9852785468101501
Epoch 0, Step 1044: train/loss = 0.6821992993354797, train/raw-loss = 0.5620845556259155, train/logprobs = tensor([[-2.3253, -4.5225],
        [-3.9863, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4003823399543762
Epoch 0, Step 1045: train/loss = 0.5615586638450623, train/raw-loss = 0.3350260257720947, train/logprobs = tensor([[-2.5436, -6.8345],
        [-4.8516, -1.3869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7551087141036987
