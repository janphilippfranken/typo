[2024-02-21 08:40:13,411][root][INFO] - beta: 0.1
[2024-02-21 08:40:13,412][root][INFO] - max_iter: 0
[2024-02-21 08:40:13,412][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-0
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 10000 training examples...
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-0 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-0 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-0 after each epoch.
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-0 after each epoch.
Epoch 0, Step 0: train/loss = 0.7138399481773376, train/raw-loss = 0.7138399481773376, train/logprobs = tensor([[-0.7455, -1.0226],
        [-0.7364, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7512333989143372, train/raw-loss = 0.7512333989143372, train/logprobs = tensor([[-0.8334, -1.3747],
        [-0.8682, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7132431268692017, train/raw-loss = 0.7132431268692017, train/logprobs = tensor([[-0.7484, -0.8076],
        [-0.7838, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.7270166873931885, train/raw-loss = 0.7270166873931885, train/logprobs = tensor([[-0.8421, -1.3549],
        [-0.8680, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.733940839767456, train/raw-loss = 0.733940839767456, train/logprobs = tensor([[-1.0698, -1.4510],
        [-1.0413, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7201582193374634, train/raw-loss = 0.7201582193374634, train/logprobs = tensor([[-0.7672, -1.0824],
        [-0.7821, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.7509020566940308, train/raw-loss = 0.7509020566940308, train/logprobs = tensor([[-0.7953, -1.0975],
        [-0.8507, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.8749185800552368, train/raw-loss = 0.8749185800552368, train/logprobs = tensor([[-1.0779, -1.1902],
        [-1.1492, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.7719928026199341, train/raw-loss = 0.7719928026199341, train/logprobs = tensor([[-1.1014, -1.1445],
        [-1.1211, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.7304704785346985, train/raw-loss = 0.7304704785346985, train/logprobs = tensor([[-1.1188, -1.2011],
        [-1.0964, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7590556144714355, train/raw-loss = 0.7590556144714355, train/logprobs = tensor([[-1.2226, -1.6038],
        [-1.1765, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7034578323364258, train/raw-loss = 0.7034578323364258, train/logprobs = tensor([[-0.7342, -1.0580],
        [-0.9309, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7423051595687866, train/raw-loss = 0.7423051595687866, train/logprobs = tensor([[-0.9704, -1.2385],
        [-0.9914, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.8156082034111023, train/raw-loss = 0.8156082034111023, train/logprobs = tensor([[-1.0279, -1.1002],
        [-1.0404, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7227445244789124, train/raw-loss = 0.7227445244789124, train/logprobs = tensor([[-0.9607, -1.3427],
        [-0.9610, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6962406039237976, train/raw-loss = 0.6962406039237976, train/logprobs = tensor([[-0.8196, -0.9555],
        [-0.8241, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.7046530842781067, train/raw-loss = 0.7046530842781067, train/logprobs = tensor([[-0.8221, -0.9929],
        [-0.8046, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7580117583274841, train/raw-loss = 0.7580117583274841, train/logprobs = tensor([[-0.8956, -1.5347],
        [-0.8674, -1.3455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.709159255027771, train/raw-loss = 0.709159255027771, train/logprobs = tensor([[-0.8134, -0.7455],
        [-0.8448, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.7066819667816162, train/raw-loss = 0.7066819667816162, train/logprobs = tensor([[-0.9296, -1.0342],
        [-0.9464, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7092275023460388, train/raw-loss = 0.7092275023460388, train/logprobs = tensor([[-1.3012, -1.2005],
        [-1.1840, -1.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7093645334243774, train/raw-loss = 0.7093645334243774, train/logprobs = tensor([[-1.3539, -1.5973],
        [-1.3506, -1.4699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7000235319137573, train/raw-loss = 0.7000235319137573, train/logprobs = tensor([[-0.7490, -1.1321],
        [-0.8108, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6963785290718079, train/raw-loss = 0.6963785290718079, train/logprobs = tensor([[-0.9989, -1.1937],
        [-1.0223, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.7021785378456116, train/raw-loss = 0.7021785378456116, train/logprobs = tensor([[-0.7175, -0.9525],
        [-0.6778, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7016822099685669, train/raw-loss = 0.7016822099685669, train/logprobs = tensor([[-0.8638, -1.1275],
        [-0.8749, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7350553274154663, train/raw-loss = 0.7350553274154663, train/logprobs = tensor([[-0.6463, -1.1039],
        [-0.6486, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7169654369354248, train/raw-loss = 0.7169654369354248, train/logprobs = tensor([[-1.1485, -1.2242],
        [-1.0707, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7439044713973999, train/raw-loss = 0.7439044713973999, train/logprobs = tensor([[-0.9744, -1.1718],
        [-1.0203, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7085131406784058, train/raw-loss = 0.7085131406784058, train/logprobs = tensor([[-1.1477, -1.0259],
        [-1.1191, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7012028694152832, train/raw-loss = 0.7012028694152832, train/logprobs = tensor([[-1.1280, -1.2579],
        [-1.1611, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6932780742645264, train/raw-loss = 0.6932780742645264, train/logprobs = tensor([[-1.2200, -1.2428],
        [-1.2477, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6990011930465698, train/raw-loss = 0.6990011930465698, train/logprobs = tensor([[-1.1544, -1.2933],
        [-1.2153, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.7183241844177246, train/raw-loss = 0.7183241844177246, train/logprobs = tensor([[-1.0192, -0.8052],
        [-1.0312, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.7209362983703613, train/raw-loss = 0.7209362983703613, train/logprobs = tensor([[-0.5816, -0.8397],
        [-0.5714, -0.7817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.7233304977416992, train/raw-loss = 0.7233304977416992, train/logprobs = tensor([[-0.9061, -0.6373],
        [-0.9531, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6992183327674866, train/raw-loss = 0.6992183327674866, train/logprobs = tensor([[-0.9190, -0.9279],
        [-0.9578, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.8078498840332031, train/raw-loss = 0.8078498840332031, train/logprobs = tensor([[-0.9128, -1.6764],
        [-0.8827, -1.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.7209069132804871, train/raw-loss = 0.7209069132804871, train/logprobs = tensor([[-0.9563, -1.2494],
        [-0.9473, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.7364293336868286, train/raw-loss = 0.7364293336868286, train/logprobs = tensor([[-1.1877, -1.0266],
        [-1.1895, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.7226386070251465, train/raw-loss = 0.7226386070251465, train/logprobs = tensor([[-1.0432, -1.0242],
        [-1.1040, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.7265266180038452, train/raw-loss = 0.7265266180038452, train/logprobs = tensor([[-0.6492, -1.1424],
        [-0.6564, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.721763014793396, train/raw-loss = 0.721763014793396, train/logprobs = tensor([[-1.0915, -1.6032],
        [-1.1550, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.7680507302284241, train/raw-loss = 0.7680507302284241, train/logprobs = tensor([[-0.9045, -1.5780],
        [-0.9263, -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.7660417556762695, train/raw-loss = 0.7660417556762695, train/logprobs = tensor([[-0.7626, -1.1490],
        [-0.7788, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.711141049861908, train/raw-loss = 0.711141049861908, train/logprobs = tensor([[-0.6316, -0.9687],
        [-0.6322, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.7303359508514404, train/raw-loss = 0.7303359508514404, train/logprobs = tensor([[-0.9770, -1.3808],
        [-1.0208, -1.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.7417276501655579, train/raw-loss = 0.7417276501655579, train/logprobs = tensor([[-1.3705, -1.1575],
        [-1.3663, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.7140246629714966, train/raw-loss = 0.7140246629714966, train/logprobs = tensor([[-0.8059, -0.9450],
        [-0.8191, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.8124833703041077, train/raw-loss = 0.8124833703041077, train/logprobs = tensor([[-0.8137, -1.6513],
        [-0.8865, -1.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.7228094339370728, train/raw-loss = 0.7228094339370728, train/logprobs = tensor([[-0.9871, -1.3782],
        [-0.9947, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.7078929543495178, train/raw-loss = 0.7078929543495178, train/logprobs = tensor([[-0.8649, -1.2225],
        [-0.8688, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.7376704216003418, train/raw-loss = 0.7376704216003418, train/logprobs = tensor([[-1.0971, -0.7423],
        [-1.1489, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.7063559293746948, train/raw-loss = 0.7063559293746948, train/logprobs = tensor([[-1.3404, -1.3085],
        [-1.3279, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6973018050193787, train/raw-loss = 0.6973018050193787, train/logprobs = tensor([[-0.9319, -0.9996],
        [-1.0078, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.7213075160980225, train/raw-loss = 0.7213075160980225, train/logprobs = tensor([[-1.0288, -1.1987],
        [-0.9993, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.700077474117279, train/raw-loss = 0.700077474117279, train/logprobs = tensor([[-0.8808, -0.7692],
        [-0.8665, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.7421349287033081, train/raw-loss = 0.7421349287033081, train/logprobs = tensor([[-0.8949, -1.2674],
        [-0.9367, -1.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.7090649604797363, train/raw-loss = 0.7090649604797363, train/logprobs = tensor([[-0.6935, -0.9580],
        [-0.7386, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.7432193756103516, train/raw-loss = 0.7432193756103516, train/logprobs = tensor([[-1.2190, -1.1246],
        [-1.2778, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.741159200668335, train/raw-loss = 0.741159200668335, train/logprobs = tensor([[-1.0228, -1.0941],
        [-1.1349, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.7869737148284912, train/raw-loss = 0.7869737148284912, train/logprobs = tensor([[-0.7442, -1.3274],
        [-0.7931, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.719154953956604, train/raw-loss = 0.719154953956604, train/logprobs = tensor([[-1.0222, -1.2890],
        [-1.0348, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7206997275352478, train/raw-loss = 0.7206997275352478, train/logprobs = tensor([[-1.1953, -1.2005],
        [-1.1689, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.7038036584854126, train/raw-loss = 0.7038028836250305, train/logprobs = tensor([[-0.8897, -1.0967],
        [-0.8964, -0.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.422735507134348e-06
Epoch 0, Step 65: train/loss = 0.7389895915985107, train/raw-loss = 0.7389895915985107, train/logprobs = tensor([[-0.8027, -1.0570],
        [-0.8318, -1.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.844012775924057e-07
Epoch 0, Step 66: train/loss = 0.7460809946060181, train/raw-loss = 0.7460793256759644, train/logprobs = tensor([[-1.2319, -0.7560],
        [-1.3379, -0.6791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6621206668787636e-05
Epoch 0, Step 67: train/loss = 0.6990000009536743, train/raw-loss = 0.6989997625350952, train/logprobs = tensor([[-0.9310, -0.8403],
        [-0.8892, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2849162633065134e-06
Epoch 0, Step 68: train/loss = 0.8089921474456787, train/raw-loss = 0.8089913129806519, train/logprobs = tensor([[-0.7667, -1.3556],
        [-0.7234, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.514958608429879e-06
Epoch 0, Step 69: train/loss = 0.7165948152542114, train/raw-loss = 0.7165884971618652, train/logprobs = tensor([[-1.2565, -1.5033],
        [-1.2338, -1.2556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.33609015494585e-05
Epoch 0, Step 70: train/loss = 0.7692795991897583, train/raw-loss = 0.7692784070968628, train/logprobs = tensor([[-1.2215, -0.9232],
        [-1.3290, -0.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2156083357695024e-05
Epoch 0, Step 71: train/loss = 0.6943777203559875, train/raw-loss = 0.6943762898445129, train/logprobs = tensor([[-1.1882, -1.3111],
        [-1.1980, -1.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4471443137153983e-05
Epoch 0, Step 72: train/loss = 0.6991875767707825, train/raw-loss = 0.6991868615150452, train/logprobs = tensor([[-0.8068, -1.0327],
        [-0.7655, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.466493116226047e-06
Epoch 0, Step 73: train/loss = 0.8019555807113647, train/raw-loss = 0.8019551038742065, train/logprobs = tensor([[-0.7473, -1.5395],
        [-0.7399, -1.4623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.863421963818837e-06
Epoch 0, Step 74: train/loss = 0.7405166029930115, train/raw-loss = 0.7405145168304443, train/logprobs = tensor([[-0.7297, -1.2266],
        [-0.7587, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.118764678016305e-05
Epoch 0, Step 75: train/loss = 0.7794454097747803, train/raw-loss = 0.7794452905654907, train/logprobs = tensor([[-0.7272, -1.1778],
        [-0.7513, -1.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.305214578285813e-07
Epoch 0, Step 76: train/loss = 0.7436234951019287, train/raw-loss = 0.7436226606369019, train/logprobs = tensor([[-0.6892, -1.3881],
        [-0.6924, -1.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.202379831345752e-06
Epoch 0, Step 77: train/loss = 0.717145562171936, train/raw-loss = 0.7171443700790405, train/logprobs = tensor([[-1.0153, -1.3157],
        [-0.9979, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2009510101052001e-05
Epoch 0, Step 78: train/loss = 0.6949678659439087, train/raw-loss = 0.6949676275253296, train/logprobs = tensor([[-0.7686, -0.8228],
        [-0.7311, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4172077246475965e-06
Epoch 0, Step 79: train/loss = 0.6946347951889038, train/raw-loss = 0.6946346759796143, train/logprobs = tensor([[-0.7990, -0.8590],
        [-0.8149, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.248096279799938e-06
Epoch 0, Step 80: train/loss = 0.7355984449386597, train/raw-loss = 0.735596239566803, train/logprobs = tensor([[-0.9636, -1.3038],
        [-0.9283, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1820429537910968e-05
Epoch 0, Step 81: train/loss = 0.720716655254364, train/raw-loss = 0.7207155227661133, train/logprobs = tensor([[-1.0867, -1.4989],
        [-1.1229, -1.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1785683454945683e-05
Epoch 0, Step 82: train/loss = 0.7090379595756531, train/raw-loss = 0.7090363502502441, train/logprobs = tensor([[-0.8753, -0.9820],
        [-0.8993, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5930418157950044e-05
Epoch 0, Step 83: train/loss = 0.9426147937774658, train/raw-loss = 0.9426107406616211, train/logprobs = tensor([[-0.9149, -1.7280],
        [-0.9025, -1.5210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.990659024566412e-05
Epoch 0, Step 84: train/loss = 0.7110342979431152, train/raw-loss = 0.7110339999198914, train/logprobs = tensor([[-1.2174, -1.1601],
        [-1.2631, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.133460384357022e-06
Epoch 0, Step 85: train/loss = 0.6975379586219788, train/raw-loss = 0.6975370645523071, train/logprobs = tensor([[-1.0018, -1.1078],
        [-1.0832, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.605598850408569e-06
Epoch 0, Step 86: train/loss = 0.734968364238739, train/raw-loss = 0.7349681258201599, train/logprobs = tensor([[-0.6892, -1.1786],
        [-0.6784, -1.1108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.584030880825594e-06
Epoch 0, Step 87: train/loss = 0.7024592161178589, train/raw-loss = 0.7024590969085693, train/logprobs = tensor([[-0.6943, -0.8504],
        [-0.6864, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1513911886140704e-06
Epoch 0, Step 88: train/loss = 0.706599235534668, train/raw-loss = 0.7065991163253784, train/logprobs = tensor([[-0.6479, -0.8914],
        [-0.6174, -0.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3774915714748204e-06
Epoch 0, Step 89: train/loss = 0.7086294889450073, train/raw-loss = 0.7086293697357178, train/logprobs = tensor([[-0.7855, -0.5897],
        [-0.7929, -0.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.261959010269493e-07
Epoch 0, Step 90: train/loss = 0.7006345987319946, train/raw-loss = 0.7006332874298096, train/logprobs = tensor([[-1.0375, -1.2011],
        [-1.0473, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3758532077190466e-05
Epoch 0, Step 91: train/loss = 0.7272515892982483, train/raw-loss = 0.7272502779960632, train/logprobs = tensor([[-0.7960, -1.2593],
        [-0.7807, -1.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3573866453953087e-05
Epoch 0, Step 92: train/loss = 0.7355097532272339, train/raw-loss = 0.7355091571807861, train/logprobs = tensor([[-0.9001, -1.4662],
        [-0.8966, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.208334187045693e-06
Epoch 0, Step 93: train/loss = 0.6949101686477661, train/raw-loss = 0.6949100494384766, train/logprobs = tensor([[-0.8624, -0.9896],
        [-0.7897, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3631715773954056e-06
Epoch 0, Step 94: train/loss = 0.7347631454467773, train/raw-loss = 0.7347589731216431, train/logprobs = tensor([[-1.2958, -1.5844],
        [-1.3238, -1.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.20689866587054e-05
Epoch 0, Step 95: train/loss = 0.6924819946289062, train/raw-loss = 0.692479133605957, train/logprobs = tensor([[-0.8858, -1.0630],
        [-0.9292, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8745234885718673e-05
Epoch 0, Step 96: train/loss = 0.719731330871582, train/raw-loss = 0.7197176814079285, train/logprobs = tensor([[-0.9046, -1.3517],
        [-0.9635, -1.1888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013592297909781337
Epoch 0, Step 97: train/loss = 0.7313398122787476, train/raw-loss = 0.7313288450241089, train/logprobs = tensor([[-0.8161, -1.3459],
        [-0.9366, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011002132669091225
Epoch 0, Step 98: train/loss = 0.7094061970710754, train/raw-loss = 0.709396481513977, train/logprobs = tensor([[-0.7276, -0.7807],
        [-0.8087, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.780895197764039e-05
Epoch 0, Step 99: train/loss = 0.6943156123161316, train/raw-loss = 0.6942999362945557, train/logprobs = tensor([[-0.9904, -1.0211],
        [-0.9750, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015700026415288448
Epoch 0, Step 100: train/loss = 0.7136642932891846, train/raw-loss = 0.7136605978012085, train/logprobs = tensor([[-0.8023, -1.0929],
        [-0.8025, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6882469430565834e-05
Epoch 0, Step 101: train/loss = 0.7320205569267273, train/raw-loss = 0.7320169806480408, train/logprobs = tensor([[-0.9123, -1.1213],
        [-0.9628, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5176490200683475e-05
Epoch 0, Step 102: train/loss = 0.7177597284317017, train/raw-loss = 0.7177364826202393, train/logprobs = tensor([[-0.7786, -1.1495],
        [-0.8111, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023200479336082935
Epoch 0, Step 103: train/loss = 0.7718605399131775, train/raw-loss = 0.7718541622161865, train/logprobs = tensor([[-0.8957, -1.4676],
        [-0.9576, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.380013655871153e-05
Epoch 0, Step 104: train/loss = 0.7110655903816223, train/raw-loss = 0.7110468149185181, train/logprobs = tensor([[-0.7529, -1.1202],
        [-0.7422, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001882691285572946
Epoch 0, Step 105: train/loss = 0.7095237374305725, train/raw-loss = 0.7095215916633606, train/logprobs = tensor([[-1.0721, -1.1933],
        [-1.0935, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1358500816859305e-05
Epoch 0, Step 106: train/loss = 0.7454267740249634, train/raw-loss = 0.7454214096069336, train/logprobs = tensor([[-0.5956, -1.1637],
        [-0.6900, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.400276859290898e-05
Epoch 0, Step 107: train/loss = 0.697993278503418, train/raw-loss = 0.697981595993042, train/logprobs = tensor([[-0.9673, -0.9861],
        [-1.0324, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011686066136462614
Epoch 0, Step 108: train/loss = 0.7192429900169373, train/raw-loss = 0.7192399501800537, train/logprobs = tensor([[-1.4206, -1.7082],
        [-1.2318, -1.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0363851692527533e-05
Epoch 0, Step 109: train/loss = 0.7493141889572144, train/raw-loss = 0.749269962310791, train/logprobs = tensor([[-1.0680, -1.8408],
        [-1.0363, -1.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000442926655523479
Epoch 0, Step 110: train/loss = 0.7268401384353638, train/raw-loss = 0.7268311977386475, train/logprobs = tensor([[-1.2038, -1.2242],
        [-1.3346, -1.1739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.992273069452494e-05
Epoch 0, Step 111: train/loss = 0.7018844485282898, train/raw-loss = 0.7018787860870361, train/logprobs = tensor([[-0.7732, -0.7587],
        [-0.8099, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.644747579935938e-05
Epoch 0, Step 112: train/loss = 0.6951260566711426, train/raw-loss = 0.6951254606246948, train/logprobs = tensor([[-0.6646, -0.7150],
        [-0.6784, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.9689518820960075e-06
Epoch 0, Step 113: train/loss = 0.7402865886688232, train/raw-loss = 0.7402797341346741, train/logprobs = tensor([[-0.9332, -1.3172],
        [-0.9052, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.882048910483718e-05
Epoch 0, Step 114: train/loss = 0.694621205329895, train/raw-loss = 0.6946033239364624, train/logprobs = tensor([[-0.9139, -1.0711],
        [-1.0065, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001787641376722604
Epoch 0, Step 115: train/loss = 0.7209318280220032, train/raw-loss = 0.720862627029419, train/logprobs = tensor([[-0.9778, -1.2436],
        [-1.0421, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006916082929819822
Epoch 0, Step 116: train/loss = 0.7061870098114014, train/raw-loss = 0.7061825394630432, train/logprobs = tensor([[-0.7768, -1.0595],
        [-0.7890, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.446289312909357e-05
Epoch 0, Step 117: train/loss = 0.6994084119796753, train/raw-loss = 0.6993604898452759, train/logprobs = tensor([[-0.7844, -1.1004],
        [-0.8230, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047852876014076173
Epoch 0, Step 118: train/loss = 0.7383411526679993, train/raw-loss = 0.7383366823196411, train/logprobs = tensor([[-0.9994, -0.6689],
        [-1.0219, -0.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.538519715424627e-05
Epoch 0, Step 119: train/loss = 0.7115073204040527, train/raw-loss = 0.7115066051483154, train/logprobs = tensor([[-0.6245, -0.7935],
        [-0.6176, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.711096259299666e-06
Epoch 0, Step 120: train/loss = 0.7419601678848267, train/raw-loss = 0.7418943643569946, train/logprobs = tensor([[-0.8907, -1.5914],
        [-0.9363, -1.4098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006572284619323909
Epoch 0, Step 121: train/loss = 0.7281771898269653, train/raw-loss = 0.7280924320220947, train/logprobs = tensor([[-0.8720, -1.2716],
        [-0.9128, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008478145464323461
Epoch 0, Step 122: train/loss = 0.7131358981132507, train/raw-loss = 0.7131330370903015, train/logprobs = tensor([[-0.6630, -1.0043],
        [-0.7408, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8075111913494766e-05
Epoch 0, Step 123: train/loss = 0.7137349843978882, train/raw-loss = 0.7137300372123718, train/logprobs = tensor([[-0.9866, -0.9511],
        [-0.9753, -0.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.955767508363351e-05
Epoch 0, Step 124: train/loss = 0.693034827709198, train/raw-loss = 0.6930280327796936, train/logprobs = tensor([[-0.8265, -0.8910],
        [-0.8507, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.754975038347766e-05
Epoch 0, Step 125: train/loss = 0.7457789778709412, train/raw-loss = 0.7457704544067383, train/logprobs = tensor([[-0.9255, -1.5168],
        [-1.0434, -1.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.472654735669494e-05
Epoch 0, Step 126: train/loss = 0.7395747900009155, train/raw-loss = 0.7395352721214294, train/logprobs = tensor([[-0.8714, -1.5174],
        [-0.9041, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003950605168938637
Epoch 0, Step 127: train/loss = 0.7002856135368347, train/raw-loss = 0.7002689838409424, train/logprobs = tensor([[-1.0498, -0.9282],
        [-1.1402, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016650927136652172
Epoch 0, Step 128: train/loss = 0.6994273066520691, train/raw-loss = 0.6992195248603821, train/logprobs = tensor([[-0.9036, -1.0189],
        [-1.0054, -0.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002078365534543991
Epoch 0, Step 129: train/loss = 0.7134743332862854, train/raw-loss = 0.7129786014556885, train/logprobs = tensor([[-0.6999, -1.1853],
        [-0.7260, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004957666154950857
Epoch 0, Step 130: train/loss = 0.7088504433631897, train/raw-loss = 0.7088476419448853, train/logprobs = tensor([[-0.6831, -0.6528],
        [-0.6897, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8048540116287768e-05
Epoch 0, Step 131: train/loss = 0.7174147963523865, train/raw-loss = 0.7167748212814331, train/logprobs = tensor([[-1.0528, -1.3517],
        [-1.1075, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006399909965693951
Epoch 0, Step 132: train/loss = 0.7409228682518005, train/raw-loss = 0.740545928478241, train/logprobs = tensor([[-1.1162, -1.4114],
        [-1.1348, -1.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003769444301724434
Epoch 0, Step 133: train/loss = 0.7306010127067566, train/raw-loss = 0.7301713228225708, train/logprobs = tensor([[-0.8514, -1.4972],
        [-0.9038, -1.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004296780098229647
Epoch 0, Step 134: train/loss = 0.7000116109848022, train/raw-loss = 0.6999700665473938, train/logprobs = tensor([[-0.8894, -0.7873],
        [-0.8564, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041549972957000136
Epoch 0, Step 135: train/loss = 0.6971181631088257, train/raw-loss = 0.6971086263656616, train/logprobs = tensor([[-0.7251, -0.8209],
        [-0.7354, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.451420919504017e-05
Epoch 0, Step 136: train/loss = 0.7114534378051758, train/raw-loss = 0.7114409804344177, train/logprobs = tensor([[-0.8943, -0.8406],
        [-0.9204, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012456212425604463
Epoch 0, Step 137: train/loss = 0.7052029967308044, train/raw-loss = 0.705128014087677, train/logprobs = tensor([[-0.8205, -1.0801],
        [-0.8820, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007499799248762429
Epoch 0, Step 138: train/loss = 0.7190718650817871, train/raw-loss = 0.718537449836731, train/logprobs = tensor([[-0.6577, -1.1932],
        [-0.7045, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005344142206013203
Epoch 0, Step 139: train/loss = 0.7664326429367065, train/raw-loss = 0.766232430934906, train/logprobs = tensor([[-0.6495, -1.2418],
        [-0.7126, -1.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002001784509047866
Epoch 0, Step 140: train/loss = 0.7286025285720825, train/raw-loss = 0.7285400032997131, train/logprobs = tensor([[-1.1091, -0.9904],
        [-1.1759, -0.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006248934660106897
Epoch 0, Step 141: train/loss = 0.6978325843811035, train/raw-loss = 0.6977858543395996, train/logprobs = tensor([[-0.8266, -0.9443],
        [-0.7801, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004669334157370031
Epoch 0, Step 142: train/loss = 0.6961343288421631, train/raw-loss = 0.696110188961029, train/logprobs = tensor([[-0.7938, -0.7755],
        [-0.8773, -0.7789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024118972942233086
Epoch 0, Step 143: train/loss = 0.6978483200073242, train/raw-loss = 0.6978325247764587, train/logprobs = tensor([[-0.8415, -0.8959],
        [-0.7802, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015788472956046462
Epoch 0, Step 144: train/loss = 0.8659007549285889, train/raw-loss = 0.8656300902366638, train/logprobs = tensor([[-0.7622, -1.8439],
        [-0.8213, -1.5284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002706737956032157
Epoch 0, Step 145: train/loss = 0.7190927267074585, train/raw-loss = 0.718300461769104, train/logprobs = tensor([[-1.0134, -1.8449],
        [-1.1182, -1.3832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007922069169580936
Epoch 0, Step 146: train/loss = 0.7076647281646729, train/raw-loss = 0.7075105309486389, train/logprobs = tensor([[-1.0620, -1.2167],
        [-1.1615, -1.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015419753035530448
Epoch 0, Step 147: train/loss = 0.7108609676361084, train/raw-loss = 0.7107115983963013, train/logprobs = tensor([[-0.7423, -0.9684],
        [-0.7548, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014938540989533067
Epoch 0, Step 148: train/loss = 0.6980273723602295, train/raw-loss = 0.6976889371871948, train/logprobs = tensor([[-0.7009, -0.7723],
        [-0.8053, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003384500276297331
Epoch 0, Step 149: train/loss = 0.6984673142433167, train/raw-loss = 0.6984177231788635, train/logprobs = tensor([[-0.5895, -0.7947],
        [-0.6122, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004962450475431979
Epoch 0, Step 150: train/loss = 0.7183375954627991, train/raw-loss = 0.7182583212852478, train/logprobs = tensor([[-1.0966, -0.9470],
        [-1.1176, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007930232677608728
Epoch 0, Step 151: train/loss = 0.7027089595794678, train/raw-loss = 0.7025301456451416, train/logprobs = tensor([[-0.7210, -0.9010],
        [-0.7478, -0.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017888267757371068
Epoch 0, Step 152: train/loss = 0.7150604724884033, train/raw-loss = 0.7142690420150757, train/logprobs = tensor([[-1.0401, -1.0782],
        [-1.1709, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007914293557405472
Epoch 0, Step 153: train/loss = 0.7057143449783325, train/raw-loss = 0.7056372165679932, train/logprobs = tensor([[-0.7390, -1.0232],
        [-0.9176, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007716768886893988
Epoch 0, Step 154: train/loss = 0.8761001825332642, train/raw-loss = 0.8760529160499573, train/logprobs = tensor([[-0.7002, -1.7433],
        [-0.6812, -1.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004737281706184149
Epoch 0, Step 155: train/loss = 0.7431926131248474, train/raw-loss = 0.7430007457733154, train/logprobs = tensor([[-0.7389, -1.5109],
        [-0.7731, -1.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001918625202961266
Epoch 0, Step 156: train/loss = 0.6904159784317017, train/raw-loss = 0.6897269487380981, train/logprobs = tensor([[-0.9578, -1.1648],
        [-0.9937, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006890136748552322
Epoch 0, Step 157: train/loss = 0.7329890727996826, train/raw-loss = 0.7327706217765808, train/logprobs = tensor([[-0.8594, -1.4115],
        [-0.8677, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002183917909860611
Epoch 0, Step 158: train/loss = 0.7013618350028992, train/raw-loss = 0.7012337446212769, train/logprobs = tensor([[-0.6292, -0.8898],
        [-0.6794, -0.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012804953148588538
Epoch 0, Step 159: train/loss = 0.6982036232948303, train/raw-loss = 0.6981048583984375, train/logprobs = tensor([[-0.9499, -1.0709],
        [-0.9725, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009879129938781261
Epoch 0, Step 160: train/loss = 0.708672046661377, train/raw-loss = 0.7086383700370789, train/logprobs = tensor([[-0.7950, -1.0314],
        [-0.8394, -0.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003371774801053107
Epoch 0, Step 161: train/loss = 0.7042257785797119, train/raw-loss = 0.704104483127594, train/logprobs = tensor([[-0.6422, -0.9120],
        [-0.7207, -0.7787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012128327507525682
Epoch 0, Step 162: train/loss = 0.708228349685669, train/raw-loss = 0.7080849409103394, train/logprobs = tensor([[-0.7030, -0.8969],
        [-0.8012, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001433324534446001
Epoch 0, Step 163: train/loss = 0.7543385624885559, train/raw-loss = 0.7542134523391724, train/logprobs = tensor([[-0.9555, -1.2707],
        [-0.9904, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012508564395830035
Epoch 0, Step 164: train/loss = 0.7112596035003662, train/raw-loss = 0.7112217545509338, train/logprobs = tensor([[-0.5750, -0.9274],
        [-0.5917, -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037856772541999817
Epoch 0, Step 165: train/loss = 0.705756425857544, train/raw-loss = 0.7057230472564697, train/logprobs = tensor([[-0.8841, -1.0034],
        [-1.0408, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033376598730683327
Epoch 0, Step 166: train/loss = 0.7041966319084167, train/raw-loss = 0.7041825652122498, train/logprobs = tensor([[-0.8228, -1.0355],
        [-0.9260, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001414168073097244
Epoch 0, Step 167: train/loss = 0.7055637240409851, train/raw-loss = 0.7053833603858948, train/logprobs = tensor([[-0.7671, -1.1386],
        [-1.0176, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018034016247838736
Epoch 0, Step 168: train/loss = 0.7168488502502441, train/raw-loss = 0.7166014313697815, train/logprobs = tensor([[-0.6354, -1.1933],
        [-0.6863, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002474521053954959
Epoch 0, Step 169: train/loss = 0.7050403952598572, train/raw-loss = 0.7037261724472046, train/logprobs = tensor([[-0.5789, -1.1907],
        [-0.7276, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013142065145075321
Epoch 0, Step 170: train/loss = 0.7394790649414062, train/raw-loss = 0.739275336265564, train/logprobs = tensor([[-0.7600, -1.3598],
        [-0.8255, -1.1963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00203748163767159
Epoch 0, Step 171: train/loss = 0.7006951570510864, train/raw-loss = 0.7004750370979309, train/logprobs = tensor([[-0.6535, -0.8158],
        [-0.7501, -0.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022006514482200146
Epoch 0, Step 172: train/loss = 0.708439290523529, train/raw-loss = 0.708306074142456, train/logprobs = tensor([[-0.8497, -1.0446],
        [-0.9569, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013318888377398252
Epoch 0, Step 173: train/loss = 0.7136203050613403, train/raw-loss = 0.7135803699493408, train/logprobs = tensor([[-1.0442, -1.4708],
        [-1.0950, -1.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003992937272414565
Epoch 0, Step 174: train/loss = 0.702835202217102, train/raw-loss = 0.7018879652023315, train/logprobs = tensor([[-0.6762, -1.3104],
        [-0.8138, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009472556412220001
Epoch 0, Step 175: train/loss = 0.793249249458313, train/raw-loss = 0.7930306792259216, train/logprobs = tensor([[-0.8783, -1.4817],
        [-0.9208, -1.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021859658882021904
Epoch 0, Step 176: train/loss = 0.7058821320533752, train/raw-loss = 0.7056417465209961, train/logprobs = tensor([[-1.0423, -1.2868],
        [-1.0245, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024037370458245277
Epoch 0, Step 177: train/loss = 0.7097814083099365, train/raw-loss = 0.7097374200820923, train/logprobs = tensor([[-0.9783, -0.9570],
        [-0.9453, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004403538769111037
Epoch 0, Step 178: train/loss = 0.74344801902771, train/raw-loss = 0.7426029443740845, train/logprobs = tensor([[-0.7078, -1.5282],
        [-0.8782, -1.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008451176807284355
Epoch 0, Step 179: train/loss = 0.6972861289978027, train/raw-loss = 0.6972391605377197, train/logprobs = tensor([[-1.0334, -0.9453],
        [-1.0022, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046959597966633737
Epoch 0, Step 180: train/loss = 0.7008545398712158, train/raw-loss = 0.7007596492767334, train/logprobs = tensor([[-0.7104, -1.0506],
        [-0.7807, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009486973285675049
Epoch 0, Step 181: train/loss = 0.8021929860115051, train/raw-loss = 0.8007601499557495, train/logprobs = tensor([[-1.2365, -1.6258],
        [-1.1006, -1.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014328563585877419
Epoch 0, Step 182: train/loss = 0.6983323097229004, train/raw-loss = 0.6982433199882507, train/logprobs = tensor([[-0.8141, -1.0173],
        [-0.9070, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008897873922251165
Epoch 0, Step 183: train/loss = 0.7428775429725647, train/raw-loss = 0.7421014308929443, train/logprobs = tensor([[-0.8459, -1.5514],
        [-0.9605, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007760943844914436
Epoch 0, Step 184: train/loss = 0.6937429904937744, train/raw-loss = 0.6937251091003418, train/logprobs = tensor([[-0.8763, -0.8182],
        [-0.8210, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017876527272164822
Epoch 0, Step 185: train/loss = 0.699727475643158, train/raw-loss = 0.69971764087677, train/logprobs = tensor([[-0.6492, -0.7772],
        [-0.7479, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.803894499782473e-05
Epoch 0, Step 186: train/loss = 0.7671784162521362, train/raw-loss = 0.7667251825332642, train/logprobs = tensor([[-1.1312, -1.5022],
        [-1.2057, -1.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004532091785222292
Epoch 0, Step 187: train/loss = 0.7020819187164307, train/raw-loss = 0.7015150785446167, train/logprobs = tensor([[-1.0498, -1.0538],
        [-1.1346, -0.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005668247118592262
Epoch 0, Step 188: train/loss = 0.7654162049293518, train/raw-loss = 0.7649505138397217, train/logprobs = tensor([[-1.0555, -1.5494],
        [-1.1679, -1.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004656377714127302
Epoch 0, Step 189: train/loss = 0.73995041847229, train/raw-loss = 0.7397538423538208, train/logprobs = tensor([[-0.6852, -1.2922],
        [-0.8416, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019652831833809614
Epoch 0, Step 190: train/loss = 0.7031132578849792, train/raw-loss = 0.7028327584266663, train/logprobs = tensor([[-0.8157, -1.0473],
        [-0.9117, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002804997842758894
Epoch 0, Step 191: train/loss = 0.7508138418197632, train/raw-loss = 0.7507709264755249, train/logprobs = tensor([[-0.9776, -1.2129],
        [-1.1233, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000429183361120522
Epoch 0, Step 192: train/loss = 0.6992918848991394, train/raw-loss = 0.6992689371109009, train/logprobs = tensor([[-0.7917, -0.9239],
        [-0.8052, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022931757848709822
Epoch 0, Step 193: train/loss = 0.6956616640090942, train/raw-loss = 0.695499062538147, train/logprobs = tensor([[-1.0000, -1.2499],
        [-1.2465, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001625429606065154
Epoch 0, Step 194: train/loss = 0.735822856426239, train/raw-loss = 0.7346010208129883, train/logprobs = tensor([[-0.9147, -1.6927],
        [-0.9528, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01221807673573494
Epoch 0, Step 195: train/loss = 0.695931077003479, train/raw-loss = 0.6959095597267151, train/logprobs = tensor([[-0.6802, -0.8400],
        [-0.7279, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000215248204767704
Epoch 0, Step 196: train/loss = 0.7990273833274841, train/raw-loss = 0.7951046228408813, train/logprobs = tensor([[-0.8247, -2.6507],
        [-0.9561, -1.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03922789916396141
Epoch 0, Step 197: train/loss = 0.7257442474365234, train/raw-loss = 0.7256899476051331, train/logprobs = tensor([[-0.6181, -1.0585],
        [-0.7447, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005430090823210776
Epoch 0, Step 198: train/loss = 0.7136088013648987, train/raw-loss = 0.7133028507232666, train/logprobs = tensor([[-0.9961, -0.9876],
        [-1.0896, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003059487324208021
Epoch 0, Step 199: train/loss = 0.7327362298965454, train/raw-loss = 0.7313593626022339, train/logprobs = tensor([[-0.9296, -1.1501],
        [-1.0883, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013768745586276054
Epoch 0, Step 200: train/loss = 0.7742888927459717, train/raw-loss = 0.7726807594299316, train/logprobs = tensor([[-0.7786, -1.5828],
        [-1.0211, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016080934554338455
Epoch 0, Step 201: train/loss = 0.7070785164833069, train/raw-loss = 0.7065730094909668, train/logprobs = tensor([[-0.6419, -1.0878],
        [-0.7349, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0050542959943413734
Epoch 0, Step 202: train/loss = 0.6985381841659546, train/raw-loss = 0.6979924440383911, train/logprobs = tensor([[-0.7080, -0.9949],
        [-0.9414, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054573118686676025
Epoch 0, Step 203: train/loss = 0.7098594903945923, train/raw-loss = 0.7094918489456177, train/logprobs = tensor([[-1.0115, -1.0238],
        [-1.0967, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003676534164696932
Epoch 0, Step 204: train/loss = 0.6979779005050659, train/raw-loss = 0.6978358030319214, train/logprobs = tensor([[-0.7710, -0.8046],
        [-0.9314, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001420829794369638
Epoch 0, Step 205: train/loss = 0.693182647228241, train/raw-loss = 0.6931150555610657, train/logprobs = tensor([[-0.9538, -1.0285],
        [-1.1173, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006761079421266913
Epoch 0, Step 206: train/loss = 0.7014628648757935, train/raw-loss = 0.7014276385307312, train/logprobs = tensor([[-0.7938, -0.9458],
        [-0.8091, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035224470775574446
Epoch 0, Step 207: train/loss = 0.7002311944961548, train/raw-loss = 0.700215756893158, train/logprobs = tensor([[-0.9509, -1.0182],
        [-0.9806, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015454225649591535
Epoch 0, Step 208: train/loss = 0.6952853202819824, train/raw-loss = 0.6952526569366455, train/logprobs = tensor([[-0.7424, -0.6788],
        [-0.8237, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003271709429100156
Epoch 0, Step 209: train/loss = 0.7192714810371399, train/raw-loss = 0.7185232639312744, train/logprobs = tensor([[-0.9774, -1.6287],
        [-1.0901, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007481866516172886
Epoch 0, Step 210: train/loss = 0.7090423703193665, train/raw-loss = 0.7087597846984863, train/logprobs = tensor([[-0.9158, -0.8886],
        [-1.2573, -0.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028250657487660646
Epoch 0, Step 211: train/loss = 0.7156251668930054, train/raw-loss = 0.7152655720710754, train/logprobs = tensor([[-0.6724, -1.0955],
        [-0.8628, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035959738306701183
Epoch 0, Step 212: train/loss = 0.6968336701393127, train/raw-loss = 0.696515679359436, train/logprobs = tensor([[-0.8654, -0.8445],
        [-1.0316, -0.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031795238610357046
Epoch 0, Step 213: train/loss = 0.7032833099365234, train/raw-loss = 0.7029232382774353, train/logprobs = tensor([[-1.0100, -1.2189],
        [-1.2695, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036010362673550844
Epoch 0, Step 214: train/loss = 0.713919997215271, train/raw-loss = 0.7133433818817139, train/logprobs = tensor([[-0.6896, -1.0381],
        [-0.8255, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005766855087131262
Epoch 0, Step 215: train/loss = 0.7323862910270691, train/raw-loss = 0.7320497035980225, train/logprobs = tensor([[-1.2827, -1.0884],
        [-1.4195, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00336555321700871
Epoch 0, Step 216: train/loss = 0.7067632079124451, train/raw-loss = 0.7063036561012268, train/logprobs = tensor([[-1.0282, -1.3823],
        [-1.0998, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004595563746988773
Epoch 0, Step 217: train/loss = 0.6967079639434814, train/raw-loss = 0.6962335705757141, train/logprobs = tensor([[-0.7111, -0.9690],
        [-0.7854, -0.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047440193593502045
Epoch 0, Step 218: train/loss = 0.7128376960754395, train/raw-loss = 0.7121706008911133, train/logprobs = tensor([[-0.6961, -1.2458],
        [-0.8594, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006671567913144827
Epoch 0, Step 219: train/loss = 0.7123940587043762, train/raw-loss = 0.7116578817367554, train/logprobs = tensor([[-0.9936, -1.5481],
        [-0.9880, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007361804135143757
Epoch 0, Step 220: train/loss = 0.6959229707717896, train/raw-loss = 0.6959195733070374, train/logprobs = tensor([[-0.7559, -0.8338],
        [-0.7558, -0.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4196695196442306e-05
Epoch 0, Step 221: train/loss = 0.7190172672271729, train/raw-loss = 0.7186328172683716, train/logprobs = tensor([[-1.0721, -1.2663],
        [-1.2566, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038445827085524797
Epoch 0, Step 222: train/loss = 0.703254222869873, train/raw-loss = 0.702964186668396, train/logprobs = tensor([[-0.6677, -0.8672],
        [-0.8354, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029003943782299757
Epoch 0, Step 223: train/loss = 0.7045085430145264, train/raw-loss = 0.70447838306427, train/logprobs = tensor([[-0.7317, -1.0090],
        [-0.8736, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003012725501321256
Epoch 0, Step 224: train/loss = 0.7000362277030945, train/raw-loss = 0.6995071768760681, train/logprobs = tensor([[-0.8882, -1.2261],
        [-1.0512, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005291070323437452
Epoch 0, Step 225: train/loss = 0.7040120363235474, train/raw-loss = 0.7038081884384155, train/logprobs = tensor([[-0.6978, -0.6803],
        [-0.8935, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020386776886880398
Epoch 0, Step 226: train/loss = 0.7243882417678833, train/raw-loss = 0.7240996360778809, train/logprobs = tensor([[-0.9259, -0.9579],
        [-1.0914, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002886621979996562
Epoch 0, Step 227: train/loss = 0.698465883731842, train/raw-loss = 0.6983740329742432, train/logprobs = tensor([[-0.8772, -0.9900],
        [-1.1536, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009181452915072441
Epoch 0, Step 228: train/loss = 0.7080310583114624, train/raw-loss = 0.7078198194503784, train/logprobs = tensor([[-1.1452, -0.9957],
        [-1.4142, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002112245187163353
Epoch 0, Step 229: train/loss = 0.7596343755722046, train/raw-loss = 0.7595592737197876, train/logprobs = tensor([[-0.7727, -1.2949],
        [-0.8717, -1.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007513224263675511
Epoch 0, Step 230: train/loss = 0.7052832841873169, train/raw-loss = 0.7052186727523804, train/logprobs = tensor([[-0.8859, -0.7793],
        [-1.0775, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006463562604039907
Epoch 0, Step 231: train/loss = 0.7094230651855469, train/raw-loss = 0.70941162109375, train/logprobs = tensor([[-0.6271, -0.9163],
        [-0.7558, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011454230116214603
Epoch 0, Step 232: train/loss = 0.7073037028312683, train/raw-loss = 0.7071658968925476, train/logprobs = tensor([[-0.6731, -0.6655],
        [-0.8718, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013780926819890738
Epoch 0, Step 233: train/loss = 0.747275173664093, train/raw-loss = 0.7472306489944458, train/logprobs = tensor([[-0.7071, -1.1101],
        [-0.8353, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004450855776667595
Epoch 0, Step 234: train/loss = 0.7870115041732788, train/raw-loss = 0.7869665622711182, train/logprobs = tensor([[-0.8479, -0.9283],
        [-0.9200, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044974079355597496
Epoch 0, Step 235: train/loss = 0.7221622467041016, train/raw-loss = 0.7218042016029358, train/logprobs = tensor([[-0.7748, -1.0763],
        [-0.9509, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035802642814815044
Epoch 0, Step 236: train/loss = 0.6926801204681396, train/raw-loss = 0.692611575126648, train/logprobs = tensor([[-0.7707, -0.8434],
        [-0.8609, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006859690765850246
Epoch 0, Step 237: train/loss = 0.6960306167602539, train/raw-loss = 0.6958502531051636, train/logprobs = tensor([[-1.0021, -1.0641],
        [-1.2659, -1.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018032994121313095
Epoch 0, Step 238: train/loss = 0.7153493165969849, train/raw-loss = 0.7153218984603882, train/logprobs = tensor([[-0.9177, -0.8957],
        [-1.0863, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002744191442616284
Epoch 0, Step 239: train/loss = 0.6960254907608032, train/raw-loss = 0.6958874464035034, train/logprobs = tensor([[-0.6328, -0.8555],
        [-0.7567, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013799526495859027
Epoch 0, Step 240: train/loss = 0.7269784212112427, train/raw-loss = 0.726367712020874, train/logprobs = tensor([[-1.1898, -0.9455],
        [-1.5016, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006107723340392113
Epoch 0, Step 241: train/loss = 0.6947483420372009, train/raw-loss = 0.6947196125984192, train/logprobs = tensor([[-0.9165, -0.9483],
        [-0.9758, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002871858887374401
Epoch 0, Step 242: train/loss = 0.6968258619308472, train/raw-loss = 0.696697473526001, train/logprobs = tensor([[-0.7383, -0.8967],
        [-0.9015, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012832675129175186
Epoch 0, Step 243: train/loss = 0.6936976909637451, train/raw-loss = 0.6931999921798706, train/logprobs = tensor([[-0.8705, -0.8178],
        [-1.0161, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049769701436161995
Epoch 0, Step 244: train/loss = 0.7086167335510254, train/raw-loss = 0.7086029052734375, train/logprobs = tensor([[-1.0440, -0.8377],
        [-1.1472, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001380807807436213
Epoch 0, Step 245: train/loss = 0.7025450468063354, train/raw-loss = 0.7024778127670288, train/logprobs = tensor([[-0.9792, -1.2529],
        [-1.2215, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006721462123095989
Epoch 0, Step 246: train/loss = 0.6947113275527954, train/raw-loss = 0.6946943998336792, train/logprobs = tensor([[-0.8728, -0.9467],
        [-1.0233, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001696848776191473
Epoch 0, Step 247: train/loss = 0.7154422402381897, train/raw-loss = 0.7150471210479736, train/logprobs = tensor([[-0.9479, -1.0646],
        [-1.1534, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003951430320739746
Epoch 0, Step 248: train/loss = 0.7501963376998901, train/raw-loss = 0.7496246099472046, train/logprobs = tensor([[-1.0088, -1.5221],
        [-1.0586, -1.3311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005717085674405098
Epoch 0, Step 249: train/loss = 0.7079981565475464, train/raw-loss = 0.70794278383255, train/logprobs = tensor([[-0.7857, -0.6675],
        [-1.0064, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005539646372199059
Epoch 0, Step 250: train/loss = 0.6943827867507935, train/raw-loss = 0.6942591071128845, train/logprobs = tensor([[-0.8412, -0.8347],
        [-1.0015, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012366697192192078
Epoch 0, Step 251: train/loss = 0.7404389381408691, train/raw-loss = 0.7398011684417725, train/logprobs = tensor([[-0.8503, -1.4013],
        [-0.9787, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006377363111823797
Epoch 0, Step 252: train/loss = 0.7005103230476379, train/raw-loss = 0.7004625797271729, train/logprobs = tensor([[-0.6918, -0.8559],
        [-0.8602, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004774535191245377
Epoch 0, Step 253: train/loss = 0.6957854628562927, train/raw-loss = 0.695772647857666, train/logprobs = tensor([[-0.6372, -0.7287],
        [-0.7308, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001283409947063774
Epoch 0, Step 254: train/loss = 0.7039297819137573, train/raw-loss = 0.703640341758728, train/logprobs = tensor([[-0.8540, -1.1635],
        [-0.9835, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028953547589480877
Epoch 0, Step 255: train/loss = 0.7104655504226685, train/raw-loss = 0.7102948427200317, train/logprobs = tensor([[-1.0084, -0.7342],
        [-1.0058, -0.7753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017064500134438276
Epoch 0, Step 256: train/loss = 0.7141228914260864, train/raw-loss = 0.7140363454818726, train/logprobs = tensor([[-1.2802, -1.0722],
        [-1.4739, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008654271950945258
Epoch 0, Step 257: train/loss = 0.7358487248420715, train/raw-loss = 0.7358071804046631, train/logprobs = tensor([[-1.0052, -1.4721],
        [-1.1951, -1.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041444177622906864
Epoch 0, Step 258: train/loss = 0.737280011177063, train/raw-loss = 0.737053394317627, train/logprobs = tensor([[-1.0689, -0.6820],
        [-1.3429, -0.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022668144665658474
Epoch 0, Step 259: train/loss = 0.7110698223114014, train/raw-loss = 0.7108371257781982, train/logprobs = tensor([[-1.2439, -1.0203],
        [-1.3261, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023267120122909546
Epoch 0, Step 260: train/loss = 0.7006476521492004, train/raw-loss = 0.7006453275680542, train/logprobs = tensor([[-1.0194, -0.8811],
        [-1.1053, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3688282453804277e-05
Epoch 0, Step 261: train/loss = 0.7138978242874146, train/raw-loss = 0.7138717770576477, train/logprobs = tensor([[-0.7300, -1.1222],
        [-0.8360, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026023894315585494
Epoch 0, Step 262: train/loss = 0.8088059425354004, train/raw-loss = 0.8085389733314514, train/logprobs = tensor([[-1.2776, -0.5834],
        [-1.5530, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026695281267166138
Epoch 0, Step 263: train/loss = 0.7471389770507812, train/raw-loss = 0.747099757194519, train/logprobs = tensor([[-1.0329, -0.6586],
        [-1.2232, -0.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039263733197003603
Epoch 0, Step 264: train/loss = 0.7241312265396118, train/raw-loss = 0.7238190770149231, train/logprobs = tensor([[-0.8236, -0.6149],
        [-0.8973, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003121858462691307
Epoch 0, Step 265: train/loss = 0.7421144247055054, train/raw-loss = 0.7418407201766968, train/logprobs = tensor([[-0.8091, -1.3753],
        [-0.9439, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027366969734430313
Epoch 0, Step 266: train/loss = 0.6964413523674011, train/raw-loss = 0.6963682174682617, train/logprobs = tensor([[-0.9822, -0.9149],
        [-1.1729, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007315025432035327
Epoch 0, Step 267: train/loss = 0.7253232002258301, train/raw-loss = 0.7249661684036255, train/logprobs = tensor([[-1.1536, -1.0654],
        [-1.3286, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003570558037608862
Epoch 0, Step 268: train/loss = 0.7587924599647522, train/raw-loss = 0.7585828900337219, train/logprobs = tensor([[-1.0888, -1.0890],
        [-1.2558, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002096457639709115
Epoch 0, Step 269: train/loss = 0.6946946382522583, train/raw-loss = 0.6945751905441284, train/logprobs = tensor([[-0.9076, -0.9450],
        [-1.0937, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001194120035506785
Epoch 0, Step 270: train/loss = 0.713820219039917, train/raw-loss = 0.7136192917823792, train/logprobs = tensor([[-0.8875, -0.7367],
        [-1.0212, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00200848001986742
Epoch 0, Step 271: train/loss = 0.7092205286026001, train/raw-loss = 0.7089987993240356, train/logprobs = tensor([[-0.9344, -1.1322],
        [-1.2159, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002217457629740238
Epoch 0, Step 272: train/loss = 0.7251059412956238, train/raw-loss = 0.7245733141899109, train/logprobs = tensor([[-0.9977, -1.3561],
        [-1.1350, -1.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005326531361788511
Epoch 0, Step 273: train/loss = 0.7134019732475281, train/raw-loss = 0.7131912708282471, train/logprobs = tensor([[-0.8927, -1.1142],
        [-1.3206, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00210689683444798
Epoch 0, Step 274: train/loss = 0.6969523429870605, train/raw-loss = 0.696933388710022, train/logprobs = tensor([[-1.1037, -1.1228],
        [-1.2545, -1.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019001845794264227
Epoch 0, Step 275: train/loss = 0.7085205316543579, train/raw-loss = 0.708324134349823, train/logprobs = tensor([[-1.2383, -0.9731],
        [-1.4039, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001964057795703411
Epoch 0, Step 276: train/loss = 0.6994854211807251, train/raw-loss = 0.6994776725769043, train/logprobs = tensor([[-0.6549, -0.8038],
        [-0.7625, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.779001316521317e-05
Epoch 0, Step 277: train/loss = 0.6962185502052307, train/raw-loss = 0.6959859132766724, train/logprobs = tensor([[-0.8072, -0.7668],
        [-0.8728, -0.8483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023253222461789846
Epoch 0, Step 278: train/loss = 0.711904764175415, train/raw-loss = 0.7114928960800171, train/logprobs = tensor([[-0.6219, -0.9506],
        [-0.7121, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004118562676012516
Epoch 0, Step 279: train/loss = 0.7045952081680298, train/raw-loss = 0.7044791579246521, train/logprobs = tensor([[-0.9367, -0.9037],
        [-1.0463, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011601126752793789
Epoch 0, Step 280: train/loss = 0.7024908065795898, train/raw-loss = 0.7024786472320557, train/logprobs = tensor([[-0.9348, -0.9034],
        [-1.1088, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001220992999151349
Epoch 0, Step 281: train/loss = 0.7553556561470032, train/raw-loss = 0.7551395893096924, train/logprobs = tensor([[-1.0672, -0.6586],
        [-1.2891, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002160403411835432
Epoch 0, Step 282: train/loss = 0.7001630663871765, train/raw-loss = 0.6999844908714294, train/logprobs = tensor([[-0.8552, -1.0363],
        [-1.0061, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001785509753972292
Epoch 0, Step 283: train/loss = 0.7051209807395935, train/raw-loss = 0.705093264579773, train/logprobs = tensor([[-1.1086, -0.9358],
        [-1.2286, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002771903818938881
Epoch 0, Step 284: train/loss = 0.6882926225662231, train/raw-loss = 0.6870622634887695, train/logprobs = tensor([[-0.8323, -0.9493],
        [-1.0942, -0.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012303191237151623
Epoch 0, Step 285: train/loss = 0.7332872152328491, train/raw-loss = 0.7332778573036194, train/logprobs = tensor([[-0.9279, -0.8681],
        [-1.0472, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.425033931620419e-05
Epoch 0, Step 286: train/loss = 0.6961390376091003, train/raw-loss = 0.6960920095443726, train/logprobs = tensor([[-0.4886, -0.5675],
        [-0.5815, -0.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047086464473977685
Epoch 0, Step 287: train/loss = 0.7017730474472046, train/raw-loss = 0.7017491459846497, train/logprobs = tensor([[-0.7424, -0.7485],
        [-0.8343, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023845327086746693
Epoch 0, Step 288: train/loss = 0.70036381483078, train/raw-loss = 0.7002776265144348, train/logprobs = tensor([[-0.9620, -0.8511],
        [-1.0523, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008621987653896213
Epoch 0, Step 289: train/loss = 0.7362539768218994, train/raw-loss = 0.736221432685852, train/logprobs = tensor([[-1.1884, -0.8570],
        [-1.4496, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003250240988563746
Epoch 0, Step 290: train/loss = 0.7404261231422424, train/raw-loss = 0.7391379475593567, train/logprobs = tensor([[-1.0426, -1.1259],
        [-1.1413, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012881665490567684
Epoch 0, Step 291: train/loss = 0.7215043306350708, train/raw-loss = 0.7214975953102112, train/logprobs = tensor([[-1.2553, -0.9208],
        [-1.3504, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.710554589517415e-05
Epoch 0, Step 292: train/loss = 0.7591180801391602, train/raw-loss = 0.7586146593093872, train/logprobs = tensor([[-1.3991, -0.8377],
        [-1.5639, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005034557543694973
Epoch 0, Step 293: train/loss = 0.7250239849090576, train/raw-loss = 0.7248234748840332, train/logprobs = tensor([[-1.3144, -1.2772],
        [-1.3753, -1.3270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020051337778568268
Epoch 0, Step 294: train/loss = 0.7948518991470337, train/raw-loss = 0.7947794198989868, train/logprobs = tensor([[-1.0425, -0.5623],
        [-1.1168, -0.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007238613907247782
Epoch 0, Step 295: train/loss = 0.7178006172180176, train/raw-loss = 0.7177088856697083, train/logprobs = tensor([[-1.2125, -1.1835],
        [-1.3757, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009175058221444488
Epoch 0, Step 296: train/loss = 0.7360571026802063, train/raw-loss = 0.7360339164733887, train/logprobs = tensor([[-1.0057, -0.7751],
        [-1.1508, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023196206893771887
Epoch 0, Step 297: train/loss = 0.7211171984672546, train/raw-loss = 0.7210462093353271, train/logprobs = tensor([[-0.7930, -1.1861],
        [-0.9196, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007095616892911494
Epoch 0, Step 298: train/loss = 0.7527364492416382, train/raw-loss = 0.7525942325592041, train/logprobs = tensor([[-1.1479, -0.9175],
        [-1.3444, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014233478577807546
Epoch 0, Step 299: train/loss = 0.7399611473083496, train/raw-loss = 0.7398552894592285, train/logprobs = tensor([[-1.3693, -0.8177],
        [-1.5766, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010592371691018343
Epoch 0, Step 300: train/loss = 0.724053144454956, train/raw-loss = 0.7238450050354004, train/logprobs = tensor([[-1.0717, -0.8352],
        [-1.2806, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020820475183427334
Epoch 0, Step 301: train/loss = 0.7416032552719116, train/raw-loss = 0.7415961027145386, train/logprobs = tensor([[-0.7690, -0.7794],
        [-0.8538, -0.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.167283911257982e-05
Epoch 0, Step 302: train/loss = 0.6956889629364014, train/raw-loss = 0.6956810355186462, train/logprobs = tensor([[-0.8638, -0.7952],
        [-1.0418, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.9224249930121e-05
Epoch 0, Step 303: train/loss = 0.7171287536621094, train/raw-loss = 0.7169978022575378, train/logprobs = tensor([[-1.4039, -1.4556],
        [-1.6102, -1.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013088848209008574
Epoch 0, Step 304: train/loss = 0.7117182612419128, train/raw-loss = 0.7116329073905945, train/logprobs = tensor([[-1.0006, -0.9736],
        [-1.1017, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008534250082448125
Epoch 0, Step 305: train/loss = 0.7052755355834961, train/raw-loss = 0.7052522897720337, train/logprobs = tensor([[-0.7419, -0.9755],
        [-1.0013, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002328776754438877
Epoch 0, Step 306: train/loss = 0.6953814625740051, train/raw-loss = 0.6953319311141968, train/logprobs = tensor([[-1.0363, -1.1213],
        [-1.1124, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004956645425409079
Epoch 0, Step 307: train/loss = 0.7338699102401733, train/raw-loss = 0.7338504791259766, train/logprobs = tensor([[-1.3675, -1.0651],
        [-1.5314, -1.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001946303527802229
Epoch 0, Step 308: train/loss = 0.7011657357215881, train/raw-loss = 0.7011357545852661, train/logprobs = tensor([[-0.7388, -0.6308],
        [-0.8550, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029952172189950943
Epoch 0, Step 309: train/loss = 0.7340511679649353, train/raw-loss = 0.7340177297592163, train/logprobs = tensor([[-1.2898, -0.8516],
        [-1.5480, -0.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003342322015669197
Epoch 0, Step 310: train/loss = 0.6932252049446106, train/raw-loss = 0.6930932998657227, train/logprobs = tensor([[-1.1275, -1.1636],
        [-1.3192, -1.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013185457792133093
Epoch 0, Step 311: train/loss = 0.7301166653633118, train/raw-loss = 0.7301018238067627, train/logprobs = tensor([[-0.7735, -1.0725],
        [-0.8839, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001482668158132583
Epoch 0, Step 312: train/loss = 0.7158331274986267, train/raw-loss = 0.7156649231910706, train/logprobs = tensor([[-1.2356, -0.9601],
        [-1.4370, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016821542521938682
Epoch 0, Step 313: train/loss = 0.7349148988723755, train/raw-loss = 0.7349134683609009, train/logprobs = tensor([[-1.0069, -0.7234],
        [-1.1779, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4753371942788363e-05
Epoch 0, Step 314: train/loss = 0.7436304688453674, train/raw-loss = 0.7434919476509094, train/logprobs = tensor([[-0.9812, -0.8185],
        [-1.1711, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001384792267344892
Epoch 0, Step 315: train/loss = 0.7133426666259766, train/raw-loss = 0.7105112075805664, train/logprobs = tensor([[-1.0488, -1.2654],
        [-1.2300, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02831522561609745
Epoch 0, Step 316: train/loss = 0.7043641805648804, train/raw-loss = 0.7040196061134338, train/logprobs = tensor([[-0.9586, -1.0135],
        [-1.0283, -1.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034461738541722298
Epoch 0, Step 317: train/loss = 0.7144952416419983, train/raw-loss = 0.7142239212989807, train/logprobs = tensor([[-1.2375, -1.2629],
        [-1.4462, -1.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027131394017487764
Epoch 0, Step 318: train/loss = 0.7408746480941772, train/raw-loss = 0.7407495975494385, train/logprobs = tensor([[-1.3302, -0.8330],
        [-1.4257, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001250397297553718
Epoch 0, Step 319: train/loss = 0.6976997256278992, train/raw-loss = 0.6973109245300293, train/logprobs = tensor([[-1.1591, -1.2360],
        [-1.3316, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038878358900547028
Epoch 0, Step 320: train/loss = 0.7230750918388367, train/raw-loss = 0.7226272821426392, train/logprobs = tensor([[-1.4060, -1.1633],
        [-1.6063, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004478496499359608
Epoch 0, Step 321: train/loss = 0.7249642610549927, train/raw-loss = 0.7248051166534424, train/logprobs = tensor([[-1.0702, -0.8124],
        [-1.3590, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001591099426150322
Epoch 0, Step 322: train/loss = 0.7117895483970642, train/raw-loss = 0.7116671204566956, train/logprobs = tensor([[-0.7479, -0.5377],
        [-0.9370, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012245529796928167
Epoch 0, Step 323: train/loss = 0.7258902788162231, train/raw-loss = 0.7257741093635559, train/logprobs = tensor([[-1.1925, -0.8334],
        [-1.3426, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011613807873800397
Epoch 0, Step 324: train/loss = 0.7347375750541687, train/raw-loss = 0.7347301244735718, train/logprobs = tensor([[-1.2093, -0.7191],
        [-1.2181, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.409512181766331e-05
Epoch 0, Step 325: train/loss = 0.7323561906814575, train/raw-loss = 0.732309877872467, train/logprobs = tensor([[-1.0109, -0.6695],
        [-1.1022, -0.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046325207222253084
Epoch 0, Step 326: train/loss = 0.7252632975578308, train/raw-loss = 0.7250604629516602, train/logprobs = tensor([[-0.7155, -1.0486],
        [-0.8536, -1.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002027754206210375
Epoch 0, Step 327: train/loss = 0.7204297184944153, train/raw-loss = 0.7202947735786438, train/logprobs = tensor([[-0.7237, -1.0292],
        [-0.8570, -1.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013495092280209064
Epoch 0, Step 328: train/loss = 0.750909149646759, train/raw-loss = 0.7507168650627136, train/logprobs = tensor([[-1.3808, -0.9987],
        [-1.4308, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019230034667998552
Epoch 0, Step 329: train/loss = 0.7749239206314087, train/raw-loss = 0.7747601270675659, train/logprobs = tensor([[-0.9931, -1.1548],
        [-1.0898, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016378527507185936
Epoch 0, Step 330: train/loss = 0.7065793871879578, train/raw-loss = 0.706437349319458, train/logprobs = tensor([[-1.0333, -0.9538],
        [-1.1528, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014213465619832277
Epoch 0, Step 331: train/loss = 0.7002744674682617, train/raw-loss = 0.7001999020576477, train/logprobs = tensor([[-1.1117, -1.1069],
        [-1.2280, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007456306484527886
Epoch 0, Step 332: train/loss = 0.7012861371040344, train/raw-loss = 0.7012648582458496, train/logprobs = tensor([[-0.9933, -0.9227],
        [-1.1229, -0.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021280255168676376
Epoch 0, Step 333: train/loss = 0.6970776915550232, train/raw-loss = 0.6970672607421875, train/logprobs = tensor([[-1.1967, -1.0745],
        [-1.2699, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010441738413646817
Epoch 0, Step 334: train/loss = 0.72572922706604, train/raw-loss = 0.7255887389183044, train/logprobs = tensor([[-1.1098, -1.1179],
        [-1.3200, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001404237118549645
Epoch 0, Step 335: train/loss = 0.7346243262290955, train/raw-loss = 0.7346088886260986, train/logprobs = tensor([[-1.1036, -0.8722],
        [-1.1673, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015393047942779958
Epoch 0, Step 336: train/loss = 0.7038914561271667, train/raw-loss = 0.7037972807884216, train/logprobs = tensor([[-1.1334, -1.3275],
        [-1.1815, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009419390698894858
Epoch 0, Step 337: train/loss = 0.6966952085494995, train/raw-loss = 0.696668267250061, train/logprobs = tensor([[-0.8541, -0.8317],
        [-0.9758, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002698238240554929
Epoch 0, Step 338: train/loss = 0.7186712026596069, train/raw-loss = 0.7186383008956909, train/logprobs = tensor([[-1.0279, -0.7656],
        [-1.0605, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032927613938227296
Epoch 0, Step 339: train/loss = 0.6971266865730286, train/raw-loss = 0.6970873475074768, train/logprobs = tensor([[-0.7510, -0.8760],
        [-0.8950, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003935577115043998
Epoch 0, Step 340: train/loss = 0.6958494186401367, train/raw-loss = 0.6957443356513977, train/logprobs = tensor([[-1.3393, -1.2726],
        [-1.4738, -1.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010507446713745594
Epoch 0, Step 341: train/loss = 0.6962623596191406, train/raw-loss = 0.6962613463401794, train/logprobs = tensor([[-0.9380, -0.8688],
        [-0.9869, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0373583791079e-05
Epoch 0, Step 342: train/loss = 0.7068977355957031, train/raw-loss = 0.7068167328834534, train/logprobs = tensor([[-1.1131, -0.9316],
        [-1.3224, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008099552942439914
Epoch 0, Step 343: train/loss = 0.723823606967926, train/raw-loss = 0.7237991094589233, train/logprobs = tensor([[-0.9928, -1.2887],
        [-1.0743, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024517110432498157
Epoch 0, Step 344: train/loss = 0.7057489156723022, train/raw-loss = 0.7057371139526367, train/logprobs = tensor([[-1.1931, -0.9537],
        [-1.2756, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011822499800473452
Epoch 0, Step 345: train/loss = 0.7183862328529358, train/raw-loss = 0.7182965278625488, train/logprobs = tensor([[-1.0648, -0.8304],
        [-1.2388, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008979319245554507
Epoch 0, Step 346: train/loss = 0.7049703598022461, train/raw-loss = 0.7044565677642822, train/logprobs = tensor([[-1.3398, -1.2836],
        [-1.5018, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005137737840414047
Epoch 0, Step 347: train/loss = 0.7122764587402344, train/raw-loss = 0.7116020321846008, train/logprobs = tensor([[-1.1256, -1.1485],
        [-1.2254, -1.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006744183599948883
Epoch 0, Step 348: train/loss = 0.7525554895401001, train/raw-loss = 0.7522990703582764, train/logprobs = tensor([[-1.3256, -1.1310],
        [-1.4402, -1.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025644530542194843
Epoch 0, Step 349: train/loss = 0.7088654041290283, train/raw-loss = 0.708856999874115, train/logprobs = tensor([[-1.0019, -1.1838],
        [-1.0349, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.407555287703872e-05
Epoch 0, Step 350: train/loss = 0.7273695468902588, train/raw-loss = 0.7273470163345337, train/logprobs = tensor([[-1.2299, -0.9423],
        [-1.3773, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022557818738278002
Epoch 0, Step 351: train/loss = 0.7368205189704895, train/raw-loss = 0.7367326021194458, train/logprobs = tensor([[-1.2979, -0.8677],
        [-1.3889, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008795252069830894
Epoch 0, Step 352: train/loss = 0.7050088047981262, train/raw-loss = 0.7049387693405151, train/logprobs = tensor([[-0.9307, -1.2647],
        [-1.0673, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007004349026829004
Epoch 0, Step 353: train/loss = 0.6968094110488892, train/raw-loss = 0.6967855095863342, train/logprobs = tensor([[-1.3681, -1.2488],
        [-1.4324, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023837905609980226
Epoch 0, Step 354: train/loss = 0.694364070892334, train/raw-loss = 0.6943636536598206, train/logprobs = tensor([[-0.9925, -0.9239],
        [-1.0440, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.502180672716349e-06
Epoch 0, Step 355: train/loss = 0.7060079574584961, train/raw-loss = 0.705990731716156, train/logprobs = tensor([[-0.8088, -0.7900],
        [-0.9201, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017224118346348405
Epoch 0, Step 356: train/loss = 0.6998625993728638, train/raw-loss = 0.6998165249824524, train/logprobs = tensor([[-0.9753, -0.9953],
        [-1.1717, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046076218131929636
Epoch 0, Step 357: train/loss = 0.7295485138893127, train/raw-loss = 0.7294678688049316, train/logprobs = tensor([[-1.2024, -0.9982],
        [-1.3768, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008065992733463645
Epoch 0, Step 358: train/loss = 0.7023931741714478, train/raw-loss = 0.7023535966873169, train/logprobs = tensor([[-1.1340, -0.9796],
        [-1.2471, -0.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039494887460023165
Epoch 0, Step 359: train/loss = 0.7663930654525757, train/raw-loss = 0.7662398219108582, train/logprobs = tensor([[-1.1125, -1.2421],
        [-1.2653, -1.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001532353344373405
Epoch 0, Step 360: train/loss = 0.7280303835868835, train/raw-loss = 0.7279056906700134, train/logprobs = tensor([[-1.0309, -0.7618],
        [-1.1453, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012469920329749584
Epoch 0, Step 361: train/loss = 0.738416314125061, train/raw-loss = 0.7382458448410034, train/logprobs = tensor([[-0.7617, -1.2213],
        [-0.8343, -1.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017050476744771004
Epoch 0, Step 362: train/loss = 0.7055085897445679, train/raw-loss = 0.7054581642150879, train/logprobs = tensor([[-0.7989, -0.6062],
        [-0.9215, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005040075047872961
Epoch 0, Step 363: train/loss = 0.6982753276824951, train/raw-loss = 0.6982647180557251, train/logprobs = tensor([[-1.0833, -1.2797],
        [-1.2258, -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001068690326064825
Epoch 0, Step 364: train/loss = 0.7158260345458984, train/raw-loss = 0.7157760858535767, train/logprobs = tensor([[-1.1086, -0.9171],
        [-1.1631, -0.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000499621732160449
Epoch 0, Step 365: train/loss = 0.7185607552528381, train/raw-loss = 0.7184480428695679, train/logprobs = tensor([[-1.1454, -0.9172],
        [-1.4939, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001126962131820619
Epoch 0, Step 366: train/loss = 0.7349429130554199, train/raw-loss = 0.7348543405532837, train/logprobs = tensor([[-1.0941, -1.2009],
        [-1.1625, -1.2586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000886646332219243
Epoch 0, Step 367: train/loss = 0.75021892786026, train/raw-loss = 0.7501266598701477, train/logprobs = tensor([[-1.1336, -1.0823],
        [-1.2276, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009234986500814557
Epoch 0, Step 368: train/loss = 0.7083112001419067, train/raw-loss = 0.7081588506698608, train/logprobs = tensor([[-1.1512, -0.9989],
        [-1.4431, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015227498952299356
Epoch 0, Step 369: train/loss = 0.7128186225891113, train/raw-loss = 0.7127879858016968, train/logprobs = tensor([[-0.9142, -0.7293],
        [-0.9887, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003065007331315428
Epoch 0, Step 370: train/loss = 0.7181689739227295, train/raw-loss = 0.7181203365325928, train/logprobs = tensor([[-1.1231, -0.9427],
        [-1.2155, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048665632493793964
Epoch 0, Step 371: train/loss = 0.7201319336891174, train/raw-loss = 0.7200129628181458, train/logprobs = tensor([[-1.1495, -0.8280],
        [-1.3532, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001189611037261784
Epoch 0, Step 372: train/loss = 0.7005324363708496, train/raw-loss = 0.7004369497299194, train/logprobs = tensor([[-1.0726, -1.0519],
        [-1.1922, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009548109956085682
Epoch 0, Step 373: train/loss = 0.7000533938407898, train/raw-loss = 0.7000299692153931, train/logprobs = tensor([[-0.8505, -0.7841],
        [-0.9277, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002349025453440845
Epoch 0, Step 374: train/loss = 0.7019037008285522, train/raw-loss = 0.7018082141876221, train/logprobs = tensor([[-1.1792, -1.2880],
        [-1.3152, -1.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009546494693495333
Epoch 0, Step 375: train/loss = 0.7051081657409668, train/raw-loss = 0.7050919532775879, train/logprobs = tensor([[-1.0420, -0.8420],
        [-1.1466, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016203400446102023
Epoch 0, Step 376: train/loss = 0.7149088382720947, train/raw-loss = 0.7148866653442383, train/logprobs = tensor([[-1.3303, -0.9996],
        [-1.3117, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022165838163346052
Epoch 0, Step 377: train/loss = 0.6940723657608032, train/raw-loss = 0.6940610408782959, train/logprobs = tensor([[-1.0320, -0.9809],
        [-1.1999, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011310330592095852
Epoch 0, Step 378: train/loss = 0.728519082069397, train/raw-loss = 0.7283711433410645, train/logprobs = tensor([[-1.1640, -1.0926],
        [-1.2253, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014801255892962217
Epoch 0, Step 379: train/loss = 0.7325981855392456, train/raw-loss = 0.7325722575187683, train/logprobs = tensor([[-0.9723, -0.6814],
        [-1.0560, -0.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002595542464405298
Epoch 0, Step 380: train/loss = 0.7182289361953735, train/raw-loss = 0.7181835174560547, train/logprobs = tensor([[-1.0274, -1.0023],
        [-1.0900, -1.0579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004544394323602319
Epoch 0, Step 381: train/loss = 0.6967201828956604, train/raw-loss = 0.6966856122016907, train/logprobs = tensor([[-1.1514, -1.2284],
        [-1.1557, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034598249476403
Epoch 0, Step 382: train/loss = 0.6996802687644958, train/raw-loss = 0.6996644139289856, train/logprobs = tensor([[-0.8994, -0.7594],
        [-0.9736, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015817733947187662
Epoch 0, Step 383: train/loss = 0.7011367678642273, train/raw-loss = 0.7010334730148315, train/logprobs = tensor([[-1.1530, -1.0954],
        [-1.3472, -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010330332443118095
Epoch 0, Step 384: train/loss = 0.7599378824234009, train/raw-loss = 0.7599120140075684, train/logprobs = tensor([[-0.7570, -0.9960],
        [-0.8074, -1.0443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002581461740192026
Epoch 0, Step 385: train/loss = 0.7215911149978638, train/raw-loss = 0.7212469577789307, train/logprobs = tensor([[-1.1949, -1.0041],
        [-1.3188, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003441806882619858
Epoch 0, Step 386: train/loss = 0.7042434215545654, train/raw-loss = 0.7042240500450134, train/logprobs = tensor([[-1.0178, -0.8118],
        [-1.0641, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001937593042384833
Epoch 0, Step 387: train/loss = 0.73151695728302, train/raw-loss = 0.7314575910568237, train/logprobs = tensor([[-1.0790, -1.0791],
        [-1.2209, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005940397386439145
Epoch 0, Step 388: train/loss = 0.695869505405426, train/raw-loss = 0.6957192420959473, train/logprobs = tensor([[-1.0754, -1.2526],
        [-1.2211, -1.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015025469474494457
Epoch 0, Step 389: train/loss = 0.8512332439422607, train/raw-loss = 0.8511844277381897, train/logprobs = tensor([[-1.3525, -0.5298],
        [-1.5574, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004886625683866441
Epoch 0, Step 390: train/loss = 0.731163501739502, train/raw-loss = 0.7311094403266907, train/logprobs = tensor([[-1.4775, -1.3515],
        [-1.6611, -1.3492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005407624412328005
Epoch 0, Step 391: train/loss = 0.6979333758354187, train/raw-loss = 0.6978508234024048, train/logprobs = tensor([[-0.9326, -0.7758],
        [-1.0813, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008260766044259071
Epoch 0, Step 392: train/loss = 0.702268660068512, train/raw-loss = 0.7020092010498047, train/logprobs = tensor([[-0.7307, -0.7820],
        [-0.8086, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025947364047169685
Epoch 0, Step 393: train/loss = 0.7056645154953003, train/raw-loss = 0.7056108117103577, train/logprobs = tensor([[-0.8739, -0.6709],
        [-1.0287, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005372293526306748
Epoch 0, Step 394: train/loss = 0.7267282605171204, train/raw-loss = 0.7267244458198547, train/logprobs = tensor([[-1.1830, -0.9860],
        [-1.2253, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.858125637634657e-05
Epoch 0, Step 395: train/loss = 0.7234264612197876, train/raw-loss = 0.7230820655822754, train/logprobs = tensor([[-1.4698, -0.9894],
        [-1.5897, -1.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034433365799486637
Epoch 0, Step 396: train/loss = 0.7399458885192871, train/raw-loss = 0.7397263050079346, train/logprobs = tensor([[-1.1843, -1.0739],
        [-1.3144, -1.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002195661189034581
Epoch 0, Step 397: train/loss = 0.7094066143035889, train/raw-loss = 0.7092303037643433, train/logprobs = tensor([[-0.9477, -1.1607],
        [-1.0512, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001763598178513348
Epoch 0, Step 398: train/loss = 0.7181416153907776, train/raw-loss = 0.7181332111358643, train/logprobs = tensor([[-0.8024, -0.8653],
        [-0.8673, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.371782314497977e-05
Epoch 0, Step 399: train/loss = 0.7437208890914917, train/raw-loss = 0.7436439990997314, train/logprobs = tensor([[-1.4905, -1.2552],
        [-1.6429, -1.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007683819276280701
Epoch 0, Step 400: train/loss = 0.722855269908905, train/raw-loss = 0.7228184938430786, train/logprobs = tensor([[-1.1211, -0.9749],
        [-1.2687, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003683196846395731
Epoch 0, Step 401: train/loss = 0.706298828125, train/raw-loss = 0.7061873078346252, train/logprobs = tensor([[-1.3202, -1.2484],
        [-1.4118, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011154226958751678
Epoch 0, Step 402: train/loss = 0.7338990569114685, train/raw-loss = 0.7338252067565918, train/logprobs = tensor([[-1.2154, -0.7883],
        [-1.3937, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000738637347240001
Epoch 0, Step 403: train/loss = 0.6963410377502441, train/raw-loss = 0.6960808634757996, train/logprobs = tensor([[-0.7969, -0.9631],
        [-0.9225, -1.0465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026013217866420746
Epoch 0, Step 404: train/loss = 0.7422032356262207, train/raw-loss = 0.7418951988220215, train/logprobs = tensor([[-1.5195, -0.9893],
        [-1.6364, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003080388531088829
Epoch 0, Step 405: train/loss = 0.7064701318740845, train/raw-loss = 0.7064049243927002, train/logprobs = tensor([[-0.8940, -1.1326],
        [-0.9832, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006521602626889944
Epoch 0, Step 406: train/loss = 0.7311707139015198, train/raw-loss = 0.731037437915802, train/logprobs = tensor([[-1.2444, -1.3236],
        [-1.2772, -1.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001333026448264718
Epoch 0, Step 407: train/loss = 0.7139592170715332, train/raw-loss = 0.713918149471283, train/logprobs = tensor([[-0.8027, -1.0660],
        [-0.8965, -1.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004106963751837611
Epoch 0, Step 408: train/loss = 0.7294417023658752, train/raw-loss = 0.7294275760650635, train/logprobs = tensor([[-1.0354, -0.9452],
        [-1.1883, -0.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001418160682078451
Epoch 0, Step 409: train/loss = 0.7216618061065674, train/raw-loss = 0.7216161489486694, train/logprobs = tensor([[-1.1848, -0.9970],
        [-1.3439, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045676366426050663
Epoch 0, Step 410: train/loss = 0.7222752571105957, train/raw-loss = 0.7221934795379639, train/logprobs = tensor([[-1.2644, -1.0000],
        [-1.3592, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008173438836820424
Epoch 0, Step 411: train/loss = 0.7029496431350708, train/raw-loss = 0.7029318809509277, train/logprobs = tensor([[-0.9582, -0.8881],
        [-1.1501, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017788176774047315
Epoch 0, Step 412: train/loss = 0.718410313129425, train/raw-loss = 0.7183996438980103, train/logprobs = tensor([[-0.7198, -0.9754],
        [-0.8063, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010690194903872907
Epoch 0, Step 413: train/loss = 0.7608838081359863, train/raw-loss = 0.7608029842376709, train/logprobs = tensor([[-1.1723, -0.7199],
        [-1.2231, -0.7650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008074560901150107
Epoch 0, Step 414: train/loss = 0.7171353101730347, train/raw-loss = 0.7168776392936707, train/logprobs = tensor([[-0.7547, -0.7728],
        [-0.8555, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002576214261353016
Epoch 0, Step 415: train/loss = 0.7278864979743958, train/raw-loss = 0.7275823950767517, train/logprobs = tensor([[-0.9966, -1.4398],
        [-1.1637, -1.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030409572646021843
Epoch 0, Step 416: train/loss = 0.7352700233459473, train/raw-loss = 0.7351641058921814, train/logprobs = tensor([[-0.9678, -0.7466],
        [-1.1884, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010594972409307957
Epoch 0, Step 417: train/loss = 0.7052909135818481, train/raw-loss = 0.704888641834259, train/logprobs = tensor([[-1.2896, -1.1823],
        [-1.4474, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004022678360342979
Epoch 0, Step 418: train/loss = 0.7310481071472168, train/raw-loss = 0.7308120131492615, train/logprobs = tensor([[-0.7837, -0.7566],
        [-0.8982, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023602182045578957
Epoch 0, Step 419: train/loss = 0.694193959236145, train/raw-loss = 0.6941906213760376, train/logprobs = tensor([[-0.8628, -0.8930],
        [-1.0136, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3396994695067406e-05
Epoch 0, Step 420: train/loss = 0.7208809852600098, train/raw-loss = 0.7207249999046326, train/logprobs = tensor([[-1.4836, -1.1487],
        [-1.6641, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015595626318827271
Epoch 0, Step 421: train/loss = 0.7020657062530518, train/raw-loss = 0.7019302845001221, train/logprobs = tensor([[-1.3644, -1.2701],
        [-1.7450, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013547693379223347
Epoch 0, Step 422: train/loss = 0.7539582252502441, train/raw-loss = 0.753777801990509, train/logprobs = tensor([[-1.4665, -0.8699],
        [-1.7254, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018046190962195396
Epoch 0, Step 423: train/loss = 0.7185272574424744, train/raw-loss = 0.7185203433036804, train/logprobs = tensor([[-1.3496, -1.1076],
        [-1.5496, -1.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.862172449473292e-05
Epoch 0, Step 424: train/loss = 0.7332984805107117, train/raw-loss = 0.7332926392555237, train/logprobs = tensor([[-1.0234, -0.6487],
        [-1.1498, -0.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.832524038851261e-05
Epoch 0, Step 425: train/loss = 0.7729248404502869, train/raw-loss = 0.7727783918380737, train/logprobs = tensor([[-1.1371, -0.5456],
        [-1.3834, -0.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014648496871814132
Epoch 0, Step 426: train/loss = 0.6986865997314453, train/raw-loss = 0.6985312700271606, train/logprobs = tensor([[-0.9811, -0.9867],
        [-1.0856, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015534752747043967
Epoch 0, Step 427: train/loss = 0.7303878664970398, train/raw-loss = 0.7302889823913574, train/logprobs = tensor([[-1.1809, -0.7542],
        [-1.2835, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009888409404084086
Epoch 0, Step 428: train/loss = 0.7160789966583252, train/raw-loss = 0.7159258127212524, train/logprobs = tensor([[-0.8018, -0.7212],
        [-0.8089, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001531500369310379
Epoch 0, Step 429: train/loss = 0.6929823160171509, train/raw-loss = 0.6928392648696899, train/logprobs = tensor([[-0.7859, -0.8435],
        [-1.0318, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014309994876384735
Epoch 0, Step 430: train/loss = 0.7677880525588989, train/raw-loss = 0.7676964402198792, train/logprobs = tensor([[-1.3259, -0.8496],
        [-1.4567, -0.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009156159358099103
Epoch 0, Step 431: train/loss = 0.6929500102996826, train/raw-loss = 0.692859411239624, train/logprobs = tensor([[-0.8278, -0.7706],
        [-1.1938, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009060854208655655
Epoch 0, Step 432: train/loss = 0.7111908197402954, train/raw-loss = 0.7106640338897705, train/logprobs = tensor([[-1.3609, -1.0679],
        [-1.8692, -1.1969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005267820321023464
Epoch 0, Step 433: train/loss = 0.724739670753479, train/raw-loss = 0.7245578765869141, train/logprobs = tensor([[-1.2553, -0.9421],
        [-1.4945, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001817816635593772
Epoch 0, Step 434: train/loss = 0.7116844058036804, train/raw-loss = 0.7116189002990723, train/logprobs = tensor([[-0.9447, -0.9503],
        [-1.1098, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006547163357026875
Epoch 0, Step 435: train/loss = 0.7144632339477539, train/raw-loss = 0.7143489122390747, train/logprobs = tensor([[-0.8324, -1.0012],
        [-0.9995, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011431908933445811
Epoch 0, Step 436: train/loss = 0.7010282278060913, train/raw-loss = 0.7009609937667847, train/logprobs = tensor([[-1.1892, -1.1344],
        [-1.3124, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006725139683112502
Epoch 0, Step 437: train/loss = 0.7073202133178711, train/raw-loss = 0.7071653604507446, train/logprobs = tensor([[-0.7976, -0.6991],
        [-0.8568, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015482496237382293
Epoch 0, Step 438: train/loss = 0.7168848514556885, train/raw-loss = 0.7168148159980774, train/logprobs = tensor([[-0.8920, -1.0598],
        [-0.9609, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007006587111391127
Epoch 0, Step 439: train/loss = 0.7131611108779907, train/raw-loss = 0.7130375504493713, train/logprobs = tensor([[-1.2550, -1.0525],
        [-1.4202, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012356931110844016
Epoch 0, Step 440: train/loss = 0.7046204805374146, train/raw-loss = 0.7044637799263, train/logprobs = tensor([[-0.8280, -1.0262],
        [-1.0264, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015667093684896827
Epoch 0, Step 441: train/loss = 0.7741310596466064, train/raw-loss = 0.7741207480430603, train/logprobs = tensor([[-1.2299, -0.6970],
        [-1.4570, -0.7823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001032119762385264
Epoch 0, Step 442: train/loss = 0.7069951295852661, train/raw-loss = 0.7066949605941772, train/logprobs = tensor([[-1.1503, -1.3866],
        [-1.2795, -1.4090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030018796678632498
Epoch 0, Step 443: train/loss = 0.7014537453651428, train/raw-loss = 0.7013030052185059, train/logprobs = tensor([[-1.0701, -1.0563],
        [-1.2047, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001507521839812398
Epoch 0, Step 444: train/loss = 0.7116525769233704, train/raw-loss = 0.711621105670929, train/logprobs = tensor([[-1.0823, -0.9172],
        [-1.2717, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031463702907785773
Epoch 0, Step 445: train/loss = 0.7342047691345215, train/raw-loss = 0.73414546251297, train/logprobs = tensor([[-0.8355, -0.6834],
        [-0.8996, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005932243657298386
Epoch 0, Step 446: train/loss = 0.7229772210121155, train/raw-loss = 0.7229440808296204, train/logprobs = tensor([[-1.0684, -0.8018],
        [-1.1647, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033133907709270716
Epoch 0, Step 447: train/loss = 0.7053521871566772, train/raw-loss = 0.7052886486053467, train/logprobs = tensor([[-1.1062, -1.1422],
        [-1.5932, -1.1860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006357777747325599
Epoch 0, Step 448: train/loss = 0.7033920288085938, train/raw-loss = 0.7030403017997742, train/logprobs = tensor([[-1.2041, -0.9638],
        [-1.2541, -1.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035183802247047424
Epoch 0, Step 449: train/loss = 0.6939130425453186, train/raw-loss = 0.6938930749893188, train/logprobs = tensor([[-1.1232, -1.2259],
        [-1.2508, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019998432253487408
Epoch 0, Step 450: train/loss = 0.7263390421867371, train/raw-loss = 0.726253092288971, train/logprobs = tensor([[-1.3224, -1.1781],
        [-1.5838, -1.3861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008597103296779096
Epoch 0, Step 451: train/loss = 0.7551041841506958, train/raw-loss = 0.7548090219497681, train/logprobs = tensor([[-1.2074, -0.8237],
        [-1.4054, -0.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029518287628889084
Epoch 0, Step 452: train/loss = 0.7082279920578003, train/raw-loss = 0.7082014083862305, train/logprobs = tensor([[-1.0005, -0.9009],
        [-1.2359, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002658660523593426
Epoch 0, Step 453: train/loss = 0.7145857810974121, train/raw-loss = 0.7145509123802185, train/logprobs = tensor([[-0.9243, -0.7606],
        [-1.0723, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003493311523925513
Epoch 0, Step 454: train/loss = 0.7166419625282288, train/raw-loss = 0.7165268659591675, train/logprobs = tensor([[-1.2802, -0.9986],
        [-1.4177, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001151195028796792
Epoch 0, Step 455: train/loss = 0.7012089490890503, train/raw-loss = 0.7010961771011353, train/logprobs = tensor([[-0.8932, -0.9547],
        [-0.9673, -0.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011271474650129676
Epoch 0, Step 456: train/loss = 0.7044734954833984, train/raw-loss = 0.7044525146484375, train/logprobs = tensor([[-1.1405, -0.9334],
        [-1.2937, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020950398175045848
Epoch 0, Step 457: train/loss = 0.6954902410507202, train/raw-loss = 0.6953532695770264, train/logprobs = tensor([[-0.9067, -0.8913],
        [-1.0528, -0.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013692951761186123
Epoch 0, Step 458: train/loss = 0.6932394504547119, train/raw-loss = 0.6932233572006226, train/logprobs = tensor([[-0.7815, -0.8075],
        [-0.8711, -0.8616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016145099652931094
Epoch 0, Step 459: train/loss = 0.7178518176078796, train/raw-loss = 0.7177128195762634, train/logprobs = tensor([[-1.1372, -0.8940],
        [-1.2864, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001390031073242426
Epoch 0, Step 460: train/loss = 0.703738808631897, train/raw-loss = 0.7035973072052002, train/logprobs = tensor([[-0.9295, -0.9272],
        [-0.9951, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00141504080966115
Epoch 0, Step 461: train/loss = 0.7393951416015625, train/raw-loss = 0.7393826246261597, train/logprobs = tensor([[-1.1623, -0.8580],
        [-1.3450, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012513884576037526
Epoch 0, Step 462: train/loss = 0.7042644023895264, train/raw-loss = 0.7041579484939575, train/logprobs = tensor([[-0.9376, -0.7471],
        [-1.3291, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010642653796821833
Epoch 0, Step 463: train/loss = 0.705344021320343, train/raw-loss = 0.7051492929458618, train/logprobs = tensor([[-0.8184, -0.8326],
        [-0.9769, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019480583723634481
Epoch 0, Step 464: train/loss = 0.7110787034034729, train/raw-loss = 0.710992157459259, train/logprobs = tensor([[-1.0306, -0.8455],
        [-1.1458, -0.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008651153184473515
Epoch 0, Step 465: train/loss = 0.7039414644241333, train/raw-loss = 0.7038539052009583, train/logprobs = tensor([[-1.1749, -1.0225],
        [-1.4797, -1.1347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008757485775277019
Epoch 0, Step 466: train/loss = 0.7197070717811584, train/raw-loss = 0.7196944952011108, train/logprobs = tensor([[-1.1538, -0.9028],
        [-1.3246, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012587950914166868
Epoch 0, Step 467: train/loss = 0.7187691330909729, train/raw-loss = 0.7185909748077393, train/logprobs = tensor([[-1.0679, -0.9578],
        [-1.2149, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017820614157244563
Epoch 0, Step 468: train/loss = 0.7241908311843872, train/raw-loss = 0.7241020798683167, train/logprobs = tensor([[-1.1913, -0.8656],
        [-1.6006, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008869231678545475
Epoch 0, Step 469: train/loss = 0.72002774477005, train/raw-loss = 0.7199944853782654, train/logprobs = tensor([[-0.9474, -0.8124],
        [-1.1414, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003327172598801553
Epoch 0, Step 470: train/loss = 0.7116796374320984, train/raw-loss = 0.711643397808075, train/logprobs = tensor([[-1.1299, -0.8883],
        [-1.2631, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003623176598921418
Epoch 0, Step 471: train/loss = 0.7211312651634216, train/raw-loss = 0.7209082245826721, train/logprobs = tensor([[-0.9080, -0.7100],
        [-1.1606, -0.7465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002229807898402214
Epoch 0, Step 472: train/loss = 0.7087545990943909, train/raw-loss = 0.7087498307228088, train/logprobs = tensor([[-1.0371, -0.8935],
        [-1.2114, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7892521251924336e-05
Epoch 0, Step 473: train/loss = 0.7197831273078918, train/raw-loss = 0.7197450399398804, train/logprobs = tensor([[-1.0238, -1.1795],
        [-1.1762, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003806229215115309
Epoch 0, Step 474: train/loss = 0.746971070766449, train/raw-loss = 0.7469112277030945, train/logprobs = tensor([[-0.9553, -0.7028],
        [-1.0302, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005985212046653032
Epoch 0, Step 475: train/loss = 0.726200520992279, train/raw-loss = 0.7261742353439331, train/logprobs = tensor([[-1.2149, -0.8760],
        [-1.3960, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002620686427690089
Epoch 0, Step 476: train/loss = 0.7150204181671143, train/raw-loss = 0.7146768569946289, train/logprobs = tensor([[-0.9718, -0.7662],
        [-1.0991, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034355618990957737
Epoch 0, Step 477: train/loss = 0.7057519555091858, train/raw-loss = 0.7051569223403931, train/logprobs = tensor([[-0.6837, -0.8980],
        [-0.8132, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005950070917606354
Epoch 0, Step 478: train/loss = 0.7149936556816101, train/raw-loss = 0.7149174213409424, train/logprobs = tensor([[-1.0788, -0.9166],
        [-1.2270, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000762784737162292
Epoch 0, Step 479: train/loss = 0.7624638676643372, train/raw-loss = 0.7622907757759094, train/logprobs = tensor([[-1.2787, -0.7066],
        [-1.4324, -0.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017306111985817552
Epoch 0, Step 480: train/loss = 0.7201493382453918, train/raw-loss = 0.7201221585273743, train/logprobs = tensor([[-1.1232, -0.7735],
        [-1.3503, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027172837872058153
Epoch 0, Step 481: train/loss = 0.7046607732772827, train/raw-loss = 0.7044973969459534, train/logprobs = tensor([[-0.9945, -1.3910],
        [-1.2305, -1.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00163340347353369
Epoch 0, Step 482: train/loss = 0.6977939009666443, train/raw-loss = 0.6977344751358032, train/logprobs = tensor([[-1.1477, -1.1939],
        [-1.3238, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005945956218056381
Epoch 0, Step 483: train/loss = 0.7216018438339233, train/raw-loss = 0.7214539051055908, train/logprobs = tensor([[-1.0875, -0.7125],
        [-1.3209, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014794337330386043
Epoch 0, Step 484: train/loss = 0.7149589657783508, train/raw-loss = 0.7149125337600708, train/logprobs = tensor([[-1.2157, -1.1716],
        [-1.3736, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046395513345487416
Epoch 0, Step 485: train/loss = 0.7106044292449951, train/raw-loss = 0.7105340957641602, train/logprobs = tensor([[-0.9920, -0.9360],
        [-1.0384, -0.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000703154772054404
Epoch 0, Step 486: train/loss = 0.7136369943618774, train/raw-loss = 0.7136029601097107, train/logprobs = tensor([[-1.0137, -0.7436],
        [-1.1816, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034039642196148634
Epoch 0, Step 487: train/loss = 0.7248147130012512, train/raw-loss = 0.7246698141098022, train/logprobs = tensor([[-0.9829, -0.8577],
        [-1.0854, -0.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014491258189082146
Epoch 0, Step 488: train/loss = 0.7087564468383789, train/raw-loss = 0.7087498903274536, train/logprobs = tensor([[-1.1714, -1.1215],
        [-1.3027, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.535234570037574e-05
Epoch 0, Step 489: train/loss = 0.73280930519104, train/raw-loss = 0.7327700853347778, train/logprobs = tensor([[-1.3172, -1.0884],
        [-1.5246, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039272813592106104
Epoch 0, Step 490: train/loss = 0.6954025030136108, train/raw-loss = 0.6953246593475342, train/logprobs = tensor([[-0.7719, -0.7376],
        [-0.8469, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007779750740155578
Epoch 0, Step 491: train/loss = 0.7120841145515442, train/raw-loss = 0.7120349407196045, train/logprobs = tensor([[-0.8177, -0.8723],
        [-1.0167, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004913614830002189
Epoch 0, Step 492: train/loss = 0.7055574655532837, train/raw-loss = 0.7055282592773438, train/logprobs = tensor([[-0.7705, -0.6723],
        [-0.8148, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002923317952081561
Epoch 0, Step 493: train/loss = 0.700680673122406, train/raw-loss = 0.7002938985824585, train/logprobs = tensor([[-1.0154, -1.1606],
        [-1.1524, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003867353778332472
Epoch 0, Step 494: train/loss = 0.7074767351150513, train/raw-loss = 0.7069838047027588, train/logprobs = tensor([[-1.0997, -0.9762],
        [-1.2258, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004928849637508392
Epoch 0, Step 495: train/loss = 0.7528645992279053, train/raw-loss = 0.7527504563331604, train/logprobs = tensor([[-1.1539, -0.6970],
        [-1.3374, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011416749330237508
Epoch 0, Step 496: train/loss = 0.7068312168121338, train/raw-loss = 0.7067825794219971, train/logprobs = tensor([[-0.9082, -0.8793],
        [-1.0848, -0.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048655905993655324
Epoch 0, Step 497: train/loss = 0.6938239336013794, train/raw-loss = 0.693639874458313, train/logprobs = tensor([[-0.8784, -0.9327],
        [-0.9925, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018408290343359113
Epoch 0, Step 498: train/loss = 0.70063716173172, train/raw-loss = 0.7005593776702881, train/logprobs = tensor([[-1.2469, -1.1452],
        [-1.5189, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007767985807731748
Epoch 0, Step 499: train/loss = 0.729415237903595, train/raw-loss = 0.7293627858161926, train/logprobs = tensor([[-0.8715, -1.0499],
        [-0.9368, -1.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005250663962215185
eval/loss: 0.7076684236526489
Epoch 0, Step 500: train/loss = 0.7258248329162598, train/raw-loss = 0.7256743907928467, train/logprobs = tensor([[-1.1506, -0.9987],
        [-1.3418, -1.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001504112035036087
Epoch 0, Step 501: train/loss = 0.7022570371627808, train/raw-loss = 0.7021235227584839, train/logprobs = tensor([[-0.9736, -1.0145],
        [-1.2271, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013348598731681705
Epoch 0, Step 502: train/loss = 0.7098711729049683, train/raw-loss = 0.7098078727722168, train/logprobs = tensor([[-0.8863, -0.8692],
        [-1.0722, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006331357290036976
Epoch 0, Step 503: train/loss = 0.7248106598854065, train/raw-loss = 0.7246730327606201, train/logprobs = tensor([[-0.9893, -1.0449],
        [-1.1034, -1.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013755523832514882
Epoch 0, Step 504: train/loss = 0.7151903510093689, train/raw-loss = 0.7150899171829224, train/logprobs = tensor([[-0.9773, -0.8495],
        [-1.0951, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010045678354799747
Epoch 0, Step 505: train/loss = 0.6945210695266724, train/raw-loss = 0.6943587064743042, train/logprobs = tensor([[-1.1257, -1.2215],
        [-1.3509, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001623790361918509
Epoch 0, Step 506: train/loss = 0.7066240906715393, train/raw-loss = 0.705909013748169, train/logprobs = tensor([[-1.1618, -1.0583],
        [-1.4459, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00715077668428421
Epoch 0, Step 507: train/loss = 0.6995418071746826, train/raw-loss = 0.6995373964309692, train/logprobs = tensor([[-1.1032, -1.0304],
        [-1.1848, -1.0910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.4036431063432246e-05
Epoch 0, Step 508: train/loss = 0.7092804908752441, train/raw-loss = 0.7092409133911133, train/logprobs = tensor([[-1.3629, -1.1173],
        [-1.5863, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039616011781618
Epoch 0, Step 509: train/loss = 0.696489155292511, train/raw-loss = 0.6962762475013733, train/logprobs = tensor([[-0.9620, -1.0020],
        [-1.1406, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021289039868861437
Epoch 0, Step 510: train/loss = 0.7060797810554504, train/raw-loss = 0.706062912940979, train/logprobs = tensor([[-0.8555, -0.8181],
        [-0.9488, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016844258061610162
Epoch 0, Step 511: train/loss = 0.7091553211212158, train/raw-loss = 0.7091223001480103, train/logprobs = tensor([[-0.5932, -0.9253],
        [-0.6673, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033075056853704154
Epoch 0, Step 512: train/loss = 0.6968705058097839, train/raw-loss = 0.6968152523040771, train/logprobs = tensor([[-1.1634, -1.2645],
        [-1.2913, -1.3211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005519224214367568
Epoch 0, Step 513: train/loss = 0.7102428078651428, train/raw-loss = 0.710085391998291, train/logprobs = tensor([[-0.9860, -0.7678],
        [-1.1504, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015737710054963827
Epoch 0, Step 514: train/loss = 0.7141270041465759, train/raw-loss = 0.7139983177185059, train/logprobs = tensor([[-0.9994, -1.0368],
        [-1.1709, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012870961800217628
Epoch 0, Step 515: train/loss = 0.6969372630119324, train/raw-loss = 0.6968492269515991, train/logprobs = tensor([[-0.7901, -0.8774],
        [-0.8920, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008809303399175406
Epoch 0, Step 516: train/loss = 0.7065529227256775, train/raw-loss = 0.7065367698669434, train/logprobs = tensor([[-1.0846, -0.8498],
        [-1.2501, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001613980857655406
Epoch 0, Step 517: train/loss = 0.6982115507125854, train/raw-loss = 0.6980370283126831, train/logprobs = tensor([[-0.9508, -1.1196],
        [-1.1084, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017459917580708861
Epoch 0, Step 518: train/loss = 0.6984964609146118, train/raw-loss = 0.6982594728469849, train/logprobs = tensor([[-1.0928, -0.9739],
        [-1.3852, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00236974423751235
Epoch 0, Step 519: train/loss = 0.7021427750587463, train/raw-loss = 0.702109694480896, train/logprobs = tensor([[-0.8164, -0.9756],
        [-0.9109, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003308694576844573
Epoch 0, Step 520: train/loss = 0.6908036470413208, train/raw-loss = 0.6905253529548645, train/logprobs = tensor([[-0.9516, -1.1112],
        [-1.2057, -1.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002782221417874098
Epoch 0, Step 521: train/loss = 0.6777631044387817, train/raw-loss = 0.6770552396774292, train/logprobs = tensor([[-0.8718, -1.1434],
        [-1.0673, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007077695336192846
Epoch 0, Step 522: train/loss = 0.697638988494873, train/raw-loss = 0.697564959526062, train/logprobs = tensor([[-1.1522, -1.2416],
        [-1.3049, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007397620938718319
Epoch 0, Step 523: train/loss = 0.7008170485496521, train/raw-loss = 0.7007522583007812, train/logprobs = tensor([[-0.7521, -0.8277],
        [-0.8759, -0.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006482340395450592
Epoch 0, Step 524: train/loss = 0.7699779272079468, train/raw-loss = 0.7698023915290833, train/logprobs = tensor([[-1.4240, -0.8253],
        [-1.6488, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017552784411236644
Epoch 0, Step 525: train/loss = 0.6944146752357483, train/raw-loss = 0.6943414211273193, train/logprobs = tensor([[-0.8601, -0.8330],
        [-1.0644, -0.9260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007324213511310518
Epoch 0, Step 526: train/loss = 0.7075369954109192, train/raw-loss = 0.7075128555297852, train/logprobs = tensor([[-1.0394, -0.8740],
        [-1.1531, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024174508871510625
Epoch 0, Step 527: train/loss = 0.7132632732391357, train/raw-loss = 0.7132377624511719, train/logprobs = tensor([[-1.1960, -0.9675],
        [-1.2644, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025457466836087406
Epoch 0, Step 528: train/loss = 0.7032768130302429, train/raw-loss = 0.7017585039138794, train/logprobs = tensor([[-1.0563, -1.1315],
        [-1.3520, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015182863920927048
Epoch 0, Step 529: train/loss = 0.7075108289718628, train/raw-loss = 0.7073386311531067, train/logprobs = tensor([[-0.8967, -0.9365],
        [-1.1152, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017227986827492714
Epoch 0, Step 530: train/loss = 0.7021118402481079, train/raw-loss = 0.7019625306129456, train/logprobs = tensor([[-0.9941, -1.2646],
        [-1.0788, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014927495503798127
Epoch 0, Step 531: train/loss = 0.6959249973297119, train/raw-loss = 0.6958365440368652, train/logprobs = tensor([[-0.6361, -0.7647],
        [-0.7110, -0.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008842781535349786
Epoch 0, Step 532: train/loss = 0.693242609500885, train/raw-loss = 0.6928545236587524, train/logprobs = tensor([[-1.0995, -0.9337],
        [-1.6505, -1.0295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038806202355772257
Epoch 0, Step 533: train/loss = 0.7137414216995239, train/raw-loss = 0.7135928273200989, train/logprobs = tensor([[-1.1851, -0.9131],
        [-1.3560, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014861045638099313
Epoch 0, Step 534: train/loss = 0.711442232131958, train/raw-loss = 0.7112451791763306, train/logprobs = tensor([[-0.9425, -1.2310],
        [-1.0810, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001970073441043496
Epoch 0, Step 535: train/loss = 0.695709764957428, train/raw-loss = 0.6956289410591125, train/logprobs = tensor([[-0.8592, -0.9215],
        [-0.9606, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008085922454483807
Epoch 0, Step 536: train/loss = 0.7251138687133789, train/raw-loss = 0.7249799966812134, train/logprobs = tensor([[-1.2183, -0.8158],
        [-1.4223, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013393956469371915
Epoch 0, Step 537: train/loss = 0.7088710069656372, train/raw-loss = 0.7088508009910583, train/logprobs = tensor([[-0.8951, -1.0068],
        [-1.0407, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020207511261105537
Epoch 0, Step 538: train/loss = 0.7172853946685791, train/raw-loss = 0.7172572612762451, train/logprobs = tensor([[-0.9911, -0.9488],
        [-1.2208, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028132431907579303
Epoch 0, Step 539: train/loss = 0.69893479347229, train/raw-loss = 0.6987054944038391, train/logprobs = tensor([[-0.9757, -1.0982],
        [-1.1383, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002292643766850233
Epoch 0, Step 540: train/loss = 0.713779628276825, train/raw-loss = 0.7137284278869629, train/logprobs = tensor([[-0.9828, -0.9554],
        [-1.1820, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005124491872265935
Epoch 0, Step 541: train/loss = 0.7343733310699463, train/raw-loss = 0.7338458299636841, train/logprobs = tensor([[-0.7924, -1.0566],
        [-1.0041, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005274748895317316
Epoch 0, Step 542: train/loss = 0.7110387086868286, train/raw-loss = 0.7109971046447754, train/logprobs = tensor([[-0.9508, -0.7100],
        [-1.1107, -0.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041645060991868377
Epoch 0, Step 543: train/loss = 0.7028407454490662, train/raw-loss = 0.7028223872184753, train/logprobs = tensor([[-1.1877, -0.9520],
        [-1.3554, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018322128744330257
Epoch 0, Step 544: train/loss = 0.6936269998550415, train/raw-loss = 0.6934918165206909, train/logprobs = tensor([[-1.0390, -1.0880],
        [-1.0774, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001351564540527761
Epoch 0, Step 545: train/loss = 0.6938431859016418, train/raw-loss = 0.6937522888183594, train/logprobs = tensor([[-0.9645, -1.1266],
        [-1.1303, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009081250755116343
Epoch 0, Step 546: train/loss = 0.7184133529663086, train/raw-loss = 0.7181892395019531, train/logprobs = tensor([[-0.7809, -1.1637],
        [-0.9259, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022411211393773556
Epoch 0, Step 547: train/loss = 0.7089341282844543, train/raw-loss = 0.7088677287101746, train/logprobs = tensor([[-1.0902, -1.1449],
        [-1.3855, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006644916138611734
Epoch 0, Step 548: train/loss = 0.6961669921875, train/raw-loss = 0.6956458687782288, train/logprobs = tensor([[-1.0219, -0.9647],
        [-1.2177, -1.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005210808478295803
Epoch 0, Step 549: train/loss = 0.6976772546768188, train/raw-loss = 0.6973731517791748, train/logprobs = tensor([[-0.9889, -0.9482],
        [-1.0542, -0.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003040857380256057
Epoch 0, Step 550: train/loss = 0.668861985206604, train/raw-loss = 0.6679897904396057, train/logprobs = tensor([[-0.8922, -1.1853],
        [-1.5727, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008721570484340191
Epoch 0, Step 551: train/loss = 0.7989071011543274, train/raw-loss = 0.7988471984863281, train/logprobs = tensor([[-0.9740, -1.7686],
        [-1.0858, -1.5893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005986237665638328
Epoch 0, Step 552: train/loss = 0.714168131351471, train/raw-loss = 0.7139255404472351, train/logprobs = tensor([[-0.8336, -1.0332],
        [-1.0416, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002425564918667078
Epoch 0, Step 553: train/loss = 0.6960554718971252, train/raw-loss = 0.6960288286209106, train/logprobs = tensor([[-0.9844, -0.9291],
        [-1.1556, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026624451857060194
Epoch 0, Step 554: train/loss = 0.6989899277687073, train/raw-loss = 0.6983919143676758, train/logprobs = tensor([[-1.0259, -1.0644],
        [-1.3442, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059798117727041245
Epoch 0, Step 555: train/loss = 0.7177832722663879, train/raw-loss = 0.7175986766815186, train/logprobs = tensor([[-0.9234, -1.5456],
        [-1.0560, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018459606217220426
Epoch 0, Step 556: train/loss = 0.7034456729888916, train/raw-loss = 0.7032628059387207, train/logprobs = tensor([[-0.8831, -0.8918],
        [-1.0418, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001828511944040656
Epoch 0, Step 557: train/loss = 0.7051994800567627, train/raw-loss = 0.7042156457901001, train/logprobs = tensor([[-0.9722, -0.9418],
        [-1.0826, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009838441386818886
Epoch 0, Step 558: train/loss = 0.6938959956169128, train/raw-loss = 0.6929925680160522, train/logprobs = tensor([[-1.1473, -1.2091],
        [-1.4044, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009033748880028725
Epoch 0, Step 559: train/loss = 0.7164694666862488, train/raw-loss = 0.7162593603134155, train/logprobs = tensor([[-0.8744, -0.8002],
        [-1.0896, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021008183248341084
Epoch 0, Step 560: train/loss = 0.6934182047843933, train/raw-loss = 0.6932106018066406, train/logprobs = tensor([[-1.1743, -1.2165],
        [-1.3519, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020762281492352486
Epoch 0, Step 561: train/loss = 0.7080495357513428, train/raw-loss = 0.7079775929450989, train/logprobs = tensor([[-1.1939, -0.9329],
        [-1.3565, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000719903502613306
Epoch 0, Step 562: train/loss = 0.7173342704772949, train/raw-loss = 0.717302680015564, train/logprobs = tensor([[-1.1990, -1.2105],
        [-1.2853, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003158000181429088
Epoch 0, Step 563: train/loss = 0.697933554649353, train/raw-loss = 0.6976343393325806, train/logprobs = tensor([[-1.0468, -1.0262],
        [-1.1668, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002991847461089492
Epoch 0, Step 564: train/loss = 0.6958925724029541, train/raw-loss = 0.6958651542663574, train/logprobs = tensor([[-1.0225, -1.0182],
        [-1.1311, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002743296208791435
Epoch 0, Step 565: train/loss = 0.6954917311668396, train/raw-loss = 0.6954560875892639, train/logprobs = tensor([[-0.7755, -0.6965],
        [-0.8902, -0.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003564900252968073
Epoch 0, Step 566: train/loss = 0.6996266841888428, train/raw-loss = 0.6986914277076721, train/logprobs = tensor([[-0.9247, -1.0827],
        [-1.2107, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009352859109640121
Epoch 0, Step 567: train/loss = 0.7052434682846069, train/raw-loss = 0.7051777243614197, train/logprobs = tensor([[-1.1307, -0.9506],
        [-1.3604, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006571726407855749
Epoch 0, Step 568: train/loss = 0.7112606763839722, train/raw-loss = 0.7111380696296692, train/logprobs = tensor([[-1.1760, -1.0108],
        [-1.3416, -1.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012264200486242771
Epoch 0, Step 569: train/loss = 0.6993163228034973, train/raw-loss = 0.6992640495300293, train/logprobs = tensor([[-0.9115, -0.9047],
        [-1.0210, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005225794739089906
Epoch 0, Step 570: train/loss = 0.7008379697799683, train/raw-loss = 0.7008259296417236, train/logprobs = tensor([[-0.9234, -1.0303],
        [-0.9402, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012067484203726053
Epoch 0, Step 571: train/loss = 0.6951178908348083, train/raw-loss = 0.6950938105583191, train/logprobs = tensor([[-0.9305, -1.0550],
        [-1.0272, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002402427198830992
Epoch 0, Step 572: train/loss = 0.7948884963989258, train/raw-loss = 0.7948158383369446, train/logprobs = tensor([[-1.0216, -1.0002],
        [-1.1935, -1.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007270169444382191
Epoch 0, Step 573: train/loss = 0.7111498117446899, train/raw-loss = 0.7111254930496216, train/logprobs = tensor([[-0.7128, -1.0849],
        [-0.8113, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024361087707802653
Epoch 0, Step 574: train/loss = 0.7088691592216492, train/raw-loss = 0.7088325023651123, train/logprobs = tensor([[-1.0207, -1.0476],
        [-1.1563, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036694208392873406
Epoch 0, Step 575: train/loss = 0.6996643543243408, train/raw-loss = 0.6994945406913757, train/logprobs = tensor([[-0.8575, -0.9303],
        [-0.8904, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016984387766569853
Epoch 0, Step 576: train/loss = 0.7091197967529297, train/raw-loss = 0.7087867259979248, train/logprobs = tensor([[-0.9930, -1.1618],
        [-1.1173, -1.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003330749459564686
Epoch 0, Step 577: train/loss = 0.7078380584716797, train/raw-loss = 0.707694411277771, train/logprobs = tensor([[-0.9399, -0.7766],
        [-1.1194, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014362824149429798
Epoch 0, Step 578: train/loss = 0.7044659852981567, train/raw-loss = 0.7040700316429138, train/logprobs = tensor([[-0.8404, -0.9777],
        [-1.0907, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003959305584430695
Epoch 0, Step 579: train/loss = 0.6971502900123596, train/raw-loss = 0.6971362829208374, train/logprobs = tensor([[-0.8189, -0.8074],
        [-0.9770, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014028817531652749
Epoch 0, Step 580: train/loss = 0.6993221044540405, train/raw-loss = 0.6993024349212646, train/logprobs = tensor([[-0.7301, -0.8505],
        [-0.8516, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019701110431924462
Epoch 0, Step 581: train/loss = 0.69841468334198, train/raw-loss = 0.6980393528938293, train/logprobs = tensor([[-1.0347, -1.1840],
        [-1.2036, -1.2699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037533314898610115
Epoch 0, Step 582: train/loss = 0.7401517629623413, train/raw-loss = 0.7401310801506042, train/logprobs = tensor([[-1.0898, -0.7976],
        [-1.2012, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020681586465798318
Epoch 0, Step 583: train/loss = 0.7051365375518799, train/raw-loss = 0.7051169872283936, train/logprobs = tensor([[-1.0383, -0.8902],
        [-1.1848, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001956028863787651
Epoch 0, Step 584: train/loss = 0.7015489339828491, train/raw-loss = 0.7014234066009521, train/logprobs = tensor([[-0.8843, -0.9585],
        [-1.0877, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012550598476082087
Epoch 0, Step 585: train/loss = 0.7036385536193848, train/raw-loss = 0.7035796642303467, train/logprobs = tensor([[-0.8773, -0.7428],
        [-0.9684, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005891734617762268
Epoch 0, Step 586: train/loss = 0.698347270488739, train/raw-loss = 0.6978787183761597, train/logprobs = tensor([[-0.9582, -1.2663],
        [-1.1773, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00468516955152154
Epoch 0, Step 587: train/loss = 0.7129945755004883, train/raw-loss = 0.7126436829566956, train/logprobs = tensor([[-0.9340, -0.6299],
        [-1.1585, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035082087852060795
Epoch 0, Step 588: train/loss = 0.6962961554527283, train/raw-loss = 0.6962425708770752, train/logprobs = tensor([[-0.8509, -1.0596],
        [-1.0259, -1.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005352893495000899
Epoch 0, Step 589: train/loss = 0.6970189213752747, train/raw-loss = 0.6969299912452698, train/logprobs = tensor([[-0.9139, -0.9271],
        [-1.0114, -0.9842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008890117751434445
Epoch 0, Step 590: train/loss = 0.6926156878471375, train/raw-loss = 0.6919606328010559, train/logprobs = tensor([[-0.8750, -1.0132],
        [-1.0473, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006550719495862722
Epoch 0, Step 591: train/loss = 0.7020657658576965, train/raw-loss = 0.7019959092140198, train/logprobs = tensor([[-0.9924, -1.1006],
        [-1.1956, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00069872394669801
Epoch 0, Step 592: train/loss = 0.6999064683914185, train/raw-loss = 0.6998864412307739, train/logprobs = tensor([[-0.9519, -0.8141],
        [-1.0456, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019945271196775138
Epoch 0, Step 593: train/loss = 0.6950891613960266, train/raw-loss = 0.6950748562812805, train/logprobs = tensor([[-0.9998, -1.0868],
        [-1.1876, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001435810117982328
Epoch 0, Step 594: train/loss = 0.6787599325180054, train/raw-loss = 0.6787512898445129, train/logprobs = tensor([[-0.8909, -1.2061],
        [-0.9720, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.546814933652058e-05
Epoch 0, Step 595: train/loss = 0.7048192024230957, train/raw-loss = 0.7047395706176758, train/logprobs = tensor([[-1.0633, -1.0881],
        [-1.2272, -1.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007971371524035931
Epoch 0, Step 596: train/loss = 0.6850857138633728, train/raw-loss = 0.6840871572494507, train/logprobs = tensor([[-1.0834, -1.2378],
        [-1.3805, -1.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009985177777707577
Epoch 0, Step 597: train/loss = 0.6976521015167236, train/raw-loss = 0.6976308226585388, train/logprobs = tensor([[-1.2635, -1.3172],
        [-1.4997, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021250071586109698
Epoch 0, Step 598: train/loss = 0.6960821151733398, train/raw-loss = 0.6960002779960632, train/logprobs = tensor([[-0.9693, -1.0772],
        [-1.1117, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008182140300050378
Epoch 0, Step 599: train/loss = 0.6997238993644714, train/raw-loss = 0.699225902557373, train/logprobs = tensor([[-0.8188, -1.1661],
        [-1.0153, -1.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004980599042028189
Epoch 0, Step 600: train/loss = 0.7644660472869873, train/raw-loss = 0.7644630670547485, train/logprobs = tensor([[-1.0447, -0.9562],
        [-1.2049, -1.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0218994652386755e-05
Epoch 0, Step 601: train/loss = 0.7092324495315552, train/raw-loss = 0.7091195583343506, train/logprobs = tensor([[-1.0606, -0.8592],
        [-1.4282, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011287046363577247
Epoch 0, Step 602: train/loss = 0.6975253820419312, train/raw-loss = 0.697435736656189, train/logprobs = tensor([[-0.6938, -0.5891],
        [-0.8417, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008969764458015561
Epoch 0, Step 603: train/loss = 0.6941515207290649, train/raw-loss = 0.693973958492279, train/logprobs = tensor([[-1.0029, -1.2451],
        [-1.1940, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017751295818015933
Epoch 0, Step 604: train/loss = 0.7475599646568298, train/raw-loss = 0.747442364692688, train/logprobs = tensor([[-1.5504, -1.4862],
        [-1.8880, -1.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011760592460632324
Epoch 0, Step 605: train/loss = 0.6970781087875366, train/raw-loss = 0.6970640420913696, train/logprobs = tensor([[-0.9215, -0.9192],
        [-0.9776, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014024783740751445
Epoch 0, Step 606: train/loss = 0.7286026477813721, train/raw-loss = 0.7285902500152588, train/logprobs = tensor([[-0.8052, -1.0849],
        [-0.8656, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012370230979286134
Epoch 0, Step 607: train/loss = 0.6944103240966797, train/raw-loss = 0.6943730115890503, train/logprobs = tensor([[-0.9425, -0.9274],
        [-1.0251, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003732827608473599
Epoch 0, Step 608: train/loss = 0.7024140954017639, train/raw-loss = 0.7023378610610962, train/logprobs = tensor([[-1.1379, -1.0929],
        [-1.2535, -1.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007627154118381441
Epoch 0, Step 609: train/loss = 0.778850793838501, train/raw-loss = 0.7784947752952576, train/logprobs = tensor([[-1.1382, -1.6411],
        [-1.4036, -1.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035594620276242495
Epoch 0, Step 610: train/loss = 0.7047159075737, train/raw-loss = 0.7046390175819397, train/logprobs = tensor([[-1.0285, -0.9875],
        [-1.1204, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007693818188272417
Epoch 0, Step 611: train/loss = 0.7139413952827454, train/raw-loss = 0.7132478356361389, train/logprobs = tensor([[-1.1351, -1.0323],
        [-1.3761, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006936144083738327
Epoch 0, Step 612: train/loss = 0.6934820413589478, train/raw-loss = 0.693449854850769, train/logprobs = tensor([[-0.8954, -0.8662],
        [-0.9577, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032135890796780586
Epoch 0, Step 613: train/loss = 0.7968469858169556, train/raw-loss = 0.7967773675918579, train/logprobs = tensor([[-0.9289, -1.2903],
        [-0.9959, -1.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006959449965506792
Epoch 0, Step 614: train/loss = 0.6944350004196167, train/raw-loss = 0.6944054365158081, train/logprobs = tensor([[-0.8651, -0.9881],
        [-0.9724, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002949323388747871
Epoch 0, Step 615: train/loss = 0.7344104647636414, train/raw-loss = 0.7342718839645386, train/logprobs = tensor([[-0.8074, -1.1484],
        [-1.0614, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013856666628271341
Epoch 0, Step 616: train/loss = 0.7149388194084167, train/raw-loss = 0.714812695980072, train/logprobs = tensor([[-1.1228, -1.0265],
        [-1.3120, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012604788644239306
Epoch 0, Step 617: train/loss = 0.7016589045524597, train/raw-loss = 0.7015361785888672, train/logprobs = tensor([[-1.2242, -1.0919],
        [-1.3170, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012276078341528773
Epoch 0, Step 618: train/loss = 0.705508828163147, train/raw-loss = 0.7052639126777649, train/logprobs = tensor([[-0.8724, -0.7058],
        [-1.0428, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002449345774948597
Epoch 0, Step 619: train/loss = 0.7023779153823853, train/raw-loss = 0.7023322582244873, train/logprobs = tensor([[-0.9281, -0.7948],
        [-1.0081, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004565914859995246
Epoch 0, Step 620: train/loss = 0.7697360515594482, train/raw-loss = 0.7695444822311401, train/logprobs = tensor([[-1.0018, -1.5074],
        [-1.1350, -1.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019165102858096361
Epoch 0, Step 621: train/loss = 0.7160416841506958, train/raw-loss = 0.7158204913139343, train/logprobs = tensor([[-1.2195, -0.9964],
        [-1.3559, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002212229184806347
Epoch 0, Step 622: train/loss = 0.7150255441665649, train/raw-loss = 0.7148575186729431, train/logprobs = tensor([[-1.0041, -0.9461],
        [-1.0836, -0.8797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016801318852230906
Epoch 0, Step 623: train/loss = 0.6912501454353333, train/raw-loss = 0.6912380456924438, train/logprobs = tensor([[-0.9236, -0.9586],
        [-1.0993, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012041479931212962
Epoch 0, Step 624: train/loss = 0.6965330839157104, train/raw-loss = 0.69644695520401, train/logprobs = tensor([[-0.9333, -1.0452],
        [-1.0522, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008608606876805425
Epoch 0, Step 625: train/loss = 0.7263262271881104, train/raw-loss = 0.7261685729026794, train/logprobs = tensor([[-0.9175, -1.3344],
        [-1.0449, -1.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001576435286551714
Epoch 0, Step 626: train/loss = 0.7054774761199951, train/raw-loss = 0.7051737904548645, train/logprobs = tensor([[-0.9993, -1.2556],
        [-1.2248, -1.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030369518790394068
Epoch 0, Step 627: train/loss = 0.6933634281158447, train/raw-loss = 0.6933607459068298, train/logprobs = tensor([[-0.7719, -0.7919],
        [-0.9206, -0.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.683955244719982e-05
Epoch 0, Step 628: train/loss = 0.699346661567688, train/raw-loss = 0.6991568803787231, train/logprobs = tensor([[-0.9641, -1.0965],
        [-1.1526, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018977962899953127
Epoch 0, Step 629: train/loss = 0.7051056623458862, train/raw-loss = 0.7049747705459595, train/logprobs = tensor([[-0.6651, -0.9345],
        [-0.7419, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013090742286294699
Epoch 0, Step 630: train/loss = 0.7821637988090515, train/raw-loss = 0.782141923904419, train/logprobs = tensor([[-0.8074, -1.2462],
        [-0.9158, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021866976749151945
Epoch 0, Step 631: train/loss = 0.7299737930297852, train/raw-loss = 0.7299556732177734, train/logprobs = tensor([[-0.7377, -1.1201],
        [-0.7885, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018171023111790419
Epoch 0, Step 632: train/loss = 0.7171322703361511, train/raw-loss = 0.7170412540435791, train/logprobs = tensor([[-1.0888, -0.8510],
        [-1.2218, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009100604220293462
Epoch 0, Step 633: train/loss = 0.704500675201416, train/raw-loss = 0.7043717503547668, train/logprobs = tensor([[-0.9636, -1.2352],
        [-1.0678, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001289208885282278
Epoch 0, Step 634: train/loss = 0.6953907012939453, train/raw-loss = 0.6953532099723816, train/logprobs = tensor([[-0.9266, -1.0479],
        [-0.9334, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003754573408514261
Epoch 0, Step 635: train/loss = 0.7389374375343323, train/raw-loss = 0.738808274269104, train/logprobs = tensor([[-1.1410, -1.5044],
        [-1.2376, -1.4008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012908766511827707
Epoch 0, Step 636: train/loss = 0.7146857976913452, train/raw-loss = 0.7144932150840759, train/logprobs = tensor([[-0.9588, -1.3120],
        [-1.0696, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00192566541954875
Epoch 0, Step 637: train/loss = 0.7050825953483582, train/raw-loss = 0.7049931883811951, train/logprobs = tensor([[-0.8886, -0.8716],
        [-0.9433, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008935492369346321
Epoch 0, Step 638: train/loss = 0.7015165686607361, train/raw-loss = 0.7014765739440918, train/logprobs = tensor([[-0.9621, -0.9766],
        [-1.1298, -1.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040024943882599473
Epoch 0, Step 639: train/loss = 0.7220925092697144, train/raw-loss = 0.7219103574752808, train/logprobs = tensor([[-1.1893, -1.3550],
        [-1.3851, -1.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018217932665720582
Epoch 0, Step 640: train/loss = 0.7043025493621826, train/raw-loss = 0.7042170763015747, train/logprobs = tensor([[-0.9370, -1.1017],
        [-1.0767, -1.1429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008545203600078821
Epoch 0, Step 641: train/loss = 0.7040129899978638, train/raw-loss = 0.7037795782089233, train/logprobs = tensor([[-0.8158, -0.7546],
        [-1.0152, -0.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002334327669814229
Epoch 0, Step 642: train/loss = 0.6971104145050049, train/raw-loss = 0.6970490217208862, train/logprobs = tensor([[-1.1244, -1.0615],
        [-1.2157, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006136966403573751
Epoch 0, Step 643: train/loss = 0.6961677074432373, train/raw-loss = 0.6959258913993835, train/logprobs = tensor([[-0.8258, -0.9952],
        [-0.9616, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002418666146695614
Epoch 0, Step 644: train/loss = 0.7486124038696289, train/raw-loss = 0.7485618591308594, train/logprobs = tensor([[-1.0173, -1.1186],
        [-1.0823, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005057580419816077
Epoch 0, Step 645: train/loss = 0.6942703723907471, train/raw-loss = 0.6939699649810791, train/logprobs = tensor([[-0.9454, -1.0705],
        [-1.1334, -1.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030041858553886414
Epoch 0, Step 646: train/loss = 0.7009736895561218, train/raw-loss = 0.7006758451461792, train/logprobs = tensor([[-0.7645, -0.9481],
        [-0.9654, -1.0165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002978675067424774
Epoch 0, Step 647: train/loss = 0.7141036987304688, train/raw-loss = 0.7140116691589355, train/logprobs = tensor([[-0.9468, -1.3693],
        [-1.2506, -1.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000920205086003989
Epoch 0, Step 648: train/loss = 0.6975485682487488, train/raw-loss = 0.6974753737449646, train/logprobs = tensor([[-1.0966, -1.2120],
        [-1.1621, -1.1108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007323464378714561
Epoch 0, Step 649: train/loss = 0.6977823972702026, train/raw-loss = 0.6977538466453552, train/logprobs = tensor([[-0.8240, -0.9756],
        [-0.9423, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002849257434718311
Epoch 0, Step 650: train/loss = 0.6950051188468933, train/raw-loss = 0.694990873336792, train/logprobs = tensor([[-1.0118, -1.1360],
        [-1.1969, -1.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014232151443138719
Epoch 0, Step 651: train/loss = 0.7284505367279053, train/raw-loss = 0.7283031940460205, train/logprobs = tensor([[-1.0887, -1.3134],
        [-1.2749, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014735227450728416
Epoch 0, Step 652: train/loss = 0.6993613243103027, train/raw-loss = 0.699317455291748, train/logprobs = tensor([[-0.8581, -0.9915],
        [-1.0040, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043868902139365673
Epoch 0, Step 653: train/loss = 0.7023640275001526, train/raw-loss = 0.7022400498390198, train/logprobs = tensor([[-1.0399, -0.8618],
        [-1.1360, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012401198036968708
Epoch 0, Step 654: train/loss = 0.7018470168113708, train/raw-loss = 0.7016564011573792, train/logprobs = tensor([[-1.0082, -1.1974],
        [-1.2470, -1.1535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001905667595565319
Epoch 0, Step 655: train/loss = 0.6949501633644104, train/raw-loss = 0.6949157118797302, train/logprobs = tensor([[-0.8562, -0.8823],
        [-0.9258, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003446635964792222
Epoch 0, Step 656: train/loss = 0.7032262086868286, train/raw-loss = 0.7031675577163696, train/logprobs = tensor([[-1.1043, -1.0035],
        [-1.1837, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000586070935241878
Epoch 0, Step 657: train/loss = 0.695641279220581, train/raw-loss = 0.6955749988555908, train/logprobs = tensor([[-0.8786, -1.0196],
        [-0.9595, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006631467258557677
Epoch 0, Step 658: train/loss = 0.6978830099105835, train/raw-loss = 0.6974902749061584, train/logprobs = tensor([[-0.8733, -1.0364],
        [-1.0982, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003927282989025116
Epoch 0, Step 659: train/loss = 0.7490224242210388, train/raw-loss = 0.7488106489181519, train/logprobs = tensor([[-0.8517, -1.4372],
        [-1.0511, -1.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021177870221436024
Epoch 0, Step 660: train/loss = 0.7010014057159424, train/raw-loss = 0.7005696296691895, train/logprobs = tensor([[-0.9689, -0.9668],
        [-1.2292, -0.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004317563958466053
Epoch 0, Step 661: train/loss = 0.6935354471206665, train/raw-loss = 0.693447470664978, train/logprobs = tensor([[-0.9060, -0.9553],
        [-1.0968, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008799021015875041
Epoch 0, Step 662: train/loss = 0.6960257291793823, train/raw-loss = 0.6960116624832153, train/logprobs = tensor([[-1.1035, -1.1648],
        [-1.1602, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014065043069422245
Epoch 0, Step 663: train/loss = 0.6931025385856628, train/raw-loss = 0.6926153898239136, train/logprobs = tensor([[-0.8496, -0.9277],
        [-1.1444, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004871244076639414
Epoch 0, Step 664: train/loss = 0.7087936401367188, train/raw-loss = 0.7087070941925049, train/logprobs = tensor([[-0.9371, -1.0928],
        [-1.1496, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008662862237542868
Epoch 0, Step 665: train/loss = 0.6938062906265259, train/raw-loss = 0.6936790347099304, train/logprobs = tensor([[-0.9556, -1.0171],
        [-1.1025, -0.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012726541608572006
Epoch 0, Step 666: train/loss = 0.699870228767395, train/raw-loss = 0.6997686624526978, train/logprobs = tensor([[-0.7048, -0.9292],
        [-0.8183, -0.9082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010153441689908504
Epoch 0, Step 667: train/loss = 0.7183060646057129, train/raw-loss = 0.7181146740913391, train/logprobs = tensor([[-0.8751, -0.8656],
        [-0.9173, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019139859359711409
Epoch 0, Step 668: train/loss = 0.694311261177063, train/raw-loss = 0.694298267364502, train/logprobs = tensor([[-0.8581, -0.9047],
        [-1.0117, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013008862151764333
Epoch 0, Step 669: train/loss = 0.6983632445335388, train/raw-loss = 0.6981151103973389, train/logprobs = tensor([[-1.0138, -1.3239],
        [-1.2637, -1.2820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024808335583657026
Epoch 0, Step 670: train/loss = 0.7162636518478394, train/raw-loss = 0.7161615490913391, train/logprobs = tensor([[-0.8826, -1.1348],
        [-0.9907, -1.2109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001021576696075499
Epoch 0, Step 671: train/loss = 0.7048765420913696, train/raw-loss = 0.7047589421272278, train/logprobs = tensor([[-0.7652, -1.1190],
        [-0.8939, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011753491126000881
Epoch 0, Step 672: train/loss = 0.7010818719863892, train/raw-loss = 0.7010115385055542, train/logprobs = tensor([[-1.1135, -0.9314],
        [-1.2149, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007031608838587999
Epoch 0, Step 673: train/loss = 0.7198452949523926, train/raw-loss = 0.7198346257209778, train/logprobs = tensor([[-0.9825, -1.1318],
        [-1.1579, -1.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010692741489037871
Epoch 0, Step 674: train/loss = 0.6972612738609314, train/raw-loss = 0.6970615386962891, train/logprobs = tensor([[-1.1485, -1.3108],
        [-1.1877, -1.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001996647333726287
Epoch 0, Step 675: train/loss = 0.7131748795509338, train/raw-loss = 0.7129909992218018, train/logprobs = tensor([[-1.1114, -1.3627],
        [-1.1618, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001838791649788618
Epoch 0, Step 676: train/loss = 0.6662730574607849, train/raw-loss = 0.6658176183700562, train/logprobs = tensor([[-0.8958, -0.9019],
        [-1.6035, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004554366692900658
Epoch 0, Step 677: train/loss = 0.6988987922668457, train/raw-loss = 0.6986951231956482, train/logprobs = tensor([[-0.9590, -1.0222],
        [-1.1169, -1.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002036518882960081
Epoch 0, Step 678: train/loss = 0.7038881778717041, train/raw-loss = 0.7038179039955139, train/logprobs = tensor([[-1.0791, -1.3075],
        [-1.2292, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007026683888398111
Epoch 0, Step 679: train/loss = 0.702953577041626, train/raw-loss = 0.7027974128723145, train/logprobs = tensor([[-0.9470, -0.8430],
        [-1.1569, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001560951117426157
Epoch 0, Step 680: train/loss = 0.701677143573761, train/raw-loss = 0.7015523314476013, train/logprobs = tensor([[-0.8987, -1.2060],
        [-0.9969, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001248408341780305
Epoch 0, Step 681: train/loss = 0.6768288612365723, train/raw-loss = 0.6764930486679077, train/logprobs = tensor([[-0.7755, -1.0089],
        [-1.3395, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003358450485393405
Epoch 0, Step 682: train/loss = 0.7179064750671387, train/raw-loss = 0.7177254557609558, train/logprobs = tensor([[-0.9785, -1.3619],
        [-1.0963, -1.2329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018097494030371308
Epoch 0, Step 683: train/loss = 0.7178487777709961, train/raw-loss = 0.7176388502120972, train/logprobs = tensor([[-0.8927, -0.8980],
        [-1.0375, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002099309815093875
Epoch 0, Step 684: train/loss = 0.728936493396759, train/raw-loss = 0.7287883758544922, train/logprobs = tensor([[-0.9935, -1.4515],
        [-1.1442, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001480600330978632
Epoch 0, Step 685: train/loss = 0.7039888501167297, train/raw-loss = 0.7039387226104736, train/logprobs = tensor([[-0.8869, -0.8850],
        [-1.0202, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005016095237806439
Epoch 0, Step 686: train/loss = 0.6951038241386414, train/raw-loss = 0.695046603679657, train/logprobs = tensor([[-1.0685, -1.2227],
        [-1.2051, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005727492971345782
Epoch 0, Step 687: train/loss = 0.6890186071395874, train/raw-loss = 0.6881502866744995, train/logprobs = tensor([[-1.1498, -1.2702],
        [-1.3126, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008682833053171635
Epoch 0, Step 688: train/loss = 0.7497462630271912, train/raw-loss = 0.7495348453521729, train/logprobs = tensor([[-0.8578, -1.5416],
        [-0.9738, -1.5031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021145432256162167
Epoch 0, Step 689: train/loss = 0.7057508230209351, train/raw-loss = 0.7057475447654724, train/logprobs = tensor([[-0.7209, -0.9066],
        [-0.8228, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2281990570481867e-05
Epoch 0, Step 690: train/loss = 0.7069107294082642, train/raw-loss = 0.7068842053413391, train/logprobs = tensor([[-1.1083, -1.2350],
        [-1.2342, -1.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002646561770234257
Epoch 0, Step 691: train/loss = 0.6956866979598999, train/raw-loss = 0.6956744194030762, train/logprobs = tensor([[-0.9181, -0.8786],
        [-0.9337, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012314628111198545
Epoch 0, Step 692: train/loss = 0.7086270451545715, train/raw-loss = 0.7085349559783936, train/logprobs = tensor([[-0.8609, -1.0502],
        [-1.0674, -1.1241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009206855902448297
Epoch 0, Step 693: train/loss = 0.6955438852310181, train/raw-loss = 0.695534884929657, train/logprobs = tensor([[-0.9207, -0.9295],
        [-1.0231, -1.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.026293992064893e-05
Epoch 0, Step 694: train/loss = 0.7055834531784058, train/raw-loss = 0.7055380344390869, train/logprobs = tensor([[-0.9161, -1.1224],
        [-0.9845, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045413855696097016
Epoch 0, Step 695: train/loss = 0.6933813095092773, train/raw-loss = 0.6933703422546387, train/logprobs = tensor([[-0.9726, -1.0130],
        [-1.0436, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010897243919316679
Epoch 0, Step 696: train/loss = 0.7084348201751709, train/raw-loss = 0.7082012891769409, train/logprobs = tensor([[-0.9994, -1.2832],
        [-1.0732, -1.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023354545701295137
Epoch 0, Step 697: train/loss = 0.6903123259544373, train/raw-loss = 0.6895987391471863, train/logprobs = tensor([[-1.1062, -1.1041],
        [-1.3383, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0071353428065776825
Epoch 0, Step 698: train/loss = 0.7117502689361572, train/raw-loss = 0.7114859819412231, train/logprobs = tensor([[-1.1078, -1.4176],
        [-1.1607, -1.3028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026430413126945496
Epoch 0, Step 699: train/loss = 0.753071129322052, train/raw-loss = 0.7529392242431641, train/logprobs = tensor([[-1.1347, -0.9836],
        [-1.3453, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013190784957259893
Epoch 0, Step 700: train/loss = 0.6926155090332031, train/raw-loss = 0.6925199031829834, train/logprobs = tensor([[-0.8851, -0.9995],
        [-1.0735, -0.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009559524478390813
Epoch 0, Step 701: train/loss = 0.6978305578231812, train/raw-loss = 0.6972184181213379, train/logprobs = tensor([[-0.9335, -1.1651],
        [-1.1651, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006121268030256033
Epoch 0, Step 702: train/loss = 0.7808010578155518, train/raw-loss = 0.7807246446609497, train/logprobs = tensor([[-0.8357, -1.0754],
        [-0.9217, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007649001199752092
Epoch 0, Step 703: train/loss = 0.7020248770713806, train/raw-loss = 0.7017107009887695, train/logprobs = tensor([[-0.9608, -1.0452],
        [-1.2041, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031406781636178493
Epoch 0, Step 704: train/loss = 0.702928900718689, train/raw-loss = 0.7021591663360596, train/logprobs = tensor([[-0.9771, -1.5377],
        [-1.3978, -1.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0076970853842794895
Epoch 0, Step 705: train/loss = 0.7001510262489319, train/raw-loss = 0.7000325918197632, train/logprobs = tensor([[-0.9762, -1.0745],
        [-1.0815, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001184001099318266
Epoch 0, Step 706: train/loss = 0.7035375237464905, train/raw-loss = 0.7034304738044739, train/logprobs = tensor([[-1.0137, -0.9514],
        [-1.0910, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010700812563300133
Epoch 0, Step 707: train/loss = 0.723463237285614, train/raw-loss = 0.7232170701026917, train/logprobs = tensor([[-1.0138, -1.3898],
        [-1.1648, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002461368218064308
Epoch 0, Step 708: train/loss = 0.6961057186126709, train/raw-loss = 0.6956340670585632, train/logprobs = tensor([[-0.9808, -1.2436],
        [-1.0845, -1.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004717114847153425
Epoch 0, Step 709: train/loss = 0.7322008609771729, train/raw-loss = 0.7320212125778198, train/logprobs = tensor([[-1.1853, -1.0878],
        [-1.3549, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017971170600503683
Epoch 0, Step 710: train/loss = 0.71067875623703, train/raw-loss = 0.7106598615646362, train/logprobs = tensor([[-1.0135, -1.0362],
        [-1.0583, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018921167065855116
Epoch 0, Step 711: train/loss = 0.7131111025810242, train/raw-loss = 0.7130460143089294, train/logprobs = tensor([[-0.9395, -1.1794],
        [-0.9738, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006500505842268467
Epoch 0, Step 712: train/loss = 0.6991342306137085, train/raw-loss = 0.6990365386009216, train/logprobs = tensor([[-0.9957, -0.9280],
        [-1.2158, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000976612907834351
Epoch 0, Step 713: train/loss = 0.7060332298278809, train/raw-loss = 0.705848217010498, train/logprobs = tensor([[-0.9771, -1.2260],
        [-1.0725, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001850336673669517
Epoch 0, Step 714: train/loss = 0.7047933340072632, train/raw-loss = 0.7046718001365662, train/logprobs = tensor([[-1.0546, -1.1106],
        [-1.2676, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012157981982454658
Epoch 0, Step 715: train/loss = 0.6943448185920715, train/raw-loss = 0.6942741274833679, train/logprobs = tensor([[-0.9131, -0.9115],
        [-1.1245, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007073801243677735
Epoch 0, Step 716: train/loss = 0.7064133882522583, train/raw-loss = 0.7063001990318298, train/logprobs = tensor([[-0.9245, -1.1445],
        [-1.0585, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011325199156999588
Epoch 0, Step 717: train/loss = 0.7017157673835754, train/raw-loss = 0.7014850974082947, train/logprobs = tensor([[-1.1473, -1.0911],
        [-1.2956, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023067141883075237
Epoch 0, Step 718: train/loss = 0.6964677572250366, train/raw-loss = 0.6964528560638428, train/logprobs = tensor([[-0.9761, -1.1969],
        [-1.0639, -1.1327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014943421410862356
Epoch 0, Step 719: train/loss = 0.7933016419410706, train/raw-loss = 0.7931936979293823, train/logprobs = tensor([[-0.8461, -1.3312],
        [-0.8697, -1.3042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010793600231409073
Epoch 0, Step 720: train/loss = 0.7216293811798096, train/raw-loss = 0.7216020226478577, train/logprobs = tensor([[-0.8077, -1.1128],
        [-0.9312, -1.0539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002735175658017397
Epoch 0, Step 721: train/loss = 0.739479124546051, train/raw-loss = 0.7393432259559631, train/logprobs = tensor([[-0.6557, -0.9941],
        [-0.7827, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013584615662693977
Epoch 0, Step 722: train/loss = 0.714607834815979, train/raw-loss = 0.7144978046417236, train/logprobs = tensor([[-0.8600, -0.8983],
        [-0.9387, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011000765953212976
Epoch 0, Step 723: train/loss = 0.7068282961845398, train/raw-loss = 0.706566333770752, train/logprobs = tensor([[-0.8856, -1.0091],
        [-1.0921, -1.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002620014362037182
Epoch 0, Step 724: train/loss = 0.6991882920265198, train/raw-loss = 0.6991304159164429, train/logprobs = tensor([[-1.0602, -1.2309],
        [-1.0873, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005782196531072259
Epoch 0, Step 725: train/loss = 0.7145698666572571, train/raw-loss = 0.7144397497177124, train/logprobs = tensor([[-1.0291, -0.9884],
        [-1.1615, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013015054864808917
Epoch 0, Step 726: train/loss = 0.7089033722877502, train/raw-loss = 0.7085530161857605, train/logprobs = tensor([[-1.0007, -1.1399],
        [-1.0952, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003504038555547595
Epoch 0, Step 727: train/loss = 0.7141192555427551, train/raw-loss = 0.7139757871627808, train/logprobs = tensor([[-1.0350, -1.3651],
        [-1.2275, -1.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014343764632940292
Epoch 0, Step 728: train/loss = 0.6984856128692627, train/raw-loss = 0.6984562873840332, train/logprobs = tensor([[-0.9542, -1.1618],
        [-1.0902, -1.2171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029297309811227024
Epoch 0, Step 729: train/loss = 0.6964426040649414, train/raw-loss = 0.695728600025177, train/logprobs = tensor([[-0.8906, -1.2318],
        [-1.0527, -1.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007140489760786295
Epoch 0, Step 730: train/loss = 0.7101384401321411, train/raw-loss = 0.7100790739059448, train/logprobs = tensor([[-1.1493, -1.4191],
        [-1.2305, -1.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005929862381890416
Epoch 0, Step 731: train/loss = 0.69664067029953, train/raw-loss = 0.6964083313941956, train/logprobs = tensor([[-0.8780, -0.9855],
        [-1.1384, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002323582535609603
Epoch 0, Step 732: train/loss = 0.7057163715362549, train/raw-loss = 0.705511212348938, train/logprobs = tensor([[-0.9945, -1.1676],
        [-1.0382, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020516011863946915
Epoch 0, Step 733: train/loss = 0.6962377429008484, train/raw-loss = 0.6962321996688843, train/logprobs = tensor([[-0.7646, -0.8162],
        [-0.8144, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.515114389709197e-05
Epoch 0, Step 734: train/loss = 0.6928597688674927, train/raw-loss = 0.6919280290603638, train/logprobs = tensor([[-0.8978, -1.2500],
        [-1.0017, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009316403418779373
Epoch 0, Step 735: train/loss = 0.6923683881759644, train/raw-loss = 0.6918600797653198, train/logprobs = tensor([[-1.0400, -1.2516],
        [-1.2058, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005082873627543449
Epoch 0, Step 736: train/loss = 0.6955230236053467, train/raw-loss = 0.6955153942108154, train/logprobs = tensor([[-0.9489, -0.8698],
        [-1.0396, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.674991502426565e-05
Epoch 0, Step 737: train/loss = 0.6993083953857422, train/raw-loss = 0.6991921663284302, train/logprobs = tensor([[-0.9326, -1.0137],
        [-0.9883, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011626677587628365
Epoch 0, Step 738: train/loss = 0.7037140727043152, train/raw-loss = 0.703508734703064, train/logprobs = tensor([[-1.0570, -1.1991],
        [-1.2354, -1.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020536943338811398
Epoch 0, Step 739: train/loss = 0.6973897218704224, train/raw-loss = 0.6972945928573608, train/logprobs = tensor([[-0.7980, -0.9808],
        [-0.9181, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009515502024441957
Epoch 0, Step 740: train/loss = 0.6951561570167542, train/raw-loss = 0.6950980424880981, train/logprobs = tensor([[-0.8883, -1.0225],
        [-0.9711, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005810371949337423
Epoch 0, Step 741: train/loss = 0.6953856945037842, train/raw-loss = 0.6953113079071045, train/logprobs = tensor([[-0.9782, -1.0855],
        [-1.0051, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007440275512635708
Epoch 0, Step 742: train/loss = 0.6955121159553528, train/raw-loss = 0.6953154802322388, train/logprobs = tensor([[-0.9381, -1.0612],
        [-1.1308, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00196685828268528
Epoch 0, Step 743: train/loss = 0.7153681516647339, train/raw-loss = 0.7150731086730957, train/logprobs = tensor([[-0.9882, -1.2215],
        [-1.2769, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002950996858999133
Epoch 0, Step 744: train/loss = 0.6988347768783569, train/raw-loss = 0.6987254619598389, train/logprobs = tensor([[-1.0205, -1.1453],
        [-1.1373, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010932195000350475
Epoch 0, Step 745: train/loss = 0.698338508605957, train/raw-loss = 0.6978018283843994, train/logprobs = tensor([[-0.9165, -0.8800],
        [-1.0208, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053669726476073265
Epoch 0, Step 746: train/loss = 0.7054771184921265, train/raw-loss = 0.7053200602531433, train/logprobs = tensor([[-1.0640, -0.9528],
        [-1.1861, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015703401295468211
Epoch 0, Step 747: train/loss = 0.701959490776062, train/raw-loss = 0.7017124891281128, train/logprobs = tensor([[-0.9333, -1.2498],
        [-1.1263, -1.1108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024696742184460163
Epoch 0, Step 748: train/loss = 0.6975061893463135, train/raw-loss = 0.6973963379859924, train/logprobs = tensor([[-1.2049, -1.3190],
        [-1.2564, -1.2426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010984638938680291
Epoch 0, Step 749: train/loss = 0.7120475172996521, train/raw-loss = 0.7118164300918579, train/logprobs = tensor([[-0.7466, -1.0736],
        [-0.9601, -1.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023112052585929632
Epoch 0, Step 750: train/loss = 0.6948161125183105, train/raw-loss = 0.6948152780532837, train/logprobs = tensor([[-0.7478, -0.8571],
        [-0.8123, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.936593076214194e-06
Epoch 0, Step 751: train/loss = 0.7004678249359131, train/raw-loss = 0.7001391053199768, train/logprobs = tensor([[-0.9385, -0.9407],
        [-1.0698, -0.9379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003286721184849739
Epoch 0, Step 752: train/loss = 0.7084368467330933, train/raw-loss = 0.7082995772361755, train/logprobs = tensor([[-0.9662, -1.2480],
        [-0.9962, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013734862441197038
Epoch 0, Step 753: train/loss = 0.7105568647384644, train/raw-loss = 0.7105004787445068, train/logprobs = tensor([[-0.9617, -1.3319],
        [-1.1590, -1.4207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005632108077406883
Epoch 0, Step 754: train/loss = 0.7008804082870483, train/raw-loss = 0.7008252143859863, train/logprobs = tensor([[-0.5607, -0.7690],
        [-0.6005, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005524939042516053
Epoch 0, Step 755: train/loss = 0.6955437064170837, train/raw-loss = 0.6954663991928101, train/logprobs = tensor([[-1.1180, -1.1195],
        [-1.2373, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007725495379418135
Epoch 0, Step 756: train/loss = 0.7183075547218323, train/raw-loss = 0.7178989052772522, train/logprobs = tensor([[-1.1184, -0.9121],
        [-1.2348, -0.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004086395725607872
Epoch 0, Step 757: train/loss = 0.6960594654083252, train/raw-loss = 0.6957060098648071, train/logprobs = tensor([[-0.7991, -0.9321],
        [-0.9974, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035340571776032448
Epoch 0, Step 758: train/loss = 0.6969254016876221, train/raw-loss = 0.696721076965332, train/logprobs = tensor([[-0.9511, -0.9915],
        [-1.0756, -0.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020435587503015995
Epoch 0, Step 759: train/loss = 0.6983028650283813, train/raw-loss = 0.6981337070465088, train/logprobs = tensor([[-0.9325, -1.0843],
        [-1.0494, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016913944855332375
Epoch 0, Step 760: train/loss = 0.6944794058799744, train/raw-loss = 0.6943724155426025, train/logprobs = tensor([[-0.9532, -1.0842],
        [-0.9439, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010693185031414032
Epoch 0, Step 761: train/loss = 0.6954383850097656, train/raw-loss = 0.6953973174095154, train/logprobs = tensor([[-0.9494, -1.0342],
        [-0.9845, -1.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041038962081074715
Epoch 0, Step 762: train/loss = 0.7269399762153625, train/raw-loss = 0.7247002720832825, train/logprobs = tensor([[-0.8949, -1.4471],
        [-1.0299, -1.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022397611290216446
Epoch 0, Step 763: train/loss = 0.6977726221084595, train/raw-loss = 0.6976455450057983, train/logprobs = tensor([[-0.8563, -0.9480],
        [-0.9483, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001271153800189495
Epoch 0, Step 764: train/loss = 0.7089757919311523, train/raw-loss = 0.7086833119392395, train/logprobs = tensor([[-0.7725, -1.1238],
        [-0.9614, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029248823411762714
Epoch 0, Step 765: train/loss = 0.697282075881958, train/raw-loss = 0.6972748041152954, train/logprobs = tensor([[-1.0129, -1.1657],
        [-1.0663, -1.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.28103332221508e-05
Epoch 0, Step 766: train/loss = 0.7188454270362854, train/raw-loss = 0.7179267406463623, train/logprobs = tensor([[-1.0215, -1.3827],
        [-1.1643, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009187227115035057
Epoch 0, Step 767: train/loss = 0.7154312133789062, train/raw-loss = 0.7152026891708374, train/logprobs = tensor([[-0.9927, -1.0149],
        [-1.2268, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022855787537992
Epoch 0, Step 768: train/loss = 0.7079602479934692, train/raw-loss = 0.7075013518333435, train/logprobs = tensor([[-0.9908, -0.9915],
        [-1.3077, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004588591866195202
Epoch 0, Step 769: train/loss = 0.6989855170249939, train/raw-loss = 0.6986774206161499, train/logprobs = tensor([[-1.0254, -1.1352],
        [-1.0259, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030807508155703545
Epoch 0, Step 770: train/loss = 0.6942434906959534, train/raw-loss = 0.6941840052604675, train/logprobs = tensor([[-0.8742, -0.9870],
        [-0.9540, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005949885817244649
Epoch 0, Step 771: train/loss = 0.7130982875823975, train/raw-loss = 0.7127662897109985, train/logprobs = tensor([[-1.1274, -0.8850],
        [-1.4603, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033206576481461525
Epoch 0, Step 772: train/loss = 0.7163428068161011, train/raw-loss = 0.7162904143333435, train/logprobs = tensor([[-1.0695, -0.8628],
        [-1.1813, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005246176151558757
Epoch 0, Step 773: train/loss = 0.6936554908752441, train/raw-loss = 0.6935855150222778, train/logprobs = tensor([[-1.1043, -1.1933],
        [-1.1834, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006994931027293205
Epoch 0, Step 774: train/loss = 0.6958003640174866, train/raw-loss = 0.6957201361656189, train/logprobs = tensor([[-0.8658, -0.8175],
        [-1.0042, -0.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008026054129004478
Epoch 0, Step 775: train/loss = 0.7129362225532532, train/raw-loss = 0.712899386882782, train/logprobs = tensor([[-1.0100, -1.1603],
        [-1.0802, -1.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036779523361474276
Epoch 0, Step 776: train/loss = 0.6961191892623901, train/raw-loss = 0.6960620284080505, train/logprobs = tensor([[-1.0115, -1.1923],
        [-1.0681, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005723221111111343
Epoch 0, Step 777: train/loss = 0.6957566142082214, train/raw-loss = 0.6954823732376099, train/logprobs = tensor([[-1.0525, -1.1859],
        [-1.2468, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027433428913354874
Epoch 0, Step 778: train/loss = 0.6977353096008301, train/raw-loss = 0.6977205872535706, train/logprobs = tensor([[-1.0287, -0.9357],
        [-1.0578, -0.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001472569420002401
Epoch 0, Step 779: train/loss = 0.6978853344917297, train/raw-loss = 0.6975328326225281, train/logprobs = tensor([[-0.6693, -0.8221],
        [-0.8370, -0.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035247253254055977
Epoch 0, Step 780: train/loss = 0.7269401550292969, train/raw-loss = 0.7263320684432983, train/logprobs = tensor([[-1.1232, -1.0534],
        [-1.4328, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006080370396375656
Epoch 0, Step 781: train/loss = 0.7003430724143982, train/raw-loss = 0.7003110647201538, train/logprobs = tensor([[-1.0212, -0.9225],
        [-1.1221, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003198092745151371
Epoch 0, Step 782: train/loss = 0.6939522624015808, train/raw-loss = 0.6939454078674316, train/logprobs = tensor([[-0.8034, -0.8987],
        [-0.9109, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.849698547739536e-05
Epoch 0, Step 783: train/loss = 0.6971337795257568, train/raw-loss = 0.6966902017593384, train/logprobs = tensor([[-0.9602, -1.2947],
        [-1.1475, -1.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004435292910784483
Epoch 0, Step 784: train/loss = 0.6917960047721863, train/raw-loss = 0.6915240287780762, train/logprobs = tensor([[-0.9110, -1.0361],
        [-1.0917, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027192472480237484
Epoch 0, Step 785: train/loss = 0.7011013031005859, train/raw-loss = 0.7010040879249573, train/logprobs = tensor([[-0.8708, -0.8346],
        [-0.9109, -0.8042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009723111288622022
Epoch 0, Step 786: train/loss = 0.6995626091957092, train/raw-loss = 0.6995487213134766, train/logprobs = tensor([[-0.9056, -0.8530],
        [-0.9672, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013898179167881608
Epoch 0, Step 787: train/loss = 0.7018766403198242, train/raw-loss = 0.7018009424209595, train/logprobs = tensor([[-0.8945, -0.7795],
        [-1.0126, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007564307888969779
Epoch 0, Step 788: train/loss = 0.6962597370147705, train/raw-loss = 0.6962488293647766, train/logprobs = tensor([[-0.7780, -0.9397],
        [-0.8363, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001099670771509409
Epoch 0, Step 789: train/loss = 0.7074986100196838, train/raw-loss = 0.7072494626045227, train/logprobs = tensor([[-0.9271, -1.2117],
        [-1.2244, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024913623929023743
Epoch 0, Step 790: train/loss = 0.6983840465545654, train/raw-loss = 0.6980454921722412, train/logprobs = tensor([[-0.9489, -1.0467],
        [-1.1015, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033854511566460133
Epoch 0, Step 791: train/loss = 0.6959512233734131, train/raw-loss = 0.6957403421401978, train/logprobs = tensor([[-0.8390, -1.0159],
        [-0.9238, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002109176479279995
Epoch 0, Step 792: train/loss = 0.694068968296051, train/raw-loss = 0.6940233707427979, train/logprobs = tensor([[-0.8627, -0.9173],
        [-0.8098, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000455628294730559
Epoch 0, Step 793: train/loss = 0.6932246685028076, train/raw-loss = 0.6930314302444458, train/logprobs = tensor([[-0.9291, -0.9216],
        [-1.0759, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001932505751028657
Epoch 0, Step 794: train/loss = 0.7059682607650757, train/raw-loss = 0.7057696580886841, train/logprobs = tensor([[-0.9310, -0.7506],
        [-1.0265, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019859769381582737
Epoch 0, Step 795: train/loss = 0.6979669332504272, train/raw-loss = 0.6979268193244934, train/logprobs = tensor([[-1.0726, -1.0684],
        [-1.1791, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004011478740721941
Epoch 0, Step 796: train/loss = 0.7199779152870178, train/raw-loss = 0.7196013331413269, train/logprobs = tensor([[-0.9337, -0.8907],
        [-0.9814, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003766004927456379
Epoch 0, Step 797: train/loss = 0.6996091604232788, train/raw-loss = 0.6995083689689636, train/logprobs = tensor([[-0.9397, -1.0828],
        [-1.0892, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010081729851663113
Epoch 0, Step 798: train/loss = 0.7037673592567444, train/raw-loss = 0.7036659717559814, train/logprobs = tensor([[-0.9689, -0.8988],
        [-1.0545, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010139778023585677
Epoch 0, Step 799: train/loss = 0.7054567933082581, train/raw-loss = 0.7054364681243896, train/logprobs = tensor([[-1.1032, -1.1562],
        [-1.1451, -1.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020332509302534163
Epoch 0, Step 800: train/loss = 0.6984679102897644, train/raw-loss = 0.6981803178787231, train/logprobs = tensor([[-0.9618, -1.1500],
        [-1.1373, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002876423764973879
Epoch 0, Step 801: train/loss = 0.6938313841819763, train/raw-loss = 0.6937297582626343, train/logprobs = tensor([[-0.8248, -0.8391],
        [-0.8601, -0.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010162980761379004
Epoch 0, Step 802: train/loss = 0.726093053817749, train/raw-loss = 0.7260095477104187, train/logprobs = tensor([[-0.6863, -0.8311],
        [-0.8039, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008344484958797693
Epoch 0, Step 803: train/loss = 0.6949583292007446, train/raw-loss = 0.6949010491371155, train/logprobs = tensor([[-0.8151, -0.8064],
        [-0.8948, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005720726912841201
Epoch 0, Step 804: train/loss = 0.6960265636444092, train/raw-loss = 0.6958686709403992, train/logprobs = tensor([[-0.8323, -0.7827],
        [-0.9381, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015793782658874989
Epoch 0, Step 805: train/loss = 0.6986114978790283, train/raw-loss = 0.6985608339309692, train/logprobs = tensor([[-0.9407, -0.8664],
        [-0.9913, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005060003022663295
Epoch 0, Step 806: train/loss = 0.690305769443512, train/raw-loss = 0.6897393465042114, train/logprobs = tensor([[-1.0953, -1.1423],
        [-1.3358, -1.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005664506461471319
Epoch 0, Step 807: train/loss = 0.6946954727172852, train/raw-loss = 0.6946805715560913, train/logprobs = tensor([[-0.9349, -0.9101],
        [-1.1038, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014821189688518643
Epoch 0, Step 808: train/loss = 0.6931373476982117, train/raw-loss = 0.6929451823234558, train/logprobs = tensor([[-0.8274, -0.9305],
        [-0.9534, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019217501394450665
Epoch 0, Step 809: train/loss = 0.7033400535583496, train/raw-loss = 0.7032268047332764, train/logprobs = tensor([[-0.9866, -1.1762],
        [-1.1145, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011325808009132743
Epoch 0, Step 810: train/loss = 0.7119161486625671, train/raw-loss = 0.7115668654441833, train/logprobs = tensor([[-0.9563, -1.1286],
        [-1.0854, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003493001451715827
Epoch 0, Step 811: train/loss = 0.7136289477348328, train/raw-loss = 0.7133750915527344, train/logprobs = tensor([[-1.0920, -1.0967],
        [-1.1999, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025383501779288054
Epoch 0, Step 812: train/loss = 0.689126193523407, train/raw-loss = 0.6889151930809021, train/logprobs = tensor([[-0.9243, -0.9932],
        [-1.1911, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021100775338709354
Epoch 0, Step 813: train/loss = 0.6926814317703247, train/raw-loss = 0.6926640868186951, train/logprobs = tensor([[-0.8968, -0.9628],
        [-1.0274, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001733535318635404
Epoch 0, Step 814: train/loss = 0.7055724859237671, train/raw-loss = 0.7055705189704895, train/logprobs = tensor([[-0.9093, -1.0967],
        [-0.9879, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0153856894467026e-05
Epoch 0, Step 815: train/loss = 0.7137970924377441, train/raw-loss = 0.7131710648536682, train/logprobs = tensor([[-0.8614, -1.3569],
        [-0.9628, -1.2657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062605394050478935
Epoch 0, Step 816: train/loss = 0.6907696723937988, train/raw-loss = 0.6903784275054932, train/logprobs = tensor([[-0.9833, -1.1264],
        [-1.0890, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003912223968654871
Epoch 0, Step 817: train/loss = 0.6957318186759949, train/raw-loss = 0.6956867575645447, train/logprobs = tensor([[-0.9273, -1.1689],
        [-1.0745, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045078154653310776
Epoch 0, Step 818: train/loss = 0.716213047504425, train/raw-loss = 0.7161900997161865, train/logprobs = tensor([[-0.9420, -1.3061],
        [-0.9170, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022884662030264735
Epoch 0, Step 819: train/loss = 0.7096062302589417, train/raw-loss = 0.7095222473144531, train/logprobs = tensor([[-0.9872, -0.9250],
        [-1.1418, -0.9082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008397909696213901
Epoch 0, Step 820: train/loss = 0.6978126168251038, train/raw-loss = 0.6977799534797668, train/logprobs = tensor([[-0.8457, -0.6602],
        [-0.8641, -0.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032615356030873954
Epoch 0, Step 821: train/loss = 0.6965555548667908, train/raw-loss = 0.6962854862213135, train/logprobs = tensor([[-0.9457, -1.1202],
        [-1.0780, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027006648015230894
Epoch 0, Step 822: train/loss = 0.6991697549819946, train/raw-loss = 0.6990389823913574, train/logprobs = tensor([[-1.0915, -1.0742],
        [-1.1234, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013078663032501936
Epoch 0, Step 823: train/loss = 0.6933208703994751, train/raw-loss = 0.693084716796875, train/logprobs = tensor([[-0.7736, -0.7504],
        [-0.7557, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023617418482899666
Epoch 0, Step 824: train/loss = 0.7011939287185669, train/raw-loss = 0.7009509205818176, train/logprobs = tensor([[-0.8346, -1.0286],
        [-0.8933, -1.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024301609955728054
Epoch 0, Step 825: train/loss = 0.7372188568115234, train/raw-loss = 0.7368813753128052, train/logprobs = tensor([[-1.3112, -1.0037],
        [-1.4959, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033751640003174543
Epoch 0, Step 826: train/loss = 0.7160050868988037, train/raw-loss = 0.7158046960830688, train/logprobs = tensor([[-0.9302, -1.3832],
        [-1.0689, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020032720640301704
Epoch 0, Step 827: train/loss = 0.6980593800544739, train/raw-loss = 0.6980134844779968, train/logprobs = tensor([[-0.8104, -1.0354],
        [-0.8226, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004591259639710188
Epoch 0, Step 828: train/loss = 0.6990698575973511, train/raw-loss = 0.6988129615783691, train/logprobs = tensor([[-0.9069, -1.0635],
        [-1.1147, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025696405209600925
Epoch 0, Step 829: train/loss = 0.7361369132995605, train/raw-loss = 0.7359768748283386, train/logprobs = tensor([[-0.9968, -1.3264],
        [-1.0707, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016010338440537453
Epoch 0, Step 830: train/loss = 0.7142923474311829, train/raw-loss = 0.7139492630958557, train/logprobs = tensor([[-0.9285, -1.3748],
        [-1.2230, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034315185621380806
Epoch 0, Step 831: train/loss = 0.712261438369751, train/raw-loss = 0.7117910981178284, train/logprobs = tensor([[-0.9491, -0.9539],
        [-1.0563, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004703078884631395
Epoch 0, Step 832: train/loss = 0.6918284893035889, train/raw-loss = 0.6910433769226074, train/logprobs = tensor([[-0.9417, -1.0175],
        [-1.2440, -1.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007851873524487019
Epoch 0, Step 833: train/loss = 0.6962069272994995, train/raw-loss = 0.6961390972137451, train/logprobs = tensor([[-0.9519, -1.0776],
        [-1.1178, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006783962016925216
Epoch 0, Step 834: train/loss = 0.6965879797935486, train/raw-loss = 0.6964863538742065, train/logprobs = tensor([[-1.0251, -1.0187],
        [-1.1073, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010159856174141169
Epoch 0, Step 835: train/loss = 0.7027713060379028, train/raw-loss = 0.7024716734886169, train/logprobs = tensor([[-1.0480, -1.0532],
        [-1.2193, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029956514481455088
Epoch 0, Step 836: train/loss = 0.6936116218566895, train/raw-loss = 0.6935017704963684, train/logprobs = tensor([[-0.9580, -1.0623],
        [-1.0913, -1.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010980640072375536
Epoch 0, Step 837: train/loss = 0.6959900856018066, train/raw-loss = 0.6956727504730225, train/logprobs = tensor([[-0.8654, -1.1364],
        [-0.9631, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003173477714881301
Epoch 0, Step 838: train/loss = 0.6894639134407043, train/raw-loss = 0.687424898147583, train/logprobs = tensor([[-1.0117, -1.3447],
        [-1.1219, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020389460027217865
Epoch 0, Step 839: train/loss = 0.6978968977928162, train/raw-loss = 0.6977984309196472, train/logprobs = tensor([[-0.9788, -1.1666],
        [-1.1054, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000985392602160573
Epoch 0, Step 840: train/loss = 0.7624335289001465, train/raw-loss = 0.7619545459747314, train/logprobs = tensor([[-0.8356, -1.5333],
        [-0.9029, -1.4208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047903042286634445
Epoch 0, Step 841: train/loss = 0.7060268521308899, train/raw-loss = 0.7057353854179382, train/logprobs = tensor([[-0.8833, -1.1613],
        [-0.9888, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002914970740675926
Epoch 0, Step 842: train/loss = 0.6978520154953003, train/raw-loss = 0.6977862119674683, train/logprobs = tensor([[-0.9881, -0.9428],
        [-1.0293, -0.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000658295932225883
Epoch 0, Step 843: train/loss = 0.7053017616271973, train/raw-loss = 0.7050897479057312, train/logprobs = tensor([[-1.2425, -1.2930],
        [-1.4010, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021196675952523947
Epoch 0, Step 844: train/loss = 0.6934829950332642, train/raw-loss = 0.6934824585914612, train/logprobs = tensor([[-0.8145, -0.8727],
        [-0.8554, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.343463271856308e-06
Epoch 0, Step 845: train/loss = 0.6969363689422607, train/raw-loss = 0.6968081593513489, train/logprobs = tensor([[-1.0317, -1.0982],
        [-1.1067, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001282116980291903
Epoch 0, Step 846: train/loss = 0.6988463997840881, train/raw-loss = 0.6987758874893188, train/logprobs = tensor([[-0.8786, -1.2154],
        [-0.9455, -1.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007053019944578409
Epoch 0, Step 847: train/loss = 0.6972986459732056, train/raw-loss = 0.697290301322937, train/logprobs = tensor([[-0.9914, -0.8704],
        [-1.0635, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.425675332546234e-05
Epoch 0, Step 848: train/loss = 0.7279748320579529, train/raw-loss = 0.7279504537582397, train/logprobs = tensor([[-1.0700, -0.9003],
        [-1.1660, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002431746106594801
Epoch 0, Step 849: train/loss = 0.7071400284767151, train/raw-loss = 0.706713080406189, train/logprobs = tensor([[-0.9541, -1.1816],
        [-1.0730, -1.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042695049196481705
Epoch 0, Step 850: train/loss = 0.6907358765602112, train/raw-loss = 0.6905485391616821, train/logprobs = tensor([[-0.7513, -0.8138],
        [-0.9044, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001873453613370657
Epoch 0, Step 851: train/loss = 0.7084055542945862, train/raw-loss = 0.7082583904266357, train/logprobs = tensor([[-0.9686, -1.0213],
        [-1.1686, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014711704570800066
Epoch 0, Step 852: train/loss = 0.6920487880706787, train/raw-loss = 0.6917866468429565, train/logprobs = tensor([[-1.1810, -1.2790],
        [-1.0589, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002621358260512352
Epoch 0, Step 853: train/loss = 0.7024333477020264, train/raw-loss = 0.7018837928771973, train/logprobs = tensor([[-0.7396, -1.0787],
        [-0.9111, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005494999699294567
Epoch 0, Step 854: train/loss = 0.7041724920272827, train/raw-loss = 0.7041270136833191, train/logprobs = tensor([[-1.0525, -0.9015],
        [-1.1178, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004547338467091322
Epoch 0, Step 855: train/loss = 0.7108079195022583, train/raw-loss = 0.7107983827590942, train/logprobs = tensor([[-1.2135, -0.9961],
        [-1.1815, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.481661254540086e-05
Epoch 0, Step 856: train/loss = 0.7054175734519958, train/raw-loss = 0.7052228450775146, train/logprobs = tensor([[-0.9657, -1.1849],
        [-1.0691, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019469495164230466
Epoch 0, Step 857: train/loss = 0.6966943740844727, train/raw-loss = 0.6966736316680908, train/logprobs = tensor([[-0.8054, -0.8933],
        [-0.8710, -0.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020713065168820322
Epoch 0, Step 858: train/loss = 0.6960399746894836, train/raw-loss = 0.6956273317337036, train/logprobs = tensor([[-0.9084, -1.0411],
        [-1.0731, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004126368090510368
Epoch 0, Step 859: train/loss = 0.6993829011917114, train/raw-loss = 0.699359118938446, train/logprobs = tensor([[-0.9658, -0.9785],
        [-0.9544, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002381521771894768
Epoch 0, Step 860: train/loss = 0.687505841255188, train/raw-loss = 0.6861046552658081, train/logprobs = tensor([[-0.8070, -1.4509],
        [-0.8854, -0.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014011522755026817
Epoch 0, Step 861: train/loss = 0.7211778163909912, train/raw-loss = 0.7211053967475891, train/logprobs = tensor([[-0.9110, -1.0370],
        [-0.9804, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007244290318340063
Epoch 0, Step 862: train/loss = 0.6901080012321472, train/raw-loss = 0.6899024248123169, train/logprobs = tensor([[-1.0181, -1.1378],
        [-1.2354, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020553192589432
Epoch 0, Step 863: train/loss = 0.7008965611457825, train/raw-loss = 0.7003719210624695, train/logprobs = tensor([[-1.1825, -1.0998],
        [-1.3622, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052459584549069405
Epoch 0, Step 864: train/loss = 0.7329286336898804, train/raw-loss = 0.7327975630760193, train/logprobs = tensor([[-1.0413, -1.4620],
        [-1.1056, -1.3271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013103180099278688
Epoch 0, Step 865: train/loss = 0.6972866058349609, train/raw-loss = 0.6971345543861389, train/logprobs = tensor([[-0.9369, -1.0632],
        [-1.1059, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015210328856483102
Epoch 0, Step 866: train/loss = 0.7014061808586121, train/raw-loss = 0.7013006210327148, train/logprobs = tensor([[-0.8653, -0.9372],
        [-1.0073, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010563605464994907
Epoch 0, Step 867: train/loss = 0.7117751836776733, train/raw-loss = 0.7111444473266602, train/logprobs = tensor([[-0.7997, -1.4674],
        [-0.9380, -1.1888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006308137439191341
Epoch 0, Step 868: train/loss = 0.7153627276420593, train/raw-loss = 0.7152602076530457, train/logprobs = tensor([[-1.1941, -1.1729],
        [-1.2287, -1.0036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010253996588289738
Epoch 0, Step 869: train/loss = 0.6990194320678711, train/raw-loss = 0.698990523815155, train/logprobs = tensor([[-0.9262, -0.9876],
        [-0.9731, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002889764728024602
Epoch 0, Step 870: train/loss = 0.6975531578063965, train/raw-loss = 0.6975167393684387, train/logprobs = tensor([[-0.8074, -0.8405],
        [-0.8876, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003635674365796149
Epoch 0, Step 871: train/loss = 0.7334485054016113, train/raw-loss = 0.7331092357635498, train/logprobs = tensor([[-1.0048, -1.3677],
        [-1.1765, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003392456565052271
Epoch 0, Step 872: train/loss = 0.693316638469696, train/raw-loss = 0.6932990550994873, train/logprobs = tensor([[-1.0100, -1.1227],
        [-0.9842, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017488666344434023
Epoch 0, Step 873: train/loss = 0.7128669023513794, train/raw-loss = 0.712793231010437, train/logprobs = tensor([[-1.0261, -1.0990],
        [-1.1913, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007368257502093911
Epoch 0, Step 874: train/loss = 0.690671980381012, train/raw-loss = 0.690605103969574, train/logprobs = tensor([[-1.0756, -1.3028],
        [-1.1744, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006691835587844253
Epoch 0, Step 875: train/loss = 0.6989114284515381, train/raw-loss = 0.6979485154151917, train/logprobs = tensor([[-1.0021, -1.3120],
        [-0.9516, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009628747589886189
Epoch 0, Step 876: train/loss = 0.6987029314041138, train/raw-loss = 0.6985619068145752, train/logprobs = tensor([[-1.0030, -1.1083],
        [-1.1318, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014096696395426989
Epoch 0, Step 877: train/loss = 0.7234110832214355, train/raw-loss = 0.7232376337051392, train/logprobs = tensor([[-0.7443, -1.0289],
        [-0.8579, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001734958030283451
Epoch 0, Step 878: train/loss = 0.7124363780021667, train/raw-loss = 0.7119066715240479, train/logprobs = tensor([[-0.9988, -1.4012],
        [-1.1218, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005297353491187096
Epoch 0, Step 879: train/loss = 0.7043867111206055, train/raw-loss = 0.7042959928512573, train/logprobs = tensor([[-0.8188, -1.0986],
        [-0.9216, -1.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009073601686395705
Epoch 0, Step 880: train/loss = 0.7028278112411499, train/raw-loss = 0.7027496695518494, train/logprobs = tensor([[-1.0932, -0.9387],
        [-1.2464, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007814086275175214
Epoch 0, Step 881: train/loss = 0.6990841031074524, train/raw-loss = 0.6990572810173035, train/logprobs = tensor([[-0.9527, -0.9885],
        [-1.0525, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000268161587882787
Epoch 0, Step 882: train/loss = 0.7134495973587036, train/raw-loss = 0.7134082317352295, train/logprobs = tensor([[-0.9421, -1.3348],
        [-0.9096, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004135822819080204
Epoch 0, Step 883: train/loss = 0.7008518576622009, train/raw-loss = 0.7007262706756592, train/logprobs = tensor([[-0.8209, -1.0541],
        [-0.9511, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012551223626360297
Epoch 0, Step 884: train/loss = 0.6944662928581238, train/raw-loss = 0.6941482424736023, train/logprobs = tensor([[-0.9301, -1.1376],
        [-1.0026, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031800135038793087
Epoch 0, Step 885: train/loss = 0.6989437341690063, train/raw-loss = 0.698722243309021, train/logprobs = tensor([[-0.9101, -1.1691],
        [-1.1215, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022147921845316887
Epoch 0, Step 886: train/loss = 0.7124876976013184, train/raw-loss = 0.7122142910957336, train/logprobs = tensor([[-0.7022, -1.1477],
        [-0.7580, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027334606274962425
Epoch 0, Step 887: train/loss = 0.7763127684593201, train/raw-loss = 0.7761580944061279, train/logprobs = tensor([[-1.0682, -1.5406],
        [-1.2334, -1.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015471047954633832
Epoch 0, Step 888: train/loss = 0.6906483173370361, train/raw-loss = 0.6902323961257935, train/logprobs = tensor([[-0.8539, -1.1746],
        [-0.9943, -0.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004159395582973957
Epoch 0, Step 889: train/loss = 0.7144250869750977, train/raw-loss = 0.7142376899719238, train/logprobs = tensor([[-0.8844, -0.7513],
        [-1.0642, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00187409739010036
Epoch 0, Step 890: train/loss = 0.6882071495056152, train/raw-loss = 0.6873176097869873, train/logprobs = tensor([[-1.1277, -1.2269],
        [-1.3081, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008895974606275558
Epoch 0, Step 891: train/loss = 0.7122979164123535, train/raw-loss = 0.7119715809822083, train/logprobs = tensor([[-0.9756, -1.0155],
        [-1.1297, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032632993534207344
Epoch 0, Step 892: train/loss = 0.7224659323692322, train/raw-loss = 0.721710741519928, train/logprobs = tensor([[-1.3326, -1.2441],
        [-1.8515, -1.1755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007551403716206551
Epoch 0, Step 893: train/loss = 0.6948597431182861, train/raw-loss = 0.6947582960128784, train/logprobs = tensor([[-0.8554, -0.8961],
        [-0.9053, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010147247230634093
Epoch 0, Step 894: train/loss = 0.6957964897155762, train/raw-loss = 0.695758581161499, train/logprobs = tensor([[-0.7413, -0.8011],
        [-0.8103, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037807924672961235
Epoch 0, Step 895: train/loss = 0.7036739587783813, train/raw-loss = 0.7033457159996033, train/logprobs = tensor([[-1.1592, -1.3548],
        [-1.1217, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032825451344251633
Epoch 0, Step 896: train/loss = 0.6992504596710205, train/raw-loss = 0.6989721059799194, train/logprobs = tensor([[-1.0161, -1.0310],
        [-1.1390, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027834605425596237
Epoch 0, Step 897: train/loss = 0.7099595069885254, train/raw-loss = 0.7098502516746521, train/logprobs = tensor([[-0.9842, -0.7499],
        [-1.0610, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010928171686828136
Epoch 0, Step 898: train/loss = 0.6994735598564148, train/raw-loss = 0.6993849873542786, train/logprobs = tensor([[-0.8856, -0.9355],
        [-1.2450, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008853601175360382
Epoch 0, Step 899: train/loss = 0.6955069303512573, train/raw-loss = 0.6949001550674438, train/logprobs = tensor([[-0.9129, -0.8630],
        [-1.1856, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060665188357234
Epoch 0, Step 900: train/loss = 0.6935586929321289, train/raw-loss = 0.6929589509963989, train/logprobs = tensor([[-0.7499, -0.9405],
        [-0.8438, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005997782573103905
Epoch 0, Step 901: train/loss = 0.7005329132080078, train/raw-loss = 0.7005254030227661, train/logprobs = tensor([[-1.0178, -0.9880],
        [-1.1702, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.541000377386808e-05
Epoch 0, Step 902: train/loss = 0.7097220420837402, train/raw-loss = 0.7088432312011719, train/logprobs = tensor([[-1.0026, -1.5410],
        [-1.0923, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008788542822003365
Epoch 0, Step 903: train/loss = 0.7028934955596924, train/raw-loss = 0.7017601728439331, train/logprobs = tensor([[-1.0961, -1.1503],
        [-1.1578, -1.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011332799680531025
Epoch 0, Step 904: train/loss = 0.6968830227851868, train/raw-loss = 0.6966978311538696, train/logprobs = tensor([[-1.0380, -1.2300],
        [-1.2143, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018519393634051085
Epoch 0, Step 905: train/loss = 0.6978886127471924, train/raw-loss = 0.6978800296783447, train/logprobs = tensor([[-0.9073, -0.8377],
        [-0.9072, -0.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.534459630027413e-05
Epoch 0, Step 906: train/loss = 0.6915643215179443, train/raw-loss = 0.6910517811775208, train/logprobs = tensor([[-0.9476, -1.0986],
        [-1.1405, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005125289782881737
Epoch 0, Step 907: train/loss = 0.6923694610595703, train/raw-loss = 0.6921432018280029, train/logprobs = tensor([[-0.8472, -1.0018],
        [-0.9674, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022632149048149586
Epoch 0, Step 908: train/loss = 0.6985504627227783, train/raw-loss = 0.6981145143508911, train/logprobs = tensor([[-0.8880, -1.0431],
        [-0.9086, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00435965321958065
Epoch 0, Step 909: train/loss = 0.7035418152809143, train/raw-loss = 0.7034738063812256, train/logprobs = tensor([[-1.0537, -1.3235],
        [-1.2145, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006804428994655609
Epoch 0, Step 910: train/loss = 0.7002569437026978, train/raw-loss = 0.7001701593399048, train/logprobs = tensor([[-1.0307, -1.2362],
        [-0.9925, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008681573672220111
Epoch 0, Step 911: train/loss = 0.6925802230834961, train/raw-loss = 0.6925121545791626, train/logprobs = tensor([[-1.0036, -1.0227],
        [-0.9828, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000681016594171524
Epoch 0, Step 912: train/loss = 0.6934676170349121, train/raw-loss = 0.6931853294372559, train/logprobs = tensor([[-1.1367, -1.1944],
        [-1.2183, -1.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028226422145962715
Epoch 0, Step 913: train/loss = 0.693790078163147, train/raw-loss = 0.6934664845466614, train/logprobs = tensor([[-1.0788, -1.0872],
        [-1.2682, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003236480988562107
Epoch 0, Step 914: train/loss = 0.6944252848625183, train/raw-loss = 0.6944136023521423, train/logprobs = tensor([[-0.9186, -0.9811],
        [-0.9384, -0.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011663555051200092
Epoch 0, Step 915: train/loss = 0.6925259828567505, train/raw-loss = 0.691879153251648, train/logprobs = tensor([[-0.8252, -1.1639],
        [-0.9638, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00646849162876606
Epoch 0, Step 916: train/loss = 0.6939127445220947, train/raw-loss = 0.6936851739883423, train/logprobs = tensor([[-0.9489, -1.0220],
        [-1.0336, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022749733179807663
Epoch 0, Step 917: train/loss = 0.6886695623397827, train/raw-loss = 0.6884734630584717, train/logprobs = tensor([[-0.8652, -1.0128],
        [-1.1831, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019609923474490643
Epoch 0, Step 918: train/loss = 0.6985888481140137, train/raw-loss = 0.6977423429489136, train/logprobs = tensor([[-0.9147, -1.0861],
        [-1.1032, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008464938960969448
Epoch 0, Step 919: train/loss = 0.7308976650238037, train/raw-loss = 0.7306073904037476, train/logprobs = tensor([[-0.9575, -0.7704],
        [-1.2511, -0.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002903274493291974
Epoch 0, Step 920: train/loss = 0.7640158534049988, train/raw-loss = 0.7635003328323364, train/logprobs = tensor([[-1.1238, -1.7118],
        [-1.1368, -1.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0051557449623942375
Epoch 0, Step 921: train/loss = 0.7127953767776489, train/raw-loss = 0.7125163078308105, train/logprobs = tensor([[-0.9112, -1.0443],
        [-0.9308, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027905916795134544
Epoch 0, Step 922: train/loss = 0.7136263251304626, train/raw-loss = 0.7132857441902161, train/logprobs = tensor([[-1.0608, -1.3212],
        [-1.1580, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034061120823025703
Epoch 0, Step 923: train/loss = 0.7211775183677673, train/raw-loss = 0.7201396822929382, train/logprobs = tensor([[-0.9119, -1.4793],
        [-1.1095, -1.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010377817787230015
Epoch 0, Step 924: train/loss = 0.6999325156211853, train/raw-loss = 0.6996736526489258, train/logprobs = tensor([[-1.0517, -0.9207],
        [-1.0236, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025878555607050657
Epoch 0, Step 925: train/loss = 0.6970750093460083, train/raw-loss = 0.697053849697113, train/logprobs = tensor([[-1.0712, -1.0344],
        [-0.9520, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021137390285730362
Epoch 0, Step 926: train/loss = 0.699428379535675, train/raw-loss = 0.6992424726486206, train/logprobs = tensor([[-0.9224, -1.1936],
        [-1.0639, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018586544319987297
Epoch 0, Step 927: train/loss = 0.702932596206665, train/raw-loss = 0.7027494311332703, train/logprobs = tensor([[-1.0931, -1.0088],
        [-1.2765, -1.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018314460758119822
Epoch 0, Step 928: train/loss = 0.701957643032074, train/raw-loss = 0.7013720273971558, train/logprobs = tensor([[-0.9091, -1.0418],
        [-1.0422, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005855507683008909
Epoch 0, Step 929: train/loss = 0.7007063031196594, train/raw-loss = 0.7005386352539062, train/logprobs = tensor([[-1.1129, -1.3354],
        [-0.9956, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016771528171375394
Epoch 0, Step 930: train/loss = 0.7324665188789368, train/raw-loss = 0.7320806980133057, train/logprobs = tensor([[-0.8740, -1.3918],
        [-0.9860, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038577127270400524
Epoch 0, Step 931: train/loss = 0.7007521986961365, train/raw-loss = 0.7005746364593506, train/logprobs = tensor([[-0.7287, -1.0841],
        [-0.8478, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017746305093169212
Epoch 0, Step 932: train/loss = 0.7059114575386047, train/raw-loss = 0.7056450247764587, train/logprobs = tensor([[-0.9054, -1.3222],
        [-0.9745, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026640344876796007
Epoch 0, Step 933: train/loss = 0.6951578855514526, train/raw-loss = 0.69492107629776, train/logprobs = tensor([[-1.0413, -1.3966],
        [-1.0095, -1.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002368025714531541
Epoch 0, Step 934: train/loss = 0.698763370513916, train/raw-loss = 0.6984831690788269, train/logprobs = tensor([[-0.7263, -0.9035],
        [-0.8548, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028025545179843903
Epoch 0, Step 935: train/loss = 0.7079152464866638, train/raw-loss = 0.7077364325523376, train/logprobs = tensor([[-1.0018, -0.9359],
        [-1.0686, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017884026747196913
Epoch 0, Step 936: train/loss = 0.7033886909484863, train/raw-loss = 0.7028785943984985, train/logprobs = tensor([[-1.2233, -1.1429],
        [-1.3758, -0.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0051015946082770824
Epoch 0, Step 937: train/loss = 0.725894033908844, train/raw-loss = 0.7258004546165466, train/logprobs = tensor([[-0.9212, -1.2117],
        [-0.9890, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009353186469525099
Epoch 0, Step 938: train/loss = 0.7039861679077148, train/raw-loss = 0.7036635875701904, train/logprobs = tensor([[-0.9429, -0.8973],
        [-0.9873, -0.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032256166450679302
Epoch 0, Step 939: train/loss = 0.7018277049064636, train/raw-loss = 0.701675534248352, train/logprobs = tensor([[-0.9229, -1.1223],
        [-1.0314, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015215490711852908
Epoch 0, Step 940: train/loss = 0.7134806513786316, train/raw-loss = 0.7121425867080688, train/logprobs = tensor([[-1.0294, -1.4919],
        [-1.2918, -1.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01338098756968975
Epoch 0, Step 941: train/loss = 0.6927908658981323, train/raw-loss = 0.6926658153533936, train/logprobs = tensor([[-1.0870, -1.2133],
        [-1.1203, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012510372325778008
Epoch 0, Step 942: train/loss = 0.6938962936401367, train/raw-loss = 0.6938734650611877, train/logprobs = tensor([[-0.7078, -0.8416],
        [-0.7374, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022839196026325226
Epoch 0, Step 943: train/loss = 0.7146292924880981, train/raw-loss = 0.7139982581138611, train/logprobs = tensor([[-1.0743, -1.0947],
        [-1.2205, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006309492513537407
Epoch 0, Step 944: train/loss = 0.702888011932373, train/raw-loss = 0.7028367519378662, train/logprobs = tensor([[-1.1413, -1.5251],
        [-1.2498, -1.3700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005125755560584366
Epoch 0, Step 945: train/loss = 0.6969172954559326, train/raw-loss = 0.696710467338562, train/logprobs = tensor([[-0.9085, -1.1251],
        [-0.9505, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020688248332589865
Epoch 0, Step 946: train/loss = 0.7152009010314941, train/raw-loss = 0.7150166034698486, train/logprobs = tensor([[-0.9254, -1.1515],
        [-0.9842, -1.0542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001843297271989286
Epoch 0, Step 947: train/loss = 0.6947098970413208, train/raw-loss = 0.6946964263916016, train/logprobs = tensor([[-0.9360, -0.8986],
        [-1.0633, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013458510511554778
Epoch 0, Step 948: train/loss = 0.6932755708694458, train/raw-loss = 0.6931729912757874, train/logprobs = tensor([[-0.9708, -1.0380],
        [-0.9775, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010256899986416101
Epoch 0, Step 949: train/loss = 0.7020106315612793, train/raw-loss = 0.7018705010414124, train/logprobs = tensor([[-0.8897, -0.8315],
        [-0.9828, -0.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014014068292453885
Epoch 0, Step 950: train/loss = 0.6934927701950073, train/raw-loss = 0.6934182643890381, train/logprobs = tensor([[-0.7967, -0.7693],
        [-1.0057, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007445335504598916
Epoch 0, Step 951: train/loss = 0.7203606963157654, train/raw-loss = 0.7201444506645203, train/logprobs = tensor([[-1.2690, -1.5330],
        [-1.1259, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002161933109164238
Epoch 0, Step 952: train/loss = 0.7279318571090698, train/raw-loss = 0.7276552319526672, train/logprobs = tensor([[-0.8159, -1.2190],
        [-0.8704, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002766008721664548
Epoch 0, Step 953: train/loss = 0.735153079032898, train/raw-loss = 0.7350768446922302, train/logprobs = tensor([[-0.9878, -1.3159],
        [-1.0098, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007625801372341812
Epoch 0, Step 954: train/loss = 0.690601646900177, train/raw-loss = 0.6899113655090332, train/logprobs = tensor([[-0.8764, -1.0558],
        [-1.0297, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006902629975229502
Epoch 0, Step 955: train/loss = 0.6913994550704956, train/raw-loss = 0.6910584568977356, train/logprobs = tensor([[-0.9213, -0.9807],
        [-1.1283, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003409254364669323
Epoch 0, Step 956: train/loss = 0.6953274011611938, train/raw-loss = 0.6949027180671692, train/logprobs = tensor([[-0.7197, -1.0306],
        [-0.9264, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004247217904776335
Epoch 0, Step 957: train/loss = 0.6927083730697632, train/raw-loss = 0.6918459534645081, train/logprobs = tensor([[-0.8763, -1.3103],
        [-1.0390, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008624052628874779
Epoch 0, Step 958: train/loss = 0.7098053097724915, train/raw-loss = 0.7096361517906189, train/logprobs = tensor([[-0.9139, -1.1453],
        [-0.9696, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016910691047087312
Epoch 0, Step 959: train/loss = 0.7063596248626709, train/raw-loss = 0.7060787677764893, train/logprobs = tensor([[-0.9665, -0.8967],
        [-1.1549, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028081219643354416
Epoch 0, Step 960: train/loss = 0.7205126285552979, train/raw-loss = 0.7202700972557068, train/logprobs = tensor([[-0.8834, -1.2732],
        [-0.9389, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024254033342003822
Epoch 0, Step 961: train/loss = 0.6961769461631775, train/raw-loss = 0.6960829496383667, train/logprobs = tensor([[-1.0713, -1.2226],
        [-0.9767, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009399235714226961
Epoch 0, Step 962: train/loss = 0.708727240562439, train/raw-loss = 0.7073571681976318, train/logprobs = tensor([[-0.9504, -1.4660],
        [-0.9115, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013700923882424831
Epoch 0, Step 963: train/loss = 0.7117820382118225, train/raw-loss = 0.7114096879959106, train/logprobs = tensor([[-0.8105, -0.8484],
        [-0.9170, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037231759633868933
Epoch 0, Step 964: train/loss = 0.7129532098770142, train/raw-loss = 0.7128880023956299, train/logprobs = tensor([[-1.1043, -1.3498],
        [-0.9149, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006526447832584381
Epoch 0, Step 965: train/loss = 0.6943655014038086, train/raw-loss = 0.6943138837814331, train/logprobs = tensor([[-0.8946, -0.9972],
        [-1.0446, -1.0603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005156788975000381
Epoch 0, Step 966: train/loss = 0.6918120384216309, train/raw-loss = 0.6913285255432129, train/logprobs = tensor([[-0.9841, -1.0716],
        [-1.1298, -0.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004834936931729317
Epoch 0, Step 967: train/loss = 0.6995424628257751, train/raw-loss = 0.6993882656097412, train/logprobs = tensor([[-0.9467, -1.1054],
        [-1.1083, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015420146519318223
Epoch 0, Step 968: train/loss = 0.6942803859710693, train/raw-loss = 0.6942569017410278, train/logprobs = tensor([[-0.7901, -0.7232],
        [-0.8924, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002345407847315073
Epoch 0, Step 969: train/loss = 0.6892824172973633, train/raw-loss = 0.6850239038467407, train/logprobs = tensor([[-0.8576, -1.3179],
        [-1.0293, -0.9919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04258494824171066
Epoch 0, Step 970: train/loss = 0.6940309405326843, train/raw-loss = 0.6939520835876465, train/logprobs = tensor([[-0.9530, -1.0573],
        [-0.9618, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007883042562752962
Epoch 0, Step 971: train/loss = 0.7299723625183105, train/raw-loss = 0.7297122478485107, train/logprobs = tensor([[-0.8776, -0.9169],
        [-1.0169, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026015257462859154
Epoch 0, Step 972: train/loss = 0.7422288656234741, train/raw-loss = 0.7413954734802246, train/logprobs = tensor([[-1.2374, -1.2244],
        [-1.4658, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008334394544363022
Epoch 0, Step 973: train/loss = 0.6941672563552856, train/raw-loss = 0.6941578388214111, train/logprobs = tensor([[-0.9002, -0.8951],
        [-0.9018, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.445699106436223e-05
Epoch 0, Step 974: train/loss = 0.7054697871208191, train/raw-loss = 0.7054162621498108, train/logprobs = tensor([[-0.9897, -1.1568],
        [-0.9355, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005354993045330048
Epoch 0, Step 975: train/loss = 0.6921937465667725, train/raw-loss = 0.6921254396438599, train/logprobs = tensor([[-1.1292, -1.1878],
        [-1.2398, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006828633486293256
Epoch 0, Step 976: train/loss = 0.695955216884613, train/raw-loss = 0.6957917213439941, train/logprobs = tensor([[-1.1062, -1.2367],
        [-1.2017, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001635305816307664
Epoch 0, Step 977: train/loss = 0.7002933025360107, train/raw-loss = 0.7001843452453613, train/logprobs = tensor([[-1.2090, -1.1925],
        [-1.1574, -1.0170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010900248307734728
Epoch 0, Step 978: train/loss = 0.7032238841056824, train/raw-loss = 0.7026557922363281, train/logprobs = tensor([[-1.1545, -1.5658],
        [-1.2286, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005680419504642487
Epoch 0, Step 979: train/loss = 0.6966911554336548, train/raw-loss = 0.6963561773300171, train/logprobs = tensor([[-1.0426, -1.3179],
        [-1.1285, -1.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033493945375084877
Epoch 0, Step 980: train/loss = 0.6921244263648987, train/raw-loss = 0.6913707256317139, train/logprobs = tensor([[-0.9351, -1.7454],
        [-1.0889, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007536656688898802
Epoch 0, Step 981: train/loss = 0.6975089311599731, train/raw-loss = 0.6975086331367493, train/logprobs = tensor([[-0.8119, -0.9282],
        [-0.7425, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6603014450520277e-06
Epoch 0, Step 982: train/loss = 0.6999629735946655, train/raw-loss = 0.6989569067955017, train/logprobs = tensor([[-1.0131, -1.5172],
        [-1.1287, -1.2245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010060349479317665
Epoch 0, Step 983: train/loss = 0.6941365003585815, train/raw-loss = 0.6921005249023438, train/logprobs = tensor([[-0.9894, -1.4297],
        [-1.0693, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020359419286251068
Epoch 0, Step 984: train/loss = 0.6906572580337524, train/raw-loss = 0.6902561783790588, train/logprobs = tensor([[-0.8720, -1.2985],
        [-0.9594, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004011171404272318
Epoch 0, Step 985: train/loss = 0.6899351477622986, train/raw-loss = 0.6893959045410156, train/logprobs = tensor([[-0.9898, -1.1624],
        [-1.1153, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005393079482018948
Epoch 0, Step 986: train/loss = 0.7023239731788635, train/raw-loss = 0.7022653818130493, train/logprobs = tensor([[-0.9439, -1.1518],
        [-0.9612, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005861480021849275
Epoch 0, Step 987: train/loss = 0.7107425928115845, train/raw-loss = 0.7104899883270264, train/logprobs = tensor([[-0.9513, -0.8008],
        [-1.2483, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025270197074860334
Epoch 0, Step 988: train/loss = 0.688705563545227, train/raw-loss = 0.6848888397216797, train/logprobs = tensor([[-1.0461, -1.8169],
        [-1.3409, -1.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038167163729667664
Epoch 0, Step 989: train/loss = 0.7021243572235107, train/raw-loss = 0.7020592093467712, train/logprobs = tensor([[-0.9166, -0.8237],
        [-1.0301, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006521643372252584
Epoch 0, Step 990: train/loss = 0.7037131786346436, train/raw-loss = 0.7036489248275757, train/logprobs = tensor([[-1.2696, -1.1183],
        [-1.1283, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006426316685974598
Epoch 0, Step 991: train/loss = 0.6987857222557068, train/raw-loss = 0.6986531615257263, train/logprobs = tensor([[-1.0566, -1.1368],
        [-1.1115, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001325617078691721
Epoch 0, Step 992: train/loss = 0.6912062168121338, train/raw-loss = 0.6909339427947998, train/logprobs = tensor([[-0.9393, -1.0300],
        [-0.9211, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002723026555031538
Epoch 0, Step 993: train/loss = 0.706106424331665, train/raw-loss = 0.7060434222221375, train/logprobs = tensor([[-1.0976, -1.0514],
        [-1.0338, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000629906659014523
Epoch 0, Step 994: train/loss = 0.7173888683319092, train/raw-loss = 0.7173154354095459, train/logprobs = tensor([[-0.9787, -0.6809],
        [-1.1118, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007337667047977448
Epoch 0, Step 995: train/loss = 0.6986583471298218, train/raw-loss = 0.6983922123908997, train/logprobs = tensor([[-0.7487, -0.9949],
        [-0.9121, -0.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026607783511281013
Epoch 0, Step 996: train/loss = 0.6882350444793701, train/raw-loss = 0.6872650384902954, train/logprobs = tensor([[-0.9958, -1.1992],
        [-1.1671, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009699959307909012
Epoch 0, Step 997: train/loss = 0.6920157670974731, train/raw-loss = 0.6905525922775269, train/logprobs = tensor([[-1.0984, -1.1912],
        [-1.3971, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014632168225944042
Epoch 0, Step 998: train/loss = 0.6951459646224976, train/raw-loss = 0.6950924396514893, train/logprobs = tensor([[-0.9806, -1.0381],
        [-1.0734, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000534852733835578
Epoch 0, Step 999: train/loss = 0.700485348701477, train/raw-loss = 0.6977479457855225, train/logprobs = tensor([[-0.9965, -1.5955],
        [-1.1129, -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027374066412448883
eval/loss: 0.7025941610336304
Epoch 0, Step 1000: train/loss = 0.6961169838905334, train/raw-loss = 0.6957054138183594, train/logprobs = tensor([[-1.1322, -1.2293],
        [-1.2259, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004115713760256767
Epoch 0, Step 1001: train/loss = 0.6912745833396912, train/raw-loss = 0.6904560327529907, train/logprobs = tensor([[-0.8194, -1.1280],
        [-0.9592, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008184514939785004
Epoch 0, Step 1002: train/loss = 0.6935946345329285, train/raw-loss = 0.693537712097168, train/logprobs = tensor([[-1.1959, -1.2011],
        [-0.9362, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005693603307008743
Epoch 0, Step 1003: train/loss = 0.6945179104804993, train/raw-loss = 0.6943770051002502, train/logprobs = tensor([[-1.3241, -1.3024],
        [-1.2911, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014090545009821653
Epoch 0, Step 1004: train/loss = 0.7315114736557007, train/raw-loss = 0.7311548590660095, train/logprobs = tensor([[-1.1747, -1.2570],
        [-1.1846, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003566008061170578
Epoch 0, Step 1005: train/loss = 0.7048254013061523, train/raw-loss = 0.7046565413475037, train/logprobs = tensor([[-0.9262, -1.3912],
        [-1.0195, -1.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001688277698121965
Epoch 0, Step 1006: train/loss = 0.693605899810791, train/raw-loss = 0.6935304403305054, train/logprobs = tensor([[-0.9534, -1.0940],
        [-0.9012, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000754767213948071
Epoch 0, Step 1007: train/loss = 0.8268711566925049, train/raw-loss = 0.8215620517730713, train/logprobs = tensor([[-1.0378, -2.4164],
        [-1.0778, -1.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05309135466814041
Epoch 0, Step 1008: train/loss = 0.6956546902656555, train/raw-loss = 0.6954572200775146, train/logprobs = tensor([[-0.8634, -1.0018],
        [-0.9545, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001974881626665592
Epoch 0, Step 1009: train/loss = 0.6947750449180603, train/raw-loss = 0.6947572231292725, train/logprobs = tensor([[-0.9923, -0.9949],
        [-0.9879, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001777226570993662
Epoch 0, Step 1010: train/loss = 0.6909030079841614, train/raw-loss = 0.6906557083129883, train/logprobs = tensor([[-1.0284, -1.1468],
        [-1.0029, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024723978713154793
Epoch 0, Step 1011: train/loss = 0.6945832967758179, train/raw-loss = 0.6944798827171326, train/logprobs = tensor([[-1.0658, -1.0536],
        [-1.3326, -1.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010342032182961702
Epoch 0, Step 1012: train/loss = 0.6937414407730103, train/raw-loss = 0.6926460862159729, train/logprobs = tensor([[-0.8457, -1.1471],
        [-0.9773, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010953707620501518
Epoch 0, Step 1013: train/loss = 0.7001988887786865, train/raw-loss = 0.699446439743042, train/logprobs = tensor([[-0.8401, -1.1120],
        [-0.9694, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007524420507252216
Epoch 0, Step 1014: train/loss = 0.6986343264579773, train/raw-loss = 0.698405385017395, train/logprobs = tensor([[-0.9550, -0.9417],
        [-0.9399, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022890279069542885
Epoch 0, Step 1015: train/loss = 0.6957027912139893, train/raw-loss = 0.6956720352172852, train/logprobs = tensor([[-0.9925, -1.0437],
        [-1.0464, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003077136934734881
Epoch 0, Step 1016: train/loss = 0.6922230124473572, train/raw-loss = 0.6911948919296265, train/logprobs = tensor([[-1.2886, -1.5290],
        [-1.2365, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010282270610332489
Epoch 0, Step 1017: train/loss = 0.6949458122253418, train/raw-loss = 0.6948987245559692, train/logprobs = tensor([[-1.0011, -1.0260],
        [-0.8316, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004704654566012323
Epoch 0, Step 1018: train/loss = 0.6926743984222412, train/raw-loss = 0.6922858357429504, train/logprobs = tensor([[-1.0443, -1.0849],
        [-1.3102, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038855925668030977
Epoch 0, Step 1019: train/loss = 0.7176563739776611, train/raw-loss = 0.7175787091255188, train/logprobs = tensor([[-1.0951, -0.9350],
        [-1.2320, -0.8901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007768251816742122
Epoch 0, Step 1020: train/loss = 0.6936435699462891, train/raw-loss = 0.692392110824585, train/logprobs = tensor([[-1.1276, -1.4909],
        [-1.2461, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01251486036926508
Epoch 0, Step 1021: train/loss = 0.6816396713256836, train/raw-loss = 0.6809269785881042, train/logprobs = tensor([[-0.9166, -1.2953],
        [-1.0940, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007127705030143261
Epoch 0, Step 1022: train/loss = 0.6939651966094971, train/raw-loss = 0.6926547288894653, train/logprobs = tensor([[-0.9238, -1.2782],
        [-0.9265, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013104496523737907
Epoch 0, Step 1023: train/loss = 0.706771969795227, train/raw-loss = 0.7038530111312866, train/logprobs = tensor([[-0.8089, -1.7919],
        [-0.7871, -1.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029189100489020348
Epoch 0, Step 1024: train/loss = 0.6936374306678772, train/raw-loss = 0.6921970844268799, train/logprobs = tensor([[-1.3270, -1.6546],
        [-1.3377, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014403190463781357
Epoch 0, Step 1025: train/loss = 0.6924779415130615, train/raw-loss = 0.6921538710594177, train/logprobs = tensor([[-0.8533, -1.0744],
        [-0.9910, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003240355756133795
Epoch 0, Step 1026: train/loss = 0.707166314125061, train/raw-loss = 0.7044892311096191, train/logprobs = tensor([[-1.0577, -1.7223],
        [-1.1321, -1.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026770466938614845
Epoch 0, Step 1027: train/loss = 0.7169944643974304, train/raw-loss = 0.7165428400039673, train/logprobs = tensor([[-1.0550, -1.3618],
        [-0.9618, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00451625743880868
Epoch 0, Step 1028: train/loss = 0.6886438131332397, train/raw-loss = 0.6876692771911621, train/logprobs = tensor([[-0.8507, -1.0936],
        [-1.0174, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00974470004439354
Epoch 0, Step 1029: train/loss = 0.6884019374847412, train/raw-loss = 0.6864222288131714, train/logprobs = tensor([[-0.8551, -1.5861],
        [-1.0230, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01979724131524563
Epoch 0, Step 1030: train/loss = 0.6884180307388306, train/raw-loss = 0.6861798167228699, train/logprobs = tensor([[-1.0917, -1.2619],
        [-1.3441, -0.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022381801158189774
Epoch 0, Step 1031: train/loss = 0.6929136514663696, train/raw-loss = 0.6928426623344421, train/logprobs = tensor([[-0.8973, -0.9271],
        [-0.7718, -0.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007098516798578203
Epoch 0, Step 1032: train/loss = 0.6986194252967834, train/raw-loss = 0.6976853609085083, train/logprobs = tensor([[-0.9101, -1.0463],
        [-1.0091, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009340807795524597
Epoch 0, Step 1033: train/loss = 0.7098257541656494, train/raw-loss = 0.709720253944397, train/logprobs = tensor([[-1.0210, -1.5022],
        [-1.0336, -1.2989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010547006968408823
Epoch 0, Step 1034: train/loss = 0.694617748260498, train/raw-loss = 0.6946054697036743, train/logprobs = tensor([[-0.9648, -0.9972],
        [-1.0342, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012325600255280733
Epoch 0, Step 1035: train/loss = 0.688534677028656, train/raw-loss = 0.686621904373169, train/logprobs = tensor([[-0.9004, -1.2165],
        [-0.8372, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019128484651446342
Epoch 0, Step 1036: train/loss = 0.6977717280387878, train/raw-loss = 0.6958984136581421, train/logprobs = tensor([[-0.8715, -1.6037],
        [-0.9409, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018732789903879166
Epoch 0, Step 1037: train/loss = 0.6850616931915283, train/raw-loss = 0.6832132935523987, train/logprobs = tensor([[-0.9587, -1.2037],
        [-1.3182, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018483558669686317
Epoch 0, Step 1038: train/loss = 0.7152408957481384, train/raw-loss = 0.7147892713546753, train/logprobs = tensor([[-1.1422, -1.3792],
        [-1.2746, -1.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004515836946666241
Epoch 0, Step 1039: train/loss = 0.6950587034225464, train/raw-loss = 0.6946921348571777, train/logprobs = tensor([[-1.0103, -1.0080],
        [-1.0407, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003665598575025797
Epoch 0, Step 1040: train/loss = 0.7029855251312256, train/raw-loss = 0.7025055885314941, train/logprobs = tensor([[-0.9820, -1.3125],
        [-1.0744, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00479879230260849
Epoch 0, Step 1041: train/loss = 0.7060282230377197, train/raw-loss = 0.7058793306350708, train/logprobs = tensor([[-0.8034, -1.1885],
        [-0.8356, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014887650031596422
Epoch 0, Step 1042: train/loss = 0.6768964529037476, train/raw-loss = 0.673690140247345, train/logprobs = tensor([[-0.9535, -1.3608],
        [-0.8982, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032063186168670654
Epoch 0, Step 1043: train/loss = 0.698409378528595, train/raw-loss = 0.6978313326835632, train/logprobs = tensor([[-1.0737, -1.4076],
        [-1.1220, -1.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005780588835477829
Epoch 0, Step 1044: train/loss = 0.7103361487388611, train/raw-loss = 0.7092350721359253, train/logprobs = tensor([[-0.8244, -1.3718],
        [-0.9809, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011010297574102879
Epoch 0, Step 1045: train/loss = 0.7083988189697266, train/raw-loss = 0.7083183526992798, train/logprobs = tensor([[-1.0035, -0.8475],
        [-1.0455, -0.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008053460624068975
Epoch 0, Step 1046: train/loss = 0.6937938928604126, train/raw-loss = 0.693696916103363, train/logprobs = tensor([[-0.9766, -1.0678],
        [-0.9590, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009699038928374648
Epoch 0, Step 1047: train/loss = 0.6889793872833252, train/raw-loss = 0.6884326934814453, train/logprobs = tensor([[-0.9178, -1.1357],
        [-0.9643, -0.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054676225408911705
Epoch 0, Step 1048: train/loss = 0.6898083090782166, train/raw-loss = 0.689146876335144, train/logprobs = tensor([[-0.9482, -1.2501],
        [-0.9207, -0.8348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006614170502871275
Epoch 0, Step 1049: train/loss = 0.6937295198440552, train/raw-loss = 0.6926466822624207, train/logprobs = tensor([[-0.8109, -1.1310],
        [-0.9468, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01082900445908308
Epoch 0, Step 1050: train/loss = 0.6905907392501831, train/raw-loss = 0.6896190047264099, train/logprobs = tensor([[-0.9270, -1.2734],
        [-1.1030, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00971690472215414
Epoch 0, Step 1051: train/loss = 0.693930447101593, train/raw-loss = 0.6932256817817688, train/logprobs = tensor([[-1.0434, -1.4296],
        [-1.0819, -1.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007047710474580526
Epoch 0, Step 1052: train/loss = 0.696235179901123, train/raw-loss = 0.696212649345398, train/logprobs = tensor([[-0.9762, -0.9287],
        [-1.0397, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002252132399007678
Epoch 0, Step 1053: train/loss = 0.706863522529602, train/raw-loss = 0.7057377099990845, train/logprobs = tensor([[-0.7947, -1.3528],
        [-0.9755, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011257674545049667
Epoch 0, Step 1054: train/loss = 0.7029532194137573, train/raw-loss = 0.7027615308761597, train/logprobs = tensor([[-1.2246, -1.3783],
        [-1.1144, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019168048165738583
Epoch 0, Step 1055: train/loss = 0.7012521028518677, train/raw-loss = 0.7004268765449524, train/logprobs = tensor([[-0.7460, -1.1109],
        [-0.8367, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00825199019163847
Epoch 0, Step 1056: train/loss = 0.6893283128738403, train/raw-loss = 0.6883118748664856, train/logprobs = tensor([[-0.9435, -1.1167],
        [-1.1318, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010164969600737095
Epoch 0, Step 1057: train/loss = 0.6936466693878174, train/raw-loss = 0.6935659646987915, train/logprobs = tensor([[-1.0178, -1.0164],
        [-0.9560, -0.8733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008066501468420029
Epoch 0, Step 1058: train/loss = 0.7109314799308777, train/raw-loss = 0.710485577583313, train/logprobs = tensor([[-0.8934, -1.1994],
        [-0.9677, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00445910356938839
Epoch 0, Step 1059: train/loss = 0.6831181049346924, train/raw-loss = 0.6807193160057068, train/logprobs = tensor([[-0.8763, -1.2595],
        [-1.1263, -0.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023987649008631706
Epoch 0, Step 1060: train/loss = 0.6970518827438354, train/raw-loss = 0.6969220638275146, train/logprobs = tensor([[-0.9831, -1.2342],
        [-1.0181, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012980815954506397
Epoch 0, Step 1061: train/loss = 0.7283000349998474, train/raw-loss = 0.7261700630187988, train/logprobs = tensor([[-1.0333, -1.4656],
        [-1.0836, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0212998203933239
Epoch 0, Step 1062: train/loss = 0.7055392265319824, train/raw-loss = 0.7051097750663757, train/logprobs = tensor([[-1.0012, -0.9386],
        [-1.0942, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042947567999362946
Epoch 0, Step 1063: train/loss = 0.6922112107276917, train/raw-loss = 0.6909621953964233, train/logprobs = tensor([[-1.2604, -1.4271],
        [-1.0453, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01249032560735941
Epoch 0, Step 1064: train/loss = 0.6965985894203186, train/raw-loss = 0.6935665607452393, train/logprobs = tensor([[-0.9515, -1.2397],
        [-1.3322, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0303195770829916
Epoch 0, Step 1065: train/loss = 0.6921716928482056, train/raw-loss = 0.6920321583747864, train/logprobs = tensor([[-1.2152, -1.2370],
        [-1.1787, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013954350724816322
Epoch 0, Step 1066: train/loss = 0.6899815201759338, train/raw-loss = 0.6898260116577148, train/logprobs = tensor([[-1.0636, -1.1723],
        [-1.0590, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015548791270703077
Epoch 0, Step 1067: train/loss = 0.6782194972038269, train/raw-loss = 0.6757292747497559, train/logprobs = tensor([[-0.9926, -1.3723],
        [-1.1307, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024902114644646645
Epoch 0, Step 1068: train/loss = 0.6982262134552002, train/raw-loss = 0.6981159448623657, train/logprobs = tensor([[-1.0273, -1.0908],
        [-1.0390, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011026286520063877
Epoch 0, Step 1069: train/loss = 0.6913899779319763, train/raw-loss = 0.6900004148483276, train/logprobs = tensor([[-0.8708, -0.9556],
        [-1.0874, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013895520009100437
Epoch 0, Step 1070: train/loss = 0.6856821775436401, train/raw-loss = 0.6839155554771423, train/logprobs = tensor([[-0.9610, -1.2290],
        [-1.0960, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01766577921807766
Epoch 0, Step 1071: train/loss = 0.6917127966880798, train/raw-loss = 0.6909931898117065, train/logprobs = tensor([[-0.9995, -1.2230],
        [-0.9010, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00719560356810689
Epoch 0, Step 1072: train/loss = 0.676221489906311, train/raw-loss = 0.6731614470481873, train/logprobs = tensor([[-0.8467, -1.5810],
        [-1.1909, -1.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030600473284721375
Epoch 0, Step 1073: train/loss = 0.6978769898414612, train/raw-loss = 0.6955441832542419, train/logprobs = tensor([[-0.8195, -1.3407],
        [-0.9625, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02332828938961029
Epoch 0, Step 1074: train/loss = 0.691845715045929, train/raw-loss = 0.6917459964752197, train/logprobs = tensor([[-0.8359, -0.9644],
        [-0.9123, -0.8706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009974830318242311
Epoch 0, Step 1075: train/loss = 0.6849611401557922, train/raw-loss = 0.6830970048904419, train/logprobs = tensor([[-0.9084, -1.2693],
        [-1.0832, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018641291186213493
Epoch 0, Step 1076: train/loss = 0.695787787437439, train/raw-loss = 0.6951091289520264, train/logprobs = tensor([[-0.9796, -1.0240],
        [-1.0754, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006786319427192211
Epoch 0, Step 1077: train/loss = 0.7048940062522888, train/raw-loss = 0.7020689845085144, train/logprobs = tensor([[-0.8313, -1.7405],
        [-1.2386, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02824968844652176
Epoch 0, Step 1078: train/loss = 0.6843617558479309, train/raw-loss = 0.6825721859931946, train/logprobs = tensor([[-1.0888, -1.4657],
        [-1.2530, -1.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017895586788654327
Epoch 0, Step 1079: train/loss = 0.6876216530799866, train/raw-loss = 0.6864020228385925, train/logprobs = tensor([[-1.0088, -1.5012],
        [-1.1776, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012196613475680351
Epoch 0, Step 1080: train/loss = 0.695534348487854, train/raw-loss = 0.6942863464355469, train/logprobs = tensor([[-1.0327, -1.4474],
        [-1.1806, -1.0970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012479734607040882
Epoch 0, Step 1081: train/loss = 0.6924685835838318, train/raw-loss = 0.6910864114761353, train/logprobs = tensor([[-0.7505, -1.3105],
        [-0.9504, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013822120614349842
Epoch 0, Step 1082: train/loss = 0.702560544013977, train/raw-loss = 0.7025197744369507, train/logprobs = tensor([[-0.9537, -0.8727],
        [-0.9612, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004076834302395582
Epoch 0, Step 1083: train/loss = 0.689873456954956, train/raw-loss = 0.6884051561355591, train/logprobs = tensor([[-0.9224, -1.3109],
        [-1.0422, -1.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014683268964290619
Epoch 0, Step 1084: train/loss = 0.6949098110198975, train/raw-loss = 0.6943714022636414, train/logprobs = tensor([[-1.3847, -1.3348],
        [-1.0746, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053839487954974174
Epoch 0, Step 1085: train/loss = 0.6960495710372925, train/raw-loss = 0.6959492564201355, train/logprobs = tensor([[-0.8359, -0.9234],
        [-1.0973, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010031217243522406
Epoch 0, Step 1086: train/loss = 0.6989967823028564, train/raw-loss = 0.6986271142959595, train/logprobs = tensor([[-1.0723, -1.0072],
        [-1.0814, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036969035863876343
Epoch 0, Step 1087: train/loss = 0.6831977367401123, train/raw-loss = 0.680612325668335, train/logprobs = tensor([[-1.0021, -1.2574],
        [-1.0320, -0.7375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025854142382740974
Epoch 0, Step 1088: train/loss = 0.7040879726409912, train/raw-loss = 0.7034024000167847, train/logprobs = tensor([[-0.8445, -1.1466],
        [-1.0003, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006855384446680546
Epoch 0, Step 1089: train/loss = 0.7108616828918457, train/raw-loss = 0.7092013359069824, train/logprobs = tensor([[-0.9462, -1.5107],
        [-0.9912, -1.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01660318672657013
Epoch 0, Step 1090: train/loss = 0.6827056407928467, train/raw-loss = 0.6792182922363281, train/logprobs = tensor([[-0.8770, -1.4317],
        [-1.0617, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03487405925989151
Epoch 0, Step 1091: train/loss = 0.6886796951293945, train/raw-loss = 0.686927318572998, train/logprobs = tensor([[-1.3355, -1.5792],
        [-1.2232, -1.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017523212358355522
Epoch 0, Step 1092: train/loss = 0.6976386308670044, train/raw-loss = 0.6975066661834717, train/logprobs = tensor([[-0.9941, -1.0154],
        [-1.0191, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013192263431847095
Epoch 0, Step 1093: train/loss = 0.6919171810150146, train/raw-loss = 0.6914752125740051, train/logprobs = tensor([[-1.0427, -1.1495],
        [-1.1092, -0.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00442031305283308
Epoch 0, Step 1094: train/loss = 0.6971453428268433, train/raw-loss = 0.6968689560890198, train/logprobs = tensor([[-1.0956, -1.2842],
        [-0.9500, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027635174337774515
Epoch 0, Step 1095: train/loss = 0.6932376623153687, train/raw-loss = 0.6926120519638062, train/logprobs = tensor([[-0.9533, -1.0306],
        [-1.0452, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006256029941141605
Epoch 0, Step 1096: train/loss = 0.7018008232116699, train/raw-loss = 0.7011927366256714, train/logprobs = tensor([[-0.9173, -1.0541],
        [-1.0114, -1.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006080850958824158
Epoch 0, Step 1097: train/loss = 0.7023962736129761, train/raw-loss = 0.7011855244636536, train/logprobs = tensor([[-1.0602, -1.1278],
        [-1.0578, -0.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01210804283618927
Epoch 0, Step 1098: train/loss = 0.6950616240501404, train/raw-loss = 0.6945583820343018, train/logprobs = tensor([[-0.8889, -1.0782],
        [-0.9936, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005032495129853487
Epoch 0, Step 1099: train/loss = 0.6910691261291504, train/raw-loss = 0.6907114386558533, train/logprobs = tensor([[-0.9011, -0.9980],
        [-1.1170, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003577711060643196
Epoch 0, Step 1100: train/loss = 0.6960557103157043, train/raw-loss = 0.6950211524963379, train/logprobs = tensor([[-1.2663, -1.4225],
        [-1.1271, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010345731861889362
Epoch 0, Step 1101: train/loss = 0.6965645551681519, train/raw-loss = 0.6960418224334717, train/logprobs = tensor([[-0.9099, -1.0651],
        [-1.0004, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005226964596658945
Epoch 0, Step 1102: train/loss = 0.6877771019935608, train/raw-loss = 0.6850710511207581, train/logprobs = tensor([[-0.9590, -1.5472],
        [-1.1125, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02706029638648033
Epoch 0, Step 1103: train/loss = 0.690658688545227, train/raw-loss = 0.6896628737449646, train/logprobs = tensor([[-1.0046, -1.3217],
        [-0.8301, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009958488866686821
Epoch 0, Step 1104: train/loss = 0.6902170181274414, train/raw-loss = 0.6896315217018127, train/logprobs = tensor([[-0.9230, -1.1417],
        [-1.0306, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005854990798979998
Epoch 0, Step 1105: train/loss = 0.702635645866394, train/raw-loss = 0.7016443014144897, train/logprobs = tensor([[-0.8584, -1.1844],
        [-1.0120, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009913383051753044
Epoch 0, Step 1106: train/loss = 0.6953954696655273, train/raw-loss = 0.6940813064575195, train/logprobs = tensor([[-0.9269, -1.2707],
        [-0.9294, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013140679337084293
Epoch 0, Step 1107: train/loss = 0.6990816593170166, train/raw-loss = 0.698655366897583, train/logprobs = tensor([[-0.9331, -1.2161],
        [-1.0176, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004262673202902079
Epoch 0, Step 1108: train/loss = 0.7064887285232544, train/raw-loss = 0.7063713073730469, train/logprobs = tensor([[-0.8359, -0.9529],
        [-0.8540, -0.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011742780916392803
Epoch 0, Step 1109: train/loss = 0.7294598817825317, train/raw-loss = 0.7277265787124634, train/logprobs = tensor([[-1.0311, -1.9616],
        [-0.9751, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01733384281396866
Epoch 0, Step 1110: train/loss = 0.6937638521194458, train/raw-loss = 0.6930893659591675, train/logprobs = tensor([[-0.9915, -1.1452],
        [-1.0519, -0.9007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067448727786540985
Epoch 0, Step 1111: train/loss = 0.7861766815185547, train/raw-loss = 0.7856051325798035, train/logprobs = tensor([[-0.9650, -1.6110],
        [-0.9841, -1.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005715630017220974
Epoch 0, Step 1112: train/loss = 0.7132793068885803, train/raw-loss = 0.7125357389450073, train/logprobs = tensor([[-0.9476, -1.0658],
        [-0.9281, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007435438688844442
Epoch 0, Step 1113: train/loss = 0.6892410516738892, train/raw-loss = 0.6875227689743042, train/logprobs = tensor([[-0.9562, -1.3133],
        [-0.9344, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01718258485198021
Epoch 0, Step 1114: train/loss = 0.6936054825782776, train/raw-loss = 0.6929057836532593, train/logprobs = tensor([[-1.0783, -1.3777],
        [-1.0331, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006996721029281616
Epoch 0, Step 1115: train/loss = 0.6420532464981079, train/raw-loss = 0.6388058662414551, train/logprobs = tensor([[-1.0161, -1.5020],
        [-1.4308, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032473597675561905
Epoch 0, Step 1116: train/loss = 0.6748515963554382, train/raw-loss = 0.6715030074119568, train/logprobs = tensor([[-0.9634, -1.3464],
        [-1.1640, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03348609805107117
Epoch 0, Step 1117: train/loss = 0.672443151473999, train/raw-loss = 0.6673307418823242, train/logprobs = tensor([[-0.9138, -1.4791],
        [-1.1558, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051124293357133865
Epoch 0, Step 1118: train/loss = 0.6948142647743225, train/raw-loss = 0.6935729384422302, train/logprobs = tensor([[-0.8661, -0.8505],
        [-1.0495, -0.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012413541786372662
Epoch 0, Step 1119: train/loss = 0.7028560042381287, train/raw-loss = 0.7023097276687622, train/logprobs = tensor([[-0.8107, -1.3353],
        [-0.9609, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00546279177069664
Epoch 0, Step 1120: train/loss = 0.6920228600502014, train/raw-loss = 0.6899387240409851, train/logprobs = tensor([[-1.2327, -1.5615],
        [-1.3064, -1.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02084154449403286
Epoch 0, Step 1121: train/loss = 0.6946924924850464, train/raw-loss = 0.6945095062255859, train/logprobs = tensor([[-0.9546, -1.0812],
        [-0.8673, -0.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018301213858649135
Epoch 0, Step 1122: train/loss = 0.7000913619995117, train/raw-loss = 0.6998699307441711, train/logprobs = tensor([[-1.1369, -1.0895],
        [-1.1806, -0.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00221453420817852
Epoch 0, Step 1123: train/loss = 0.7026253342628479, train/raw-loss = 0.7013413906097412, train/logprobs = tensor([[-1.0089, -1.5211],
        [-1.0457, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012839678674936295
Epoch 0, Step 1124: train/loss = 0.697568953037262, train/raw-loss = 0.6972811222076416, train/logprobs = tensor([[-1.0604, -1.1763],
        [-1.0604, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028775776736438274
Epoch 0, Step 1125: train/loss = 0.6947880387306213, train/raw-loss = 0.6928550601005554, train/logprobs = tensor([[-0.9005, -1.4448],
        [-1.1640, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019330039620399475
Epoch 0, Step 1126: train/loss = 0.6915865540504456, train/raw-loss = 0.6907973289489746, train/logprobs = tensor([[-0.9358, -1.1800],
        [-1.0225, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00789235346019268
Epoch 0, Step 1127: train/loss = 0.7042036056518555, train/raw-loss = 0.7036776542663574, train/logprobs = tensor([[-0.8356, -1.2633],
        [-0.9556, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052598402835428715
Epoch 0, Step 1128: train/loss = 0.6867378950119019, train/raw-loss = 0.6846617460250854, train/logprobs = tensor([[-0.8261, -1.1824],
        [-1.0294, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020760608837008476
Epoch 0, Step 1129: train/loss = 0.6773949265480042, train/raw-loss = 0.6761882305145264, train/logprobs = tensor([[-1.0176, -1.3501],
        [-1.1527, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012067181058228016
Epoch 0, Step 1130: train/loss = 0.7382917404174805, train/raw-loss = 0.737107515335083, train/logprobs = tensor([[-0.9672, -1.5447],
        [-1.1366, -1.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011842552572488785
Epoch 0, Step 1131: train/loss = 0.7072286605834961, train/raw-loss = 0.706527590751648, train/logprobs = tensor([[-0.9623, -1.2264],
        [-0.9336, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007010428700596094
Epoch 0, Step 1132: train/loss = 0.7106751203536987, train/raw-loss = 0.7091457843780518, train/logprobs = tensor([[-0.9586, -1.3951],
        [-1.1609, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015293661504983902
Epoch 0, Step 1133: train/loss = 0.7023968696594238, train/raw-loss = 0.6994016170501709, train/logprobs = tensor([[-1.2027, -1.2882],
        [-1.2996, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029951784759759903
Epoch 0, Step 1134: train/loss = 0.7249941825866699, train/raw-loss = 0.7218810319900513, train/logprobs = tensor([[-0.8570, -1.8440],
        [-1.1832, -1.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031131580471992493
Epoch 0, Step 1135: train/loss = 0.703432023525238, train/raw-loss = 0.7023575305938721, train/logprobs = tensor([[-0.8148, -1.2355],
        [-0.9880, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010744575411081314
Epoch 0, Step 1136: train/loss = 0.7155530452728271, train/raw-loss = 0.7124708890914917, train/logprobs = tensor([[-0.8544, -1.6193],
        [-0.9463, -1.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030821142718195915
Epoch 0, Step 1137: train/loss = 0.6913561224937439, train/raw-loss = 0.6889040470123291, train/logprobs = tensor([[-0.8177, -1.2517],
        [-1.1307, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024521011859178543
Epoch 0, Step 1138: train/loss = 0.6679705381393433, train/raw-loss = 0.6651017665863037, train/logprobs = tensor([[-0.9891, -1.5007],
        [-1.2959, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02868747152388096
Epoch 0, Step 1139: train/loss = 0.653484582901001, train/raw-loss = 0.6461426019668579, train/logprobs = tensor([[-0.9231, -1.5353],
        [-1.0633, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07341935485601425
Epoch 0, Step 1140: train/loss = 0.7088426947593689, train/raw-loss = 0.7081843614578247, train/logprobs = tensor([[-1.0046, -0.9620],
        [-1.1984, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006582979578524828
Epoch 0, Step 1141: train/loss = 0.6846765279769897, train/raw-loss = 0.6818339824676514, train/logprobs = tensor([[-1.0918, -1.5095],
        [-1.2834, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028424754738807678
Epoch 0, Step 1142: train/loss = 0.690383791923523, train/raw-loss = 0.6872192621231079, train/logprobs = tensor([[-0.8603, -1.4132],
        [-1.1007, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03164548799395561
Epoch 0, Step 1143: train/loss = 0.7015519738197327, train/raw-loss = 0.7006136178970337, train/logprobs = tensor([[-1.2294, -1.1233],
        [-1.4180, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009384101256728172
Epoch 0, Step 1144: train/loss = 0.6956228613853455, train/raw-loss = 0.6953023076057434, train/logprobs = tensor([[-0.7348, -1.0902],
        [-0.7226, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032051007729023695
Epoch 0, Step 1145: train/loss = 0.6892336010932922, train/raw-loss = 0.6880365610122681, train/logprobs = tensor([[-1.0778, -1.2569],
        [-1.2740, -0.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011970242485404015
Epoch 0, Step 1146: train/loss = 0.7110679149627686, train/raw-loss = 0.7106236815452576, train/logprobs = tensor([[-0.9799, -1.1539],
        [-1.1450, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004441782832145691
Epoch 0, Step 1147: train/loss = 0.6940493583679199, train/raw-loss = 0.6940438747406006, train/logprobs = tensor([[-0.9250, -1.0086],
        [-0.9109, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.539261474041268e-05
Epoch 0, Step 1148: train/loss = 0.6825767755508423, train/raw-loss = 0.6804217100143433, train/logprobs = tensor([[-1.0001, -1.4146],
        [-1.0346, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021550381556153297
Epoch 0, Step 1149: train/loss = 0.6702587604522705, train/raw-loss = 0.6660991311073303, train/logprobs = tensor([[-0.9033, -1.5920],
        [-1.1895, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04159633815288544
Epoch 0, Step 1150: train/loss = 0.6903939843177795, train/raw-loss = 0.6894238591194153, train/logprobs = tensor([[-0.8499, -1.3191],
        [-1.0833, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009701431728899479
Epoch 0, Step 1151: train/loss = 0.7217428684234619, train/raw-loss = 0.7202106714248657, train/logprobs = tensor([[-0.9123, -1.4864],
        [-1.1441, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01532120443880558
Epoch 0, Step 1152: train/loss = 0.6841904520988464, train/raw-loss = 0.6811724901199341, train/logprobs = tensor([[-0.7658, -1.3211],
        [-0.9611, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030180351808667183
Epoch 0, Step 1153: train/loss = 0.7103365063667297, train/raw-loss = 0.7095301747322083, train/logprobs = tensor([[-1.1709, -1.4646],
        [-1.1932, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008063815534114838
Epoch 0, Step 1154: train/loss = 0.6892068386077881, train/raw-loss = 0.6872721910476685, train/logprobs = tensor([[-0.9559, -1.1868],
        [-1.1216, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019345372915267944
Epoch 0, Step 1155: train/loss = 0.6775025725364685, train/raw-loss = 0.6752850413322449, train/logprobs = tensor([[-0.8176, -1.0513],
        [-1.0399, -0.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022175215184688568
Epoch 0, Step 1156: train/loss = 0.7036014795303345, train/raw-loss = 0.7030341625213623, train/logprobs = tensor([[-0.8819, -0.9699],
        [-0.9089, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005673413164913654
Epoch 0, Step 1157: train/loss = 0.7000212669372559, train/raw-loss = 0.698792576789856, train/logprobs = tensor([[-0.7531, -1.0217],
        [-0.9137, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012287283316254616
Epoch 0, Step 1158: train/loss = 0.6937882900238037, train/raw-loss = 0.6937773823738098, train/logprobs = tensor([[-1.0273, -1.1273],
        [-1.1139, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010866117372643203
Epoch 0, Step 1159: train/loss = 0.6967794895172119, train/raw-loss = 0.6964428424835205, train/logprobs = tensor([[-1.3453, -1.3040],
        [-1.0545, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033664596267044544
Epoch 0, Step 1160: train/loss = 0.6872527003288269, train/raw-loss = 0.6848434209823608, train/logprobs = tensor([[-0.8234, -1.1852],
        [-0.9365, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024092452600598335
Epoch 0, Step 1161: train/loss = 0.6872028112411499, train/raw-loss = 0.6835916042327881, train/logprobs = tensor([[-1.1356, -1.8138],
        [-1.0023, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03611179068684578
Epoch 0, Step 1162: train/loss = 0.6961116194725037, train/raw-loss = 0.6941636800765991, train/logprobs = tensor([[-1.3034, -1.2780],
        [-1.3257, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019479211419820786
Epoch 0, Step 1163: train/loss = 0.6854310035705566, train/raw-loss = 0.6832689046859741, train/logprobs = tensor([[-0.8605, -1.1517],
        [-0.9998, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02162080444395542
Epoch 0, Step 1164: train/loss = 0.691744327545166, train/raw-loss = 0.6910744309425354, train/logprobs = tensor([[-1.1699, -1.2792],
        [-1.4388, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006699027959257364
Epoch 0, Step 1165: train/loss = 0.6870670914649963, train/raw-loss = 0.6856178045272827, train/logprobs = tensor([[-1.0575, -1.3517],
        [-1.1979, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014492427930235863
Epoch 0, Step 1166: train/loss = 0.7156546115875244, train/raw-loss = 0.7140916585922241, train/logprobs = tensor([[-1.0142, -1.3906],
        [-1.0602, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015629542991518974
Epoch 0, Step 1167: train/loss = 0.695340633392334, train/raw-loss = 0.695103645324707, train/logprobs = tensor([[-0.9592, -1.1506],
        [-1.0933, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002370222704485059
Epoch 0, Step 1168: train/loss = 0.6973611116409302, train/raw-loss = 0.6959993243217468, train/logprobs = tensor([[-1.0153, -1.2246],
        [-1.2496, -1.1458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013618025928735733
Epoch 0, Step 1169: train/loss = 0.6948844790458679, train/raw-loss = 0.6945121884346008, train/logprobs = tensor([[-0.9047, -1.0709],
        [-1.0562, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037225186824798584
Epoch 0, Step 1170: train/loss = 0.6965618133544922, train/raw-loss = 0.6960962414741516, train/logprobs = tensor([[-0.8401, -0.9670],
        [-1.0996, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004655538592487574
Epoch 0, Step 1171: train/loss = 0.6765204668045044, train/raw-loss = 0.6723036170005798, train/logprobs = tensor([[-1.1171, -1.7217],
        [-1.3886, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04216841608285904
Epoch 0, Step 1172: train/loss = 0.6873183250427246, train/raw-loss = 0.6857501268386841, train/logprobs = tensor([[-1.1012, -1.2609],
        [-1.3843, -0.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015681961551308632
Epoch 0, Step 1173: train/loss = 0.6867967247962952, train/raw-loss = 0.6853496432304382, train/logprobs = tensor([[-0.8571, -1.1372],
        [-0.9708, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014471647329628468
Epoch 0, Step 1174: train/loss = 0.6946134567260742, train/raw-loss = 0.6934596300125122, train/logprobs = tensor([[-1.0026, -1.2384],
        [-1.1065, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011538923718035221
Epoch 0, Step 1175: train/loss = 0.6834045052528381, train/raw-loss = 0.6814582347869873, train/logprobs = tensor([[-1.0907, -1.4846],
        [-1.1409, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01946284994482994
Epoch 0, Step 1176: train/loss = 0.6925961375236511, train/raw-loss = 0.6923547387123108, train/logprobs = tensor([[-1.0286, -1.0658],
        [-1.1511, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002413839101791382
Epoch 0, Step 1177: train/loss = 0.6945713758468628, train/raw-loss = 0.6936917901039124, train/logprobs = tensor([[-1.1899, -1.1967],
        [-1.0255, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008795535191893578
Epoch 0, Step 1178: train/loss = 0.6610540151596069, train/raw-loss = 0.6552525758743286, train/logprobs = tensor([[-1.1754, -1.6339],
        [-1.3388, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0580144003033638
Epoch 0, Step 1179: train/loss = 0.7039101123809814, train/raw-loss = 0.7023506164550781, train/logprobs = tensor([[-1.0056, -1.4887],
        [-1.5131, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015594870783388615
Epoch 0, Step 1180: train/loss = 0.6925749778747559, train/raw-loss = 0.6919348239898682, train/logprobs = tensor([[-1.0404, -1.2349],
        [-1.3331, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006400863640010357
Epoch 0, Step 1181: train/loss = 0.68649822473526, train/raw-loss = 0.6852828860282898, train/logprobs = tensor([[-1.0240, -1.1057],
        [-1.4572, -0.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012153301388025284
Epoch 0, Step 1182: train/loss = 0.7037755250930786, train/raw-loss = 0.7006164789199829, train/logprobs = tensor([[-0.9472, -1.5595],
        [-1.0850, -1.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031590238213539124
Epoch 0, Step 1183: train/loss = 0.7872264981269836, train/raw-loss = 0.7853832244873047, train/logprobs = tensor([[-1.1113, -1.8653],
        [-1.1884, -1.4108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0184326209127903
Epoch 0, Step 1184: train/loss = 0.6922584772109985, train/raw-loss = 0.6917586326599121, train/logprobs = tensor([[-1.1892, -1.3473],
        [-1.1322, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004997887182980776
Epoch 0, Step 1185: train/loss = 0.6797809600830078, train/raw-loss = 0.677601158618927, train/logprobs = tensor([[-0.9055, -1.2572],
        [-1.2842, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02179768867790699
Epoch 0, Step 1186: train/loss = 0.6723323464393616, train/raw-loss = 0.6703099012374878, train/logprobs = tensor([[-0.8975, -1.3395],
        [-1.2358, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020224234089255333
Epoch 0, Step 1187: train/loss = 0.6906870007514954, train/raw-loss = 0.6898632049560547, train/logprobs = tensor([[-0.9962, -1.0043],
        [-1.0964, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008237475529313087
Epoch 0, Step 1188: train/loss = 0.7086902856826782, train/raw-loss = 0.7050541639328003, train/logprobs = tensor([[-0.7741, -1.6717],
        [-1.1448, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0363609679043293
Epoch 0, Step 1189: train/loss = 0.695391058921814, train/raw-loss = 0.6937288641929626, train/logprobs = tensor([[-1.1227, -1.4295],
        [-1.2403, -1.0866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016622191295027733
Epoch 0, Step 1190: train/loss = 0.6921812295913696, train/raw-loss = 0.6919251680374146, train/logprobs = tensor([[-0.9949, -1.0071],
        [-1.1029, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025601673405617476
Epoch 0, Step 1191: train/loss = 0.6931990385055542, train/raw-loss = 0.6883502006530762, train/logprobs = tensor([[-0.8242, -1.6911],
        [-1.1137, -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0484880693256855
Epoch 0, Step 1192: train/loss = 0.6973168849945068, train/raw-loss = 0.6971459984779358, train/logprobs = tensor([[-1.1481, -1.1541],
        [-1.3129, -1.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017086098669096828
Epoch 0, Step 1193: train/loss = 0.687293529510498, train/raw-loss = 0.6854426860809326, train/logprobs = tensor([[-0.8338, -1.2298],
        [-1.0576, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0185077004134655
Epoch 0, Step 1194: train/loss = 0.6985616683959961, train/raw-loss = 0.6955302357673645, train/logprobs = tensor([[-0.9662, -0.9042],
        [-0.9638, -0.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030314452946186066
Epoch 0, Step 1195: train/loss = 0.6762344241142273, train/raw-loss = 0.6739081740379333, train/logprobs = tensor([[-1.1353, -1.4061],
        [-1.2397, -0.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023262277245521545
Epoch 0, Step 1196: train/loss = 0.6888501048088074, train/raw-loss = 0.6862960457801819, train/logprobs = tensor([[-0.9467, -1.4003],
        [-1.0097, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025540271773934364
Epoch 0, Step 1197: train/loss = 0.698987603187561, train/raw-loss = 0.6981221437454224, train/logprobs = tensor([[-1.0222, -1.0928],
        [-1.1344, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008653877303004265
Epoch 0, Step 1198: train/loss = 0.6930087804794312, train/raw-loss = 0.6918948292732239, train/logprobs = tensor([[-1.0448, -1.0575],
        [-1.2390, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011139687150716782
Epoch 0, Step 1199: train/loss = 0.6830134987831116, train/raw-loss = 0.6811546087265015, train/logprobs = tensor([[-1.0106, -1.2494],
        [-1.2766, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01858828216791153
Epoch 0, Step 1200: train/loss = 0.687611997127533, train/raw-loss = 0.6873399019241333, train/logprobs = tensor([[-1.0498, -1.0494],
        [-1.1130, -0.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002720228396356106
Epoch 0, Step 1201: train/loss = 0.6895588636398315, train/raw-loss = 0.688091516494751, train/logprobs = tensor([[-1.2687, -1.4103],
        [-1.1546, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014673248864710331
Epoch 0, Step 1202: train/loss = 0.7136949896812439, train/raw-loss = 0.7130588293075562, train/logprobs = tensor([[-1.2480, -1.1514],
        [-1.4412, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006361321546137333
Epoch 0, Step 1203: train/loss = 0.6895822286605835, train/raw-loss = 0.6871634721755981, train/logprobs = tensor([[-0.9724, -1.4081],
        [-1.2577, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024187153205275536
Epoch 0, Step 1204: train/loss = 0.6920910477638245, train/raw-loss = 0.691840648651123, train/logprobs = tensor([[-0.7578, -0.7599],
        [-0.9430, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025044074282050133
Epoch 0, Step 1205: train/loss = 0.7250785827636719, train/raw-loss = 0.7224170565605164, train/logprobs = tensor([[-1.2024, -1.1813],
        [-1.2604, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026615064591169357
Epoch 0, Step 1206: train/loss = 0.6995091438293457, train/raw-loss = 0.6987043023109436, train/logprobs = tensor([[-0.9539, -1.3509],
        [-1.1579, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008047706447541714
Epoch 0, Step 1207: train/loss = 0.703725278377533, train/raw-loss = 0.702711820602417, train/logprobs = tensor([[-1.1368, -1.1833],
        [-1.2209, -0.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010134381242096424
Epoch 0, Step 1208: train/loss = 0.6975654363632202, train/raw-loss = 0.6973826885223389, train/logprobs = tensor([[-1.2062, -1.1927],
        [-1.3624, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018271285807713866
Epoch 0, Step 1209: train/loss = 0.6855679154396057, train/raw-loss = 0.6829360723495483, train/logprobs = tensor([[-1.0579, -1.6776],
        [-1.3146, -1.2361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026317600160837173
Epoch 0, Step 1210: train/loss = 0.6960394382476807, train/raw-loss = 0.6958696842193604, train/logprobs = tensor([[-0.8364, -0.8558],
        [-1.0754, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001696974504739046
Epoch 0, Step 1211: train/loss = 0.6781585216522217, train/raw-loss = 0.6733031868934631, train/logprobs = tensor([[-1.0278, -1.2478],
        [-1.4135, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855375364422798
Epoch 0, Step 1212: train/loss = 0.6827203035354614, train/raw-loss = 0.6797946095466614, train/logprobs = tensor([[-1.0314, -1.3252],
        [-1.1931, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029257213696837425
Epoch 0, Step 1213: train/loss = 0.6372575759887695, train/raw-loss = 0.6223920583724976, train/logprobs = tensor([[-1.3783, -2.1714],
        [-1.5121, -0.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14865544438362122
Epoch 0, Step 1214: train/loss = 0.7129278779029846, train/raw-loss = 0.7110732197761536, train/logprobs = tensor([[-0.9034, -1.3627],
        [-1.0503, -1.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01854671910405159
Epoch 0, Step 1215: train/loss = 0.6863742470741272, train/raw-loss = 0.6843662261962891, train/logprobs = tensor([[-1.0683, -1.4745],
        [-0.9370, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02008023113012314
Epoch 0, Step 1216: train/loss = 0.6796417832374573, train/raw-loss = 0.6768428087234497, train/logprobs = tensor([[-1.0105, -1.6952],
        [-1.3450, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027989476919174194
Epoch 0, Step 1217: train/loss = 0.6951435804367065, train/raw-loss = 0.6948664784431458, train/logprobs = tensor([[-1.1205, -1.2775],
        [-1.0597, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027714166790246964
Epoch 0, Step 1218: train/loss = 0.6876254081726074, train/raw-loss = 0.6862918734550476, train/logprobs = tensor([[-1.1625, -1.3595],
        [-1.1933, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013335637748241425
Epoch 0, Step 1219: train/loss = 0.6938759088516235, train/raw-loss = 0.6932252645492554, train/logprobs = tensor([[-0.8988, -1.1619],
        [-1.1981, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065065533854067326
Epoch 0, Step 1220: train/loss = 0.7336302399635315, train/raw-loss = 0.7331177592277527, train/logprobs = tensor([[-0.9562, -1.2046],
        [-0.9513, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005124546121805906
Epoch 0, Step 1221: train/loss = 0.6589311361312866, train/raw-loss = 0.6540846228599548, train/logprobs = tensor([[-0.8436, -1.1711],
        [-1.2391, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04846502095460892
Epoch 0, Step 1222: train/loss = 0.6958465576171875, train/raw-loss = 0.6926988363265991, train/logprobs = tensor([[-0.9962, -1.5408],
        [-1.1064, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031477343291044235
Epoch 0, Step 1223: train/loss = 0.6930352449417114, train/raw-loss = 0.6925852298736572, train/logprobs = tensor([[-1.1631, -1.1632],
        [-1.1276, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00450072530657053
Epoch 0, Step 1224: train/loss = 0.6934477090835571, train/raw-loss = 0.6906095147132874, train/logprobs = tensor([[-0.7995, -1.3504],
        [-1.0015, -1.0767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028382433578372
Epoch 0, Step 1225: train/loss = 0.6886095404624939, train/raw-loss = 0.6872372627258301, train/logprobs = tensor([[-0.7767, -1.1071],
        [-1.1451, -0.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01372259110212326
Epoch 0, Step 1226: train/loss = 0.6903437376022339, train/raw-loss = 0.6891183853149414, train/logprobs = tensor([[-0.8187, -1.1442],
        [-1.0899, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012253529392182827
Epoch 0, Step 1227: train/loss = 0.6946132183074951, train/raw-loss = 0.6909837126731873, train/logprobs = tensor([[-1.1783, -1.6015],
        [-1.3288, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036295387893915176
Epoch 0, Step 1228: train/loss = 0.7226073145866394, train/raw-loss = 0.7221667766571045, train/logprobs = tensor([[-0.7836, -1.0047],
        [-0.8574, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004405306652188301
Epoch 0, Step 1229: train/loss = 0.700705885887146, train/raw-loss = 0.6995627880096436, train/logprobs = tensor([[-1.3716, -1.4397],
        [-1.1992, -1.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011431603692471981
Epoch 0, Step 1230: train/loss = 0.687199592590332, train/raw-loss = 0.6851849555969238, train/logprobs = tensor([[-1.0984, -1.3583],
        [-1.2888, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020145956426858902
Epoch 0, Step 1231: train/loss = 0.7088096141815186, train/raw-loss = 0.7082448601722717, train/logprobs = tensor([[-1.0909, -0.9214],
        [-1.1767, -0.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056472765281796455
Epoch 0, Step 1232: train/loss = 0.68699049949646, train/raw-loss = 0.6848384141921997, train/logprobs = tensor([[-0.9786, -1.2777],
        [-1.2790, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021520672366023064
Epoch 0, Step 1233: train/loss = 0.6865423321723938, train/raw-loss = 0.6840353608131409, train/logprobs = tensor([[-1.1662, -1.3152],
        [-1.4396, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025070086121559143
Epoch 0, Step 1234: train/loss = 0.689750075340271, train/raw-loss = 0.6874845623970032, train/logprobs = tensor([[-1.0943, -1.2886],
        [-1.5542, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022654537111520767
Epoch 0, Step 1235: train/loss = 0.6871638298034668, train/raw-loss = 0.6853902339935303, train/logprobs = tensor([[-0.7752, -0.9290],
        [-1.0089, -0.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017736300826072693
Epoch 0, Step 1236: train/loss = 0.7009672522544861, train/raw-loss = 0.699567437171936, train/logprobs = tensor([[-1.0020, -1.3722],
        [-1.1018, -1.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013998782262206078
Epoch 0, Step 1237: train/loss = 0.6764699220657349, train/raw-loss = 0.6728676557540894, train/logprobs = tensor([[-1.1891, -1.7543],
        [-1.3270, -1.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03602275252342224
Epoch 0, Step 1238: train/loss = 0.6717343330383301, train/raw-loss = 0.6688772439956665, train/logprobs = tensor([[-1.0783, -1.6270],
        [-1.2008, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028570711612701416
Epoch 0, Step 1239: train/loss = 0.6951271891593933, train/raw-loss = 0.6951082944869995, train/logprobs = tensor([[-0.8220, -0.8612],
        [-1.0332, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001888970291474834
Epoch 0, Step 1240: train/loss = 0.6762808561325073, train/raw-loss = 0.6737734079360962, train/logprobs = tensor([[-0.9720, -1.4869],
        [-1.1496, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025075014680624008
Epoch 0, Step 1241: train/loss = 0.6957998275756836, train/raw-loss = 0.6954301595687866, train/logprobs = tensor([[-0.8974, -0.9048],
        [-1.1230, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003696504980325699
Epoch 0, Step 1242: train/loss = 0.7025449275970459, train/raw-loss = 0.7017686367034912, train/logprobs = tensor([[-1.0239, -1.0572],
        [-1.0816, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0077627114951610565
Epoch 0, Step 1243: train/loss = 0.6824496984481812, train/raw-loss = 0.6800363063812256, train/logprobs = tensor([[-1.1207, -1.4747],
        [-1.3226, -1.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0241329874843359
Epoch 0, Step 1244: train/loss = 0.6704174280166626, train/raw-loss = 0.666664183139801, train/logprobs = tensor([[-1.0210, -1.5830],
        [-1.1200, -0.9828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03753283992409706
Epoch 0, Step 1245: train/loss = 0.6903653144836426, train/raw-loss = 0.6875720024108887, train/logprobs = tensor([[-1.1668, -1.3298],
        [-1.3583, -0.9188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027933210134506226
Epoch 0, Step 1246: train/loss = 0.6676876544952393, train/raw-loss = 0.6615216135978699, train/logprobs = tensor([[-0.9543, -1.4527],
        [-1.2912, -0.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06166084110736847
Epoch 0, Step 1247: train/loss = 0.7062432765960693, train/raw-loss = 0.7053409814834595, train/logprobs = tensor([[-1.0135, -0.8983],
        [-1.0556, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009023172780871391
Epoch 0, Step 1248: train/loss = 0.6894612312316895, train/raw-loss = 0.6870741844177246, train/logprobs = tensor([[-1.0436, -1.1626],
        [-1.2531, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02387062832713127
Epoch 0, Step 1249: train/loss = 0.702426552772522, train/raw-loss = 0.7016963958740234, train/logprobs = tensor([[-1.1264, -1.2583],
        [-1.1061, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007301716599613428
Epoch 0, Step 1250: train/loss = 0.6902151107788086, train/raw-loss = 0.6893693208694458, train/logprobs = tensor([[-1.1893, -1.3225],
        [-1.3987, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008457818068563938
Epoch 0, Step 1251: train/loss = 0.7051456570625305, train/raw-loss = 0.7014171481132507, train/logprobs = tensor([[-1.0614, -1.9651],
        [-1.4389, -1.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037284571677446365
Epoch 0, Step 1252: train/loss = 0.6966120600700378, train/raw-loss = 0.69557785987854, train/logprobs = tensor([[-1.0746, -1.1998],
        [-1.3525, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010341756045818329
Epoch 0, Step 1253: train/loss = 0.6989578604698181, train/raw-loss = 0.6956143379211426, train/logprobs = tensor([[-1.1134, -1.7333],
        [-1.4471, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03343573212623596
Epoch 0, Step 1254: train/loss = 0.6919240951538086, train/raw-loss = 0.6895015239715576, train/logprobs = tensor([[-1.1114, -1.4354],
        [-0.9235, -0.9379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024225641041994095
Epoch 0, Step 1255: train/loss = 0.7155996561050415, train/raw-loss = 0.7153079509735107, train/logprobs = tensor([[-0.9196, -0.7876],
        [-0.9999, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029166792519390583
Epoch 0, Step 1256: train/loss = 0.7119578719139099, train/raw-loss = 0.7105584144592285, train/logprobs = tensor([[-1.1308, -1.1816],
        [-1.2558, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01399432122707367
Epoch 0, Step 1257: train/loss = 0.6968516111373901, train/raw-loss = 0.6963123679161072, train/logprobs = tensor([[-0.9252, -1.0471],
        [-1.1190, -0.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005392081569880247
Epoch 0, Step 1258: train/loss = 0.6887452006340027, train/raw-loss = 0.6877536773681641, train/logprobs = tensor([[-1.1890, -1.2835],
        [-1.1544, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009915190748870373
Epoch 0, Step 1259: train/loss = 0.6726345419883728, train/raw-loss = 0.6683080196380615, train/logprobs = tensor([[-1.2468, -1.5103],
        [-1.6229, -1.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04326550289988518
Epoch 0, Step 1260: train/loss = 0.6465077996253967, train/raw-loss = 0.6415676474571228, train/logprobs = tensor([[-1.0628, -1.2285],
        [-2.1012, -0.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04940136894583702
Epoch 0, Step 1261: train/loss = 0.6815807819366455, train/raw-loss = 0.6773654222488403, train/logprobs = tensor([[-0.9189, -1.4716],
        [-1.2266, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04215401038527489
Epoch 0, Step 1262: train/loss = 0.6946688890457153, train/raw-loss = 0.6944717168807983, train/logprobs = tensor([[-1.4341, -1.5399],
        [-1.2929, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019718636758625507
Epoch 0, Step 1263: train/loss = 0.6936686038970947, train/raw-loss = 0.6929007768630981, train/logprobs = tensor([[-0.9785, -1.0870],
        [-1.3114, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007679194677621126
Epoch 0, Step 1264: train/loss = 0.704674243927002, train/raw-loss = 0.7038613557815552, train/logprobs = tensor([[-1.2333, -1.5755],
        [-0.9788, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008129231631755829
Epoch 0, Step 1265: train/loss = 0.6888353824615479, train/raw-loss = 0.6869583129882812, train/logprobs = tensor([[-1.0962, -1.4061],
        [-1.2945, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018770866096019745
Epoch 0, Step 1266: train/loss = 0.7022335529327393, train/raw-loss = 0.7020344734191895, train/logprobs = tensor([[-1.1061, -1.0201],
        [-1.3218, -1.1003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001990542048588395
Epoch 0, Step 1267: train/loss = 0.6961066722869873, train/raw-loss = 0.6956926584243774, train/logprobs = tensor([[-0.9297, -0.9429],
        [-1.2911, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041406722739338875
Epoch 0, Step 1268: train/loss = 0.7138805985450745, train/raw-loss = 0.7137495279312134, train/logprobs = tensor([[-1.2672, -1.1673],
        [-1.3965, -1.2411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013098823837935925
Epoch 0, Step 1269: train/loss = 0.6937885880470276, train/raw-loss = 0.692696750164032, train/logprobs = tensor([[-1.0602, -1.1364],
        [-1.2429, -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010917718522250652
Epoch 0, Step 1270: train/loss = 0.6913250684738159, train/raw-loss = 0.6899577379226685, train/logprobs = tensor([[-1.1166, -1.4709],
        [-1.2889, -1.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013673165813088417
Epoch 0, Step 1271: train/loss = 0.6985310316085815, train/raw-loss = 0.6978421211242676, train/logprobs = tensor([[-1.1205, -1.3530],
        [-1.2369, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006889896467328072
Epoch 0, Step 1272: train/loss = 0.7067751884460449, train/raw-loss = 0.7043406367301941, train/logprobs = tensor([[-1.0141, -1.4304],
        [-1.3656, -1.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024345269426703453
Epoch 0, Step 1273: train/loss = 0.7027038931846619, train/raw-loss = 0.7021620273590088, train/logprobs = tensor([[-0.9503, -0.8662],
        [-1.1983, -0.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005418999120593071
Epoch 0, Step 1274: train/loss = 0.703127384185791, train/raw-loss = 0.7014795541763306, train/logprobs = tensor([[-0.9200, -0.7873],
        [-1.2129, -0.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016478784382343292
Epoch 0, Step 1275: train/loss = 0.692138135433197, train/raw-loss = 0.6911793947219849, train/logprobs = tensor([[-1.0908, -1.1717],
        [-1.2489, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009587432257831097
Epoch 0, Step 1276: train/loss = 0.6949871778488159, train/raw-loss = 0.694904088973999, train/logprobs = tensor([[-1.1197, -1.0892],
        [-1.0157, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008307574316859245
Epoch 0, Step 1277: train/loss = 0.7151163816452026, train/raw-loss = 0.7142064571380615, train/logprobs = tensor([[-0.9214, -1.0336],
        [-0.9586, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009099235758185387
Epoch 0, Step 1278: train/loss = 0.7002188563346863, train/raw-loss = 0.6988873481750488, train/logprobs = tensor([[-0.8915, -1.1081],
        [-0.9498, -0.8063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013315539807081223
Epoch 0, Step 1279: train/loss = 0.6820219159126282, train/raw-loss = 0.6744112968444824, train/logprobs = tensor([[-1.0970, -1.6175],
        [-1.2627, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07610570639371872
Epoch 0, Step 1280: train/loss = 0.6834693551063538, train/raw-loss = 0.6801537275314331, train/logprobs = tensor([[-1.1004, -1.4294],
        [-1.5068, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03315622732043266
Epoch 0, Step 1281: train/loss = 0.6849788427352905, train/raw-loss = 0.6799260377883911, train/logprobs = tensor([[-0.9853, -1.1651],
        [-1.5549, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0505281463265419
Epoch 0, Step 1282: train/loss = 0.6843665838241577, train/raw-loss = 0.682349681854248, train/logprobs = tensor([[-1.3955, -1.7312],
        [-1.2141, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02016853354871273
Epoch 0, Step 1283: train/loss = 0.6938202381134033, train/raw-loss = 0.6923812031745911, train/logprobs = tensor([[-0.9674, -1.2855],
        [-1.1680, -1.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014390680007636547
Epoch 0, Step 1284: train/loss = 0.6889322996139526, train/raw-loss = 0.6879042983055115, train/logprobs = tensor([[-1.0483, -1.1503],
        [-1.1087, -0.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010280482470989227
Epoch 0, Step 1285: train/loss = 0.6889411211013794, train/raw-loss = 0.6854551434516907, train/logprobs = tensor([[-0.9564, -1.2718],
        [-1.1941, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03486055135726929
Epoch 0, Step 1286: train/loss = 0.6934785842895508, train/raw-loss = 0.6929417848587036, train/logprobs = tensor([[-1.1447, -1.2223],
        [-1.4467, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005368128418922424
Epoch 0, Step 1287: train/loss = 0.6898328065872192, train/raw-loss = 0.6889943480491638, train/logprobs = tensor([[-1.1804, -1.2559],
        [-1.4484, -1.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008384166285395622
Epoch 0, Step 1288: train/loss = 0.6913794279098511, train/raw-loss = 0.6875573396682739, train/logprobs = tensor([[-1.0971, -1.5571],
        [-1.4530, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03822122514247894
Epoch 0, Step 1289: train/loss = 0.6994813680648804, train/raw-loss = 0.6986535787582397, train/logprobs = tensor([[-0.8678, -0.9462],
        [-0.9930, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008277768269181252
Epoch 0, Step 1290: train/loss = 0.6951680183410645, train/raw-loss = 0.6934260725975037, train/logprobs = tensor([[-0.9087, -0.9691],
        [-1.3094, -0.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017418911680579185
Epoch 0, Step 1291: train/loss = 0.6964218020439148, train/raw-loss = 0.6955762505531311, train/logprobs = tensor([[-1.5383, -1.5928],
        [-1.3359, -1.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008455420844256878
Epoch 0, Step 1292: train/loss = 0.6753036975860596, train/raw-loss = 0.6706098318099976, train/logprobs = tensor([[-0.9738, -1.2504],
        [-1.2437, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046938732266426086
Epoch 0, Step 1293: train/loss = 0.6911700963973999, train/raw-loss = 0.6905806660652161, train/logprobs = tensor([[-0.9005, -0.9495],
        [-1.0659, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005894371774047613
Epoch 0, Step 1294: train/loss = 0.6930330991744995, train/raw-loss = 0.6925172805786133, train/logprobs = tensor([[-0.8880, -1.0136],
        [-1.1181, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005157969426363707
Epoch 0, Step 1295: train/loss = 0.6932159662246704, train/raw-loss = 0.6923450231552124, train/logprobs = tensor([[-1.0798, -1.0381],
        [-1.4187, -1.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008709180168807507
Epoch 0, Step 1296: train/loss = 0.6943618655204773, train/raw-loss = 0.694163978099823, train/logprobs = tensor([[-1.0235, -1.1395],
        [-0.9720, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019789717625826597
Epoch 0, Step 1297: train/loss = 0.6374498605728149, train/raw-loss = 0.634984016418457, train/logprobs = tensor([[-0.9909, -1.5412],
        [-1.7097, -1.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02465871162712574
Epoch 0, Step 1298: train/loss = 0.6942681670188904, train/raw-loss = 0.6940983533859253, train/logprobs = tensor([[-1.0248, -1.0220],
        [-1.2422, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001698529813438654
Epoch 0, Step 1299: train/loss = 0.6730899810791016, train/raw-loss = 0.6675106287002563, train/logprobs = tensor([[-1.0877, -1.5807],
        [-1.3408, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05579380318522453
Epoch 0, Step 1300: train/loss = 0.6717963218688965, train/raw-loss = 0.6673095226287842, train/logprobs = tensor([[-1.0908, -1.5243],
        [-1.3051, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0448681116104126
Epoch 0, Step 1301: train/loss = 0.687301754951477, train/raw-loss = 0.6851816177368164, train/logprobs = tensor([[-0.8848, -1.0575],
        [-1.1286, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02120090462267399
Epoch 0, Step 1302: train/loss = 0.6924458146095276, train/raw-loss = 0.6919933557510376, train/logprobs = tensor([[-1.0244, -1.0448],
        [-1.2820, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004525092896074057
Epoch 0, Step 1303: train/loss = 0.6766440272331238, train/raw-loss = 0.6726128458976746, train/logprobs = tensor([[-1.0961, -1.3968],
        [-1.1689, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04031145200133324
Epoch 0, Step 1304: train/loss = 0.67585688829422, train/raw-loss = 0.6724563837051392, train/logprobs = tensor([[-0.9339, -1.1877],
        [-1.2915, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03400537371635437
Epoch 0, Step 1305: train/loss = 0.6750993728637695, train/raw-loss = 0.671007513999939, train/logprobs = tensor([[-1.1037, -1.3426],
        [-1.2703, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040918923914432526
Epoch 0, Step 1306: train/loss = 0.6982450485229492, train/raw-loss = 0.6976622939109802, train/logprobs = tensor([[-0.8612, -0.8954],
        [-0.9935, -0.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005827667657285929
Epoch 0, Step 1307: train/loss = 0.6953079700469971, train/raw-loss = 0.6953059434890747, train/logprobs = tensor([[-1.3326, -1.4345],
        [-0.9804, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.01760558411479e-05
Epoch 0, Step 1308: train/loss = 0.6990803480148315, train/raw-loss = 0.6985398530960083, train/logprobs = tensor([[-0.9768, -0.9826],
        [-1.2063, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054046656005084515
Epoch 0, Step 1309: train/loss = 0.6921006441116333, train/raw-loss = 0.6908885836601257, train/logprobs = tensor([[-0.9001, -1.1439],
        [-1.1348, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012120657600462437
Epoch 0, Step 1310: train/loss = 0.7111297845840454, train/raw-loss = 0.7102937698364258, train/logprobs = tensor([[-1.0110, -1.2451],
        [-1.1546, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008360626175999641
Epoch 0, Step 1311: train/loss = 0.6906582117080688, train/raw-loss = 0.6891747117042542, train/logprobs = tensor([[-0.8938, -1.2245],
        [-0.8135, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01483483798801899
Epoch 0, Step 1312: train/loss = 0.6812112331390381, train/raw-loss = 0.6781834959983826, train/logprobs = tensor([[-1.0036, -1.1899],
        [-1.0915, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030277444049715996
Epoch 0, Step 1313: train/loss = 0.6980985403060913, train/raw-loss = 0.694770336151123, train/logprobs = tensor([[-0.9547, -1.0730],
        [-1.1621, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033282458782196045
Epoch 0, Step 1314: train/loss = 0.6650916337966919, train/raw-loss = 0.6598663330078125, train/logprobs = tensor([[-1.0406, -1.6700],
        [-1.4382, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05225283280014992
Epoch 0, Step 1315: train/loss = 0.6769422292709351, train/raw-loss = 0.6732873916625977, train/logprobs = tensor([[-1.0929, -1.3057],
        [-1.4477, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03654881566762924
Epoch 0, Step 1316: train/loss = 0.6962447166442871, train/raw-loss = 0.6957758069038391, train/logprobs = tensor([[-0.9253, -1.0858],
        [-1.1597, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004688599146902561
Epoch 0, Step 1317: train/loss = 0.6885974407196045, train/raw-loss = 0.687734842300415, train/logprobs = tensor([[-0.7949, -0.8624],
        [-1.0991, -0.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00862590316683054
Epoch 0, Step 1318: train/loss = 0.6811283826828003, train/raw-loss = 0.6791038513183594, train/logprobs = tensor([[-1.2325, -1.5035],
        [-1.2152, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020244888961315155
Epoch 0, Step 1319: train/loss = 0.6949059367179871, train/raw-loss = 0.6940381526947021, train/logprobs = tensor([[-0.8915, -0.9095],
        [-1.1834, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008678226731717587
Epoch 0, Step 1320: train/loss = 0.648426353931427, train/raw-loss = 0.6388607621192932, train/logprobs = tensor([[-0.9738, -1.7053],
        [-1.0998, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09565571695566177
Epoch 0, Step 1321: train/loss = 0.7119636535644531, train/raw-loss = 0.7106114625930786, train/logprobs = tensor([[-1.1322, -0.9878],
        [-1.4054, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013521711342036724
Epoch 0, Step 1322: train/loss = 0.6852161288261414, train/raw-loss = 0.6826410889625549, train/logprobs = tensor([[-1.0685, -1.5784],
        [-0.9272, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02575014904141426
Epoch 0, Step 1323: train/loss = 0.6927578449249268, train/raw-loss = 0.6920458674430847, train/logprobs = tensor([[-0.8809, -1.1979],
        [-0.9726, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00711918156594038
Epoch 0, Step 1324: train/loss = 0.6222285628318787, train/raw-loss = 0.607648491859436, train/logprobs = tensor([[-1.2818, -2.3468],
        [-1.3831, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14580069482326508
Epoch 0, Step 1325: train/loss = 0.6940622925758362, train/raw-loss = 0.6931824684143066, train/logprobs = tensor([[-1.0751, -1.0937],
        [-0.9125, -0.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008798478171229362
Epoch 0, Step 1326: train/loss = 0.7765457630157471, train/raw-loss = 0.7606600522994995, train/logprobs = tensor([[-1.5727, -3.7453],
        [-1.6977, -2.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15885740518569946
Epoch 0, Step 1327: train/loss = 0.6782448887825012, train/raw-loss = 0.6736621260643005, train/logprobs = tensor([[-1.2659, -1.4420],
        [-1.4107, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04582711681723595
Epoch 0, Step 1328: train/loss = 0.7051032781600952, train/raw-loss = 0.7050575017929077, train/logprobs = tensor([[-0.9312, -1.0692],
        [-1.1064, -1.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045794155448675156
Epoch 0, Step 1329: train/loss = 0.6960740685462952, train/raw-loss = 0.6927599906921387, train/logprobs = tensor([[-1.3215, -1.4833],
        [-1.3276, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03314071521162987
Epoch 0, Step 1330: train/loss = 0.7159077525138855, train/raw-loss = 0.7140926122665405, train/logprobs = tensor([[-1.3249, -1.1216],
        [-1.3511, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018151022493839264
Epoch 0, Step 1331: train/loss = 0.6990746259689331, train/raw-loss = 0.6982748508453369, train/logprobs = tensor([[-1.0500, -1.0540],
        [-1.1847, -1.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007997475564479828
Epoch 0, Step 1332: train/loss = 0.7056313753128052, train/raw-loss = 0.7042403221130371, train/logprobs = tensor([[-1.3208, -1.4623],
        [-1.2102, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01391146332025528
Epoch 0, Step 1333: train/loss = 0.6779353618621826, train/raw-loss = 0.6750398874282837, train/logprobs = tensor([[-1.1439, -1.4405],
        [-1.2193, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028954191133379936
Epoch 0, Step 1334: train/loss = 0.6906498670578003, train/raw-loss = 0.6882643699645996, train/logprobs = tensor([[-1.2451, -1.2484],
        [-1.5475, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023854896426200867
Epoch 0, Step 1335: train/loss = 0.6769660115242004, train/raw-loss = 0.6701857447624207, train/logprobs = tensor([[-0.9686, -1.8071],
        [-1.3621, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06780306249856949
Epoch 0, Step 1336: train/loss = 0.6962842345237732, train/raw-loss = 0.6945813298225403, train/logprobs = tensor([[-1.1803, -1.1861],
        [-1.4933, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01702934503555298
Epoch 0, Step 1337: train/loss = 0.6457436084747314, train/raw-loss = 0.6394014358520508, train/logprobs = tensor([[-1.1588, -1.7532],
        [-1.4745, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06342194229364395
Epoch 0, Step 1338: train/loss = 0.719408392906189, train/raw-loss = 0.7184540033340454, train/logprobs = tensor([[-1.1325, -1.2041],
        [-1.4369, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009542850777506828
Epoch 0, Step 1339: train/loss = 0.6282343864440918, train/raw-loss = 0.6187520027160645, train/logprobs = tensor([[-1.0419, -1.9101],
        [-1.2782, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09482374787330627
Epoch 0, Step 1340: train/loss = 0.6906787157058716, train/raw-loss = 0.6900821924209595, train/logprobs = tensor([[-1.2367, -1.3571],
        [-1.2628, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005965873133391142
Epoch 0, Step 1341: train/loss = 0.6787452697753906, train/raw-loss = 0.6732810139656067, train/logprobs = tensor([[-1.0014, -1.5515],
        [-1.3075, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054642751812934875
Epoch 0, Step 1342: train/loss = 0.7033926248550415, train/raw-loss = 0.7018512487411499, train/logprobs = tensor([[-1.1852, -1.1727],
        [-1.3398, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015413278713822365
Epoch 0, Step 1343: train/loss = 0.7000265121459961, train/raw-loss = 0.6992946863174438, train/logprobs = tensor([[-0.9537, -0.9100],
        [-1.3118, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073186964727938175
Epoch 0, Step 1344: train/loss = 0.6669539213180542, train/raw-loss = 0.6628720164299011, train/logprobs = tensor([[-1.2470, -1.6370],
        [-1.3591, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040819376707077026
Epoch 0, Step 1345: train/loss = 0.6935456991195679, train/raw-loss = 0.6932085752487183, train/logprobs = tensor([[-1.0133, -1.0395],
        [-1.2375, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033711884170770645
Epoch 0, Step 1346: train/loss = 0.679548978805542, train/raw-loss = 0.6773687601089478, train/logprobs = tensor([[-0.9881, -1.2686],
        [-1.3394, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021802080795168877
Epoch 0, Step 1347: train/loss = 0.6889902353286743, train/raw-loss = 0.6871883869171143, train/logprobs = tensor([[-1.2514, -1.4941],
        [-1.3150, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018019283190369606
Epoch 0, Step 1348: train/loss = 0.6958668231964111, train/raw-loss = 0.6957897543907166, train/logprobs = tensor([[-0.9980, -1.1252],
        [-1.0767, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007708232151344419
Epoch 0, Step 1349: train/loss = 0.6950480341911316, train/raw-loss = 0.6947466731071472, train/logprobs = tensor([[-0.9926, -1.1511],
        [-1.1359, -1.3199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030139272566884756
Epoch 0, Step 1350: train/loss = 0.7013670206069946, train/raw-loss = 0.700562596321106, train/logprobs = tensor([[-1.1662, -1.0660],
        [-1.4735, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00804354902356863
Epoch 0, Step 1351: train/loss = 0.6837456226348877, train/raw-loss = 0.6795268058776855, train/logprobs = tensor([[-0.9360, -1.3506],
        [-1.0580, -0.9149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042187780141830444
Epoch 0, Step 1352: train/loss = 0.6921587586402893, train/raw-loss = 0.6900511980056763, train/logprobs = tensor([[-1.2977, -1.6094],
        [-1.1390, -0.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021074993535876274
Epoch 0, Step 1353: train/loss = 0.6823464632034302, train/raw-loss = 0.6763880252838135, train/logprobs = tensor([[-0.9907, -1.5977],
        [-1.3894, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059584636241197586
Epoch 0, Step 1354: train/loss = 0.6681093573570251, train/raw-loss = 0.660323441028595, train/logprobs = tensor([[-0.8887, -1.6975],
        [-1.3066, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07785890251398087
Epoch 0, Step 1355: train/loss = 0.6798468828201294, train/raw-loss = 0.6767863631248474, train/logprobs = tensor([[-0.9290, -1.2697],
        [-1.0689, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030605198815464973
Epoch 0, Step 1356: train/loss = 0.6783047914505005, train/raw-loss = 0.675082266330719, train/logprobs = tensor([[-1.2542, -1.7166],
        [-1.0442, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032225724309682846
Epoch 0, Step 1357: train/loss = 0.6937165260314941, train/raw-loss = 0.6936556100845337, train/logprobs = tensor([[-1.4258, -1.4779],
        [-1.0863, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006095274584367871
Epoch 0, Step 1358: train/loss = 0.6394006609916687, train/raw-loss = 0.6297924518585205, train/logprobs = tensor([[-1.0232, -1.6418],
        [-1.7570, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608184546232224
Epoch 0, Step 1359: train/loss = 0.5857742428779602, train/raw-loss = 0.5639048218727112, train/logprobs = tensor([[-1.0213, -2.5396],
        [-1.4875, -0.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21869409084320068
Epoch 0, Step 1360: train/loss = 0.6944416165351868, train/raw-loss = 0.690217137336731, train/logprobs = tensor([[-1.0989, -1.8615],
        [-1.3649, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0422443225979805
Epoch 0, Step 1361: train/loss = 0.6818011999130249, train/raw-loss = 0.6768165230751038, train/logprobs = tensor([[-1.1237, -1.3366],
        [-1.4291, -0.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04984704405069351
Epoch 0, Step 1362: train/loss = 0.7250683307647705, train/raw-loss = 0.720942497253418, train/logprobs = tensor([[-1.4562, -1.1845],
        [-1.5308, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041259124875068665
Epoch 0, Step 1363: train/loss = 0.6680604219436646, train/raw-loss = 0.6599738597869873, train/logprobs = tensor([[-1.0137, -1.5812],
        [-0.9972, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08086557686328888
Epoch 0, Step 1364: train/loss = 0.6828116178512573, train/raw-loss = 0.6796950101852417, train/logprobs = tensor([[-1.0422, -1.2981],
        [-1.7174, -1.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03116554208099842
Epoch 0, Step 1365: train/loss = 0.6961550116539001, train/raw-loss = 0.6931130290031433, train/logprobs = tensor([[-1.2040, -1.2621],
        [-1.1925, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030420109629631042
Epoch 0, Step 1366: train/loss = 0.7061206102371216, train/raw-loss = 0.7060654163360596, train/logprobs = tensor([[-0.9332, -1.2130],
        [-0.7063, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005525408778339624
Epoch 0, Step 1367: train/loss = 0.5854601263999939, train/raw-loss = 0.5626076459884644, train/logprobs = tensor([[-0.8301, -2.8233],
        [-1.2056, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22852519154548645
Epoch 0, Step 1368: train/loss = 0.6997599601745605, train/raw-loss = 0.699044942855835, train/logprobs = tensor([[-1.0877, -1.1579],
        [-1.2020, -1.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007150760851800442
Epoch 0, Step 1369: train/loss = 0.6811150312423706, train/raw-loss = 0.6772524118423462, train/logprobs = tensor([[-1.0759, -1.3489],
        [-1.2309, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03862697631120682
Epoch 0, Step 1370: train/loss = 0.7034047842025757, train/raw-loss = 0.7014929056167603, train/logprobs = tensor([[-0.9445, -0.9367],
        [-1.0099, -0.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019119512289762497
Epoch 0, Step 1371: train/loss = 0.6828325986862183, train/raw-loss = 0.6807465553283691, train/logprobs = tensor([[-0.9969, -1.2018],
        [-1.3619, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020860370248556137
Epoch 0, Step 1372: train/loss = 0.702491283416748, train/raw-loss = 0.7012861967086792, train/logprobs = tensor([[-1.0932, -1.4193],
        [-1.4650, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012051685713231564
Epoch 0, Step 1373: train/loss = 0.6974579095840454, train/raw-loss = 0.6969218254089355, train/logprobs = tensor([[-1.0732, -1.0160],
        [-1.3039, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005360658746212721
Epoch 0, Step 1374: train/loss = 0.592483639717102, train/raw-loss = 0.5765219330787659, train/logprobs = tensor([[-1.1022, -2.5063],
        [-1.5621, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1596168726682663
Epoch 0, Step 1375: train/loss = 0.6917522549629211, train/raw-loss = 0.6901671886444092, train/logprobs = tensor([[-1.3828, -1.6596],
        [-1.3990, -1.3419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015851162374019623
Epoch 0, Step 1376: train/loss = 0.6836743354797363, train/raw-loss = 0.6807848215103149, train/logprobs = tensor([[-0.8762, -1.3068],
        [-1.2388, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028895240277051926
Epoch 0, Step 1377: train/loss = 0.6711223125457764, train/raw-loss = 0.6664644479751587, train/logprobs = tensor([[-1.2584, -1.6083],
        [-0.9765, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046578340232372284
Epoch 0, Step 1378: train/loss = 0.6717253923416138, train/raw-loss = 0.6649913787841797, train/logprobs = tensor([[-1.6939, -2.0248],
        [-1.4905, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06733983755111694
Epoch 0, Step 1379: train/loss = 0.6832721829414368, train/raw-loss = 0.6812634468078613, train/logprobs = tensor([[-1.0091, -1.1778],
        [-1.3688, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020087474957108498
Epoch 0, Step 1380: train/loss = 0.6913374662399292, train/raw-loss = 0.6903877854347229, train/logprobs = tensor([[-1.0009, -1.0486],
        [-1.0816, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009496537037193775
Epoch 0, Step 1381: train/loss = 0.6592530608177185, train/raw-loss = 0.6499869227409363, train/logprobs = tensor([[-1.0840, -2.1958],
        [-1.1893, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09266123920679092
Epoch 0, Step 1382: train/loss = 0.6333106756210327, train/raw-loss = 0.6180799007415771, train/logprobs = tensor([[-0.9971, -2.0091],
        [-1.3531, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15230803191661835
Epoch 0, Step 1383: train/loss = 0.6632585525512695, train/raw-loss = 0.6558551788330078, train/logprobs = tensor([[-1.3505, -1.8842],
        [-1.2101, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07403415441513062
Epoch 0, Step 1384: train/loss = 0.6766723394393921, train/raw-loss = 0.6723839044570923, train/logprobs = tensor([[-1.4571, -1.8577],
        [-1.1599, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042883966118097305
Epoch 0, Step 1385: train/loss = 0.6455183625221252, train/raw-loss = 0.6330840587615967, train/logprobs = tensor([[-1.0532, -2.0547],
        [-1.2373, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12434257566928864
Epoch 0, Step 1386: train/loss = 0.6724547743797302, train/raw-loss = 0.6674602627754211, train/logprobs = tensor([[-1.8481, -2.1693],
        [-1.1898, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04994484782218933
Epoch 0, Step 1387: train/loss = 0.6136400103569031, train/raw-loss = 0.5973466038703918, train/logprobs = tensor([[-0.9391, -2.0750],
        [-1.3236, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1629342883825302
Epoch 0, Step 1388: train/loss = 0.6455724835395813, train/raw-loss = 0.633072018623352, train/logprobs = tensor([[-0.8907, -1.7406],
        [-1.4984, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12500491738319397
Epoch 0, Step 1389: train/loss = 0.6924524903297424, train/raw-loss = 0.6896686553955078, train/logprobs = tensor([[-0.8826, -1.3118],
        [-1.1092, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02783867157995701
Epoch 0, Step 1390: train/loss = 0.6945444345474243, train/raw-loss = 0.6943145990371704, train/logprobs = tensor([[-1.1572, -1.1576],
        [-1.1514, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022982372902333736
Epoch 0, Step 1391: train/loss = 0.6819466948509216, train/raw-loss = 0.6762363910675049, train/logprobs = tensor([[-1.0971, -1.4844],
        [-1.2080, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057103559374809265
Epoch 0, Step 1392: train/loss = 0.6751445531845093, train/raw-loss = 0.6711570024490356, train/logprobs = tensor([[-1.2218, -1.6294],
        [-1.2168, -1.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03987493738532066
Epoch 0, Step 1393: train/loss = 0.6839240789413452, train/raw-loss = 0.6817294359207153, train/logprobs = tensor([[-1.3287, -1.5095],
        [-1.1172, -1.0008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0219466220587492
Epoch 0, Step 1394: train/loss = 0.6755877733230591, train/raw-loss = 0.6556715965270996, train/logprobs = tensor([[-0.8360, -2.8910],
        [-1.0850, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19916127622127533
Epoch 0, Step 1395: train/loss = 0.6955217123031616, train/raw-loss = 0.6947670578956604, train/logprobs = tensor([[-1.2822, -1.3741],
        [-1.2328, -1.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007546199019998312
Epoch 0, Step 1396: train/loss = 0.666511058807373, train/raw-loss = 0.6602014899253845, train/logprobs = tensor([[-0.8453, -1.3668],
        [-1.1766, -0.8931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06309646368026733
Epoch 0, Step 1397: train/loss = 0.6901648640632629, train/raw-loss = 0.68923419713974, train/logprobs = tensor([[-1.0308, -1.2351],
        [-1.2606, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00930745154619217
Epoch 0, Step 1398: train/loss = 0.6419343948364258, train/raw-loss = 0.6282644867897034, train/logprobs = tensor([[-1.1946, -1.8774],
        [-1.4979, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13669942319393158
Epoch 0, Step 1399: train/loss = 0.6826397180557251, train/raw-loss = 0.6793148517608643, train/logprobs = tensor([[-1.1502, -1.3579],
        [-1.0831, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03324946016073227
Epoch 0, Step 1400: train/loss = 0.6034777760505676, train/raw-loss = 0.5861448049545288, train/logprobs = tensor([[-1.0580, -2.0280],
        [-1.5977, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1733298897743225
Epoch 0, Step 1401: train/loss = 0.6524779796600342, train/raw-loss = 0.6409831047058105, train/logprobs = tensor([[-0.9272, -1.5838],
        [-1.4707, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11494864523410797
Epoch 0, Step 1402: train/loss = 0.6568592190742493, train/raw-loss = 0.6506211161613464, train/logprobs = tensor([[-1.1695, -1.6121],
        [-1.2573, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0623813197016716
Epoch 0, Step 1403: train/loss = 0.6410534381866455, train/raw-loss = 0.6302236318588257, train/logprobs = tensor([[-0.7729, -1.6914],
        [-1.3419, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10829807817935944
Epoch 0, Step 1404: train/loss = 0.6988570690155029, train/raw-loss = 0.6981087923049927, train/logprobs = tensor([[-1.0250, -1.1210],
        [-1.1136, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007482517044991255
Epoch 0, Step 1405: train/loss = 0.6086938977241516, train/raw-loss = 0.5919102430343628, train/logprobs = tensor([[-1.0616, -2.2218],
        [-1.4041, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16783671081066132
Epoch 0, Step 1406: train/loss = 0.6727078557014465, train/raw-loss = 0.6680350303649902, train/logprobs = tensor([[-0.9180, -1.4136],
        [-1.2952, -0.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04672849178314209
Epoch 0, Step 1407: train/loss = 0.6397074460983276, train/raw-loss = 0.627305269241333, train/logprobs = tensor([[-1.0585, -1.9796],
        [-1.3387, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124021977186203
Epoch 0, Step 1408: train/loss = 0.7008092999458313, train/raw-loss = 0.7005608081817627, train/logprobs = tensor([[-1.2230, -1.4775],
        [-1.3074, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024851758498698473
Epoch 0, Step 1409: train/loss = 0.6781541705131531, train/raw-loss = 0.6729791760444641, train/logprobs = tensor([[-0.8944, -1.2112],
        [-1.2382, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05175051465630531
Epoch 0, Step 1410: train/loss = 0.7092630863189697, train/raw-loss = 0.7038748264312744, train/logprobs = tensor([[-1.0618, -1.1944],
        [-1.6324, -0.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05388276278972626
Epoch 0, Step 1411: train/loss = 0.6627345681190491, train/raw-loss = 0.6566879153251648, train/logprobs = tensor([[-1.1374, -1.6925],
        [-1.3345, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06046663969755173
Epoch 0, Step 1412: train/loss = 0.6564980745315552, train/raw-loss = 0.6478124856948853, train/logprobs = tensor([[-1.2099, -1.7622],
        [-1.7442, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08685582131147385
Epoch 0, Step 1413: train/loss = 0.6815891861915588, train/raw-loss = 0.6790123581886292, train/logprobs = tensor([[-1.4413, -1.6264],
        [-1.0869, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025768572464585304
Epoch 0, Step 1414: train/loss = 0.7067548036575317, train/raw-loss = 0.7046694755554199, train/logprobs = tensor([[-1.0762, -1.3166],
        [-1.4464, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02085351198911667
Epoch 0, Step 1415: train/loss = 0.6562079787254333, train/raw-loss = 0.6487815380096436, train/logprobs = tensor([[-0.8613, -1.4286],
        [-1.0442, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07426448911428452
Epoch 0, Step 1416: train/loss = 0.6433849334716797, train/raw-loss = 0.6271046996116638, train/logprobs = tensor([[-1.8017, -2.9075],
        [-1.7094, -1.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16280320286750793
Epoch 0, Step 1417: train/loss = 0.6825042366981506, train/raw-loss = 0.6796317100524902, train/logprobs = tensor([[-1.4620, -1.9746],
        [-1.0828, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02872553840279579
Epoch 0, Step 1418: train/loss = 0.6890194416046143, train/raw-loss = 0.6872232556343079, train/logprobs = tensor([[-1.4163, -1.6289],
        [-1.1893, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01796191930770874
Epoch 0, Step 1419: train/loss = 0.6238328814506531, train/raw-loss = 0.6066251993179321, train/logprobs = tensor([[-0.9570, -2.1806],
        [-1.1754, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17207692563533783
Epoch 0, Step 1420: train/loss = 0.6221580505371094, train/raw-loss = 0.6042107939720154, train/logprobs = tensor([[-1.0742, -2.6112],
        [-1.2900, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17947210371494293
Epoch 0, Step 1421: train/loss = 0.6988397836685181, train/raw-loss = 0.6986928582191467, train/logprobs = tensor([[-1.0124, -1.0245],
        [-1.0378, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014692628756165504
Epoch 0, Step 1422: train/loss = 0.6839463710784912, train/raw-loss = 0.6789342761039734, train/logprobs = tensor([[-1.0351, -1.8422],
        [-0.9885, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05012091249227524
Epoch 0, Step 1423: train/loss = 0.697111964225769, train/raw-loss = 0.6970558166503906, train/logprobs = tensor([[-1.0295, -1.0327],
        [-1.0869, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005614272085949779
Epoch 0, Step 1424: train/loss = 0.6023341417312622, train/raw-loss = 0.5876280665397644, train/logprobs = tensor([[-1.3051, -2.5120],
        [-1.4655, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14706061780452728
Epoch 0, Step 1425: train/loss = 0.6862585544586182, train/raw-loss = 0.6822083592414856, train/logprobs = tensor([[-1.0084, -1.4593],
        [-1.4480, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040502890944480896
Epoch 0, Step 1426: train/loss = 0.6770619750022888, train/raw-loss = 0.6701315641403198, train/logprobs = tensor([[-1.5110, -1.9984],
        [-1.3775, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06930398941040039
Epoch 0, Step 1427: train/loss = 0.729421079158783, train/raw-loss = 0.7099677324295044, train/logprobs = tensor([[-1.2958, -3.1380],
        [-1.3445, -1.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19453385472297668
Epoch 0, Step 1428: train/loss = 0.5877543687820435, train/raw-loss = 0.5673198103904724, train/logprobs = tensor([[-1.1425, -2.3461],
        [-1.6118, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20434555411338806
Epoch 0, Step 1429: train/loss = 0.6884962320327759, train/raw-loss = 0.6866929531097412, train/logprobs = tensor([[-0.8596, -1.2219],
        [-1.1414, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01803310215473175
Epoch 0, Step 1430: train/loss = 0.6409425735473633, train/raw-loss = 0.6261146068572998, train/logprobs = tensor([[-1.0016, -2.0995],
        [-1.3908, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14827971160411835
Epoch 0, Step 1431: train/loss = 0.6039146184921265, train/raw-loss = 0.5973334312438965, train/logprobs = tensor([[-1.2157, -1.7452],
        [-1.7691, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06581214815378189
Epoch 0, Step 1432: train/loss = 0.6313391327857971, train/raw-loss = 0.6217151880264282, train/logprobs = tensor([[-0.8668, -1.3755],
        [-1.6980, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09623963385820389
Epoch 0, Step 1433: train/loss = 0.6861972212791443, train/raw-loss = 0.6827976107597351, train/logprobs = tensor([[-1.1827, -1.5532],
        [-1.1245, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03399593010544777
Epoch 0, Step 1434: train/loss = 0.6680549383163452, train/raw-loss = 0.6627901792526245, train/logprobs = tensor([[-0.9198, -1.3713],
        [-1.1493, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0526471771299839
Epoch 0, Step 1435: train/loss = 0.6566046476364136, train/raw-loss = 0.6470626592636108, train/logprobs = tensor([[-1.1704, -1.5181],
        [-1.4037, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541992843151093
Epoch 0, Step 1436: train/loss = 0.7108316421508789, train/raw-loss = 0.709098756313324, train/logprobs = tensor([[-1.0312, -1.5342],
        [-1.3477, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01732894405722618
Epoch 0, Step 1437: train/loss = 0.7028013467788696, train/raw-loss = 0.700879693031311, train/logprobs = tensor([[-1.0766, -1.2157],
        [-1.2110, -0.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019216138869524002
Epoch 0, Step 1438: train/loss = 0.6670824885368347, train/raw-loss = 0.6565427780151367, train/logprobs = tensor([[-1.0672, -1.8319],
        [-1.5406, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1053975373506546
Epoch 0, Step 1439: train/loss = 0.6776684522628784, train/raw-loss = 0.6717039346694946, train/logprobs = tensor([[-1.0584, -1.6641],
        [-1.2765, -1.3225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05964510142803192
Epoch 0, Step 1440: train/loss = 0.6654714941978455, train/raw-loss = 0.6522395610809326, train/logprobs = tensor([[-1.2940, -2.7160],
        [-1.3319, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13231858611106873
Epoch 0, Step 1441: train/loss = 0.6298454403877258, train/raw-loss = 0.622307300567627, train/logprobs = tensor([[-1.2265, -2.0869],
        [-0.9042, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07538114488124847
Epoch 0, Step 1442: train/loss = 0.6225633025169373, train/raw-loss = 0.6067534685134888, train/logprobs = tensor([[-1.4562, -2.4494],
        [-1.2168, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15809842944145203
Epoch 0, Step 1443: train/loss = 0.626762866973877, train/raw-loss = 0.6089258193969727, train/logprobs = tensor([[-1.2082, -2.2499],
        [-1.7010, -1.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1783696860074997
Epoch 0, Step 1444: train/loss = 0.7095943689346313, train/raw-loss = 0.7091016173362732, train/logprobs = tensor([[-1.3661, -1.6127],
        [-1.5378, -1.3851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004927475471049547
Epoch 0, Step 1445: train/loss = 0.6467041373252869, train/raw-loss = 0.6375371217727661, train/logprobs = tensor([[-1.3344, -2.0779],
        [-1.3869, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09167031943798065
Epoch 0, Step 1446: train/loss = 0.6017880439758301, train/raw-loss = 0.5772433876991272, train/logprobs = tensor([[-0.9805, -2.0383],
        [-1.4272, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24544689059257507
Epoch 0, Step 1447: train/loss = 0.6603571772575378, train/raw-loss = 0.6530776023864746, train/logprobs = tensor([[-1.1510, -1.6527],
        [-1.0566, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07279522716999054
Epoch 0, Step 1448: train/loss = 0.6693085432052612, train/raw-loss = 0.6631274223327637, train/logprobs = tensor([[-0.8676, -1.4846],
        [-1.0194, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06181124225258827
Epoch 0, Step 1449: train/loss = 0.6273825764656067, train/raw-loss = 0.6113675236701965, train/logprobs = tensor([[-1.1175, -1.9886],
        [-1.5341, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16015061736106873
Epoch 0, Step 1450: train/loss = 0.6551206707954407, train/raw-loss = 0.645938515663147, train/logprobs = tensor([[-2.4065, -3.2591],
        [-1.3776, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182164072990417
Epoch 0, Step 1451: train/loss = 0.6815158128738403, train/raw-loss = 0.6772465705871582, train/logprobs = tensor([[-1.2159, -1.2781],
        [-1.7251, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04269212484359741
Epoch 0, Step 1452: train/loss = 0.6392620801925659, train/raw-loss = 0.6267191171646118, train/logprobs = tensor([[-1.0991, -1.8119],
        [-1.0943, -0.7115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12542977929115295
Epoch 0, Step 1453: train/loss = 0.6368550062179565, train/raw-loss = 0.6250056624412537, train/logprobs = tensor([[-1.2746, -1.9507],
        [-1.3541, -0.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11849376559257507
Epoch 0, Step 1454: train/loss = 0.6249896883964539, train/raw-loss = 0.6103805899620056, train/logprobs = tensor([[-1.5143, -2.3946],
        [-1.3554, -0.9873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14609113335609436
Epoch 0, Step 1455: train/loss = 0.6384994387626648, train/raw-loss = 0.6263778805732727, train/logprobs = tensor([[-1.0952, -2.0328],
        [-1.4658, -1.0996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212158203125
Epoch 0, Step 1456: train/loss = 0.5579028725624084, train/raw-loss = 0.5325643420219421, train/logprobs = tensor([[-1.0462, -3.0714],
        [-1.5564, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253385066986084
Epoch 0, Step 1457: train/loss = 0.5830539464950562, train/raw-loss = 0.564458429813385, train/logprobs = tensor([[-1.0179, -2.4740],
        [-1.7248, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18595509231090546
Epoch 0, Step 1458: train/loss = 0.6536203026771545, train/raw-loss = 0.6448779106140137, train/logprobs = tensor([[-1.0748, -1.8805],
        [-1.1572, -0.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08742402493953705
Epoch 0, Step 1459: train/loss = 0.7188462615013123, train/raw-loss = 0.7171042561531067, train/logprobs = tensor([[-1.2839, -1.2111],
        [-1.1954, -0.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017420269548892975
Epoch 0, Step 1460: train/loss = 0.6474428772926331, train/raw-loss = 0.6370839476585388, train/logprobs = tensor([[-1.5282, -2.1107],
        [-1.5117, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358965396881104
Epoch 0, Step 1461: train/loss = 0.6219669580459595, train/raw-loss = 0.6053853034973145, train/logprobs = tensor([[-1.2725, -2.5822],
        [-1.2838, -0.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16581635177135468
Epoch 0, Step 1462: train/loss = 0.6732702255249023, train/raw-loss = 0.6685911417007446, train/logprobs = tensor([[-1.5058, -2.0651],
        [-1.1122, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04679102078080177
Epoch 0, Step 1463: train/loss = 0.6954599618911743, train/raw-loss = 0.6952557563781738, train/logprobs = tensor([[-1.7500, -1.7517],
        [-1.3251, -1.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020417459309101105
Epoch 0, Step 1464: train/loss = 0.6867384314537048, train/raw-loss = 0.68169766664505, train/logprobs = tensor([[-1.0299, -1.6214],
        [-1.4019, -1.2361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05040740966796875
Epoch 0, Step 1465: train/loss = 0.6756126880645752, train/raw-loss = 0.6742371916770935, train/logprobs = tensor([[-1.1024, -1.2785],
        [-1.4545, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01375526748597622
Epoch 0, Step 1466: train/loss = 0.6785601377487183, train/raw-loss = 0.666085958480835, train/logprobs = tensor([[-1.5716, -2.8074],
        [-1.2975, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12474095076322556
Epoch 0, Step 1467: train/loss = 0.6793617010116577, train/raw-loss = 0.6736739873886108, train/logprobs = tensor([[-1.4304, -1.8392],
        [-1.5398, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05687668174505234
Epoch 0, Step 1468: train/loss = 0.5628086924552917, train/raw-loss = 0.5363300442695618, train/logprobs = tensor([[-2.0980, -3.2934],
        [-1.5822, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26478642225265503
Epoch 0, Step 1469: train/loss = 0.6913840174674988, train/raw-loss = 0.6908949613571167, train/logprobs = tensor([[-1.4548, -1.5610],
        [-1.2472, -1.2478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004890651907771826
Epoch 0, Step 1470: train/loss = 0.647181510925293, train/raw-loss = 0.6366803646087646, train/logprobs = tensor([[-1.4406, -2.0401],
        [-1.2582, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1050119400024414
Epoch 0, Step 1471: train/loss = 0.6461368203163147, train/raw-loss = 0.6361559629440308, train/logprobs = tensor([[-1.1576, -2.0406],
        [-1.2687, -1.0372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980873018503189
Epoch 0, Step 1472: train/loss = 0.6976703405380249, train/raw-loss = 0.6917945146560669, train/logprobs = tensor([[-1.9086, -2.1436],
        [-1.3561, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0587582103908062
Epoch 0, Step 1473: train/loss = 0.631554365158081, train/raw-loss = 0.6139054894447327, train/logprobs = tensor([[-1.2072, -1.9075],
        [-1.7585, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17648860812187195
Epoch 0, Step 1474: train/loss = 0.6927549839019775, train/raw-loss = 0.6854921579360962, train/logprobs = tensor([[-1.6483, -2.3702],
        [-1.5755, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07262784242630005
Epoch 0, Step 1475: train/loss = 0.6681874990463257, train/raw-loss = 0.6549012660980225, train/logprobs = tensor([[-1.4315, -1.2621],
        [-1.7885, -1.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13286298513412476
Epoch 0, Step 1476: train/loss = 0.6891729831695557, train/raw-loss = 0.6864330768585205, train/logprobs = tensor([[-1.4479, -1.6197],
        [-1.2279, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027398426085710526
Epoch 0, Step 1477: train/loss = 0.6845439672470093, train/raw-loss = 0.6802077293395996, train/logprobs = tensor([[-1.4177, -1.5091],
        [-1.2150, -0.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043362636119127274
Epoch 0, Step 1478: train/loss = 0.6656898856163025, train/raw-loss = 0.6547824144363403, train/logprobs = tensor([[-1.6919, -1.3992],
        [-1.1561, -0.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907471179962158
Epoch 0, Step 1479: train/loss = 0.6422909498214722, train/raw-loss = 0.6289874315261841, train/logprobs = tensor([[-1.5082, -2.1604],
        [-1.6015, -0.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13303570449352264
Epoch 0, Step 1480: train/loss = 0.6613469123840332, train/raw-loss = 0.6529622077941895, train/logprobs = tensor([[-1.6408, -2.4184],
        [-1.2548, -1.0443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384710550308228
Epoch 0, Step 1481: train/loss = 0.7049428224563599, train/raw-loss = 0.7039746046066284, train/logprobs = tensor([[-1.2043, -1.1396],
        [-1.2599, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0096818208694458
Epoch 0, Step 1482: train/loss = 0.6523364782333374, train/raw-loss = 0.6406323313713074, train/logprobs = tensor([[-1.3257, -1.8685],
        [-1.0349, -0.6616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11704098433256149
Epoch 0, Step 1483: train/loss = 0.6918085813522339, train/raw-loss = 0.6863842606544495, train/logprobs = tensor([[-0.9527, -1.3269],
        [-1.1068, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05424300953745842
Epoch 0, Step 1484: train/loss = 0.5888453722000122, train/raw-loss = 0.5646450519561768, train/logprobs = tensor([[-1.3588, -2.7109],
        [-1.3780, -0.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24200300872325897
Epoch 0, Step 1485: train/loss = 0.5741872191429138, train/raw-loss = 0.5481922626495361, train/logprobs = tensor([[-1.1162, -2.9586],
        [-1.5876, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25994956493377686
Epoch 0, Step 1486: train/loss = 0.6113015413284302, train/raw-loss = 0.5935036540031433, train/logprobs = tensor([[-2.5856, -3.7893],
        [-1.1192, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17797869443893433
Epoch 0, Step 1487: train/loss = 0.6477867364883423, train/raw-loss = 0.6347720623016357, train/logprobs = tensor([[-1.2089, -2.1368],
        [-1.1566, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301470696926117
Epoch 0, Step 1488: train/loss = 0.7253623008728027, train/raw-loss = 0.7239804267883301, train/logprobs = tensor([[-1.7793, -1.5132],
        [-1.1500, -0.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013818612322211266
Epoch 0, Step 1489: train/loss = 0.6840167045593262, train/raw-loss = 0.6796134114265442, train/logprobs = tensor([[-1.2491, -1.6500],
        [-1.5094, -1.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044032368808984756
Epoch 0, Step 1490: train/loss = 0.677617609500885, train/raw-loss = 0.6697480082511902, train/logprobs = tensor([[-1.2605, -1.5512],
        [-1.4760, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07869662344455719
Epoch 0, Step 1491: train/loss = 0.5923013091087341, train/raw-loss = 0.5716623067855835, train/logprobs = tensor([[-0.9099, -2.6087],
        [-1.6036, -1.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20639029145240784
Epoch 0, Step 1492: train/loss = 0.6285588145256042, train/raw-loss = 0.6149657964706421, train/logprobs = tensor([[-1.1669, -2.0371],
        [-1.2564, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359299123287201
Epoch 0, Step 1493: train/loss = 0.6819431781768799, train/raw-loss = 0.6748242974281311, train/logprobs = tensor([[-0.8926, -1.6214],
        [-1.3346, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07118900865316391
Epoch 0, Step 1494: train/loss = 0.6845603585243225, train/raw-loss = 0.6823245882987976, train/logprobs = tensor([[-1.3456, -1.4763],
        [-1.2371, -0.9715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02235698141157627
Epoch 0, Step 1495: train/loss = 0.6253863573074341, train/raw-loss = 0.606334924697876, train/logprobs = tensor([[-1.3810, -2.9223],
        [-1.2798, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1905139833688736
Epoch 0, Step 1496: train/loss = 0.6965420246124268, train/raw-loss = 0.6904349327087402, train/logprobs = tensor([[-0.8841, -1.4380],
        [-1.0839, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06107095628976822
Epoch 0, Step 1497: train/loss = 0.6480481624603271, train/raw-loss = 0.6343528032302856, train/logprobs = tensor([[-1.4969, -1.9866],
        [-1.5670, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13695397973060608
Epoch 0, Step 1498: train/loss = 0.637671947479248, train/raw-loss = 0.6189559698104858, train/logprobs = tensor([[-1.1363, -2.5464],
        [-1.3611, -1.3987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18715983629226685
Epoch 0, Step 1499: train/loss = 0.6417281031608582, train/raw-loss = 0.6272403597831726, train/logprobs = tensor([[-1.6861, -2.5094],
        [-1.2847, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1448773741722107
eval/loss: 0.6478682160377502
Epoch 0, Step 1500: train/loss = 0.6819010972976685, train/raw-loss = 0.6765024662017822, train/logprobs = tensor([[-1.0545, -2.0037],
        [-0.8572, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05398612469434738
Epoch 0, Step 1501: train/loss = 0.660698413848877, train/raw-loss = 0.6501494646072388, train/logprobs = tensor([[-2.0777, -2.4150],
        [-1.3799, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10548949986696243
Epoch 0, Step 1502: train/loss = 0.6597996354103088, train/raw-loss = 0.6483789682388306, train/logprobs = tensor([[-1.8404, -2.4364],
        [-1.2821, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1142064705491066
Epoch 0, Step 1503: train/loss = 0.6911270618438721, train/raw-loss = 0.6837077736854553, train/logprobs = tensor([[-1.1368, -1.8211],
        [-1.2596, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07419195026159286
Epoch 0, Step 1504: train/loss = 0.625730037689209, train/raw-loss = 0.6175928115844727, train/logprobs = tensor([[-1.8690, -2.5539],
        [-1.7263, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08137257397174835
Epoch 0, Step 1505: train/loss = 0.6718900799751282, train/raw-loss = 0.6664965152740479, train/logprobs = tensor([[-1.5674, -2.1441],
        [-1.0551, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053936153650283813
Epoch 0, Step 1506: train/loss = 0.612655758857727, train/raw-loss = 0.5908021330833435, train/logprobs = tensor([[-1.3208, -2.2615],
        [-1.5648, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853622794151306
Epoch 0, Step 1507: train/loss = 0.5775296688079834, train/raw-loss = 0.5496214628219604, train/logprobs = tensor([[-1.2647, -2.8686],
        [-1.1541, -0.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27908167243003845
Epoch 0, Step 1508: train/loss = 0.6894015669822693, train/raw-loss = 0.6820824146270752, train/logprobs = tensor([[-1.4122, -2.1240],
        [-0.9970, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07319173961877823
Epoch 0, Step 1509: train/loss = 0.6502434015274048, train/raw-loss = 0.6343836188316345, train/logprobs = tensor([[-1.2167, -2.4921],
        [-1.2628, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15859800577163696
Epoch 0, Step 1510: train/loss = 0.6186901926994324, train/raw-loss = 0.6003957986831665, train/logprobs = tensor([[-1.3858, -2.3063],
        [-1.3740, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829441785812378
Epoch 0, Step 1511: train/loss = 0.6401509046554565, train/raw-loss = 0.628477156162262, train/logprobs = tensor([[-1.0099, -1.7784],
        [-1.3740, -0.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673778295516968
Epoch 0, Step 1512: train/loss = 0.6609886884689331, train/raw-loss = 0.6525898575782776, train/logprobs = tensor([[-1.6953, -2.2295],
        [-1.3914, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08398835361003876
Epoch 0, Step 1513: train/loss = 0.5934165716171265, train/raw-loss = 0.5722213983535767, train/logprobs = tensor([[-0.9954, -2.3957],
        [-1.1870, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2119518220424652
Epoch 0, Step 1514: train/loss = 0.6554291248321533, train/raw-loss = 0.6436289548873901, train/logprobs = tensor([[-1.4154, -2.5408],
        [-1.3840, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800159513950348
Epoch 0, Step 1515: train/loss = 0.6589489579200745, train/raw-loss = 0.6494818329811096, train/logprobs = tensor([[-1.1659, -1.8634],
        [-1.1680, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09467143565416336
Epoch 0, Step 1516: train/loss = 0.6481517553329468, train/raw-loss = 0.6379179358482361, train/logprobs = tensor([[-1.2680, -2.1169],
        [-1.1181, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10233859717845917
Epoch 0, Step 1517: train/loss = 0.6963537931442261, train/raw-loss = 0.6933535933494568, train/logprobs = tensor([[-1.2164, -1.3692],
        [-1.2917, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030002258718013763
Epoch 0, Step 1518: train/loss = 0.6976566314697266, train/raw-loss = 0.6923969388008118, train/logprobs = tensor([[-1.6621, -2.2389],
        [-1.3012, -1.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052597444504499435
Epoch 0, Step 1519: train/loss = 0.6378653049468994, train/raw-loss = 0.6229662895202637, train/logprobs = tensor([[-1.6469, -2.9636],
        [-1.0127, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14898979663848877
Epoch 0, Step 1520: train/loss = 0.6512598395347595, train/raw-loss = 0.6407321095466614, train/logprobs = tensor([[-2.0165, -2.7114],
        [-1.2634, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10527735203504562
Epoch 0, Step 1521: train/loss = 0.6548680067062378, train/raw-loss = 0.6438469886779785, train/logprobs = tensor([[-1.5703, -2.1257],
        [-1.4779, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11021038889884949
Epoch 0, Step 1522: train/loss = 0.6164975166320801, train/raw-loss = 0.5990391969680786, train/logprobs = tensor([[-1.2255, -2.2568],
        [-1.3864, -0.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17458252608776093
Epoch 0, Step 1523: train/loss = 0.6633047461509705, train/raw-loss = 0.6578002572059631, train/logprobs = tensor([[-1.5119, -1.9162],
        [-1.3438, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055044736713171005
Epoch 0, Step 1524: train/loss = 0.6006152629852295, train/raw-loss = 0.5791060328483582, train/logprobs = tensor([[-1.1352, -2.3169],
        [-1.5074, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21509253978729248
Epoch 0, Step 1525: train/loss = 0.6059003472328186, train/raw-loss = 0.585618257522583, train/logprobs = tensor([[-1.5817, -2.7348],
        [-1.2227, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2028210610151291
Epoch 0, Step 1526: train/loss = 0.6420632004737854, train/raw-loss = 0.6295573711395264, train/logprobs = tensor([[-1.7545, -2.4086],
        [-1.0202, -0.6339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1250581592321396
Epoch 0, Step 1527: train/loss = 0.6314793229103088, train/raw-loss = 0.6176889538764954, train/logprobs = tensor([[-0.9217, -1.7977],
        [-1.6925, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13790351152420044
Epoch 0, Step 1528: train/loss = 0.654789388179779, train/raw-loss = 0.6447523832321167, train/logprobs = tensor([[-1.1308, -1.6382],
        [-1.2939, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10037023574113846
Epoch 0, Step 1529: train/loss = 0.7110239267349243, train/raw-loss = 0.7104943990707397, train/logprobs = tensor([[-1.0428, -1.1208],
        [-1.1882, -1.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005295518320053816
Epoch 0, Step 1530: train/loss = 0.7001328468322754, train/raw-loss = 0.6999155879020691, train/logprobs = tensor([[-1.2520, -1.5620],
        [-1.0698, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002173008630052209
Epoch 0, Step 1531: train/loss = 0.693487286567688, train/raw-loss = 0.6915004849433899, train/logprobs = tensor([[-1.2099, -1.4112],
        [-1.0169, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0198676660656929
Epoch 0, Step 1532: train/loss = 0.6259799599647522, train/raw-loss = 0.6083323955535889, train/logprobs = tensor([[-1.4871, -2.7867],
        [-1.3105, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17647536098957062
Epoch 0, Step 1533: train/loss = 0.6131018996238708, train/raw-loss = 0.5971349477767944, train/logprobs = tensor([[-1.3388, -2.4411],
        [-1.3043, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15966898202896118
Epoch 0, Step 1534: train/loss = 0.6502797603607178, train/raw-loss = 0.6303375363349915, train/logprobs = tensor([[-1.7754, -2.5901],
        [-1.9826, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19942229986190796
Epoch 0, Step 1535: train/loss = 0.6948294639587402, train/raw-loss = 0.6947256326675415, train/logprobs = tensor([[-1.0213, -0.9532],
        [-1.4613, -1.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010375562123954296
Epoch 0, Step 1536: train/loss = 0.6113085746765137, train/raw-loss = 0.594367504119873, train/logprobs = tensor([[-1.4148, -2.6560],
        [-1.1799, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16941098868846893
Epoch 0, Step 1537: train/loss = 0.5431531071662903, train/raw-loss = 0.5070497989654541, train/logprobs = tensor([[-1.6967, -3.5073],
        [-1.4484, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36103251576423645
Epoch 0, Step 1538: train/loss = 0.6072202920913696, train/raw-loss = 0.5837064385414124, train/logprobs = tensor([[-1.3756, -2.8143],
        [-1.3610, -0.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23513823747634888
Epoch 0, Step 1539: train/loss = 0.6451387405395508, train/raw-loss = 0.629426121711731, train/logprobs = tensor([[-1.6746, -2.8369],
        [-1.4289, -1.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15712666511535645
Epoch 0, Step 1540: train/loss = 0.6521359086036682, train/raw-loss = 0.637175440788269, train/logprobs = tensor([[-1.6501, -2.4251],
        [-1.3444, -0.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1496047079563141
Epoch 0, Step 1541: train/loss = 0.6414862275123596, train/raw-loss = 0.6290278434753418, train/logprobs = tensor([[-1.8415, -2.4304],
        [-0.8672, -0.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12458429485559464
Epoch 0, Step 1542: train/loss = 0.6730818748474121, train/raw-loss = 0.6641242504119873, train/logprobs = tensor([[-1.1280, -1.9518],
        [-1.1554, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957673609256744
Epoch 0, Step 1543: train/loss = 0.672655463218689, train/raw-loss = 0.6659213304519653, train/logprobs = tensor([[-1.9897, -2.1970],
        [-1.3422, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0673416331410408
Epoch 0, Step 1544: train/loss = 0.5609080791473389, train/raw-loss = 0.5268402695655823, train/logprobs = tensor([[-1.3973, -3.5646],
        [-1.5681, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3406778872013092
Epoch 0, Step 1545: train/loss = 0.6495993733406067, train/raw-loss = 0.6417036056518555, train/logprobs = tensor([[-1.4122, -1.9902],
        [-1.2587, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07895791530609131
Epoch 0, Step 1546: train/loss = 0.696346640586853, train/raw-loss = 0.6930468082427979, train/logprobs = tensor([[-1.9387, -1.5965],
        [-1.1390, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299879655241966
Epoch 0, Step 1547: train/loss = 0.629683256149292, train/raw-loss = 0.6140022277832031, train/logprobs = tensor([[-2.5813, -2.9539],
        [-1.0822, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15680968761444092
Epoch 0, Step 1548: train/loss = 0.712223470211029, train/raw-loss = 0.7089512348175049, train/logprobs = tensor([[-0.9410, -1.6530],
        [-0.8092, -0.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03272201120853424
Epoch 0, Step 1549: train/loss = 0.6288530230522156, train/raw-loss = 0.6147336363792419, train/logprobs = tensor([[-1.3138, -2.1135],
        [-1.4059, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14119425415992737
Epoch 0, Step 1550: train/loss = 0.7314540147781372, train/raw-loss = 0.7223372459411621, train/logprobs = tensor([[-1.1618, -2.1793],
        [-1.3458, -1.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09116780757904053
Epoch 0, Step 1551: train/loss = 0.5750226974487305, train/raw-loss = 0.5516207218170166, train/logprobs = tensor([[-1.3303, -2.9830],
        [-1.4926, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23401981592178345
Epoch 0, Step 1552: train/loss = 0.7288517951965332, train/raw-loss = 0.7254478931427002, train/logprobs = tensor([[-1.7945, -1.5276],
        [-1.2328, -0.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03403891250491142
Epoch 0, Step 1553: train/loss = 0.6731818914413452, train/raw-loss = 0.6650558710098267, train/logprobs = tensor([[-1.4468, -2.3438],
        [-0.9788, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08125943690538406
Epoch 0, Step 1554: train/loss = 0.654267430305481, train/raw-loss = 0.6389615535736084, train/logprobs = tensor([[-1.5596, -2.7529],
        [-1.5671, -1.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15305839478969574
Epoch 0, Step 1555: train/loss = 0.6250595450401306, train/raw-loss = 0.607840359210968, train/logprobs = tensor([[-1.2764, -2.2113],
        [-1.2779, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17219212651252747
Epoch 0, Step 1556: train/loss = 0.6462690234184265, train/raw-loss = 0.6336622834205627, train/logprobs = tensor([[-1.3126, -2.0633],
        [-1.5151, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12606771290302277
Epoch 0, Step 1557: train/loss = 0.6135820150375366, train/raw-loss = 0.5932394862174988, train/logprobs = tensor([[-1.7112, -3.0027],
        [-1.6592, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20342552661895752
Epoch 0, Step 1558: train/loss = 0.6360465288162231, train/raw-loss = 0.6183127164840698, train/logprobs = tensor([[-2.2571, -2.9319],
        [-1.2820, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17733806371688843
Epoch 0, Step 1559: train/loss = 0.6196732521057129, train/raw-loss = 0.6023564338684082, train/logprobs = tensor([[-1.1467, -2.0317],
        [-1.2839, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17316848039627075
Epoch 0, Step 1560: train/loss = 0.6779527068138123, train/raw-loss = 0.6713972091674805, train/logprobs = tensor([[-1.4100, -1.8399],
        [-1.1916, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06555522233247757
Epoch 0, Step 1561: train/loss = 0.5631745457649231, train/raw-loss = 0.533293604850769, train/logprobs = tensor([[-1.5488, -3.1831],
        [-1.7936, -1.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.298809289932251
Epoch 0, Step 1562: train/loss = 0.639300525188446, train/raw-loss = 0.6256846189498901, train/logprobs = tensor([[-1.2235, -2.3771],
        [-1.3654, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361587941646576
Epoch 0, Step 1563: train/loss = 0.6488019227981567, train/raw-loss = 0.6375012993812561, train/logprobs = tensor([[-1.5677, -1.9754],
        [-1.0886, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11300595104694366
Epoch 0, Step 1564: train/loss = 0.6480987071990967, train/raw-loss = 0.6359286308288574, train/logprobs = tensor([[-1.2510, -2.1574],
        [-1.3829, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12170033156871796
Epoch 0, Step 1565: train/loss = 0.5896875262260437, train/raw-loss = 0.5774924755096436, train/logprobs = tensor([[-1.3498, -2.1933],
        [-1.8685, -1.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121950663626194
Epoch 0, Step 1566: train/loss = 0.6345707774162292, train/raw-loss = 0.6201658248901367, train/logprobs = tensor([[-2.4387, -3.1303],
        [-1.5060, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14404979348182678
Epoch 0, Step 1567: train/loss = 0.676296591758728, train/raw-loss = 0.6681857705116272, train/logprobs = tensor([[-1.5324, -2.1773],
        [-1.3120, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08110856264829636
Epoch 0, Step 1568: train/loss = 0.5980933904647827, train/raw-loss = 0.5678098797798157, train/logprobs = tensor([[-1.3068, -3.4195],
        [-1.2752, -1.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30283498764038086
Epoch 0, Step 1569: train/loss = 0.6121687889099121, train/raw-loss = 0.5979470014572144, train/logprobs = tensor([[-1.2390, -2.1463],
        [-1.3741, -0.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422177106142044
Epoch 0, Step 1570: train/loss = 0.5933957099914551, train/raw-loss = 0.5675169825553894, train/logprobs = tensor([[-0.9965, -2.8646],
        [-1.6694, -1.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2587869167327881
Epoch 0, Step 1571: train/loss = 0.623664379119873, train/raw-loss = 0.6064414978027344, train/logprobs = tensor([[-2.2662, -2.9080],
        [-1.4593, -0.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17222830653190613
Epoch 0, Step 1572: train/loss = 0.6442708969116211, train/raw-loss = 0.6304546594619751, train/logprobs = tensor([[-1.4946, -2.1070],
        [-1.1980, -0.7282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13816222548484802
Epoch 0, Step 1573: train/loss = 0.5554882884025574, train/raw-loss = 0.5285317897796631, train/logprobs = tensor([[-1.1981, -3.2369],
        [-1.6228, -1.1163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26956528425216675
Epoch 0, Step 1574: train/loss = 0.5806141495704651, train/raw-loss = 0.5568259358406067, train/logprobs = tensor([[-1.3734, -2.5605],
        [-1.4977, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23788180947303772
Epoch 0, Step 1575: train/loss = 0.5029851198196411, train/raw-loss = 0.46959376335144043, train/logprobs = tensor([[-1.0731, -3.0618],
        [-1.8557, -0.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339133560657501
Epoch 0, Step 1576: train/loss = 0.6306051015853882, train/raw-loss = 0.6151829957962036, train/logprobs = tensor([[-1.2382, -1.9863],
        [-1.2928, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15422123670578003
Epoch 0, Step 1577: train/loss = 0.6573055982589722, train/raw-loss = 0.6479616165161133, train/logprobs = tensor([[-1.9577, -2.3201],
        [-1.0987, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09344013780355453
Epoch 0, Step 1578: train/loss = 0.5744651556015015, train/raw-loss = 0.5497471690177917, train/logprobs = tensor([[-1.1403, -2.4409],
        [-1.4094, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24717964231967926
Epoch 0, Step 1579: train/loss = 0.6574984788894653, train/raw-loss = 0.6432526111602783, train/logprobs = tensor([[-1.8698, -2.5959],
        [-1.1604, -0.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424584686756134
Epoch 0, Step 1580: train/loss = 0.6467469930648804, train/raw-loss = 0.6349902153015137, train/logprobs = tensor([[-1.8457, -2.7292],
        [-0.9513, -0.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756844818592072
Epoch 0, Step 1581: train/loss = 0.6923555135726929, train/raw-loss = 0.6910791397094727, train/logprobs = tensor([[-2.0373, -2.2427],
        [-1.0998, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012763136066496372
Epoch 0, Step 1582: train/loss = 0.6388455033302307, train/raw-loss = 0.6276252865791321, train/logprobs = tensor([[-1.5821, -2.3028],
        [-1.2171, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220212280750275
Epoch 0, Step 1583: train/loss = 0.5355868935585022, train/raw-loss = 0.5031377077102661, train/logprobs = tensor([[-1.7099, -3.7997],
        [-1.6533, -1.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32449206709861755
Epoch 0, Step 1584: train/loss = 0.6109229326248169, train/raw-loss = 0.5941042304039001, train/logprobs = tensor([[-1.2276, -2.4454],
        [-1.4506, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16818749904632568
Epoch 0, Step 1585: train/loss = 0.5834100246429443, train/raw-loss = 0.5567402839660645, train/logprobs = tensor([[-2.7579, -4.3710],
        [-1.2291, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26669731736183167
Epoch 0, Step 1586: train/loss = 0.6739744544029236, train/raw-loss = 0.6648885011672974, train/logprobs = tensor([[-1.2746, -1.6909],
        [-1.3289, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0908593088388443
Epoch 0, Step 1587: train/loss = 0.634671688079834, train/raw-loss = 0.6205730438232422, train/logprobs = tensor([[-1.7940, -2.5608],
        [-1.2937, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1409856528043747
Epoch 0, Step 1588: train/loss = 0.5675985217094421, train/raw-loss = 0.540397584438324, train/logprobs = tensor([[-2.1390, -3.7337],
        [-1.3788, -0.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27200955152511597
Epoch 0, Step 1589: train/loss = 0.6753703355789185, train/raw-loss = 0.6633524894714355, train/logprobs = tensor([[-1.3957, -2.2114],
        [-1.1962, -1.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12017886340618134
Epoch 0, Step 1590: train/loss = 0.6134548187255859, train/raw-loss = 0.5935447812080383, train/logprobs = tensor([[-1.6225, -2.4818],
        [-1.5682, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19910071790218353
Epoch 0, Step 1591: train/loss = 0.5966432690620422, train/raw-loss = 0.5736857056617737, train/logprobs = tensor([[-1.5640, -2.7168],
        [-1.5362, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22957547008991241
Epoch 0, Step 1592: train/loss = 0.6217285394668579, train/raw-loss = 0.6043676137924194, train/logprobs = tensor([[-1.8250, -2.8649],
        [-1.3817, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17360903322696686
Epoch 0, Step 1593: train/loss = 0.6674154996871948, train/raw-loss = 0.6593097448348999, train/logprobs = tensor([[-1.6415, -2.4654],
        [-1.4303, -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08105738461017609
Epoch 0, Step 1594: train/loss = 0.6328250765800476, train/raw-loss = 0.6200188398361206, train/logprobs = tensor([[-1.4605, -2.1434],
        [-1.5481, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12806236743927002
Epoch 0, Step 1595: train/loss = 0.636772632598877, train/raw-loss = 0.6231415867805481, train/logprobs = tensor([[-1.7815, -2.5176],
        [-1.2713, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1363104283809662
Epoch 0, Step 1596: train/loss = 0.6542602777481079, train/raw-loss = 0.6430612206459045, train/logprobs = tensor([[-1.2201, -2.0903],
        [-0.9861, -0.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11199097335338593
Epoch 0, Step 1597: train/loss = 0.596143901348114, train/raw-loss = 0.5750625133514404, train/logprobs = tensor([[-2.3546, -3.7920],
        [-1.1897, -0.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21081435680389404
Epoch 0, Step 1598: train/loss = 0.6257367134094238, train/raw-loss = 0.611160159111023, train/logprobs = tensor([[-1.9836, -2.5130],
        [-1.4786, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1457655280828476
Epoch 0, Step 1599: train/loss = 0.5797982215881348, train/raw-loss = 0.5515633821487427, train/logprobs = tensor([[-1.3348, -3.3343],
        [-1.4066, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2823483347892761
Epoch 0, Step 1600: train/loss = 0.5909214615821838, train/raw-loss = 0.5666123628616333, train/logprobs = tensor([[-1.3924, -2.9939],
        [-1.3921, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24309062957763672
Epoch 0, Step 1601: train/loss = 0.6944395899772644, train/raw-loss = 0.6873675584793091, train/logprobs = tensor([[-1.4506, -1.5385],
        [-1.5575, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07072017341852188
Epoch 0, Step 1602: train/loss = 0.5940041542053223, train/raw-loss = 0.5717179775238037, train/logprobs = tensor([[-1.4824, -3.3508],
        [-1.5513, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2228621244430542
Epoch 0, Step 1603: train/loss = 0.5492311120033264, train/raw-loss = 0.5132838487625122, train/logprobs = tensor([[-1.9703, -4.1744],
        [-1.6264, -0.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35947340726852417
Epoch 0, Step 1604: train/loss = 0.6052409410476685, train/raw-loss = 0.5803072452545166, train/logprobs = tensor([[-1.4264, -3.0945],
        [-1.2580, -0.8276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24933628737926483
Epoch 0, Step 1605: train/loss = 0.5728611350059509, train/raw-loss = 0.5428353548049927, train/logprobs = tensor([[-1.4801, -3.9087],
        [-2.0489, -1.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30025753378868103
Epoch 0, Step 1606: train/loss = 0.6530771255493164, train/raw-loss = 0.6415004730224609, train/logprobs = tensor([[-1.2011, -1.8188],
        [-1.7616, -1.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11576659977436066
Epoch 0, Step 1607: train/loss = 0.5894872546195984, train/raw-loss = 0.5642023086547852, train/logprobs = tensor([[-1.8859, -3.1701],
        [-1.6759, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25284960865974426
Epoch 0, Step 1608: train/loss = 0.7077587842941284, train/raw-loss = 0.7030805349349976, train/logprobs = tensor([[-1.6701, -1.8485],
        [-1.4644, -0.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04678229242563248
Epoch 0, Step 1609: train/loss = 0.6157636642456055, train/raw-loss = 0.5951398611068726, train/logprobs = tensor([[-1.7229, -3.0026],
        [-1.6727, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20623818039894104
Epoch 0, Step 1610: train/loss = 0.5720095634460449, train/raw-loss = 0.5421302318572998, train/logprobs = tensor([[-1.5043, -3.3906],
        [-1.9390, -1.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29879361391067505
Epoch 0, Step 1611: train/loss = 0.6167117953300476, train/raw-loss = 0.5991218090057373, train/logprobs = tensor([[-1.7153, -2.9203],
        [-1.2308, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17589984834194183
Epoch 0, Step 1612: train/loss = 0.5772451162338257, train/raw-loss = 0.5483639240264893, train/logprobs = tensor([[-1.5796, -3.3153],
        [-1.7086, -0.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28881168365478516
Epoch 0, Step 1613: train/loss = 0.6432039737701416, train/raw-loss = 0.6255004405975342, train/logprobs = tensor([[-1.2408, -2.6012],
        [-1.7493, -1.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17703571915626526
Epoch 0, Step 1614: train/loss = 0.5669495463371277, train/raw-loss = 0.5364179015159607, train/logprobs = tensor([[-2.1376, -4.3967],
        [-1.6404, -0.9715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053169250488281
Epoch 0, Step 1615: train/loss = 0.641131579875946, train/raw-loss = 0.6290491819381714, train/logprobs = tensor([[-1.8874, -2.7387],
        [-1.4804, -1.1121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12082409858703613
Epoch 0, Step 1616: train/loss = 0.6528396606445312, train/raw-loss = 0.6363222002983093, train/logprobs = tensor([[-2.1968, -2.9683],
        [-1.4783, -0.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16517463326454163
Epoch 0, Step 1617: train/loss = 0.5454666018486023, train/raw-loss = 0.510223925113678, train/logprobs = tensor([[-1.4765, -3.7281],
        [-1.3413, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3524267375469208
Epoch 0, Step 1618: train/loss = 0.5585001707077026, train/raw-loss = 0.5270297527313232, train/logprobs = tensor([[-1.6491, -3.2530],
        [-1.5687, -0.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3147042691707611
Epoch 0, Step 1619: train/loss = 0.624911367893219, train/raw-loss = 0.6002557277679443, train/logprobs = tensor([[-1.4233, -3.0573],
        [-1.3837, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24655644595623016
Epoch 0, Step 1620: train/loss = 0.567501962184906, train/raw-loss = 0.5347436666488647, train/logprobs = tensor([[-1.3619, -3.3496],
        [-1.9012, -1.0230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32758256793022156
Epoch 0, Step 1621: train/loss = 0.5667910575866699, train/raw-loss = 0.5365656614303589, train/logprobs = tensor([[-1.3282, -3.0281],
        [-1.3330, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022540509700775
Epoch 0, Step 1622: train/loss = 0.48281559348106384, train/raw-loss = 0.43767791986465454, train/logprobs = tensor([[-1.5788, -4.7094],
        [-1.8679, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.451376736164093
Epoch 0, Step 1623: train/loss = 0.6565700173377991, train/raw-loss = 0.633928656578064, train/logprobs = tensor([[-1.9082, -3.4111],
        [-1.7202, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22641392052173615
Epoch 0, Step 1624: train/loss = 0.6477597951889038, train/raw-loss = 0.6328591108322144, train/logprobs = tensor([[-2.9184, -3.7648],
        [-1.2457, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490073949098587
Epoch 0, Step 1625: train/loss = 0.6502041816711426, train/raw-loss = 0.6412615180015564, train/logprobs = tensor([[-2.0237, -2.5280],
        [-1.6553, -1.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08942702412605286
Epoch 0, Step 1626: train/loss = 0.6922208666801453, train/raw-loss = 0.6917862296104431, train/logprobs = tensor([[-2.7060, -2.6423],
        [-1.0777, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004346335306763649
Epoch 0, Step 1627: train/loss = 0.589719295501709, train/raw-loss = 0.5635787844657898, train/logprobs = tensor([[-1.8534, -3.3594],
        [-1.8246, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614049017429352
Epoch 0, Step 1628: train/loss = 0.5745601654052734, train/raw-loss = 0.5466067790985107, train/logprobs = tensor([[-1.6036, -2.9339],
        [-2.0003, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2795341908931732
Epoch 0, Step 1629: train/loss = 0.5516093969345093, train/raw-loss = 0.5174434185028076, train/logprobs = tensor([[-1.3034, -3.5132],
        [-1.5717, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416599929332733
Epoch 0, Step 1630: train/loss = 0.6414452791213989, train/raw-loss = 0.6241961717605591, train/logprobs = tensor([[-2.1691, -3.1640],
        [-1.0121, -0.5419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17249104380607605
Epoch 0, Step 1631: train/loss = 0.6989498138427734, train/raw-loss = 0.6976568698883057, train/logprobs = tensor([[-1.6132, -1.9626],
        [-1.1795, -1.2757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012930013239383698
Epoch 0, Step 1632: train/loss = 0.6196894645690918, train/raw-loss = 0.5985280871391296, train/logprobs = tensor([[-1.6341, -3.1398],
        [-1.1599, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2116132229566574
Epoch 0, Step 1633: train/loss = 0.6527742743492126, train/raw-loss = 0.6412023305892944, train/logprobs = tensor([[-1.6215, -2.5123],
        [-1.8449, -1.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11571896076202393
Epoch 0, Step 1634: train/loss = 0.6899720430374146, train/raw-loss = 0.6755061149597168, train/logprobs = tensor([[-1.1913, -2.5512],
        [-1.4328, -1.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14465929567813873
Epoch 0, Step 1635: train/loss = 0.4830142855644226, train/raw-loss = 0.43511903285980225, train/logprobs = tensor([[-1.8983, -4.7585],
        [-1.4665, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4789526164531708
Epoch 0, Step 1636: train/loss = 0.6286465525627136, train/raw-loss = 0.6107610464096069, train/logprobs = tensor([[-2.1926, -3.1745],
        [-1.4331, -1.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178854838013649
Epoch 0, Step 1637: train/loss = 0.5705955028533936, train/raw-loss = 0.5437909364700317, train/logprobs = tensor([[-1.1561, -3.0030],
        [-1.5034, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2680457830429077
Epoch 0, Step 1638: train/loss = 0.5981764793395996, train/raw-loss = 0.5766712427139282, train/logprobs = tensor([[-1.2976, -2.7704],
        [-1.7061, -1.3480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21505233645439148
Epoch 0, Step 1639: train/loss = 0.5893211960792542, train/raw-loss = 0.5645037889480591, train/logprobs = tensor([[-1.3767, -3.6441],
        [-1.3413, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2481747567653656
Epoch 0, Step 1640: train/loss = 0.6496671438217163, train/raw-loss = 0.6356107592582703, train/logprobs = tensor([[-1.1743, -1.7301],
        [-1.5465, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14056429266929626
Epoch 0, Step 1641: train/loss = 0.6512799263000488, train/raw-loss = 0.6384024024009705, train/logprobs = tensor([[-1.6103, -2.1713],
        [-1.4934, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12877489626407623
Epoch 0, Step 1642: train/loss = 0.6281339526176453, train/raw-loss = 0.6101415157318115, train/logprobs = tensor([[-1.7279, -2.5855],
        [-1.0859, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17992469668388367
Epoch 0, Step 1643: train/loss = 0.6548526287078857, train/raw-loss = 0.6428616046905518, train/logprobs = tensor([[-2.0199, -3.0031],
        [-1.2584, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199098527431488
Epoch 0, Step 1644: train/loss = 0.5961650013923645, train/raw-loss = 0.5732142329216003, train/logprobs = tensor([[-1.4159, -2.8315],
        [-1.0932, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22950804233551025
Epoch 0, Step 1645: train/loss = 0.6610321402549744, train/raw-loss = 0.6465910077095032, train/logprobs = tensor([[-1.4949, -2.5387],
        [-1.7530, -2.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14441116154193878
Epoch 0, Step 1646: train/loss = 0.599442720413208, train/raw-loss = 0.5759332180023193, train/logprobs = tensor([[-1.7321, -3.4804],
        [-1.5378, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23509497940540314
Epoch 0, Step 1647: train/loss = 0.6994147300720215, train/raw-loss = 0.6940593719482422, train/logprobs = tensor([[-1.6399, -1.8352],
        [-1.1037, -0.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053553901612758636
Epoch 0, Step 1648: train/loss = 0.6445170640945435, train/raw-loss = 0.6305932998657227, train/logprobs = tensor([[-3.5204, -4.2096],
        [-1.1745, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13923799991607666
Epoch 0, Step 1649: train/loss = 0.6133359670639038, train/raw-loss = 0.5941760540008545, train/logprobs = tensor([[-2.5654, -3.4242],
        [-1.3341, -0.9842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19159990549087524
Epoch 0, Step 1650: train/loss = 0.6547849178314209, train/raw-loss = 0.6324821710586548, train/logprobs = tensor([[-1.7286, -3.1341],
        [-1.9947, -1.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22302782535552979
Epoch 0, Step 1651: train/loss = 0.5882725119590759, train/raw-loss = 0.5681097507476807, train/logprobs = tensor([[-2.4447, -3.8435],
        [-1.5897, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20162716507911682
Epoch 0, Step 1652: train/loss = 0.5822485089302063, train/raw-loss = 0.5565316081047058, train/logprobs = tensor([[-1.7333, -3.3020],
        [-1.2479, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25716912746429443
Epoch 0, Step 1653: train/loss = 0.6696703433990479, train/raw-loss = 0.6633733510971069, train/logprobs = tensor([[-2.8261, -3.2170],
        [-0.7630, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06296994537115097
Epoch 0, Step 1654: train/loss = 0.5880492925643921, train/raw-loss = 0.5593640208244324, train/logprobs = tensor([[-1.7548, -3.0803],
        [-1.4863, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28685247898101807
Epoch 0, Step 1655: train/loss = 0.5740693807601929, train/raw-loss = 0.5471593141555786, train/logprobs = tensor([[-1.4567, -2.7392],
        [-1.3122, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691004276275635
Epoch 0, Step 1656: train/loss = 0.6268565654754639, train/raw-loss = 0.6046226024627686, train/logprobs = tensor([[-1.6409, -2.9041],
        [-1.5153, -0.8650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22234070301055908
Epoch 0, Step 1657: train/loss = 0.6171900629997253, train/raw-loss = 0.5973301529884338, train/logprobs = tensor([[-1.2467, -2.3551],
        [-1.5106, -1.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1985989809036255
Epoch 0, Step 1658: train/loss = 0.600532591342926, train/raw-loss = 0.576280415058136, train/logprobs = tensor([[-3.2853, -3.4443],
        [-1.1335, -0.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24252170324325562
Epoch 0, Step 1659: train/loss = 0.9456507563591003, train/raw-loss = 0.9435112476348877, train/logprobs = tensor([[-1.3898, -2.1105],
        [-1.3982, -1.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021395403891801834
Epoch 0, Step 1660: train/loss = 0.575046718120575, train/raw-loss = 0.5489148497581482, train/logprobs = tensor([[-1.1022, -2.5813],
        [-2.1441, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26131874322891235
Epoch 0, Step 1661: train/loss = 0.6309244632720947, train/raw-loss = 0.6155015230178833, train/logprobs = tensor([[-1.6595, -2.5536],
        [-1.0691, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15422944724559784
Epoch 0, Step 1662: train/loss = 0.662650465965271, train/raw-loss = 0.6486257910728455, train/logprobs = tensor([[-1.1749, -2.0979],
        [-1.3545, -1.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14024706184864044
Epoch 0, Step 1663: train/loss = 0.6519066691398621, train/raw-loss = 0.6416624784469604, train/logprobs = tensor([[-1.7075, -2.5533],
        [-1.7682, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10244186222553253
Epoch 0, Step 1664: train/loss = 0.5679343938827515, train/raw-loss = 0.5332537889480591, train/logprobs = tensor([[-3.0792, -4.5813],
        [-1.9620, -0.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468054234981537
Epoch 0, Step 1665: train/loss = 0.6250168085098267, train/raw-loss = 0.6086904406547546, train/logprobs = tensor([[-1.6497, -2.6104],
        [-1.4253, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16326412558555603
Epoch 0, Step 1666: train/loss = 0.6815176606178284, train/raw-loss = 0.6768308281898499, train/logprobs = tensor([[-1.0021, -1.0586],
        [-1.3584, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046868059784173965
Epoch 0, Step 1667: train/loss = 0.5617367625236511, train/raw-loss = 0.5273785591125488, train/logprobs = tensor([[-2.4936, -4.3756],
        [-1.5142, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3435816168785095
Epoch 0, Step 1668: train/loss = 0.5940842628479004, train/raw-loss = 0.5687516927719116, train/logprobs = tensor([[-1.9253, -3.0052],
        [-1.6436, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25332581996917725
Epoch 0, Step 1669: train/loss = 0.5715622901916504, train/raw-loss = 0.5434461832046509, train/logprobs = tensor([[-2.7223, -4.4084],
        [-1.2174, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811608910560608
Epoch 0, Step 1670: train/loss = 0.5820389986038208, train/raw-loss = 0.5520877838134766, train/logprobs = tensor([[-1.5870, -3.1606],
        [-1.6694, -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29951223731040955
Epoch 0, Step 1671: train/loss = 0.707942545413971, train/raw-loss = 0.7078410983085632, train/logprobs = tensor([[-1.1184, -1.4121],
        [-1.2367, -1.5065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010151017922908068
Epoch 0, Step 1672: train/loss = 0.7096026539802551, train/raw-loss = 0.6983891725540161, train/logprobs = tensor([[-1.8653, -2.1541],
        [-1.4363, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11213415116071701
Epoch 0, Step 1673: train/loss = 0.5584701895713806, train/raw-loss = 0.5341408252716064, train/logprobs = tensor([[-1.4248, -3.3231],
        [-1.8523, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24329331517219543
Epoch 0, Step 1674: train/loss = 0.6001933813095093, train/raw-loss = 0.574579656124115, train/logprobs = tensor([[-1.5185, -3.3979],
        [-1.6285, -1.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25613725185394287
Epoch 0, Step 1675: train/loss = 0.6279243230819702, train/raw-loss = 0.6124231815338135, train/logprobs = tensor([[-1.4711, -2.1893],
        [-1.4167, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15501147508621216
Epoch 0, Step 1676: train/loss = 0.5573353171348572, train/raw-loss = 0.5225733518600464, train/logprobs = tensor([[-1.4870, -3.1965],
        [-1.4336, -0.8361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34761929512023926
Epoch 0, Step 1677: train/loss = 0.5519688725471497, train/raw-loss = 0.5116466879844666, train/logprobs = tensor([[-1.6772, -4.6384],
        [-1.6668, -1.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4032219648361206
Epoch 0, Step 1678: train/loss = 0.6422027349472046, train/raw-loss = 0.6237080097198486, train/logprobs = tensor([[-2.0366, -2.9856],
        [-1.4210, -0.6650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18494749069213867
Epoch 0, Step 1679: train/loss = 0.48790645599365234, train/raw-loss = 0.4414212107658386, train/logprobs = tensor([[-3.1447, -5.9746],
        [-1.4572, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.464852511882782
Epoch 0, Step 1680: train/loss = 0.5687736868858337, train/raw-loss = 0.5418105125427246, train/logprobs = tensor([[-2.2583, -3.6421],
        [-1.4143, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26963216066360474
Epoch 0, Step 1681: train/loss = 0.479392945766449, train/raw-loss = 0.4318837821483612, train/logprobs = tensor([[-1.0102, -3.6147],
        [-2.0132, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47509121894836426
Epoch 0, Step 1682: train/loss = 0.6809515953063965, train/raw-loss = 0.6729089617729187, train/logprobs = tensor([[-2.7064, -2.9608],
        [-1.3718, -0.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08042652159929276
Epoch 0, Step 1683: train/loss = 0.655144989490509, train/raw-loss = 0.644130289554596, train/logprobs = tensor([[-1.9114, -2.5095],
        [-1.3651, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11014699935913086
Epoch 0, Step 1684: train/loss = 0.6008272171020508, train/raw-loss = 0.5809926390647888, train/logprobs = tensor([[-2.1108, -3.4300],
        [-1.2771, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19834572076797485
Epoch 0, Step 1685: train/loss = 0.5056639909744263, train/raw-loss = 0.4592479467391968, train/logprobs = tensor([[-1.3968, -4.2288],
        [-1.4727, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4641604423522949
Epoch 0, Step 1686: train/loss = 0.5150084495544434, train/raw-loss = 0.47569790482521057, train/logprobs = tensor([[-1.0898, -3.2010],
        [-1.7267, -0.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39310574531555176
Epoch 0, Step 1687: train/loss = 0.6007211208343506, train/raw-loss = 0.5791606903076172, train/logprobs = tensor([[-2.6170, -3.3820],
        [-1.3422, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21560542285442352
Epoch 0, Step 1688: train/loss = 0.6776928305625916, train/raw-loss = 0.673149824142456, train/logprobs = tensor([[-2.4470, -2.6487],
        [-1.0974, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04543022811412811
Epoch 0, Step 1689: train/loss = 0.6194295287132263, train/raw-loss = 0.5930640697479248, train/logprobs = tensor([[-1.6794, -2.9470],
        [-1.3174, -0.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26365479826927185
Epoch 0, Step 1690: train/loss = 0.5735284090042114, train/raw-loss = 0.5440744757652283, train/logprobs = tensor([[-1.6590, -3.2110],
        [-1.5275, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945390045642853
Epoch 0, Step 1691: train/loss = 0.5709553360939026, train/raw-loss = 0.5422805547714233, train/logprobs = tensor([[-2.0302, -3.4531],
        [-1.7018, -0.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2867474853992462
Epoch 0, Step 1692: train/loss = 0.5392068028450012, train/raw-loss = 0.5006418228149414, train/logprobs = tensor([[-1.4547, -3.5659],
        [-1.5798, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3856499195098877
Epoch 0, Step 1693: train/loss = 0.6263282299041748, train/raw-loss = 0.6100801229476929, train/logprobs = tensor([[-1.8083, -2.4505],
        [-1.2931, -1.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16248108446598053
Epoch 0, Step 1694: train/loss = 0.5588298439979553, train/raw-loss = 0.5251885652542114, train/logprobs = tensor([[-1.6579, -3.6447],
        [-2.1372, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33641317486763
Epoch 0, Step 1695: train/loss = 0.5743317008018494, train/raw-loss = 0.5419864058494568, train/logprobs = tensor([[-1.8951, -4.6980],
        [-1.7318, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3234529495239258
Epoch 0, Step 1696: train/loss = 0.6283252835273743, train/raw-loss = 0.6125034093856812, train/logprobs = tensor([[-1.7721, -2.6652],
        [-1.4853, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15821878612041473
Epoch 0, Step 1697: train/loss = 0.5796780586242676, train/raw-loss = 0.5488219857215881, train/logprobs = tensor([[-3.1771, -4.3266],
        [-1.7713, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308560848236084
Epoch 0, Step 1698: train/loss = 0.5490263104438782, train/raw-loss = 0.5156703591346741, train/logprobs = tensor([[-2.3697, -4.3902],
        [-1.9445, -0.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33356016874313354
Epoch 0, Step 1699: train/loss = 0.60099196434021, train/raw-loss = 0.5809931755065918, train/logprobs = tensor([[-1.4773, -2.3490],
        [-1.7802, -1.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19998778402805328
Epoch 0, Step 1700: train/loss = 0.6431363224983215, train/raw-loss = 0.6276969313621521, train/logprobs = tensor([[-1.3453, -2.6436],
        [-1.8249, -1.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15439364314079285
Epoch 0, Step 1701: train/loss = 0.4081818461418152, train/raw-loss = 0.3478320240974426, train/logprobs = tensor([[-1.1882, -5.5754],
        [-2.2540, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.603498101234436
Epoch 0, Step 1702: train/loss = 0.5943753719329834, train/raw-loss = 0.5692896246910095, train/logprobs = tensor([[-1.6347, -3.1335],
        [-1.6098, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508571445941925
Epoch 0, Step 1703: train/loss = 0.6099914312362671, train/raw-loss = 0.5894712209701538, train/logprobs = tensor([[-2.7047, -3.6222],
        [-1.7855, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20520195364952087
Epoch 0, Step 1704: train/loss = 0.6239006519317627, train/raw-loss = 0.604705274105072, train/logprobs = tensor([[-2.0530, -3.2713],
        [-1.6747, -1.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19195324182510376
Epoch 0, Step 1705: train/loss = 0.6909017562866211, train/raw-loss = 0.6887348294258118, train/logprobs = tensor([[-1.6503, -1.8457],
        [-1.5744, -1.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021668752655386925
Epoch 0, Step 1706: train/loss = 0.5246597528457642, train/raw-loss = 0.4798961877822876, train/logprobs = tensor([[-2.0394, -4.4108],
        [-1.7334, -0.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4476352334022522
Epoch 0, Step 1707: train/loss = 0.6349143981933594, train/raw-loss = 0.6144928932189941, train/logprobs = tensor([[-1.5928, -2.8057],
        [-0.7363, -0.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20421470701694489
Epoch 0, Step 1708: train/loss = 0.6187871098518372, train/raw-loss = 0.6002830266952515, train/logprobs = tensor([[-2.9974, -3.9941],
        [-1.2480, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1850406974554062
Epoch 0, Step 1709: train/loss = 0.620807409286499, train/raw-loss = 0.6028521656990051, train/logprobs = tensor([[-3.0712, -3.7621],
        [-0.9331, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17955203354358673
Epoch 0, Step 1710: train/loss = 0.5388280749320984, train/raw-loss = 0.4971826672554016, train/logprobs = tensor([[-1.5340, -3.3538],
        [-2.0169, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41645434498786926
Epoch 0, Step 1711: train/loss = 0.5748385787010193, train/raw-loss = 0.5507181882858276, train/logprobs = tensor([[-1.3489, -2.7235],
        [-1.7119, -0.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24120397865772247
Epoch 0, Step 1712: train/loss = 0.4743373990058899, train/raw-loss = 0.42509251832962036, train/logprobs = tensor([[-1.8327, -5.0457],
        [-1.7797, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49244874715805054
Epoch 0, Step 1713: train/loss = 0.6358864307403564, train/raw-loss = 0.6204383373260498, train/logprobs = tensor([[-2.5848, -3.7136],
        [-1.2784, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1544812023639679
Epoch 0, Step 1714: train/loss = 0.7124563455581665, train/raw-loss = 0.6791322827339172, train/logprobs = tensor([[-1.9695, -5.0401],
        [-1.0671, -1.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33324047923088074
Epoch 0, Step 1715: train/loss = 0.5455245971679688, train/raw-loss = 0.5063911080360413, train/logprobs = tensor([[-1.5655, -3.4662],
        [-1.2344, -0.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3913343548774719
Epoch 0, Step 1716: train/loss = 0.5146511793136597, train/raw-loss = 0.4727538228034973, train/logprobs = tensor([[-2.1071, -5.0200],
        [-1.2902, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4189736843109131
Epoch 0, Step 1717: train/loss = 0.6414481401443481, train/raw-loss = 0.6258447766304016, train/logprobs = tensor([[-1.8591, -2.8660],
        [-1.3975, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15603388845920563
Epoch 0, Step 1718: train/loss = 0.6652400493621826, train/raw-loss = 0.6566175818443298, train/logprobs = tensor([[-1.5618, -2.1295],
        [-1.1564, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08622469007968903
Epoch 0, Step 1719: train/loss = 0.596829354763031, train/raw-loss = 0.5713368654251099, train/logprobs = tensor([[-2.1339, -3.6829],
        [-1.5982, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549244165420532
Epoch 0, Step 1720: train/loss = 0.6206140518188477, train/raw-loss = 0.6026722192764282, train/logprobs = tensor([[-2.1539, -2.9324],
        [-1.5882, -1.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17941835522651672
Epoch 0, Step 1721: train/loss = 0.6463218927383423, train/raw-loss = 0.632516622543335, train/logprobs = tensor([[-2.3308, -2.8607],
        [-0.8065, -0.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13805247843265533
Epoch 0, Step 1722: train/loss = 0.7225510478019714, train/raw-loss = 0.7188769578933716, train/logprobs = tensor([[-2.1177, -2.3622],
        [-1.2969, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036740951240062714
Epoch 0, Step 1723: train/loss = 0.5630954504013062, train/raw-loss = 0.5313389301300049, train/logprobs = tensor([[-1.6263, -3.1543],
        [-1.9214, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175649046897888
Epoch 0, Step 1724: train/loss = 0.5740432143211365, train/raw-loss = 0.5460091233253479, train/logprobs = tensor([[-2.6977, -4.5324],
        [-1.0492, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2803409695625305
Epoch 0, Step 1725: train/loss = 0.6255199909210205, train/raw-loss = 0.5913410186767578, train/logprobs = tensor([[-2.9719, -4.4377],
        [-1.3784, -0.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34178996086120605
Epoch 0, Step 1726: train/loss = 0.620851993560791, train/raw-loss = 0.6034177541732788, train/logprobs = tensor([[-3.1546, -4.1984],
        [-1.1745, -0.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17434236407279968
Epoch 0, Step 1727: train/loss = 0.5846128463745117, train/raw-loss = 0.5521810054779053, train/logprobs = tensor([[-1.4525, -4.5214],
        [-1.5747, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32431870698928833
Epoch 0, Step 1728: train/loss = 0.6260462999343872, train/raw-loss = 0.6086570024490356, train/logprobs = tensor([[-2.2490, -3.1549],
        [-1.4363, -0.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17389316856861115
Epoch 0, Step 1729: train/loss = 0.6558099985122681, train/raw-loss = 0.6420770287513733, train/logprobs = tensor([[-2.2618, -2.9475],
        [-1.3397, -1.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13733020424842834
Epoch 0, Step 1730: train/loss = 0.5913904905319214, train/raw-loss = 0.5571256875991821, train/logprobs = tensor([[-1.8464, -3.7837],
        [-1.5271, -0.8149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3426482677459717
Epoch 0, Step 1731: train/loss = 0.6153920888900757, train/raw-loss = 0.590589165687561, train/logprobs = tensor([[-1.8102, -3.4030],
        [-1.6144, -1.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.248028963804245
Epoch 0, Step 1732: train/loss = 0.4575812816619873, train/raw-loss = 0.390860378742218, train/logprobs = tensor([[-1.9624, -5.0197],
        [-2.5285, -1.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6672093868255615
Epoch 0, Step 1733: train/loss = 0.5570540428161621, train/raw-loss = 0.5244612693786621, train/logprobs = tensor([[-1.9494, -4.0927],
        [-1.2144, -0.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3259274363517761
Epoch 0, Step 1734: train/loss = 0.6204196214675903, train/raw-loss = 0.601738452911377, train/logprobs = tensor([[-1.1931, -2.2287],
        [-1.6684, -1.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1868121474981308
Epoch 0, Step 1735: train/loss = 0.6920323371887207, train/raw-loss = 0.6895198822021484, train/logprobs = tensor([[-2.7305, -3.1250],
        [-0.6902, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025124557316303253
Epoch 0, Step 1736: train/loss = 0.5388743281364441, train/raw-loss = 0.5006532669067383, train/logprobs = tensor([[-1.5143, -3.8171],
        [-1.8336, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3822104036808014
Epoch 0, Step 1737: train/loss = 0.4531748294830322, train/raw-loss = 0.3943142294883728, train/logprobs = tensor([[-1.7193, -4.9615],
        [-1.8288, -0.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5886057615280151
Epoch 0, Step 1738: train/loss = 0.5528254508972168, train/raw-loss = 0.5187665224075317, train/logprobs = tensor([[-2.2886, -4.3002],
        [-1.1695, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34058907628059387
Epoch 0, Step 1739: train/loss = 0.48133039474487305, train/raw-loss = 0.4321257770061493, train/logprobs = tensor([[-1.6981, -4.8791],
        [-1.4812, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49204587936401367
Epoch 0, Step 1740: train/loss = 0.5422278642654419, train/raw-loss = 0.508599042892456, train/logprobs = tensor([[-2.0464, -4.0076],
        [-1.6624, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33628785610198975
Epoch 0, Step 1741: train/loss = 0.6326857805252075, train/raw-loss = 0.6162888407707214, train/logprobs = tensor([[-3.3172, -4.4562],
        [-1.0992, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16396889090538025
Epoch 0, Step 1742: train/loss = 0.5478748083114624, train/raw-loss = 0.5118609666824341, train/logprobs = tensor([[-1.7270, -3.3875],
        [-2.1055, -1.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601389527320862
Epoch 0, Step 1743: train/loss = 0.6101970076560974, train/raw-loss = 0.591391921043396, train/logprobs = tensor([[-2.1681, -3.3821],
        [-1.3867, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18805086612701416
Epoch 0, Step 1744: train/loss = 0.49128782749176025, train/raw-loss = 0.44152340292930603, train/logprobs = tensor([[-1.7322, -4.7559],
        [-1.8900, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49764442443847656
Epoch 0, Step 1745: train/loss = 0.5298737287521362, train/raw-loss = 0.4903320372104645, train/logprobs = tensor([[-1.4390, -4.0178],
        [-1.3469, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3954172134399414
Epoch 0, Step 1746: train/loss = 0.7398629784584045, train/raw-loss = 0.7361236810684204, train/logprobs = tensor([[-1.4145, -1.6377],
        [-1.2150, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03739333897829056
Epoch 0, Step 1747: train/loss = 0.5553125739097595, train/raw-loss = 0.519737958908081, train/logprobs = tensor([[-1.2350, -3.9120],
        [-2.2880, -1.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3557467460632324
Epoch 0, Step 1748: train/loss = 0.5287957787513733, train/raw-loss = 0.4895726442337036, train/logprobs = tensor([[-1.0609, -3.0983],
        [-1.5964, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39223113656044006
Epoch 0, Step 1749: train/loss = 0.5797569751739502, train/raw-loss = 0.5484523773193359, train/logprobs = tensor([[-2.5870, -4.6774],
        [-1.6246, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130461871623993
Epoch 0, Step 1750: train/loss = 0.6126468777656555, train/raw-loss = 0.5942474603652954, train/logprobs = tensor([[-2.7576, -3.8398],
        [-1.4702, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18399403989315033
Epoch 0, Step 1751: train/loss = 0.7085265517234802, train/raw-loss = 0.705748975276947, train/logprobs = tensor([[-2.3486, -2.3375],
        [-1.3311, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027775652706623077
Epoch 0, Step 1752: train/loss = 0.6230926513671875, train/raw-loss = 0.6023769974708557, train/logprobs = tensor([[-3.4211, -4.5256],
        [-1.0626, -0.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20715674757957458
Epoch 0, Step 1753: train/loss = 0.5642397403717041, train/raw-loss = 0.5400023460388184, train/logprobs = tensor([[-2.0047, -3.4424],
        [-1.8657, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24237392842769623
Epoch 0, Step 1754: train/loss = 0.6320880055427551, train/raw-loss = 0.6085683107376099, train/logprobs = tensor([[-1.9672, -3.0430],
        [-1.7931, -0.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23519711196422577
Epoch 0, Step 1755: train/loss = 0.5513145327568054, train/raw-loss = 0.5160359144210815, train/logprobs = tensor([[-2.2661, -3.9838],
        [-1.5916, -0.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35278627276420593
Epoch 0, Step 1756: train/loss = 0.6632049083709717, train/raw-loss = 0.646003007888794, train/logprobs = tensor([[-2.2761, -2.8309],
        [-1.9489, -1.3326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17201828956604004
Epoch 0, Step 1757: train/loss = 0.5733550786972046, train/raw-loss = 0.541603684425354, train/logprobs = tensor([[-2.6424, -4.4304],
        [-1.8085, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31751418113708496
Epoch 0, Step 1758: train/loss = 0.5342531800270081, train/raw-loss = 0.49216800928115845, train/logprobs = tensor([[-2.8901, -5.1763],
        [-1.5282, -1.0036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4208514392375946
Epoch 0, Step 1759: train/loss = 0.6218631267547607, train/raw-loss = 0.5963988304138184, train/logprobs = tensor([[-2.5076, -3.8630],
        [-1.5178, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25464320182800293
Epoch 0, Step 1760: train/loss = 0.5163179636001587, train/raw-loss = 0.4730527102947235, train/logprobs = tensor([[-1.7848, -3.8160],
        [-2.0204, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4326525330543518
Epoch 0, Step 1761: train/loss = 0.6350394487380981, train/raw-loss = 0.6190534830093384, train/logprobs = tensor([[-2.0974, -3.3561],
        [-1.3337, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1598595827817917
Epoch 0, Step 1762: train/loss = 0.5463517904281616, train/raw-loss = 0.5110939145088196, train/logprobs = tensor([[-1.6058, -3.8549],
        [-1.5601, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525783121585846
Epoch 0, Step 1763: train/loss = 0.5131242275238037, train/raw-loss = 0.4677971601486206, train/logprobs = tensor([[-1.2765, -4.1986],
        [-1.7691, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4532703757286072
Epoch 0, Step 1764: train/loss = 0.586712121963501, train/raw-loss = 0.5609464049339294, train/logprobs = tensor([[-2.0292, -3.3911],
        [-1.9108, -1.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25765711069107056
Epoch 0, Step 1765: train/loss = 0.5480894446372986, train/raw-loss = 0.516455888748169, train/logprobs = tensor([[-1.4244, -3.7786],
        [-2.1103, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3163360059261322
Epoch 0, Step 1766: train/loss = 0.6702613830566406, train/raw-loss = 0.6629795432090759, train/logprobs = tensor([[-2.2297, -2.1239],
        [-1.2263, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07281813025474548
Epoch 0, Step 1767: train/loss = 0.38508689403533936, train/raw-loss = 0.307950496673584, train/logprobs = tensor([[-1.1849, -5.9995],
        [-2.0440, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7713640332221985
Epoch 0, Step 1768: train/loss = 0.48786211013793945, train/raw-loss = 0.44108057022094727, train/logprobs = tensor([[-2.1836, -5.9883],
        [-1.6075, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678156077861786
Epoch 0, Step 1769: train/loss = 0.6212639808654785, train/raw-loss = 0.6008042097091675, train/logprobs = tensor([[-2.2048, -3.3736],
        [-1.4835, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045980989933014
Epoch 0, Step 1770: train/loss = 0.6671477556228638, train/raw-loss = 0.6536530256271362, train/logprobs = tensor([[-1.4856, -2.2844],
        [-1.4864, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349470317363739
Epoch 0, Step 1771: train/loss = 0.7109479904174805, train/raw-loss = 0.7097196578979492, train/logprobs = tensor([[-1.5196, -1.3756],
        [-1.1992, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012283076532185078
Epoch 0, Step 1772: train/loss = 0.6193482875823975, train/raw-loss = 0.6017918586730957, train/logprobs = tensor([[-2.1120, -3.1216],
        [-1.7410, -1.3698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17556455731391907
Epoch 0, Step 1773: train/loss = 0.6362980604171753, train/raw-loss = 0.6083032488822937, train/logprobs = tensor([[-2.6286, -3.2368],
        [-1.5519, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.279947966337204
Epoch 0, Step 1774: train/loss = 0.6283208727836609, train/raw-loss = 0.6124308109283447, train/logprobs = tensor([[-1.9266, -2.8059],
        [-1.4601, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15890049934387207
Epoch 0, Step 1775: train/loss = 0.5871984958648682, train/raw-loss = 0.5554554462432861, train/logprobs = tensor([[-2.7554, -4.3966],
        [-1.4819, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3174304962158203
Epoch 0, Step 1776: train/loss = 0.5967575311660767, train/raw-loss = 0.5774208307266235, train/logprobs = tensor([[-2.4679, -3.4009],
        [-1.7441, -1.2812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19336703419685364
Epoch 0, Step 1777: train/loss = 0.5707845687866211, train/raw-loss = 0.5422247648239136, train/logprobs = tensor([[-1.6649, -3.7445],
        [-1.7779, -1.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855985462665558
Epoch 0, Step 1778: train/loss = 0.5597591996192932, train/raw-loss = 0.5261727571487427, train/logprobs = tensor([[-2.5997, -4.5946],
        [-1.6745, -0.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.335864782333374
Epoch 0, Step 1779: train/loss = 0.6295297145843506, train/raw-loss = 0.6119063496589661, train/logprobs = tensor([[-1.6451, -2.9458],
        [-1.1551, -0.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17623388767242432
Epoch 0, Step 1780: train/loss = 0.6301614046096802, train/raw-loss = 0.6102941036224365, train/logprobs = tensor([[-2.2297, -3.1853],
        [-1.4803, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1986735612154007
Epoch 0, Step 1781: train/loss = 0.5818389654159546, train/raw-loss = 0.5524102449417114, train/logprobs = tensor([[-1.0601, -2.4004],
        [-2.4690, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942868769168854
Epoch 0, Step 1782: train/loss = 0.39876341819763184, train/raw-loss = 0.32858985662460327, train/logprobs = tensor([[-1.3105, -6.7629],
        [-2.0366, -0.3798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7017353177070618
Epoch 0, Step 1783: train/loss = 0.6298099160194397, train/raw-loss = 0.6144797205924988, train/logprobs = tensor([[-1.6729, -2.6687],
        [-1.1427, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1533019244670868
Epoch 0, Step 1784: train/loss = 0.5598010420799255, train/raw-loss = 0.5156541466712952, train/logprobs = tensor([[-1.2650, -4.0533],
        [-2.0215, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4414687156677246
Epoch 0, Step 1785: train/loss = 0.5203067660331726, train/raw-loss = 0.4693620800971985, train/logprobs = tensor([[-1.1456, -4.7753],
        [-1.5422, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5094464421272278
Epoch 0, Step 1786: train/loss = 0.5697858333587646, train/raw-loss = 0.5420427918434143, train/logprobs = tensor([[-2.1181, -4.0409],
        [-1.4818, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27743011713027954
Epoch 0, Step 1787: train/loss = 0.5077451467514038, train/raw-loss = 0.45987069606781006, train/logprobs = tensor([[-0.9454, -4.2506],
        [-1.7958, -1.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4787448048591614
Epoch 0, Step 1788: train/loss = 0.47734755277633667, train/raw-loss = 0.42572659254074097, train/logprobs = tensor([[-2.2220, -5.2724],
        [-1.7929, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5162097215652466
Epoch 0, Step 1789: train/loss = 0.5472315549850464, train/raw-loss = 0.5093405246734619, train/logprobs = tensor([[-3.2224, -5.2775],
        [-1.3378, -1.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789099156856537
Epoch 0, Step 1790: train/loss = 0.5197768807411194, train/raw-loss = 0.4728677272796631, train/logprobs = tensor([[-2.0324, -5.2505],
        [-1.8059, -1.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46909207105636597
Epoch 0, Step 1791: train/loss = 0.4711800217628479, train/raw-loss = 0.4099906086921692, train/logprobs = tensor([[-0.9704, -6.7427],
        [-1.9352, -1.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6118941307067871
Epoch 0, Step 1792: train/loss = 0.5980175733566284, train/raw-loss = 0.5714300870895386, train/logprobs = tensor([[-3.1263, -4.7007],
        [-1.8071, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658751904964447
Epoch 0, Step 1793: train/loss = 0.6307475566864014, train/raw-loss = 0.6149875521659851, train/logprobs = tensor([[-1.5375, -2.4185],
        [-1.4621, -0.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15760000050067902
Epoch 0, Step 1794: train/loss = 0.635701596736908, train/raw-loss = 0.6131443977355957, train/logprobs = tensor([[-2.1490, -3.4502],
        [-1.7733, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255716770887375
Epoch 0, Step 1795: train/loss = 0.539600670337677, train/raw-loss = 0.5045419931411743, train/logprobs = tensor([[-2.6031, -4.3767],
        [-2.0205, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350586861371994
Epoch 0, Step 1796: train/loss = 0.5901607871055603, train/raw-loss = 0.5601912140846252, train/logprobs = tensor([[-3.0094, -3.5655],
        [-1.3815, -0.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29969608783721924
Epoch 0, Step 1797: train/loss = 0.6240582466125488, train/raw-loss = 0.6025286912918091, train/logprobs = tensor([[-3.9627, -4.2277],
        [-1.2485, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2152954638004303
Epoch 0, Step 1798: train/loss = 0.62116938829422, train/raw-loss = 0.5976443886756897, train/logprobs = tensor([[-0.9869, -2.0778],
        [-1.4581, -0.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23524989187717438
Epoch 0, Step 1799: train/loss = 0.56647127866745, train/raw-loss = 0.5327638983726501, train/logprobs = tensor([[-1.5411, -3.5105],
        [-1.4411, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33707407116889954
Epoch 0, Step 1800: train/loss = 0.5262013673782349, train/raw-loss = 0.486763596534729, train/logprobs = tensor([[-1.1850, -3.1333],
        [-2.0512, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3943772614002228
Epoch 0, Step 1801: train/loss = 0.6387455463409424, train/raw-loss = 0.6245658993721008, train/logprobs = tensor([[-2.5493, -3.6722],
        [-1.3985, -1.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14179620146751404
Epoch 0, Step 1802: train/loss = 0.5543828010559082, train/raw-loss = 0.5159801244735718, train/logprobs = tensor([[-2.1754, -4.1990],
        [-1.9234, -1.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38402611017227173
Epoch 0, Step 1803: train/loss = 0.5574299097061157, train/raw-loss = 0.5265277028083801, train/logprobs = tensor([[-2.4733, -4.8039],
        [-1.6035, -1.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30902212858200073
Epoch 0, Step 1804: train/loss = 0.5584487915039062, train/raw-loss = 0.5277447700500488, train/logprobs = tensor([[-2.1459, -3.9526],
        [-1.9492, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30703943967819214
Epoch 0, Step 1805: train/loss = 0.6723337173461914, train/raw-loss = 0.6535980701446533, train/logprobs = tensor([[-1.5583, -2.8929],
        [-1.4761, -1.4372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18735668063163757
Epoch 0, Step 1806: train/loss = 0.5505594611167908, train/raw-loss = 0.5147372484207153, train/logprobs = tensor([[-2.3802, -4.4872],
        [-1.9475, -1.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35822194814682007
Epoch 0, Step 1807: train/loss = 0.5745605826377869, train/raw-loss = 0.5436152815818787, train/logprobs = tensor([[-2.2217, -3.9354],
        [-1.9398, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30945318937301636
Epoch 0, Step 1808: train/loss = 0.5742387771606445, train/raw-loss = 0.5435700416564941, train/logprobs = tensor([[-1.0068, -2.9794],
        [-1.3149, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30668774247169495
Epoch 0, Step 1809: train/loss = 0.5563073754310608, train/raw-loss = 0.5241609215736389, train/logprobs = tensor([[-1.3741, -4.6371],
        [-1.6340, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32146456837654114
Epoch 0, Step 1810: train/loss = 0.6432562470436096, train/raw-loss = 0.6314705610275269, train/logprobs = tensor([[-1.6710, -2.3919],
        [-1.9507, -1.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785674840211868
Epoch 0, Step 1811: train/loss = 0.6016939878463745, train/raw-loss = 0.5813848972320557, train/logprobs = tensor([[-1.4200, -2.7606],
        [-1.5920, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20309056341648102
Epoch 0, Step 1812: train/loss = 0.5907748341560364, train/raw-loss = 0.5700359344482422, train/logprobs = tensor([[-1.7567, -3.0814],
        [-1.5852, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2073889970779419
Epoch 0, Step 1813: train/loss = 0.5971426963806152, train/raw-loss = 0.5688551068305969, train/logprobs = tensor([[-2.6451, -4.4424],
        [-1.3676, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28287577629089355
Epoch 0, Step 1814: train/loss = 0.5334454774856567, train/raw-loss = 0.49457740783691406, train/logprobs = tensor([[-2.0998, -3.1432],
        [-1.7596, -1.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38868072628974915
Epoch 0, Step 1815: train/loss = 0.5254857540130615, train/raw-loss = 0.48706144094467163, train/logprobs = tensor([[-1.9876, -4.7283],
        [-1.7147, -1.0597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3842434287071228
Epoch 0, Step 1816: train/loss = 0.5227729082107544, train/raw-loss = 0.47417885065078735, train/logprobs = tensor([[-2.4617, -5.2162],
        [-1.9819, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4859403371810913
Epoch 0, Step 1817: train/loss = 0.5886933207511902, train/raw-loss = 0.5599106550216675, train/logprobs = tensor([[-2.0726, -3.6876],
        [-1.6309, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2878269553184509
Epoch 0, Step 1818: train/loss = 0.5252598524093628, train/raw-loss = 0.4865713119506836, train/logprobs = tensor([[-1.8602, -4.8374],
        [-1.7508, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868855834007263
Epoch 0, Step 1819: train/loss = 0.6112470626831055, train/raw-loss = 0.5902673602104187, train/logprobs = tensor([[-1.6230, -2.9142],
        [-1.6980, -1.4502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20979662239551544
Epoch 0, Step 1820: train/loss = 0.5897135734558105, train/raw-loss = 0.561896562576294, train/logprobs = tensor([[-3.3350, -5.2262],
        [-1.2719, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781703472137451
Epoch 0, Step 1821: train/loss = 0.582905113697052, train/raw-loss = 0.5535708665847778, train/logprobs = tensor([[-0.9848, -2.6791],
        [-1.8115, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29334256052970886
Epoch 0, Step 1822: train/loss = 0.43792814016342163, train/raw-loss = 0.37594175338745117, train/logprobs = tensor([[-2.4019, -6.2427],
        [-1.8788, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6198639869689941
Epoch 0, Step 1823: train/loss = 0.43398338556289673, train/raw-loss = 0.37346428632736206, train/logprobs = tensor([[-1.2936, -4.4403],
        [-2.5344, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6051911115646362
Epoch 0, Step 1824: train/loss = 0.48845452070236206, train/raw-loss = 0.44015657901763916, train/logprobs = tensor([[-1.8468, -5.3363],
        [-1.7150, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48297983407974243
Epoch 0, Step 1825: train/loss = 0.5865705013275146, train/raw-loss = 0.5583784580230713, train/logprobs = tensor([[-2.3407, -3.6481],
        [-1.5440, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28192058205604553
Epoch 0, Step 1826: train/loss = 0.6206362843513489, train/raw-loss = 0.6018162965774536, train/logprobs = tensor([[-2.4985, -3.5944],
        [-1.2815, -0.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18819983303546906
Epoch 0, Step 1827: train/loss = 0.538581371307373, train/raw-loss = 0.5009841918945312, train/logprobs = tensor([[-2.7679, -4.8409],
        [-2.0263, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37597209215164185
Epoch 0, Step 1828: train/loss = 0.5887314081192017, train/raw-loss = 0.5615701079368591, train/logprobs = tensor([[-1.4432, -3.2052],
        [-1.7235, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716131806373596
Epoch 0, Step 1829: train/loss = 0.5777013301849365, train/raw-loss = 0.5494464635848999, train/logprobs = tensor([[-2.3098, -4.0156],
        [-1.9680, -1.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28254833817481995
Epoch 0, Step 1830: train/loss = 0.534045934677124, train/raw-loss = 0.4952055811882019, train/logprobs = tensor([[-2.2669, -4.9099],
        [-1.4458, -0.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3884035050868988
Epoch 0, Step 1831: train/loss = 0.6613616347312927, train/raw-loss = 0.6355811357498169, train/logprobs = tensor([[-2.0201, -4.9297],
        [-1.5523, -1.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25780510902404785
Epoch 0, Step 1832: train/loss = 0.5345509052276611, train/raw-loss = 0.4954138994216919, train/logprobs = tensor([[-1.8190, -4.1324],
        [-1.4102, -0.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39137011766433716
Epoch 0, Step 1833: train/loss = 0.5249171257019043, train/raw-loss = 0.4880552887916565, train/logprobs = tensor([[-1.3764, -4.2941],
        [-1.9600, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36861884593963623
Epoch 0, Step 1834: train/loss = 0.6154711246490479, train/raw-loss = 0.5955004692077637, train/logprobs = tensor([[-4.1571, -5.1561],
        [-1.4685, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1997072845697403
Epoch 0, Step 1835: train/loss = 0.5130307674407959, train/raw-loss = 0.4751484990119934, train/logprobs = tensor([[-2.6201, -5.1753],
        [-1.6139, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37882253527641296
Epoch 0, Step 1836: train/loss = 0.49539077281951904, train/raw-loss = 0.4476770758628845, train/logprobs = tensor([[-1.3966, -4.5567],
        [-2.1996, -1.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47713702917099
Epoch 0, Step 1837: train/loss = 0.3749123811721802, train/raw-loss = 0.30494368076324463, train/logprobs = tensor([[-1.4629, -5.6315],
        [-2.2891, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6996868848800659
Epoch 0, Step 1838: train/loss = 0.6371382474899292, train/raw-loss = 0.6218137741088867, train/logprobs = tensor([[-3.9104, -4.7541],
        [-1.0280, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15324515104293823
Epoch 0, Step 1839: train/loss = 0.567550778388977, train/raw-loss = 0.5370991230010986, train/logprobs = tensor([[-1.5166, -3.4364],
        [-1.7618, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3045170307159424
Epoch 0, Step 1840: train/loss = 0.538140058517456, train/raw-loss = 0.49478277564048767, train/logprobs = tensor([[-2.0095, -5.2452],
        [-1.8725, -1.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335726201534271
Epoch 0, Step 1841: train/loss = 0.5685409903526306, train/raw-loss = 0.5359605550765991, train/logprobs = tensor([[-2.0147, -3.4637],
        [-1.8451, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258044719696045
Epoch 0, Step 1842: train/loss = 0.5988922715187073, train/raw-loss = 0.5667861700057983, train/logprobs = tensor([[-1.5142, -3.5888],
        [-1.5468, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32106074690818787
Epoch 0, Step 1843: train/loss = 0.5915126204490662, train/raw-loss = 0.5664278268814087, train/logprobs = tensor([[-2.3263, -3.6255],
        [-1.4160, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508475184440613
Epoch 0, Step 1844: train/loss = 0.579885721206665, train/raw-loss = 0.545411229133606, train/logprobs = tensor([[-2.0922, -3.8720],
        [-1.9722, -1.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34474480152130127
Epoch 0, Step 1845: train/loss = 0.6928125023841858, train/raw-loss = 0.6921436786651611, train/logprobs = tensor([[-2.5236, -2.5588],
        [-1.6047, -1.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006688385270535946
Epoch 0, Step 1846: train/loss = 0.6228857636451721, train/raw-loss = 0.5999911427497864, train/logprobs = tensor([[-3.8897, -5.0430],
        [-1.4060, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22894635796546936
Epoch 0, Step 1847: train/loss = 0.6629812717437744, train/raw-loss = 0.6462008357048035, train/logprobs = tensor([[-1.9073, -2.6181],
        [-1.7964, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16780464351177216
Epoch 0, Step 1848: train/loss = 0.6522632837295532, train/raw-loss = 0.6401383876800537, train/logprobs = tensor([[-3.2844, -3.5932],
        [-1.0922, -0.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12124932557344437
Epoch 0, Step 1849: train/loss = 0.5571157336235046, train/raw-loss = 0.5253230333328247, train/logprobs = tensor([[-4.1520, -6.5296],
        [-0.9237, -0.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317926824092865
Epoch 0, Step 1850: train/loss = 0.5468515157699585, train/raw-loss = 0.5139403343200684, train/logprobs = tensor([[-1.4773, -3.8363],
        [-1.9308, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32911109924316406
Epoch 0, Step 1851: train/loss = 0.5875640511512756, train/raw-loss = 0.5568550825119019, train/logprobs = tensor([[-1.4118, -3.7755],
        [-1.9323, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3070892095565796
Epoch 0, Step 1852: train/loss = 0.6022273302078247, train/raw-loss = 0.5794157981872559, train/logprobs = tensor([[-1.7595, -3.0164],
        [-1.9635, -1.2571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22811587154865265
Epoch 0, Step 1853: train/loss = 0.6271291375160217, train/raw-loss = 0.6053348779678345, train/logprobs = tensor([[-3.3383, -4.9096],
        [-1.4676, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21794280409812927
Epoch 0, Step 1854: train/loss = 0.45160722732543945, train/raw-loss = 0.3892052173614502, train/logprobs = tensor([[-1.7063, -5.7562],
        [-1.6589, -0.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6240203380584717
Epoch 0, Step 1855: train/loss = 0.7403929829597473, train/raw-loss = 0.7360576391220093, train/logprobs = tensor([[-2.6018, -2.5789],
        [-1.8726, -1.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04335319250822067
Epoch 0, Step 1856: train/loss = 0.6777675151824951, train/raw-loss = 0.6453598141670227, train/logprobs = tensor([[-2.8711, -3.9261],
        [-1.4951, -0.6123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32407689094543457
Epoch 0, Step 1857: train/loss = 0.5428760647773743, train/raw-loss = 0.49401381611824036, train/logprobs = tensor([[-2.2539, -4.7915],
        [-2.4215, -1.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4886223077774048
Epoch 0, Step 1858: train/loss = 0.6826692819595337, train/raw-loss = 0.6779835820198059, train/logprobs = tensor([[-2.3806, -3.1650],
        [-1.0768, -1.1181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04685676097869873
Epoch 0, Step 1859: train/loss = 0.5042542219161987, train/raw-loss = 0.45495477318763733, train/logprobs = tensor([[-2.1613, -5.2266],
        [-1.7815, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.492994487285614
Epoch 0, Step 1860: train/loss = 0.6022364497184753, train/raw-loss = 0.5818639397621155, train/logprobs = tensor([[-2.8594, -4.3365],
        [-1.3259, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20372551679611206
Epoch 0, Step 1861: train/loss = 0.4960380494594574, train/raw-loss = 0.45009922981262207, train/logprobs = tensor([[-1.0276, -3.7881],
        [-1.8096, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4593878984451294
Epoch 0, Step 1862: train/loss = 0.5173921585083008, train/raw-loss = 0.4682098925113678, train/logprobs = tensor([[-3.1376, -5.5094],
        [-2.0624, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4918227791786194
Epoch 0, Step 1863: train/loss = 0.5615798234939575, train/raw-loss = 0.52787846326828, train/logprobs = tensor([[-1.9705, -3.8532],
        [-2.0680, -1.4377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33701327443122864
Epoch 0, Step 1864: train/loss = 0.6119118928909302, train/raw-loss = 0.5842069387435913, train/logprobs = tensor([[-3.8415, -4.5781],
        [-1.2933, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.277050256729126
Epoch 0, Step 1865: train/loss = 0.6878347992897034, train/raw-loss = 0.6714032888412476, train/logprobs = tensor([[-4.0487, -3.9059],
        [-1.5658, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16431552171707153
Epoch 0, Step 1866: train/loss = 0.6326065063476562, train/raw-loss = 0.6150561571121216, train/logprobs = tensor([[-3.8749, -4.5749],
        [-1.0719, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17550337314605713
Epoch 0, Step 1867: train/loss = 0.6394778490066528, train/raw-loss = 0.6244975328445435, train/logprobs = tensor([[-2.9128, -3.2695],
        [-1.7598, -0.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980275928974152
Epoch 0, Step 1868: train/loss = 0.6078953146934509, train/raw-loss = 0.5838537216186523, train/logprobs = tensor([[-1.9349, -3.1661],
        [-1.6800, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24041570723056793
Epoch 0, Step 1869: train/loss = 0.4650176763534546, train/raw-loss = 0.41120660305023193, train/logprobs = tensor([[-1.0828, -4.0731],
        [-2.1363, -1.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5381112098693848
Epoch 0, Step 1870: train/loss = 0.6888856887817383, train/raw-loss = 0.6872612237930298, train/logprobs = tensor([[-1.7264, -1.9354],
        [-1.3695, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016244426369667053
Epoch 0, Step 1871: train/loss = 0.6089285612106323, train/raw-loss = 0.587794303894043, train/logprobs = tensor([[-1.2373, -2.3371],
        [-2.1485, -1.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21134278178215027
Epoch 0, Step 1872: train/loss = 0.4007052481174469, train/raw-loss = 0.3327999711036682, train/logprobs = tensor([[-1.5269, -6.5082],
        [-2.2958, -1.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6790530681610107
Epoch 0, Step 1873: train/loss = 0.6566959619522095, train/raw-loss = 0.6408857107162476, train/logprobs = tensor([[-3.1804, -4.2976],
        [-1.2786, -1.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15810243785381317
Epoch 0, Step 1874: train/loss = 0.43021029233932495, train/raw-loss = 0.36901623010635376, train/logprobs = tensor([[-3.6081, -6.9986],
        [-2.4592, -0.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6119402647018433
Epoch 0, Step 1875: train/loss = 0.6944276094436646, train/raw-loss = 0.6879895925521851, train/logprobs = tensor([[-2.7136, -3.1005],
        [-1.5318, -1.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0643792599439621
Epoch 0, Step 1876: train/loss = 0.6383476257324219, train/raw-loss = 0.6244563460350037, train/logprobs = tensor([[-2.0759, -2.7751],
        [-1.0887, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13891226053237915
Epoch 0, Step 1877: train/loss = 0.607833743095398, train/raw-loss = 0.5853803157806396, train/logprobs = tensor([[-2.1536, -3.0838],
        [-1.4195, -1.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22453443706035614
Epoch 0, Step 1878: train/loss = 0.5926240682601929, train/raw-loss = 0.5659611225128174, train/logprobs = tensor([[-1.5048, -2.7747],
        [-1.9007, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26663023233413696
Epoch 0, Step 1879: train/loss = 0.38847970962524414, train/raw-loss = 0.3195320963859558, train/logprobs = tensor([[-0.8595, -4.2644],
        [-2.6891, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6894758939743042
Epoch 0, Step 1880: train/loss = 0.5284996628761292, train/raw-loss = 0.48241305351257324, train/logprobs = tensor([[-3.2159, -5.2687],
        [-1.6007, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46086639165878296
Epoch 0, Step 1881: train/loss = 0.6091898679733276, train/raw-loss = 0.582012414932251, train/logprobs = tensor([[-2.1167, -5.7703],
        [-2.2257, -1.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27177441120147705
Epoch 0, Step 1882: train/loss = 0.7147228121757507, train/raw-loss = 0.7114916443824768, train/logprobs = tensor([[-1.9454, -2.0873],
        [-1.3464, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03231174871325493
Epoch 0, Step 1883: train/loss = 0.5864266753196716, train/raw-loss = 0.5583287477493286, train/logprobs = tensor([[-2.0043, -3.5269],
        [-1.5865, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28097909688949585
Epoch 0, Step 1884: train/loss = 0.5315156579017639, train/raw-loss = 0.49626556038856506, train/logprobs = tensor([[-1.8730, -4.4713],
        [-1.8043, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35250094532966614
Epoch 0, Step 1885: train/loss = 0.4184735119342804, train/raw-loss = 0.35990267992019653, train/logprobs = tensor([[-2.3523, -7.3754],
        [-1.8347, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5857084393501282
Epoch 0, Step 1886: train/loss = 0.6271793842315674, train/raw-loss = 0.6079530715942383, train/logprobs = tensor([[-1.7528, -2.3743],
        [-2.0341, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19226276874542236
Epoch 0, Step 1887: train/loss = 0.41725975275039673, train/raw-loss = 0.35174858570098877, train/logprobs = tensor([[-2.1770, -6.9984],
        [-2.0750, -0.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6551118493080139
Epoch 0, Step 1888: train/loss = 0.5941131711006165, train/raw-loss = 0.5483297109603882, train/logprobs = tensor([[-3.4445, -6.0468],
        [-1.8558, -0.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45783424377441406
Epoch 0, Step 1889: train/loss = 0.5654273629188538, train/raw-loss = 0.5290797352790833, train/logprobs = tensor([[-2.0009, -3.3707],
        [-2.0792, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634766638278961
Epoch 0, Step 1890: train/loss = 0.5986866354942322, train/raw-loss = 0.5685406923294067, train/logprobs = tensor([[-2.0865, -3.4811],
        [-1.8275, -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30145931243896484
Epoch 0, Step 1891: train/loss = 0.5710387229919434, train/raw-loss = 0.5387881994247437, train/logprobs = tensor([[-2.7434, -5.0805],
        [-1.6335, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225049078464508
Epoch 0, Step 1892: train/loss = 0.711625337600708, train/raw-loss = 0.6984066963195801, train/logprobs = tensor([[-1.0849, -2.3960],
        [-1.5027, -1.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13218578696250916
Epoch 0, Step 1893: train/loss = 0.6348589658737183, train/raw-loss = 0.619710385799408, train/logprobs = tensor([[-2.7407, -3.8392],
        [-1.6328, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514856219291687
Epoch 0, Step 1894: train/loss = 0.533652126789093, train/raw-loss = 0.4943775236606598, train/logprobs = tensor([[-2.4797, -4.6211],
        [-1.8987, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3927462697029114
Epoch 0, Step 1895: train/loss = 0.5292984843254089, train/raw-loss = 0.4843297004699707, train/logprobs = tensor([[-1.9517, -4.2112],
        [-1.8363, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44968724250793457
Epoch 0, Step 1896: train/loss = 0.46941810846328735, train/raw-loss = 0.41883721947669983, train/logprobs = tensor([[-1.9049, -6.0638],
        [-2.2350, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5058090686798096
Epoch 0, Step 1897: train/loss = 0.5847135186195374, train/raw-loss = 0.5527782440185547, train/logprobs = tensor([[-2.0575, -3.5104],
        [-1.8841, -1.1930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31935298442840576
Epoch 0, Step 1898: train/loss = 0.5923359394073486, train/raw-loss = 0.5637426972389221, train/logprobs = tensor([[-3.8903, -4.9324],
        [-1.7858, -1.2620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28593242168426514
Epoch 0, Step 1899: train/loss = 0.37697964906692505, train/raw-loss = 0.3058890402317047, train/logprobs = tensor([[-1.1757, -6.0440],
        [-2.1387, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7109061479568481
Epoch 0, Step 1900: train/loss = 0.6362648606300354, train/raw-loss = 0.6203951835632324, train/logprobs = tensor([[-3.3335, -4.2513],
        [-1.0736, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15869683027267456
Epoch 0, Step 1901: train/loss = 0.6445353627204895, train/raw-loss = 0.6315016150474548, train/logprobs = tensor([[-3.2681, -3.7355],
        [-1.7062, -1.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13033729791641235
Epoch 0, Step 1902: train/loss = 0.4942561984062195, train/raw-loss = 0.4508412480354309, train/logprobs = tensor([[-2.9761, -6.7283],
        [-1.5880, -1.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4341496229171753
Epoch 0, Step 1903: train/loss = 0.6231815814971924, train/raw-loss = 0.6021906137466431, train/logprobs = tensor([[-1.5017, -2.8170],
        [-1.8205, -1.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20990969240665436
Epoch 0, Step 1904: train/loss = 0.481391966342926, train/raw-loss = 0.4326668381690979, train/logprobs = tensor([[-2.2730, -5.1475],
        [-1.4337, -0.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48725149035453796
Epoch 0, Step 1905: train/loss = 0.5606194138526917, train/raw-loss = 0.5272977948188782, train/logprobs = tensor([[-2.5744, -4.8421],
        [-1.6498, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33321595191955566
Epoch 0, Step 1906: train/loss = 0.5702530145645142, train/raw-loss = 0.5417734980583191, train/logprobs = tensor([[-2.3996, -3.6068],
        [-1.6440, -0.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28479495644569397
Epoch 0, Step 1907: train/loss = 0.6262564063072205, train/raw-loss = 0.6045287847518921, train/logprobs = tensor([[-3.3177, -3.0239],
        [-1.6608, -1.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2172764092683792
Epoch 0, Step 1908: train/loss = 0.6133313179016113, train/raw-loss = 0.580207109451294, train/logprobs = tensor([[-1.6278, -4.6178],
        [-1.1756, -1.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3312419056892395
Epoch 0, Step 1909: train/loss = 0.6168481111526489, train/raw-loss = 0.5984376668930054, train/logprobs = tensor([[-1.7975, -3.0744],
        [-1.1604, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.184103861451149
Epoch 0, Step 1910: train/loss = 0.6090104579925537, train/raw-loss = 0.5884634256362915, train/logprobs = tensor([[-2.5662, -3.5308],
        [-1.8090, -1.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20547008514404297
Epoch 0, Step 1911: train/loss = 0.5017569065093994, train/raw-loss = 0.4531271755695343, train/logprobs = tensor([[-1.5629, -4.1254],
        [-1.5563, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48629721999168396
Epoch 0, Step 1912: train/loss = 0.6094582080841064, train/raw-loss = 0.5871768593788147, train/logprobs = tensor([[-1.9278, -3.5850],
        [-1.9402, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22281335294246674
Epoch 0, Step 1913: train/loss = 0.42877259850502014, train/raw-loss = 0.3693368136882782, train/logprobs = tensor([[-1.9566, -6.3798],
        [-1.8961, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5943577289581299
Epoch 0, Step 1914: train/loss = 0.624657154083252, train/raw-loss = 0.6049203276634216, train/logprobs = tensor([[-1.9842, -2.6498],
        [-1.7630, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19736771285533905
Epoch 0, Step 1915: train/loss = 0.530629575252533, train/raw-loss = 0.4864687919616699, train/logprobs = tensor([[-1.6759, -3.9713],
        [-1.6456, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4416079819202423
Epoch 0, Step 1916: train/loss = 0.5470131635665894, train/raw-loss = 0.511410117149353, train/logprobs = tensor([[-1.5688, -4.1453],
        [-1.5664, -1.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560306429862976
Epoch 0, Step 1917: train/loss = 0.49767348170280457, train/raw-loss = 0.4481806755065918, train/logprobs = tensor([[-1.8633, -5.7125],
        [-2.0006, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49492812156677246
Epoch 0, Step 1918: train/loss = 0.5032868981361389, train/raw-loss = 0.4511958956718445, train/logprobs = tensor([[-3.7563, -6.5787],
        [-1.5938, -0.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5209100246429443
Epoch 0, Step 1919: train/loss = 0.5610911846160889, train/raw-loss = 0.5282093286514282, train/logprobs = tensor([[-2.7651, -4.6132],
        [-1.6053, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288182318210602
Epoch 0, Step 1920: train/loss = 0.42002683877944946, train/raw-loss = 0.35578644275665283, train/logprobs = tensor([[-1.1262, -6.6545],
        [-2.4527, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6424039602279663
Epoch 0, Step 1921: train/loss = 0.603851318359375, train/raw-loss = 0.5772980451583862, train/logprobs = tensor([[-1.0771, -2.9804],
        [-2.4372, -1.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655327320098877
Epoch 0, Step 1922: train/loss = 0.5902103781700134, train/raw-loss = 0.5634655952453613, train/logprobs = tensor([[-1.6703, -2.7552],
        [-2.0228, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2674475908279419
Epoch 0, Step 1923: train/loss = 0.5356763601303101, train/raw-loss = 0.49175748229026794, train/logprobs = tensor([[-1.5326, -4.1166],
        [-1.7021, -0.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4391888380050659
Epoch 0, Step 1924: train/loss = 0.6408398151397705, train/raw-loss = 0.6268965005874634, train/logprobs = tensor([[-2.0039, -2.8384],
        [-1.5037, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.139433354139328
Epoch 0, Step 1925: train/loss = 0.4894289970397949, train/raw-loss = 0.44267767667770386, train/logprobs = tensor([[-2.1717, -3.4656],
        [-1.8263, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46751314401626587
Epoch 0, Step 1926: train/loss = 0.5352375507354736, train/raw-loss = 0.4980970621109009, train/logprobs = tensor([[-1.6137, -4.5256],
        [-2.4417, -1.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714056611061096
Epoch 0, Step 1927: train/loss = 0.5398839712142944, train/raw-loss = 0.4985262155532837, train/logprobs = tensor([[-2.1407, -4.0710],
        [-1.9289, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4135773777961731
Epoch 0, Step 1928: train/loss = 0.6702791452407837, train/raw-loss = 0.6579819917678833, train/logprobs = tensor([[-1.5543, -2.0474],
        [-2.2755, -1.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12297196686267853
Epoch 0, Step 1929: train/loss = 0.5532407164573669, train/raw-loss = 0.519349217414856, train/logprobs = tensor([[-3.8911, -4.7735],
        [-2.9997, -2.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3389151096343994
Epoch 0, Step 1930: train/loss = 0.691990852355957, train/raw-loss = 0.6742749810218811, train/logprobs = tensor([[-3.1414, -4.7335],
        [-2.3304, -1.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17715945839881897
Epoch 0, Step 1931: train/loss = 0.6403169631958008, train/raw-loss = 0.6250510811805725, train/logprobs = tensor([[-1.7380, -2.1644],
        [-1.8754, -1.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15265902876853943
Epoch 0, Step 1932: train/loss = 0.6099721193313599, train/raw-loss = 0.5886796712875366, train/logprobs = tensor([[-2.1866, -2.8510],
        [-1.5773, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21292537450790405
Epoch 0, Step 1933: train/loss = 0.6116973161697388, train/raw-loss = 0.5902640223503113, train/logprobs = tensor([[-2.1052, -4.6966],
        [-1.3512, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21433280408382416
Epoch 0, Step 1934: train/loss = 0.6238275170326233, train/raw-loss = 0.604690432548523, train/logprobs = tensor([[-3.3646, -4.1741],
        [-1.7416, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191371351480484
Epoch 0, Step 1935: train/loss = 0.5163203477859497, train/raw-loss = 0.47083306312561035, train/logprobs = tensor([[-1.4703, -3.4325],
        [-1.8689, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45487266778945923
Epoch 0, Step 1936: train/loss = 0.6196064352989197, train/raw-loss = 0.5765434503555298, train/logprobs = tensor([[-1.0876, -5.7787],
        [-1.6841, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43063005805015564
Epoch 0, Step 1937: train/loss = 0.5389862656593323, train/raw-loss = 0.49857407808303833, train/logprobs = tensor([[-2.6957, -3.2902],
        [-1.4842, -1.3652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40412211418151855
Epoch 0, Step 1938: train/loss = 0.5683078169822693, train/raw-loss = 0.5349057912826538, train/logprobs = tensor([[-2.4358, -3.4580],
        [-1.4574, -0.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3340199291706085
Epoch 0, Step 1939: train/loss = 0.5232555866241455, train/raw-loss = 0.4857659637928009, train/logprobs = tensor([[-2.8763, -6.4138],
        [-1.3321, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3748960494995117
Epoch 0, Step 1940: train/loss = 0.5072643756866455, train/raw-loss = 0.457065224647522, train/logprobs = tensor([[-1.2209, -7.0517],
        [-2.4575, -1.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.501991331577301
Epoch 0, Step 1941: train/loss = 0.4748373031616211, train/raw-loss = 0.41811293363571167, train/logprobs = tensor([[-1.1590, -3.6648],
        [-2.5164, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5672438740730286
Epoch 0, Step 1942: train/loss = 0.47779807448387146, train/raw-loss = 0.42542439699172974, train/logprobs = tensor([[-1.8999, -5.8322],
        [-1.2467, -0.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523736298084259
Epoch 0, Step 1943: train/loss = 0.5234039425849915, train/raw-loss = 0.4817403256893158, train/logprobs = tensor([[-2.8424, -4.0769],
        [-1.6847, -1.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4166363775730133
Epoch 0, Step 1944: train/loss = 0.5151135921478271, train/raw-loss = 0.46781840920448303, train/logprobs = tensor([[-1.8335, -3.9692],
        [-2.2628, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47295159101486206
Epoch 0, Step 1945: train/loss = 0.626117467880249, train/raw-loss = 0.6073375940322876, train/logprobs = tensor([[-1.8683, -2.8326],
        [-1.7097, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1877990961074829
Epoch 0, Step 1946: train/loss = 0.4735771119594574, train/raw-loss = 0.4138897657394409, train/logprobs = tensor([[-1.6265, -5.0777],
        [-1.9112, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5968730449676514
Epoch 0, Step 1947: train/loss = 0.6131616830825806, train/raw-loss = 0.592624843120575, train/logprobs = tensor([[-2.9751, -4.1828],
        [-1.5276, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20536863803863525
Epoch 0, Step 1948: train/loss = 0.5051167011260986, train/raw-loss = 0.4617918133735657, train/logprobs = tensor([[-1.9667, -5.4514],
        [-2.1178, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4332486391067505
Epoch 0, Step 1949: train/loss = 0.45495593547821045, train/raw-loss = 0.39217910170555115, train/logprobs = tensor([[-1.6287, -8.0468],
        [-2.1396, -1.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6277685761451721
Epoch 0, Step 1950: train/loss = 0.5249359607696533, train/raw-loss = 0.48427048325538635, train/logprobs = tensor([[-2.5600, -4.8377],
        [-1.9937, -1.2433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4066546857357025
Epoch 0, Step 1951: train/loss = 0.5386258363723755, train/raw-loss = 0.501030683517456, train/logprobs = tensor([[-2.9766, -5.7258],
        [-1.4933, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37595105171203613
Epoch 0, Step 1952: train/loss = 0.40674808621406555, train/raw-loss = 0.33857470750808716, train/logprobs = tensor([[-2.0453, -6.1644],
        [-2.3526, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6817336082458496
Epoch 0, Step 1953: train/loss = 0.5311456918716431, train/raw-loss = 0.4898644685745239, train/logprobs = tensor([[-1.8297, -3.7278],
        [-1.8873, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4128117859363556
Epoch 0, Step 1954: train/loss = 0.6366299390792847, train/raw-loss = 0.6206096410751343, train/logprobs = tensor([[-1.4414, -2.7244],
        [-1.9773, -2.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16020254790782928
Epoch 0, Step 1955: train/loss = 0.5564891695976257, train/raw-loss = 0.5187731385231018, train/logprobs = tensor([[-1.9089, -6.1519],
        [-1.5774, -1.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37716031074523926
Epoch 0, Step 1956: train/loss = 0.5372772812843323, train/raw-loss = 0.4963729679584503, train/logprobs = tensor([[-2.6122, -4.7493],
        [-2.3570, -1.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4090428948402405
Epoch 0, Step 1957: train/loss = 0.48066043853759766, train/raw-loss = 0.43012917041778564, train/logprobs = tensor([[-1.5467, -4.7214],
        [-1.8386, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5053126215934753
Epoch 0, Step 1958: train/loss = 0.548794686794281, train/raw-loss = 0.5167754888534546, train/logprobs = tensor([[-2.3036, -5.1432],
        [-1.8486, -1.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201920986175537
Epoch 0, Step 1959: train/loss = 0.6165637969970703, train/raw-loss = 0.5966217517852783, train/logprobs = tensor([[-2.4417, -2.6440],
        [-1.0909, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994209587574005
Epoch 0, Step 1960: train/loss = 0.6078658103942871, train/raw-loss = 0.5765625834465027, train/logprobs = tensor([[-1.6893, -3.1630],
        [-1.6194, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31303220987319946
Epoch 0, Step 1961: train/loss = 0.6376864314079285, train/raw-loss = 0.615230143070221, train/logprobs = tensor([[-1.8794, -2.7792],
        [-2.1035, -1.1774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22456257045269012
Epoch 0, Step 1962: train/loss = 0.5420318841934204, train/raw-loss = 0.5046441555023193, train/logprobs = tensor([[-1.1648, -3.1658],
        [-2.0753, -1.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3738778829574585
Epoch 0, Step 1963: train/loss = 0.4995008409023285, train/raw-loss = 0.45363113284111023, train/logprobs = tensor([[-0.6847, -4.0450],
        [-2.7002, -1.7132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4586969017982483
Epoch 0, Step 1964: train/loss = 0.44214028120040894, train/raw-loss = 0.38535964488983154, train/logprobs = tensor([[-1.2297, -5.3734],
        [-2.8572, -1.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5678063631057739
Epoch 0, Step 1965: train/loss = 0.39822712540626526, train/raw-loss = 0.3339368402957916, train/logprobs = tensor([[-1.4958, -6.2350],
        [-2.5831, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6429028511047363
Epoch 0, Step 1966: train/loss = 0.695669412612915, train/raw-loss = 0.6940630078315735, train/logprobs = tensor([[-1.8383, -1.7834],
        [-1.8261, -1.7205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016063833609223366
Epoch 0, Step 1967: train/loss = 0.6417731046676636, train/raw-loss = 0.6236961483955383, train/logprobs = tensor([[-2.9188, -3.7933],
        [-1.4882, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18076929450035095
Epoch 0, Step 1968: train/loss = 0.5525960922241211, train/raw-loss = 0.5122897624969482, train/logprobs = tensor([[-2.1116, -4.5207],
        [-1.7124, -0.5327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4030631482601166
Epoch 0, Step 1969: train/loss = 0.6439335942268372, train/raw-loss = 0.6105920076370239, train/logprobs = tensor([[-2.6131, -4.1594],
        [-2.0966, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334159553050995
Epoch 0, Step 1970: train/loss = 0.6924495100975037, train/raw-loss = 0.6919245719909668, train/logprobs = tensor([[-2.5971, -2.6675],
        [-2.3191, -2.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005249219015240669
Epoch 0, Step 1971: train/loss = 0.6049826741218567, train/raw-loss = 0.5790209174156189, train/logprobs = tensor([[-2.2028, -4.2918],
        [-1.5275, -0.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25961822271347046
Epoch 0, Step 1972: train/loss = 0.5235809683799744, train/raw-loss = 0.4835732877254486, train/logprobs = tensor([[-1.3474, -4.5154],
        [-1.9611, -1.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40007713437080383
Epoch 0, Step 1973: train/loss = 0.46342337131500244, train/raw-loss = 0.40904396772384644, train/logprobs = tensor([[-1.1462, -4.6133],
        [-2.0583, -0.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5437941551208496
Epoch 0, Step 1974: train/loss = 0.6556087732315063, train/raw-loss = 0.6433313488960266, train/logprobs = tensor([[-4.4348, -4.0608],
        [-0.8658, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12277460843324661
Epoch 0, Step 1975: train/loss = 0.45843416452407837, train/raw-loss = 0.4008437395095825, train/logprobs = tensor([[-1.3879, -4.6384],
        [-2.6645, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5759042501449585
Epoch 0, Step 1976: train/loss = 0.5974249839782715, train/raw-loss = 0.5758481025695801, train/logprobs = tensor([[-1.8143, -2.4810],
        [-1.6466, -1.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21576941013336182
Epoch 0, Step 1977: train/loss = 0.4973016381263733, train/raw-loss = 0.4531726837158203, train/logprobs = tensor([[-2.3551, -5.2771],
        [-1.3657, -0.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44128966331481934
Epoch 0, Step 1978: train/loss = 0.5926433205604553, train/raw-loss = 0.5626392364501953, train/logprobs = tensor([[-3.0299, -4.5066],
        [-2.1575, -1.3670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30004066228866577
Epoch 0, Step 1979: train/loss = 0.5016598105430603, train/raw-loss = 0.45099401473999023, train/logprobs = tensor([[-2.0908, -4.9324],
        [-2.3306, -1.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5066580772399902
Epoch 0, Step 1980: train/loss = 0.42702716588974, train/raw-loss = 0.36284491419792175, train/logprobs = tensor([[-1.7606, -5.0720],
        [-2.0536, -0.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6418226957321167
Epoch 0, Step 1981: train/loss = 0.557418167591095, train/raw-loss = 0.5208644866943359, train/logprobs = tensor([[-1.7142, -3.7505],
        [-1.7681, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36553722620010376
Epoch 0, Step 1982: train/loss = 0.536577582359314, train/raw-loss = 0.49652111530303955, train/logprobs = tensor([[-1.5427, -4.8067],
        [-1.6484, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4005647897720337
Epoch 0, Step 1983: train/loss = 0.39051857590675354, train/raw-loss = 0.31590330600738525, train/logprobs = tensor([[-1.2598, -6.4171],
        [-2.5734, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.746152937412262
Epoch 0, Step 1984: train/loss = 0.5278535485267639, train/raw-loss = 0.4835743308067322, train/logprobs = tensor([[-2.3651, -5.1476],
        [-2.5260, -1.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44279244542121887
Epoch 0, Step 1985: train/loss = 0.5978000164031982, train/raw-loss = 0.5781019330024719, train/logprobs = tensor([[-1.7702, -3.0848],
        [-1.5651, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19698114693164825
Epoch 0, Step 1986: train/loss = 0.5603572726249695, train/raw-loss = 0.5256013870239258, train/logprobs = tensor([[-1.6787, -3.1865],
        [-1.9048, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34755855798721313
Epoch 0, Step 1987: train/loss = 0.5607119798660278, train/raw-loss = 0.5300491452217102, train/logprobs = tensor([[-2.3689, -5.4640],
        [-1.1537, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30662810802459717
Epoch 0, Step 1988: train/loss = 0.5482818484306335, train/raw-loss = 0.5113961100578308, train/logprobs = tensor([[-1.6487, -3.6362],
        [-1.9504, -0.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.368857204914093
Epoch 0, Step 1989: train/loss = 0.521302342414856, train/raw-loss = 0.4769321084022522, train/logprobs = tensor([[-2.1381, -2.9053],
        [-1.7824, -1.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4437020421028137
Epoch 0, Step 1990: train/loss = 0.5495761632919312, train/raw-loss = 0.5164023637771606, train/logprobs = tensor([[-2.9504, -4.8869],
        [-1.6820, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3317379653453827
Epoch 0, Step 1991: train/loss = 0.5094021558761597, train/raw-loss = 0.4580116271972656, train/logprobs = tensor([[-2.3890, -5.7287],
        [-1.9909, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5139051079750061
Epoch 0, Step 1992: train/loss = 0.5657172203063965, train/raw-loss = 0.5310110449790955, train/logprobs = tensor([[-2.0463, -5.0582],
        [-1.7631, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34706130623817444
Epoch 0, Step 1993: train/loss = 0.5584504008293152, train/raw-loss = 0.5251950025558472, train/logprobs = tensor([[-2.0261, -4.0271],
        [-1.4559, -0.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3325541019439697
Epoch 0, Step 1994: train/loss = 0.6542358994483948, train/raw-loss = 0.6409186124801636, train/logprobs = tensor([[-1.4110, -1.6737],
        [-2.1268, -1.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13317279517650604
Epoch 0, Step 1995: train/loss = 0.5144603252410889, train/raw-loss = 0.4688904285430908, train/logprobs = tensor([[-1.4506, -4.1463],
        [-2.2573, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4556988477706909
Epoch 0, Step 1996: train/loss = 0.5332270860671997, train/raw-loss = 0.4922441244125366, train/logprobs = tensor([[-2.3043, -4.4911],
        [-1.9130, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40982964634895325
Epoch 0, Step 1997: train/loss = 0.4467831552028656, train/raw-loss = 0.394082248210907, train/logprobs = tensor([[-1.5816, -5.1174],
        [-2.1608, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5270094275474548
Epoch 0, Step 1998: train/loss = 0.6625987887382507, train/raw-loss = 0.6534700393676758, train/logprobs = tensor([[-3.4152, -4.0434],
        [-1.4985, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09128797799348831
Epoch 0, Step 1999: train/loss = 0.5428643822669983, train/raw-loss = 0.5051884651184082, train/logprobs = tensor([[-2.4802, -4.9273],
        [-2.0257, -1.0821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37675946950912476
eval/loss: 0.5368242859840393
Epoch 0, Step 2000: train/loss = 0.5438109636306763, train/raw-loss = 0.5002267360687256, train/logprobs = tensor([[-2.2457, -6.7576],
        [-1.7094, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4358419179916382
Epoch 0, Step 2001: train/loss = 0.590550422668457, train/raw-loss = 0.5664283633232117, train/logprobs = tensor([[-1.3740, -3.1272],
        [-2.1057, -1.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24122034013271332
Epoch 0, Step 2002: train/loss = 0.36369502544403076, train/raw-loss = 0.2921349108219147, train/logprobs = tensor([[-0.8493, -5.0820],
        [-2.2714, -0.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7156011462211609
Epoch 0, Step 2003: train/loss = 0.5513941049575806, train/raw-loss = 0.5042664408683777, train/logprobs = tensor([[-4.5258, -7.4034],
        [-1.5678, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4712764322757721
Epoch 0, Step 2004: train/loss = 0.6407155394554138, train/raw-loss = 0.6219733953475952, train/logprobs = tensor([[-2.5947, -4.0017],
        [-1.4183, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18742188811302185
Epoch 0, Step 2005: train/loss = 0.4776083528995514, train/raw-loss = 0.42056018114089966, train/logprobs = tensor([[-1.7233, -6.9383],
        [-1.9311, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5704814195632935
Epoch 0, Step 2006: train/loss = 0.5270266532897949, train/raw-loss = 0.4853544235229492, train/logprobs = tensor([[-1.9006, -3.6443],
        [-2.0746, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4167220890522003
Epoch 0, Step 2007: train/loss = 0.4783594012260437, train/raw-loss = 0.42377135157585144, train/logprobs = tensor([[-2.2086, -3.2269],
        [-1.3635, -1.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5458802580833435
Epoch 0, Step 2008: train/loss = 0.4542124271392822, train/raw-loss = 0.3966044485569, train/logprobs = tensor([[-2.1229, -6.2432],
        [-1.9259, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.576079785823822
Epoch 0, Step 2009: train/loss = 0.5696309208869934, train/raw-loss = 0.5341178774833679, train/logprobs = tensor([[-2.5174, -4.6437],
        [-1.5813, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.355130672454834
Epoch 0, Step 2010: train/loss = 0.5000423192977905, train/raw-loss = 0.4486028850078583, train/logprobs = tensor([[-1.6465, -4.6578],
        [-2.3565, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5143946409225464
Epoch 0, Step 2011: train/loss = 0.4729781150817871, train/raw-loss = 0.4193233251571655, train/logprobs = tensor([[-2.8430, -6.0269],
        [-1.6946, -0.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5365477800369263
Epoch 0, Step 2012: train/loss = 0.37542518973350525, train/raw-loss = 0.29799163341522217, train/logprobs = tensor([[-1.3792, -7.3182],
        [-2.3110, -0.3644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7743358612060547
Epoch 0, Step 2013: train/loss = 0.48624393343925476, train/raw-loss = 0.43818145990371704, train/logprobs = tensor([[-2.2916, -6.5538],
        [-2.1051, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48062506318092346
Epoch 0, Step 2014: train/loss = 0.5086538791656494, train/raw-loss = 0.462271511554718, train/logprobs = tensor([[-1.7043, -3.9114],
        [-1.9915, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4638236165046692
Epoch 0, Step 2015: train/loss = 0.6597385406494141, train/raw-loss = 0.6519266366958618, train/logprobs = tensor([[-2.6705, -3.3260],
        [-1.7233, -1.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07811929285526276
Epoch 0, Step 2016: train/loss = 0.4963882863521576, train/raw-loss = 0.4521808326244354, train/logprobs = tensor([[-3.3717, -6.2482],
        [-1.9468, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4420745372772217
Epoch 0, Step 2017: train/loss = 0.46870172023773193, train/raw-loss = 0.4136394262313843, train/logprobs = tensor([[-2.7738, -6.4817],
        [-1.9611, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5506226420402527
Epoch 0, Step 2018: train/loss = 0.3752226233482361, train/raw-loss = 0.29777103662490845, train/logprobs = tensor([[-1.4035, -6.0745],
        [-2.5678, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7745159268379211
Epoch 0, Step 2019: train/loss = 0.6989353895187378, train/raw-loss = 0.6986169815063477, train/logprobs = tensor([[-3.2268, -3.1605],
        [-1.6430, -1.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031839751172810793
Epoch 0, Step 2020: train/loss = 0.6836685538291931, train/raw-loss = 0.6791967153549194, train/logprobs = tensor([[-1.5616, -1.2994],
        [-2.0056, -2.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044718559831380844
Epoch 0, Step 2021: train/loss = 0.5101813077926636, train/raw-loss = 0.46731236577033997, train/logprobs = tensor([[-1.6292, -4.6583],
        [-2.3397, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4286894202232361
Epoch 0, Step 2022: train/loss = 0.3179524540901184, train/raw-loss = 0.23255515098571777, train/logprobs = tensor([[-1.1674, -7.7164],
        [-2.7524, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8539730310440063
Epoch 0, Step 2023: train/loss = 0.6065710186958313, train/raw-loss = 0.5882503390312195, train/logprobs = tensor([[-2.3267, -3.6140],
        [-1.6356, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1832069754600525
Epoch 0, Step 2024: train/loss = 0.6047507524490356, train/raw-loss = 0.5776866674423218, train/logprobs = tensor([[-3.2411, -4.6717],
        [-1.2880, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27064114809036255
Epoch 0, Step 2025: train/loss = 0.5634486675262451, train/raw-loss = 0.5337951183319092, train/logprobs = tensor([[-1.7668, -3.9468],
        [-2.1282, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965354025363922
Epoch 0, Step 2026: train/loss = 0.6335004568099976, train/raw-loss = 0.6164336204528809, train/logprobs = tensor([[-4.3180, -5.9493],
        [-1.4668, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17066849768161774
Epoch 0, Step 2027: train/loss = 0.551335334777832, train/raw-loss = 0.5141054391860962, train/logprobs = tensor([[-2.9278, -5.3231],
        [-1.0828, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722992241382599
Epoch 0, Step 2028: train/loss = 0.56060791015625, train/raw-loss = 0.5265331268310547, train/logprobs = tensor([[-1.8985, -3.8684],
        [-1.7549, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34074780344963074
Epoch 0, Step 2029: train/loss = 0.3389507532119751, train/raw-loss = 0.24940502643585205, train/logprobs = tensor([[-1.3021, -7.0019],
        [-2.5361, -0.4138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.89545738697052
Epoch 0, Step 2030: train/loss = 0.34240540862083435, train/raw-loss = 0.26250818371772766, train/logprobs = tensor([[-1.2088, -7.3115],
        [-2.3208, -0.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7989720106124878
Epoch 0, Step 2031: train/loss = 0.4889909029006958, train/raw-loss = 0.43828284740448, train/logprobs = tensor([[-1.1880, -3.1696],
        [-2.5784, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5070804357528687
Epoch 0, Step 2032: train/loss = 0.5811715722084045, train/raw-loss = 0.5522477030754089, train/logprobs = tensor([[-3.7948, -6.0568],
        [-1.8460, -1.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28923869132995605
Epoch 0, Step 2033: train/loss = 0.4931337237358093, train/raw-loss = 0.44163036346435547, train/logprobs = tensor([[-1.7928, -3.7815],
        [-2.4494, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5150331854820251
Epoch 0, Step 2034: train/loss = 0.47986283898353577, train/raw-loss = 0.4337588846683502, train/logprobs = tensor([[-1.6090, -5.3209],
        [-2.1586, -0.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46103915572166443
Epoch 0, Step 2035: train/loss = 0.6012546420097351, train/raw-loss = 0.5704259276390076, train/logprobs = tensor([[-1.9521, -3.2374],
        [-2.3601, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30828696489334106
Epoch 0, Step 2036: train/loss = 0.4774903357028961, train/raw-loss = 0.4258432984352112, train/logprobs = tensor([[-1.3307, -4.3994],
        [-1.8838, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5164704918861389
Epoch 0, Step 2037: train/loss = 0.49042993783950806, train/raw-loss = 0.42930012941360474, train/logprobs = tensor([[-0.8427, -4.0290],
        [-2.5557, -1.4851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.611298143863678
Epoch 0, Step 2038: train/loss = 0.5927674770355225, train/raw-loss = 0.5670042634010315, train/logprobs = tensor([[-2.7430, -4.0473],
        [-1.4493, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25763219594955444
Epoch 0, Step 2039: train/loss = 0.4872131049633026, train/raw-loss = 0.43594855070114136, train/logprobs = tensor([[-2.7841, -6.0425],
        [-2.0610, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5126454830169678
Epoch 0, Step 2040: train/loss = 0.6106778979301453, train/raw-loss = 0.5872529149055481, train/logprobs = tensor([[-2.1996, -3.2068],
        [-1.8275, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23424947261810303
Epoch 0, Step 2041: train/loss = 0.5664722919464111, train/raw-loss = 0.5370070338249207, train/logprobs = tensor([[-1.3332, -2.4876],
        [-2.3478, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2946527302265167
Epoch 0, Step 2042: train/loss = 0.44930052757263184, train/raw-loss = 0.3942100405693054, train/logprobs = tensor([[-1.0847, -5.1836],
        [-2.1228, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5509046912193298
Epoch 0, Step 2043: train/loss = 0.5408529043197632, train/raw-loss = 0.4932665228843689, train/logprobs = tensor([[-2.8400, -5.8602],
        [-2.2141, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4758637249469757
Epoch 0, Step 2044: train/loss = 0.5656355619430542, train/raw-loss = 0.5289158821105957, train/logprobs = tensor([[-2.7562, -5.0428],
        [-2.0513, -1.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3671969473361969
Epoch 0, Step 2045: train/loss = 0.49827128648757935, train/raw-loss = 0.4399709105491638, train/logprobs = tensor([[-3.3966, -7.9338],
        [-1.6548, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5830039978027344
Epoch 0, Step 2046: train/loss = 0.5615019202232361, train/raw-loss = 0.5256574153900146, train/logprobs = tensor([[-1.5787, -4.6302],
        [-2.1726, -1.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35844457149505615
Epoch 0, Step 2047: train/loss = 0.6241906881332397, train/raw-loss = 0.6064382791519165, train/logprobs = tensor([[-1.9632, -2.7928],
        [-2.1017, -1.6965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1775239259004593
Epoch 0, Step 2048: train/loss = 0.4134815037250519, train/raw-loss = 0.3524250388145447, train/logprobs = tensor([[-1.2954, -5.0552],
        [-2.3277, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.610564649105072
Epoch 0, Step 2049: train/loss = 0.5235432982444763, train/raw-loss = 0.4826396107673645, train/logprobs = tensor([[-2.3571, -5.5446],
        [-2.1582, -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40903720259666443
Epoch 0, Step 2050: train/loss = 0.5338771939277649, train/raw-loss = 0.48726728558540344, train/logprobs = tensor([[-5.8958, -9.5572],
        [-2.0216, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46609896421432495
Epoch 0, Step 2051: train/loss = 0.5199089050292969, train/raw-loss = 0.47248363494873047, train/logprobs = tensor([[-1.9614, -4.6659],
        [-2.4442, -0.7787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.474252849817276
Epoch 0, Step 2052: train/loss = 0.5402005910873413, train/raw-loss = 0.49010932445526123, train/logprobs = tensor([[-2.1146, -4.0257],
        [-2.4736, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5009123086929321
Epoch 0, Step 2053: train/loss = 0.550660252571106, train/raw-loss = 0.5163623094558716, train/logprobs = tensor([[-1.7718, -3.4592],
        [-1.8623, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34297898411750793
Epoch 0, Step 2054: train/loss = 0.7612279057502747, train/raw-loss = 0.7539448738098145, train/logprobs = tensor([[-2.8232, -3.2040],
        [-2.0919, -2.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07283028215169907
Epoch 0, Step 2055: train/loss = 0.46029236912727356, train/raw-loss = 0.4061926007270813, train/logprobs = tensor([[-1.3275, -6.9223],
        [-2.3182, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5409976243972778
Epoch 0, Step 2056: train/loss = 0.6232534646987915, train/raw-loss = 0.5929486751556396, train/logprobs = tensor([[-2.1694, -4.2343],
        [-2.3396, -1.4185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30304789543151855
Epoch 0, Step 2057: train/loss = 0.42452219128608704, train/raw-loss = 0.35077089071273804, train/logprobs = tensor([[-1.3487, -4.6894],
        [-2.6624, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7375128269195557
Epoch 0, Step 2058: train/loss = 0.5664082169532776, train/raw-loss = 0.5351877808570862, train/logprobs = tensor([[-2.5331, -4.1289],
        [-2.0017, -1.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3122042715549469
Epoch 0, Step 2059: train/loss = 0.6894820928573608, train/raw-loss = 0.6852913498878479, train/logprobs = tensor([[-3.4938, -3.6508],
        [-1.6459, -1.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041907280683517456
Epoch 0, Step 2060: train/loss = 0.6746731996536255, train/raw-loss = 0.6692267060279846, train/logprobs = tensor([[-3.4558, -3.6859],
        [-1.2952, -1.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05446562543511391
Epoch 0, Step 2061: train/loss = 0.537683367729187, train/raw-loss = 0.5001461505889893, train/logprobs = tensor([[-1.0940, -3.5781],
        [-2.1412, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3753724694252014
Epoch 0, Step 2062: train/loss = 0.5600420832633972, train/raw-loss = 0.5234318971633911, train/logprobs = tensor([[-3.9799, -5.9775],
        [-1.3254, -0.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661026358604431
Epoch 0, Step 2063: train/loss = 0.517589807510376, train/raw-loss = 0.47576501965522766, train/logprobs = tensor([[-2.2782, -5.8842],
        [-1.7831, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182473421096802
Epoch 0, Step 2064: train/loss = 0.5246665477752686, train/raw-loss = 0.48715734481811523, train/logprobs = tensor([[-2.8406, -6.0734],
        [-1.6391, -0.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37509191036224365
Epoch 0, Step 2065: train/loss = 0.4306289255619049, train/raw-loss = 0.36377477645874023, train/logprobs = tensor([[-2.3003, -6.5067],
        [-1.9887, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6685417294502258
Epoch 0, Step 2066: train/loss = 0.5623562335968018, train/raw-loss = 0.5215617418289185, train/logprobs = tensor([[-1.8514, -4.6136],
        [-1.6980, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4079449474811554
Epoch 0, Step 2067: train/loss = 0.6557275056838989, train/raw-loss = 0.6461123824119568, train/logprobs = tensor([[-3.9853, -3.9651],
        [-1.4812, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09615059196949005
Epoch 0, Step 2068: train/loss = 0.46725502610206604, train/raw-loss = 0.42044246196746826, train/logprobs = tensor([[-4.9207, -7.1542],
        [-2.1807, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46812543272972107
Epoch 0, Step 2069: train/loss = 0.47976741194725037, train/raw-loss = 0.435411274433136, train/logprobs = tensor([[-2.4556, -3.7283],
        [-1.7713, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44356146454811096
Epoch 0, Step 2070: train/loss = 0.4275074005126953, train/raw-loss = 0.3656960725784302, train/logprobs = tensor([[-1.8515, -5.1893],
        [-2.4374, -0.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6181128025054932
Epoch 0, Step 2071: train/loss = 0.646523118019104, train/raw-loss = 0.631801187992096, train/logprobs = tensor([[-2.1160, -2.6347],
        [-1.3410, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472194641828537
Epoch 0, Step 2072: train/loss = 0.5971365571022034, train/raw-loss = 0.5757172107696533, train/logprobs = tensor([[-3.0695, -5.1781],
        [-1.4843, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21419382095336914
Epoch 0, Step 2073: train/loss = 0.6060817241668701, train/raw-loss = 0.5789493322372437, train/logprobs = tensor([[-4.2868, -4.7876],
        [-1.2681, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713245153427124
Epoch 0, Step 2074: train/loss = 0.5011979937553406, train/raw-loss = 0.45467332005500793, train/logprobs = tensor([[-1.2980, -3.9326],
        [-2.0852, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4652468264102936
Epoch 0, Step 2075: train/loss = 0.5350081920623779, train/raw-loss = 0.49721065163612366, train/logprobs = tensor([[-2.7284, -4.3585],
        [-2.1352, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3779756426811218
Epoch 0, Step 2076: train/loss = 0.5016498565673828, train/raw-loss = 0.45445072650909424, train/logprobs = tensor([[-2.1691, -5.2492],
        [-2.7145, -1.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47199106216430664
Epoch 0, Step 2077: train/loss = 0.4685591459274292, train/raw-loss = 0.415172815322876, train/logprobs = tensor([[-1.6961, -5.5115],
        [-2.3910, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5338634848594666
Epoch 0, Step 2078: train/loss = 0.609439492225647, train/raw-loss = 0.5834739208221436, train/logprobs = tensor([[-2.5399, -4.9363],
        [-2.7295, -2.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25965583324432373
Epoch 0, Step 2079: train/loss = 0.6980103254318237, train/raw-loss = 0.690780758857727, train/logprobs = tensor([[-2.4637, -2.7461],
        [-1.9201, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0722963735461235
Epoch 0, Step 2080: train/loss = 0.5951615571975708, train/raw-loss = 0.5684816837310791, train/logprobs = tensor([[-3.6588, -5.4828],
        [-1.4811, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2667984962463379
Epoch 0, Step 2081: train/loss = 0.6179313659667969, train/raw-loss = 0.5930188894271851, train/logprobs = tensor([[-4.5894, -5.6931],
        [-1.8263, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24912509322166443
Epoch 0, Step 2082: train/loss = 0.5334628820419312, train/raw-loss = 0.4946386218070984, train/logprobs = tensor([[-1.7815, -3.3891],
        [-2.3986, -1.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3882432281970978
Epoch 0, Step 2083: train/loss = 0.6085332036018372, train/raw-loss = 0.5799320936203003, train/logprobs = tensor([[-2.0662, -3.3981],
        [-1.8578, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860114574432373
Epoch 0, Step 2084: train/loss = 0.6048361659049988, train/raw-loss = 0.5802538990974426, train/logprobs = tensor([[-5.6086, -7.1296],
        [-1.4298, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24582237005233765
Epoch 0, Step 2085: train/loss = 0.37523239850997925, train/raw-loss = 0.3005298376083374, train/logprobs = tensor([[-1.9493, -7.5152],
        [-2.5968, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7470254898071289
Epoch 0, Step 2086: train/loss = 0.6088365316390991, train/raw-loss = 0.5842688083648682, train/logprobs = tensor([[-2.1274, -3.2547],
        [-2.0510, -1.3007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24567735195159912
Epoch 0, Step 2087: train/loss = 0.5027962923049927, train/raw-loss = 0.4530656635761261, train/logprobs = tensor([[-3.6401, -5.7694],
        [-2.0303, -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4973062574863434
Epoch 0, Step 2088: train/loss = 0.6013581156730652, train/raw-loss = 0.5774803757667542, train/logprobs = tensor([[-2.9831, -4.1659],
        [-1.2992, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23877757787704468
Epoch 0, Step 2089: train/loss = 0.6143787503242493, train/raw-loss = 0.5880982875823975, train/logprobs = tensor([[-5.3310, -7.8733],
        [-1.5665, -1.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2628041207790375
Epoch 0, Step 2090: train/loss = 0.6645863652229309, train/raw-loss = 0.6521498560905457, train/logprobs = tensor([[-1.6750, -2.5717],
        [-2.0703, -1.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12436510622501373
Epoch 0, Step 2091: train/loss = 0.5556533336639404, train/raw-loss = 0.5105782747268677, train/logprobs = tensor([[-3.4108, -6.0156],
        [-1.6689, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45075082778930664
Epoch 0, Step 2092: train/loss = 0.48828035593032837, train/raw-loss = 0.43887463212013245, train/logprobs = tensor([[-1.3449, -4.6314],
        [-2.3233, -1.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49405670166015625
Epoch 0, Step 2093: train/loss = 0.6768701076507568, train/raw-loss = 0.6457933187484741, train/logprobs = tensor([[-5.4631, -5.2536],
        [-2.1165, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107684850692749
Epoch 0, Step 2094: train/loss = 0.5459470748901367, train/raw-loss = 0.5079803466796875, train/logprobs = tensor([[-1.0362, -3.6762],
        [-2.7124, -1.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3796675205230713
Epoch 0, Step 2095: train/loss = 0.5188033580780029, train/raw-loss = 0.4747447073459625, train/logprobs = tensor([[-3.5581, -5.7840],
        [-1.8823, -0.7468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4405866861343384
Epoch 0, Step 2096: train/loss = 0.42514127492904663, train/raw-loss = 0.3571570813655853, train/logprobs = tensor([[-2.1849, -7.2599],
        [-2.4750, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6798420548439026
Epoch 0, Step 2097: train/loss = 0.5663777589797974, train/raw-loss = 0.5345356464385986, train/logprobs = tensor([[-3.2939, -4.9583],
        [-1.5526, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184211254119873
Epoch 0, Step 2098: train/loss = 0.538042426109314, train/raw-loss = 0.5065253973007202, train/logprobs = tensor([[-1.2152, -2.5556],
        [-3.1753, -1.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3151699900627136
Epoch 0, Step 2099: train/loss = 0.4145685136318207, train/raw-loss = 0.34899044036865234, train/logprobs = tensor([[-2.9275, -6.5237],
        [-2.9233, -1.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.655780553817749
Epoch 0, Step 2100: train/loss = 0.44012707471847534, train/raw-loss = 0.3772203326225281, train/logprobs = tensor([[-1.6274, -5.3835],
        [-3.1310, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6290674209594727
Epoch 0, Step 2101: train/loss = 0.6809092164039612, train/raw-loss = 0.677700936794281, train/logprobs = tensor([[-3.7873, -4.0441],
        [-1.5376, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032083310186862946
Epoch 0, Step 2102: train/loss = 0.5955839157104492, train/raw-loss = 0.5724653601646423, train/logprobs = tensor([[-3.7582, -4.8739],
        [-1.7297, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23118580877780914
Epoch 0, Step 2103: train/loss = 0.5440824031829834, train/raw-loss = 0.5041002035140991, train/logprobs = tensor([[-3.5835, -5.9774],
        [-1.7629, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998219966888428
Epoch 0, Step 2104: train/loss = 0.5256085395812988, train/raw-loss = 0.4856413006782532, train/logprobs = tensor([[-3.5443, -6.1826],
        [-1.8513, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3996729254722595
Epoch 0, Step 2105: train/loss = 0.4621073007583618, train/raw-loss = 0.4031717777252197, train/logprobs = tensor([[-1.3363, -4.4937],
        [-3.0400, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5893549919128418
Epoch 0, Step 2106: train/loss = 0.43741750717163086, train/raw-loss = 0.376941055059433, train/logprobs = tensor([[-1.4485, -5.5288],
        [-2.1461, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6047642230987549
Epoch 0, Step 2107: train/loss = 0.6804693937301636, train/raw-loss = 0.6487027406692505, train/logprobs = tensor([[-3.1044, -3.7922],
        [-2.4436, -2.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3176661729812622
Epoch 0, Step 2108: train/loss = 0.6449299454689026, train/raw-loss = 0.6291213631629944, train/logprobs = tensor([[-2.7131, -3.1407],
        [-1.3993, -1.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15808574855327606
Epoch 0, Step 2109: train/loss = 0.6228199601173401, train/raw-loss = 0.6044145822525024, train/logprobs = tensor([[-1.2991, -2.5909],
        [-2.2167, -2.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18405365943908691
Epoch 0, Step 2110: train/loss = 0.35722148418426514, train/raw-loss = 0.27689534425735474, train/logprobs = tensor([[-1.0521, -5.3312],
        [-2.8526, -1.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8032616376876831
Epoch 0, Step 2111: train/loss = 0.4705425202846527, train/raw-loss = 0.4163382947444916, train/logprobs = tensor([[-2.5668, -6.1141],
        [-1.8753, -0.7986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5420424938201904
Epoch 0, Step 2112: train/loss = 0.48299261927604675, train/raw-loss = 0.4327225685119629, train/logprobs = tensor([[-1.8095, -5.2535],
        [-2.4559, -1.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.502700686454773
Epoch 0, Step 2113: train/loss = 0.5212029218673706, train/raw-loss = 0.47077566385269165, train/logprobs = tensor([[-3.0123, -5.8550],
        [-1.8940, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5042722225189209
Epoch 0, Step 2114: train/loss = 0.5486387610435486, train/raw-loss = 0.5125337839126587, train/logprobs = tensor([[-1.4574, -3.6898],
        [-1.9932, -1.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610495328903198
Epoch 0, Step 2115: train/loss = 0.5653257369995117, train/raw-loss = 0.5271382331848145, train/logprobs = tensor([[-2.6750, -5.1235],
        [-2.0575, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38187524676322937
Epoch 0, Step 2116: train/loss = 0.5900415182113647, train/raw-loss = 0.5666983723640442, train/logprobs = tensor([[-1.7991, -3.5706],
        [-2.1592, -1.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23343133926391602
Epoch 0, Step 2117: train/loss = 0.650554358959198, train/raw-loss = 0.6357394456863403, train/logprobs = tensor([[-2.3001, -3.4993],
        [-2.5617, -2.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14814920723438263
Epoch 0, Step 2118: train/loss = 0.4847579598426819, train/raw-loss = 0.43652281165122986, train/logprobs = tensor([[-1.9936, -4.8958],
        [-2.1836, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48235148191452026
Epoch 0, Step 2119: train/loss = 0.46851205825805664, train/raw-loss = 0.41117265820503235, train/logprobs = tensor([[-1.0892, -5.1376],
        [-3.3070, -1.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5733940005302429
Epoch 0, Step 2120: train/loss = 0.42377838492393494, train/raw-loss = 0.36291858553886414, train/logprobs = tensor([[-1.2557, -4.2346],
        [-2.3197, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.608597993850708
Epoch 0, Step 2121: train/loss = 0.66832435131073, train/raw-loss = 0.6173110604286194, train/logprobs = tensor([[-3.5065, -3.3221],
        [-2.8077, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5101335048675537
Epoch 0, Step 2122: train/loss = 0.36356306076049805, train/raw-loss = 0.29047340154647827, train/logprobs = tensor([[-1.8330, -7.2388],
        [-3.3355, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7308967709541321
Epoch 0, Step 2123: train/loss = 0.4717336595058441, train/raw-loss = 0.41886842250823975, train/logprobs = tensor([[-1.2032, -5.2193],
        [-2.3030, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5286524295806885
Epoch 0, Step 2124: train/loss = 0.45736315846443176, train/raw-loss = 0.3991411626338959, train/logprobs = tensor([[-1.2292, -3.8696],
        [-2.7612, -1.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5822197198867798
Epoch 0, Step 2125: train/loss = 0.7007687091827393, train/raw-loss = 0.6938867568969727, train/logprobs = tensor([[-3.7853, -3.8156],
        [-1.5331, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06881939619779587
Epoch 0, Step 2126: train/loss = 0.36220118403434753, train/raw-loss = 0.28438064455986023, train/logprobs = tensor([[-1.5216, -6.2567],
        [-2.7677, -1.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7782055735588074
Epoch 0, Step 2127: train/loss = 0.6517781019210815, train/raw-loss = 0.6371300220489502, train/logprobs = tensor([[-2.0353, -3.0507],
        [-2.1882, -1.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14648137986660004
Epoch 0, Step 2128: train/loss = 0.4716719388961792, train/raw-loss = 0.4144752025604248, train/logprobs = tensor([[-1.8205, -5.1577],
        [-2.0275, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5719673037528992
Epoch 0, Step 2129: train/loss = 0.6441766619682312, train/raw-loss = 0.632328987121582, train/logprobs = tensor([[-2.7464, -3.5773],
        [-2.1014, -1.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847623437643051
Epoch 0, Step 2130: train/loss = 0.5283150672912598, train/raw-loss = 0.485186368227005, train/logprobs = tensor([[-2.0884, -4.8286],
        [-2.1870, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43128693103790283
Epoch 0, Step 2131: train/loss = 0.498165488243103, train/raw-loss = 0.45142319798469543, train/logprobs = tensor([[-1.4904, -4.1681],
        [-2.2105, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4674230217933655
Epoch 0, Step 2132: train/loss = 0.541024923324585, train/raw-loss = 0.5035330057144165, train/logprobs = tensor([[-2.5981, -4.8698],
        [-1.9687, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3749186098575592
Epoch 0, Step 2133: train/loss = 0.47513413429260254, train/raw-loss = 0.4220363199710846, train/logprobs = tensor([[-2.3898, -6.0121],
        [-1.6778, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5309780240058899
Epoch 0, Step 2134: train/loss = 0.5332205891609192, train/raw-loss = 0.49837449193000793, train/logprobs = tensor([[-3.1658, -4.0609],
        [-1.8596, -1.5654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34846070408821106
Epoch 0, Step 2135: train/loss = 0.531699001789093, train/raw-loss = 0.49269425868988037, train/logprobs = tensor([[-1.8124, -4.4277],
        [-1.6006, -0.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3900470733642578
Epoch 0, Step 2136: train/loss = 0.462228387594223, train/raw-loss = 0.40461570024490356, train/logprobs = tensor([[-2.1841, -5.8391],
        [-2.0542, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5761268138885498
Epoch 0, Step 2137: train/loss = 0.4862164855003357, train/raw-loss = 0.4339445233345032, train/logprobs = tensor([[-2.4396, -4.8399],
        [-2.3248, -0.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5227196216583252
Epoch 0, Step 2138: train/loss = 0.5532732009887695, train/raw-loss = 0.4918738603591919, train/logprobs = tensor([[-2.4591, -6.0589],
        [-2.6942, -1.3281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6139932870864868
Epoch 0, Step 2139: train/loss = 0.6652870178222656, train/raw-loss = 0.6327008008956909, train/logprobs = tensor([[-1.6693, -2.4809],
        [-2.9844, -2.5105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258625566959381
Epoch 0, Step 2140: train/loss = 0.6443092823028564, train/raw-loss = 0.6296086311340332, train/logprobs = tensor([[-6.2622, -7.2077],
        [-0.9405, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14700698852539062
Epoch 0, Step 2141: train/loss = 0.5712248086929321, train/raw-loss = 0.53865647315979, train/logprobs = tensor([[-2.6415, -3.4569],
        [-1.8821, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3256838917732239
Epoch 0, Step 2142: train/loss = 0.5727189779281616, train/raw-loss = 0.5382830500602722, train/logprobs = tensor([[-2.0570, -4.5172],
        [-2.1407, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34435975551605225
Epoch 0, Step 2143: train/loss = 0.6109541058540344, train/raw-loss = 0.5785183906555176, train/logprobs = tensor([[-1.4677, -3.7602],
        [-1.7369, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32435694336891174
Epoch 0, Step 2144: train/loss = 0.6464152336120605, train/raw-loss = 0.6327488422393799, train/logprobs = tensor([[-1.4855, -1.7016],
        [-2.0838, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13666385412216187
Epoch 0, Step 2145: train/loss = 0.46094709634780884, train/raw-loss = 0.4076235592365265, train/logprobs = tensor([[-1.8792, -4.2480],
        [-2.4037, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5332353115081787
Epoch 0, Step 2146: train/loss = 0.4874083995819092, train/raw-loss = 0.43903225660324097, train/logprobs = tensor([[-2.7616, -6.0086],
        [-1.9207, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4837613105773926
Epoch 0, Step 2147: train/loss = 0.4217224717140198, train/raw-loss = 0.3583243489265442, train/logprobs = tensor([[-1.2388, -4.7022],
        [-2.6609, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6339809894561768
Epoch 0, Step 2148: train/loss = 0.5722148418426514, train/raw-loss = 0.5425264835357666, train/logprobs = tensor([[-1.1750, -2.6454],
        [-2.3870, -1.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968839406967163
Epoch 0, Step 2149: train/loss = 0.28451040387153625, train/raw-loss = 0.1867453157901764, train/logprobs = tensor([[-0.6564, -5.1006],
        [-3.3307, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9776508212089539
Epoch 0, Step 2150: train/loss = 0.38173866271972656, train/raw-loss = 0.3113907277584076, train/logprobs = tensor([[-1.5561, -5.9377],
        [-3.3514, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7034792900085449
Epoch 0, Step 2151: train/loss = 0.39714515209198, train/raw-loss = 0.32012939453125, train/logprobs = tensor([[-1.9973, -6.4753],
        [-2.3313, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7701574563980103
Epoch 0, Step 2152: train/loss = 0.5258191227912903, train/raw-loss = 0.4868720769882202, train/logprobs = tensor([[-1.2176, -3.6768],
        [-1.9165, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894706666469574
Epoch 0, Step 2153: train/loss = 0.43115055561065674, train/raw-loss = 0.3660236597061157, train/logprobs = tensor([[-1.6087, -5.1083],
        [-2.2654, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6512689590454102
Epoch 0, Step 2154: train/loss = 0.5844285488128662, train/raw-loss = 0.5574557185173035, train/logprobs = tensor([[-1.2749, -2.4656],
        [-2.6666, -2.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697281539440155
Epoch 0, Step 2155: train/loss = 0.45987460017204285, train/raw-loss = 0.3979697823524475, train/logprobs = tensor([[-1.3115, -4.7340],
        [-3.1545, -1.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6190482378005981
Epoch 0, Step 2156: train/loss = 0.4894142746925354, train/raw-loss = 0.43426036834716797, train/logprobs = tensor([[-3.0663, -7.4204],
        [-2.2583, -0.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5515388250350952
Epoch 0, Step 2157: train/loss = 0.6632050275802612, train/raw-loss = 0.6375591158866882, train/logprobs = tensor([[-2.9337, -5.0019],
        [-2.8343, -2.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564590573310852
Epoch 0, Step 2158: train/loss = 0.5981225967407227, train/raw-loss = 0.5716773271560669, train/logprobs = tensor([[-1.6815, -3.2142],
        [-2.3069, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26445192098617554
Epoch 0, Step 2159: train/loss = 0.5126088261604309, train/raw-loss = 0.46778178215026855, train/logprobs = tensor([[-1.4281, -3.8872],
        [-2.9104, -1.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4482700228691101
Epoch 0, Step 2160: train/loss = 0.5953226089477539, train/raw-loss = 0.5634998083114624, train/logprobs = tensor([[-1.4202, -2.7511],
        [-3.0839, -1.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182278871536255
Epoch 0, Step 2161: train/loss = 0.8873528242111206, train/raw-loss = 0.8457375764846802, train/logprobs = tensor([[-1.0927, -5.1059],
        [-2.6440, -2.7100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4161531925201416
Epoch 0, Step 2162: train/loss = 0.48064881563186646, train/raw-loss = 0.42904308438301086, train/logprobs = tensor([[-2.1252, -4.7833],
        [-2.9407, -1.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5160572528839111
Epoch 0, Step 2163: train/loss = 0.5906738638877869, train/raw-loss = 0.5646766424179077, train/logprobs = tensor([[-4.9495, -7.0592],
        [-1.2788, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25997254252433777
Epoch 0, Step 2164: train/loss = 0.42232373356819153, train/raw-loss = 0.3630114793777466, train/logprobs = tensor([[-2.6324, -7.2602],
        [-2.2989, -0.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5931227207183838
Epoch 0, Step 2165: train/loss = 0.3666161298751831, train/raw-loss = 0.2963867485523224, train/logprobs = tensor([[-2.2676, -8.1691],
        [-2.9389, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7022939324378967
Epoch 0, Step 2166: train/loss = 0.5451145768165588, train/raw-loss = 0.49332451820373535, train/logprobs = tensor([[-2.4725, -6.6091],
        [-1.7251, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5179005861282349
Epoch 0, Step 2167: train/loss = 0.460475891828537, train/raw-loss = 0.4060356616973877, train/logprobs = tensor([[-0.7245, -3.9445],
        [-2.2101, -1.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5444023609161377
Epoch 0, Step 2168: train/loss = 0.4466053545475006, train/raw-loss = 0.39092162251472473, train/logprobs = tensor([[-1.9346, -5.9288],
        [-2.3339, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5568374395370483
Epoch 0, Step 2169: train/loss = 0.6947202086448669, train/raw-loss = 0.6850488781929016, train/logprobs = tensor([[-5.4561, -5.1605],
        [-1.5029, -1.1551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09671343863010406
Epoch 0, Step 2170: train/loss = 0.5685200095176697, train/raw-loss = 0.5315941572189331, train/logprobs = tensor([[-1.5126, -3.8097],
        [-2.6322, -1.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692585527896881
Epoch 0, Step 2171: train/loss = 0.6080129146575928, train/raw-loss = 0.5810512900352478, train/logprobs = tensor([[-1.0294, -2.5892],
        [-1.8760, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26961591839790344
Epoch 0, Step 2172: train/loss = 0.471497118473053, train/raw-loss = 0.42335882782936096, train/logprobs = tensor([[-2.7337, -4.8015],
        [-3.0792, -1.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48138293623924255
Epoch 0, Step 2173: train/loss = 0.591421365737915, train/raw-loss = 0.5678191184997559, train/logprobs = tensor([[-1.2704, -2.8781],
        [-2.5524, -2.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2360222041606903
Epoch 0, Step 2174: train/loss = 0.5060615539550781, train/raw-loss = 0.45423856377601624, train/logprobs = tensor([[-2.6678, -5.9754],
        [-2.4607, -1.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5182296633720398
Epoch 0, Step 2175: train/loss = 0.6355984210968018, train/raw-loss = 0.6233578324317932, train/logprobs = tensor([[-1.9782, -2.5924],
        [-2.7451, -2.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12240534275770187
Epoch 0, Step 2176: train/loss = 0.6184607148170471, train/raw-loss = 0.5999674797058105, train/logprobs = tensor([[-2.0008, -2.9476],
        [-2.2472, -1.6408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1849319338798523
Epoch 0, Step 2177: train/loss = 0.6052112579345703, train/raw-loss = 0.5767973065376282, train/logprobs = tensor([[-3.3639, -1.6280],
        [-1.6667, -1.2247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2841392457485199
Epoch 0, Step 2178: train/loss = 0.5753240585327148, train/raw-loss = 0.5443546772003174, train/logprobs = tensor([[-1.5102, -3.2361],
        [-2.6590, -1.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30969393253326416
Epoch 0, Step 2179: train/loss = 0.46973323822021484, train/raw-loss = 0.4167066812515259, train/logprobs = tensor([[-2.8914, -6.3708],
        [-1.9512, -1.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.530265212059021
Epoch 0, Step 2180: train/loss = 0.3508720099925995, train/raw-loss = 0.27680137753486633, train/logprobs = tensor([[-1.1623, -6.7293],
        [-3.1977, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7407064437866211
Epoch 0, Step 2181: train/loss = 0.5022091269493103, train/raw-loss = 0.4503712058067322, train/logprobs = tensor([[-1.7596, -5.6881],
        [-2.3162, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5183789134025574
Epoch 0, Step 2182: train/loss = 0.635798990726471, train/raw-loss = 0.6177117228507996, train/logprobs = tensor([[-1.8117, -2.8831],
        [-2.2761, -1.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18087276816368103
Epoch 0, Step 2183: train/loss = 0.5142298936843872, train/raw-loss = 0.4723515510559082, train/logprobs = tensor([[-3.5375, -6.1727],
        [-2.0623, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41878339648246765
Epoch 0, Step 2184: train/loss = 0.3947083353996277, train/raw-loss = 0.3307144045829773, train/logprobs = tensor([[-2.6216, -6.1784],
        [-3.0790, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6399394273757935
Epoch 0, Step 2185: train/loss = 0.5633522868156433, train/raw-loss = 0.533645749092102, train/logprobs = tensor([[-1.1327, -2.7684],
        [-2.9390, -1.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29706552624702454
Epoch 0, Step 2186: train/loss = 0.6387463212013245, train/raw-loss = 0.6239002346992493, train/logprobs = tensor([[-2.7688, -3.3183],
        [-1.5293, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484607756137848
Epoch 0, Step 2187: train/loss = 0.4673185646533966, train/raw-loss = 0.41212472319602966, train/logprobs = tensor([[-1.2522, -3.8590],
        [-2.9640, -1.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.551938533782959
Epoch 0, Step 2188: train/loss = 0.44221043586730957, train/raw-loss = 0.378495454788208, train/logprobs = tensor([[-1.7495, -5.1676],
        [-2.4065, -1.0453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.63714998960495
Epoch 0, Step 2189: train/loss = 0.6156452298164368, train/raw-loss = 0.5948893427848816, train/logprobs = tensor([[-1.7384, -3.5360],
        [-2.3013, -1.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20755881071090698
Epoch 0, Step 2190: train/loss = 0.32656729221343994, train/raw-loss = 0.2527385354042053, train/logprobs = tensor([[-1.2756, -6.6808],
        [-3.0558, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.738287627696991
Epoch 0, Step 2191: train/loss = 0.6068630218505859, train/raw-loss = 0.5924878716468811, train/logprobs = tensor([[-3.8015, -6.6131],
        [-2.1068, -1.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14375166594982147
Epoch 0, Step 2192: train/loss = 0.45425736904144287, train/raw-loss = 0.39620402455329895, train/logprobs = tensor([[-1.1802, -3.7152],
        [-2.8019, -1.0015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5805333256721497
Epoch 0, Step 2193: train/loss = 0.4778001010417938, train/raw-loss = 0.4222233295440674, train/logprobs = tensor([[-1.2282, -5.2130],
        [-2.7324, -1.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5557674169540405
Epoch 0, Step 2194: train/loss = 0.3567386865615845, train/raw-loss = 0.28829729557037354, train/logprobs = tensor([[-2.2829, -8.0479],
        [-2.7939, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6844141483306885
Epoch 0, Step 2195: train/loss = 0.4667442739009857, train/raw-loss = 0.40881457924842834, train/logprobs = tensor([[-3.5618, -6.7600],
        [-2.0989, -0.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5792970061302185
Epoch 0, Step 2196: train/loss = 0.42126697301864624, train/raw-loss = 0.3580079674720764, train/logprobs = tensor([[-2.9331, -6.9413],
        [-2.5477, -0.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6325903534889221
Epoch 0, Step 2197: train/loss = 0.5423977375030518, train/raw-loss = 0.49207016825675964, train/logprobs = tensor([[-4.2884, -6.6281],
        [-1.8755, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5032752752304077
Epoch 0, Step 2198: train/loss = 0.314318984746933, train/raw-loss = 0.2248738408088684, train/logprobs = tensor([[-1.3706, -6.4767],
        [-3.5364, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8944515585899353
Epoch 0, Step 2199: train/loss = 0.5190112590789795, train/raw-loss = 0.47819578647613525, train/logprobs = tensor([[-1.2679, -3.5305],
        [-2.2927, -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40815484523773193
Epoch 0, Step 2200: train/loss = 0.5622766017913818, train/raw-loss = 0.5269620418548584, train/logprobs = tensor([[-1.7664, -2.9003],
        [-2.0845, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35314613580703735
Epoch 0, Step 2201: train/loss = 0.5310078859329224, train/raw-loss = 0.4890438914299011, train/logprobs = tensor([[-2.3097, -5.0232],
        [-1.8183, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41964006423950195
Epoch 0, Step 2202: train/loss = 0.49230653047561646, train/raw-loss = 0.41854947805404663, train/logprobs = tensor([[-1.5014, -7.4076],
        [-3.0088, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7375704050064087
Epoch 0, Step 2203: train/loss = 0.47161242365837097, train/raw-loss = 0.41676273941993713, train/logprobs = tensor([[-2.3356, -6.7760],
        [-2.3627, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5484967231750488
Epoch 0, Step 2204: train/loss = 0.5794308185577393, train/raw-loss = 0.546387255191803, train/logprobs = tensor([[-2.1415, -3.5664],
        [-3.4397, -2.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33043572306632996
Epoch 0, Step 2205: train/loss = 0.6423860192298889, train/raw-loss = 0.6253690123558044, train/logprobs = tensor([[-3.0591, -3.5661],
        [-1.1140, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17017041146755219
Epoch 0, Step 2206: train/loss = 0.4286516606807709, train/raw-loss = 0.36493322253227234, train/logprobs = tensor([[-3.2546, -7.4252],
        [-2.1862, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.637184202671051
Epoch 0, Step 2207: train/loss = 0.6569083333015442, train/raw-loss = 0.6304973363876343, train/logprobs = tensor([[-2.4513, -3.2133],
        [-2.1636, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26410993933677673
Epoch 0, Step 2208: train/loss = 0.51149982213974, train/raw-loss = 0.45439696311950684, train/logprobs = tensor([[-1.9598, -4.4782],
        [-2.2639, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.571028470993042
Epoch 0, Step 2209: train/loss = 0.5105299949645996, train/raw-loss = 0.46968892216682434, train/logprobs = tensor([[-1.6634, -3.5920],
        [-3.2001, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084107577800751
Epoch 0, Step 2210: train/loss = 0.5860646963119507, train/raw-loss = 0.5477500557899475, train/logprobs = tensor([[-3.6557, -7.1968],
        [-1.8498, -1.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3831462264060974
Epoch 0, Step 2211: train/loss = 0.504561722278595, train/raw-loss = 0.4555182456970215, train/logprobs = tensor([[-1.4226, -3.6043],
        [-3.1351, -1.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49043428897857666
Epoch 0, Step 2212: train/loss = 0.4499979019165039, train/raw-loss = 0.3864392936229706, train/logprobs = tensor([[-3.7840, -6.2075],
        [-1.3245, -0.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6355865001678467
Epoch 0, Step 2213: train/loss = 0.4678539037704468, train/raw-loss = 0.4104663133621216, train/logprobs = tensor([[-2.0453, -6.6072],
        [-2.0736, -1.1566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5738755464553833
Epoch 0, Step 2214: train/loss = 0.44356605410575867, train/raw-loss = 0.37599116563796997, train/logprobs = tensor([[-1.5936, -6.7383],
        [-3.0058, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6757491827011108
Epoch 0, Step 2215: train/loss = 0.6477977633476257, train/raw-loss = 0.6283955574035645, train/logprobs = tensor([[-1.7689, -2.8738],
        [-2.6883, -2.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1940220147371292
Epoch 0, Step 2216: train/loss = 0.4015669524669647, train/raw-loss = 0.336444616317749, train/logprobs = tensor([[-1.9114, -5.8749],
        [-2.8248, -0.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.651223361492157
Epoch 0, Step 2217: train/loss = 0.5462431311607361, train/raw-loss = 0.5092639923095703, train/logprobs = tensor([[-1.2487, -2.9738],
        [-2.4247, -1.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3697914481163025
Epoch 0, Step 2218: train/loss = 0.6901684403419495, train/raw-loss = 0.68068528175354, train/logprobs = tensor([[-1.5203, -1.9161],
        [-2.7451, -2.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483139216899872
Epoch 0, Step 2219: train/loss = 0.5249030590057373, train/raw-loss = 0.4829065203666687, train/logprobs = tensor([[-1.7702, -4.0096],
        [-2.5429, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199654757976532
Epoch 0, Step 2220: train/loss = 0.6035158634185791, train/raw-loss = 0.5809842348098755, train/logprobs = tensor([[-2.0912, -3.6205],
        [-1.8832, -1.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253158539533615
Epoch 0, Step 2221: train/loss = 0.3136056065559387, train/raw-loss = 0.21901684999465942, train/logprobs = tensor([[-1.3058, -5.8093],
        [-3.2708, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9458876252174377
Epoch 0, Step 2222: train/loss = 0.4461362659931183, train/raw-loss = 0.39568546414375305, train/logprobs = tensor([[-2.7366, -5.3360],
        [-2.4470, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5045075416564941
Epoch 0, Step 2223: train/loss = 0.49663862586021423, train/raw-loss = 0.45245084166526794, train/logprobs = tensor([[-2.9238, -5.7424],
        [-2.3272, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44187796115875244
Epoch 0, Step 2224: train/loss = 0.529981255531311, train/raw-loss = 0.4839140772819519, train/logprobs = tensor([[-3.7324, -5.5276],
        [-2.6013, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4606720209121704
Epoch 0, Step 2225: train/loss = 0.4986454248428345, train/raw-loss = 0.4483453929424286, train/logprobs = tensor([[-2.7645, -6.1191],
        [-1.9227, -1.1003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5029999613761902
Epoch 0, Step 2226: train/loss = 0.44425827264785767, train/raw-loss = 0.387844979763031, train/logprobs = tensor([[-3.4830, -7.2218],
        [-2.7837, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5641329288482666
Epoch 0, Step 2227: train/loss = 0.5635135173797607, train/raw-loss = 0.5277397036552429, train/logprobs = tensor([[-1.8969, -3.4097],
        [-1.7846, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35773831605911255
Epoch 0, Step 2228: train/loss = 0.5580103397369385, train/raw-loss = 0.5189691185951233, train/logprobs = tensor([[-1.9655, -3.9791],
        [-3.1737, -1.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39041224122047424
Epoch 0, Step 2229: train/loss = 0.47418808937072754, train/raw-loss = 0.4159403145313263, train/logprobs = tensor([[-2.3966, -4.8709],
        [-2.8995, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.582477331161499
Epoch 0, Step 2230: train/loss = 0.6222580671310425, train/raw-loss = 0.6015142202377319, train/logprobs = tensor([[-1.5486, -2.6028],
        [-2.4229, -2.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20743894577026367
Epoch 0, Step 2231: train/loss = 0.5158191323280334, train/raw-loss = 0.4797065854072571, train/logprobs = tensor([[-1.1441, -3.9991],
        [-2.6261, -1.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36112549901008606
Epoch 0, Step 2232: train/loss = 0.31816473603248596, train/raw-loss = 0.23893281817436218, train/logprobs = tensor([[-1.3840, -7.1214],
        [-3.6065, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.792319118976593
Epoch 0, Step 2233: train/loss = 0.5274878144264221, train/raw-loss = 0.4813585877418518, train/logprobs = tensor([[-1.7133, -5.7812],
        [-2.5255, -1.7139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4612922668457031
Epoch 0, Step 2234: train/loss = 0.5417773127555847, train/raw-loss = 0.5010455846786499, train/logprobs = tensor([[-2.5177, -5.6215],
        [-2.0441, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4073169231414795
Epoch 0, Step 2235: train/loss = 0.5211512446403503, train/raw-loss = 0.4774053394794464, train/logprobs = tensor([[-1.8989, -5.0538],
        [-2.3755, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43745890259742737
Epoch 0, Step 2236: train/loss = 0.5418052077293396, train/raw-loss = 0.5092273950576782, train/logprobs = tensor([[-2.1942, -5.2680],
        [-1.8588, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32577794790267944
Epoch 0, Step 2237: train/loss = 0.5706076622009277, train/raw-loss = 0.5356888771057129, train/logprobs = tensor([[-2.6705, -6.8593],
        [-1.7706, -1.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3491875231266022
Epoch 0, Step 2238: train/loss = 0.5526912808418274, train/raw-loss = 0.5136791467666626, train/logprobs = tensor([[-5.6485, -6.3004],
        [-2.0316, -1.0474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3901214301586151
Epoch 0, Step 2239: train/loss = 0.4158461391925812, train/raw-loss = 0.36071470379829407, train/logprobs = tensor([[-1.6767, -6.0881],
        [-2.6972, -0.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5513142347335815
Epoch 0, Step 2240: train/loss = 0.5097134709358215, train/raw-loss = 0.46961238980293274, train/logprobs = tensor([[-3.1382, -7.0470],
        [-2.0435, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010108709335327
Epoch 0, Step 2241: train/loss = 0.38982972502708435, train/raw-loss = 0.3180181086063385, train/logprobs = tensor([[-1.4125, -6.9306],
        [-2.6520, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7181161642074585
Epoch 0, Step 2242: train/loss = 0.4861255884170532, train/raw-loss = 0.4350684881210327, train/logprobs = tensor([[-2.4844, -5.3114],
        [-1.6937, -1.3511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5105706453323364
Epoch 0, Step 2243: train/loss = 0.4068301320075989, train/raw-loss = 0.3380492627620697, train/logprobs = tensor([[-1.9278, -4.9615],
        [-2.4414, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6878085136413574
Epoch 0, Step 2244: train/loss = 0.5817034840583801, train/raw-loss = 0.5535942316055298, train/logprobs = tensor([[-1.7514, -2.9066],
        [-2.5120, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28109219670295715
Epoch 0, Step 2245: train/loss = 0.5569804906845093, train/raw-loss = 0.5101984143257141, train/logprobs = tensor([[-1.2270, -3.5899],
        [-2.5962, -1.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.467820942401886
Epoch 0, Step 2246: train/loss = 0.6149706840515137, train/raw-loss = 0.5948271155357361, train/logprobs = tensor([[-3.5026, -4.5831],
        [-1.7810, -1.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20143555104732513
Epoch 0, Step 2247: train/loss = 0.38672494888305664, train/raw-loss = 0.3124012351036072, train/logprobs = tensor([[-1.9900, -7.6627],
        [-2.5510, -1.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.743237316608429
Epoch 0, Step 2248: train/loss = 0.5590305924415588, train/raw-loss = 0.5240054130554199, train/logprobs = tensor([[-2.2302, -4.0405],
        [-2.4518, -1.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502519726753235
Epoch 0, Step 2249: train/loss = 0.5663463473320007, train/raw-loss = 0.5332300662994385, train/logprobs = tensor([[-3.2212, -4.1862],
        [-1.4822, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3311632573604584
Epoch 0, Step 2250: train/loss = 0.46256470680236816, train/raw-loss = 0.4032164216041565, train/logprobs = tensor([[-0.7975, -3.3792],
        [-2.7528, -1.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5934823751449585
Epoch 0, Step 2251: train/loss = 0.4249734878540039, train/raw-loss = 0.35689911246299744, train/logprobs = tensor([[-0.5761, -3.5474],
        [-3.2448, -1.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6807438731193542
Epoch 0, Step 2252: train/loss = 0.5771879553794861, train/raw-loss = 0.547518253326416, train/logprobs = tensor([[-1.5451, -3.1716],
        [-2.3152, -1.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29669639468193054
Epoch 0, Step 2253: train/loss = 0.4150710105895996, train/raw-loss = 0.35182926058769226, train/logprobs = tensor([[-1.9279, -7.3548],
        [-2.5269, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6324172616004944
Epoch 0, Step 2254: train/loss = 0.5174087285995483, train/raw-loss = 0.47065672278404236, train/logprobs = tensor([[-2.5084, -6.0250],
        [-1.7988, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4675200581550598
Epoch 0, Step 2255: train/loss = 0.5706496238708496, train/raw-loss = 0.538658618927002, train/logprobs = tensor([[-3.1789, -6.3274],
        [-2.1614, -1.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31991034746170044
Epoch 0, Step 2256: train/loss = 0.5539712905883789, train/raw-loss = 0.5216071009635925, train/logprobs = tensor([[-2.7041, -4.3262],
        [-1.6489, -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32364144921302795
Epoch 0, Step 2257: train/loss = 0.6406241059303284, train/raw-loss = 0.6039094924926758, train/logprobs = tensor([[-2.1079, -4.6566],
        [-1.8622, -1.5206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36714625358581543
Epoch 0, Step 2258: train/loss = 0.5698967576026917, train/raw-loss = 0.5384543538093567, train/logprobs = tensor([[-4.2559, -6.4933],
        [-1.9092, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31442394852638245
Epoch 0, Step 2259: train/loss = 0.47249358892440796, train/raw-loss = 0.41913551092147827, train/logprobs = tensor([[-0.8718, -2.9154],
        [-3.7132, -2.4017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5335807800292969
Epoch 0, Step 2260: train/loss = 0.363563597202301, train/raw-loss = 0.28543606400489807, train/logprobs = tensor([[-1.2160, -8.0211],
        [-3.2373, -0.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7812752723693848
Epoch 0, Step 2261: train/loss = 0.49606645107269287, train/raw-loss = 0.44915124773979187, train/logprobs = tensor([[-1.4757, -5.8364],
        [-2.4788, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46915215253829956
Epoch 0, Step 2262: train/loss = 0.459990531206131, train/raw-loss = 0.39637649059295654, train/logprobs = tensor([[-1.6025, -5.3787],
        [-2.0249, -1.1805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6361403465270996
Epoch 0, Step 2263: train/loss = 0.4477806091308594, train/raw-loss = 0.3816576898097992, train/logprobs = tensor([[-1.6748, -7.0295],
        [-2.5990, -1.3483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6612294316291809
Epoch 0, Step 2264: train/loss = 0.36058858036994934, train/raw-loss = 0.28130480647087097, train/logprobs = tensor([[-1.2207, -6.9533],
        [-3.1871, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7928379774093628
Epoch 0, Step 2265: train/loss = 0.6800533533096313, train/raw-loss = 0.6757811307907104, train/logprobs = tensor([[-3.2984, -3.6405],
        [-2.0130, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04272211715579033
Epoch 0, Step 2266: train/loss = 0.46225887537002563, train/raw-loss = 0.4158308506011963, train/logprobs = tensor([[-1.6572, -4.8620],
        [-3.1821, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46428045630455017
Epoch 0, Step 2267: train/loss = 0.5517865419387817, train/raw-loss = 0.5127006769180298, train/logprobs = tensor([[-3.4514, -7.1434],
        [-1.5084, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908587098121643
Epoch 0, Step 2268: train/loss = 0.5576187968254089, train/raw-loss = 0.5220811367034912, train/logprobs = tensor([[-2.1431, -4.8766],
        [-1.7432, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553767204284668
Epoch 0, Step 2269: train/loss = 0.6941068768501282, train/raw-loss = 0.6923906207084656, train/logprobs = tensor([[-5.1077, -4.8495],
        [-0.8739, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017163312062621117
Epoch 0, Step 2270: train/loss = 0.6838138103485107, train/raw-loss = 0.6686657667160034, train/logprobs = tensor([[-2.3149, -3.4901],
        [-1.4974, -1.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15148034691810608
Epoch 0, Step 2271: train/loss = 0.47744929790496826, train/raw-loss = 0.41664808988571167, train/logprobs = tensor([[-0.9383, -4.4975],
        [-2.9775, -1.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6080122590065002
Epoch 0, Step 2272: train/loss = 0.34965646266937256, train/raw-loss = 0.2635367512702942, train/logprobs = tensor([[-2.8739, -7.7741],
        [-2.4405, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8611971139907837
Epoch 0, Step 2273: train/loss = 0.5340267419815063, train/raw-loss = 0.4873220920562744, train/logprobs = tensor([[-0.8997, -3.2810],
        [-2.6287, -1.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46704691648483276
Epoch 0, Step 2274: train/loss = 0.5396813750267029, train/raw-loss = 0.5008560419082642, train/logprobs = tensor([[-3.4360, -6.2407],
        [-2.0775, -1.5846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38825303316116333
Epoch 0, Step 2275: train/loss = 0.5748410820960999, train/raw-loss = 0.543570876121521, train/logprobs = tensor([[-2.6014, -4.0657],
        [-1.8872, -1.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3127022981643677
Epoch 0, Step 2276: train/loss = 0.5333677530288696, train/raw-loss = 0.4932717978954315, train/logprobs = tensor([[-2.5909, -4.8772],
        [-2.1911, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4009598195552826
Epoch 0, Step 2277: train/loss = 0.6781501770019531, train/raw-loss = 0.672980785369873, train/logprobs = tensor([[-1.5037, -1.8442],
        [-2.5765, -2.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05169382691383362
Epoch 0, Step 2278: train/loss = 0.4710676968097687, train/raw-loss = 0.41551488637924194, train/logprobs = tensor([[-1.8206, -5.1851],
        [-2.7018, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5555278062820435
Epoch 0, Step 2279: train/loss = 0.5922651290893555, train/raw-loss = 0.5658937692642212, train/logprobs = tensor([[-1.6535, -3.4209],
        [-1.4578, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637137174606323
Epoch 0, Step 2280: train/loss = 0.5184264183044434, train/raw-loss = 0.4765642285346985, train/logprobs = tensor([[-1.5298, -3.5984],
        [-2.2832, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4186217188835144
Epoch 0, Step 2281: train/loss = 0.4860362410545349, train/raw-loss = 0.4344966411590576, train/logprobs = tensor([[-3.1921, -6.8097],
        [-1.8321, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.515395998954773
Epoch 0, Step 2282: train/loss = 0.41274815797805786, train/raw-loss = 0.34907644987106323, train/logprobs = tensor([[-2.2782, -6.2617],
        [-2.6070, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6367174386978149
Epoch 0, Step 2283: train/loss = 0.5677744150161743, train/raw-loss = 0.5368419885635376, train/logprobs = tensor([[-2.7937, -4.3663],
        [-2.2719, -1.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30932462215423584
Epoch 0, Step 2284: train/loss = 0.5018000602722168, train/raw-loss = 0.45010003447532654, train/logprobs = tensor([[-2.3810, -6.5985],
        [-1.6287, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5169999599456787
Epoch 0, Step 2285: train/loss = 0.3776355981826782, train/raw-loss = 0.3091999292373657, train/logprobs = tensor([[-1.4123, -7.4748],
        [-3.2835, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.684356689453125
Epoch 0, Step 2286: train/loss = 0.575153648853302, train/raw-loss = 0.5479812622070312, train/logprobs = tensor([[-1.6738, -3.4492],
        [-2.3925, -1.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2717238664627075
Epoch 0, Step 2287: train/loss = 0.3860107362270355, train/raw-loss = 0.3074128031730652, train/logprobs = tensor([[-1.1062, -6.1025],
        [-2.9237, -1.2242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7859790921211243
Epoch 0, Step 2288: train/loss = 0.46712207794189453, train/raw-loss = 0.4090837836265564, train/logprobs = tensor([[-1.8574, -4.6241],
        [-2.5589, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5803828835487366
Epoch 0, Step 2289: train/loss = 0.47218984365463257, train/raw-loss = 0.41321590542793274, train/logprobs = tensor([[-1.8490, -6.6238],
        [-2.7443, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5897396802902222
Epoch 0, Step 2290: train/loss = 0.4914562702178955, train/raw-loss = 0.4459429085254669, train/logprobs = tensor([[-1.5810, -4.1559],
        [-2.3193, -1.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45513370633125305
Epoch 0, Step 2291: train/loss = 0.5221797823905945, train/raw-loss = 0.47375422716140747, train/logprobs = tensor([[-3.6508, -7.0418],
        [-1.4347, -0.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4842556118965149
Epoch 0, Step 2292: train/loss = 0.6671720147132874, train/raw-loss = 0.6516461372375488, train/logprobs = tensor([[-3.5229, -4.1901],
        [-1.8369, -1.2766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1552589386701584
Epoch 0, Step 2293: train/loss = 0.44487354159355164, train/raw-loss = 0.3875029683113098, train/logprobs = tensor([[-1.2205, -4.8385],
        [-2.7178, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5737056732177734
Epoch 0, Step 2294: train/loss = 0.6222521066665649, train/raw-loss = 0.6038451194763184, train/logprobs = tensor([[-1.7818, -2.8360],
        [-1.5475, -1.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18407036364078522
Epoch 0, Step 2295: train/loss = 0.568083643913269, train/raw-loss = 0.5170599818229675, train/logprobs = tensor([[-3.9998, -7.1712],
        [-1.6477, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5102366209030151
Epoch 0, Step 2296: train/loss = 0.5896584987640381, train/raw-loss = 0.5425676703453064, train/logprobs = tensor([[-1.2769, -5.0293],
        [-2.7134, -2.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4709085524082184
Epoch 0, Step 2297: train/loss = 0.5845537185668945, train/raw-loss = 0.555173397064209, train/logprobs = tensor([[-3.7158, -5.8829],
        [-2.4900, -1.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29380372166633606
Epoch 0, Step 2298: train/loss = 0.6992812752723694, train/raw-loss = 0.6980608701705933, train/logprobs = tensor([[-5.1168, -5.2645],
        [-1.4337, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012203628197312355
Epoch 0, Step 2299: train/loss = 0.3234809339046478, train/raw-loss = 0.2401622235774994, train/logprobs = tensor([[-1.6077, -6.8794],
        [-2.8817, -0.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8331872224807739
Epoch 0, Step 2300: train/loss = 0.5208000540733337, train/raw-loss = 0.4636220633983612, train/logprobs = tensor([[-1.5946, -4.3052],
        [-3.0247, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5717799663543701
Epoch 0, Step 2301: train/loss = 0.2612990736961365, train/raw-loss = 0.1589943766593933, train/logprobs = tensor([[-1.3129, -8.6470],
        [-3.7414, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0230467319488525
Epoch 0, Step 2302: train/loss = 0.5232570171356201, train/raw-loss = 0.47504255175590515, train/logprobs = tensor([[-1.3842, -3.9100],
        [-2.9097, -1.4781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48214444518089294
Epoch 0, Step 2303: train/loss = 0.42663291096687317, train/raw-loss = 0.36635005474090576, train/logprobs = tensor([[-1.3980, -6.1016],
        [-2.8251, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6028285026550293
Epoch 0, Step 2304: train/loss = 0.4840572476387024, train/raw-loss = 0.43857479095458984, train/logprobs = tensor([[-1.5876, -5.4872],
        [-2.4238, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4548243284225464
Epoch 0, Step 2305: train/loss = 0.5031187534332275, train/raw-loss = 0.452009379863739, train/logprobs = tensor([[-3.2360, -4.4520],
        [-1.9380, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5110934376716614
Epoch 0, Step 2306: train/loss = 0.6166600584983826, train/raw-loss = 0.5982879400253296, train/logprobs = tensor([[-1.5008, -2.8266],
        [-2.5831, -2.5802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18372105062007904
Epoch 0, Step 2307: train/loss = 0.4290699362754822, train/raw-loss = 0.36497294902801514, train/logprobs = tensor([[-1.7996, -7.5069],
        [-2.8371, -1.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6409696340560913
Epoch 0, Step 2308: train/loss = 0.5243703722953796, train/raw-loss = 0.47878503799438477, train/logprobs = tensor([[-2.4712, -4.7807],
        [-2.5622, -1.3633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4558537006378174
Epoch 0, Step 2309: train/loss = 0.50697922706604, train/raw-loss = 0.45374763011932373, train/logprobs = tensor([[-4.4342, -6.8640],
        [-1.6400, -0.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5323158502578735
Epoch 0, Step 2310: train/loss = 0.44358882308006287, train/raw-loss = 0.3810747265815735, train/logprobs = tensor([[-1.2309, -5.8701],
        [-2.7891, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6251410245895386
Epoch 0, Step 2311: train/loss = 0.5997440218925476, train/raw-loss = 0.5698021054267883, train/logprobs = tensor([[-3.5437, -3.3936],
        [-1.2218, -0.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29941919445991516
Epoch 0, Step 2312: train/loss = 0.4930879473686218, train/raw-loss = 0.4428708851337433, train/logprobs = tensor([[-1.9935, -5.6072],
        [-2.5690, -1.5507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5021708011627197
Epoch 0, Step 2313: train/loss = 0.6063176989555359, train/raw-loss = 0.5856921076774597, train/logprobs = tensor([[-2.5065, -3.8243],
        [-1.0662, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2062562108039856
Epoch 0, Step 2314: train/loss = 0.2560468912124634, train/raw-loss = 0.15519189834594727, train/logprobs = tensor([[-1.1230, -7.6487],
        [-3.8354, -1.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0085495710372925
Epoch 0, Step 2315: train/loss = 0.49978405237197876, train/raw-loss = 0.45329010486602783, train/logprobs = tensor([[-1.1561, -4.0073],
        [-2.7387, -1.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4649394154548645
Epoch 0, Step 2316: train/loss = 0.4380984306335449, train/raw-loss = 0.380013108253479, train/logprobs = tensor([[-1.3073, -4.1068],
        [-3.0235, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5808534622192383
Epoch 0, Step 2317: train/loss = 0.6414618492126465, train/raw-loss = 0.6244540810585022, train/logprobs = tensor([[-4.6235, -5.1470],
        [-1.3046, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17007699608802795
Epoch 0, Step 2318: train/loss = 0.501197099685669, train/raw-loss = 0.4490082859992981, train/logprobs = tensor([[-1.5450, -4.3824],
        [-3.2697, -1.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5218877792358398
Epoch 0, Step 2319: train/loss = 0.522573709487915, train/raw-loss = 0.4795927107334137, train/logprobs = tensor([[-1.1779, -3.4387],
        [-2.5629, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4298095107078552
Epoch 0, Step 2320: train/loss = 0.6184064149856567, train/raw-loss = 0.5707974433898926, train/logprobs = tensor([[-3.4849, -7.7868],
        [-1.9599, -2.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47608914971351624
Epoch 0, Step 2321: train/loss = 0.5439155101776123, train/raw-loss = 0.4963098168373108, train/logprobs = tensor([[-3.3308, -5.5929],
        [-2.2095, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4760567545890808
Epoch 0, Step 2322: train/loss = 0.5818679332733154, train/raw-loss = 0.5512164235115051, train/logprobs = tensor([[-1.7258, -2.7569],
        [-3.3068, -2.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30651548504829407
Epoch 0, Step 2323: train/loss = 0.6086327433586121, train/raw-loss = 0.5871026515960693, train/logprobs = tensor([[-1.4562, -2.7915],
        [-1.8645, -1.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2153010368347168
Epoch 0, Step 2324: train/loss = 0.6376176476478577, train/raw-loss = 0.608586847782135, train/logprobs = tensor([[-3.8947, -4.4303],
        [-2.1511, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29030829668045044
Epoch 0, Step 2325: train/loss = 0.4875955581665039, train/raw-loss = 0.43497467041015625, train/logprobs = tensor([[-1.2387, -4.3767],
        [-1.9428, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5262085795402527
Epoch 0, Step 2326: train/loss = 0.6416308283805847, train/raw-loss = 0.6214419603347778, train/logprobs = tensor([[-2.8801, -3.2787],
        [-2.3905, -2.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20188872516155243
Epoch 0, Step 2327: train/loss = 0.41881969571113586, train/raw-loss = 0.3599799871444702, train/logprobs = tensor([[-0.9572, -5.9966],
        [-2.5403, -1.0057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5883973240852356
Epoch 0, Step 2328: train/loss = 0.6266432404518127, train/raw-loss = 0.6028273701667786, train/logprobs = tensor([[-3.2705, -4.3997],
        [-2.2823, -1.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23815858364105225
Epoch 0, Step 2329: train/loss = 0.6317037343978882, train/raw-loss = 0.610907256603241, train/logprobs = tensor([[-2.5908, -3.5471],
        [-1.3137, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20796433091163635
Epoch 0, Step 2330: train/loss = 0.26172637939453125, train/raw-loss = 0.16080236434936523, train/logprobs = tensor([[-1.1132, -8.8745],
        [-3.4090, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0092401504516602
Epoch 0, Step 2331: train/loss = 0.573652982711792, train/raw-loss = 0.5421546697616577, train/logprobs = tensor([[-4.7678, -3.9907],
        [-2.1408, -1.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149828314781189
Epoch 0, Step 2332: train/loss = 0.47261977195739746, train/raw-loss = 0.41835254430770874, train/logprobs = tensor([[-1.8831, -4.9743],
        [-2.2894, -1.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5426720976829529
Epoch 0, Step 2333: train/loss = 0.6844263076782227, train/raw-loss = 0.649884819984436, train/logprobs = tensor([[-4.2084, -2.8746],
        [-2.0754, -1.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34541475772857666
Epoch 0, Step 2334: train/loss = 0.3958035707473755, train/raw-loss = 0.32633498311042786, train/logprobs = tensor([[-1.2550, -5.5515],
        [-3.3388, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6946860551834106
Epoch 0, Step 2335: train/loss = 0.3780211806297302, train/raw-loss = 0.3021407425403595, train/logprobs = tensor([[-1.1317, -5.0832],
        [-2.9858, -0.9902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.758804202079773
Epoch 0, Step 2336: train/loss = 0.6116338968276978, train/raw-loss = 0.5870519876480103, train/logprobs = tensor([[-0.8338, -2.0713],
        [-2.7490, -2.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24581947922706604
Epoch 0, Step 2337: train/loss = 0.49507516622543335, train/raw-loss = 0.44897884130477905, train/logprobs = tensor([[-1.6326, -4.1770],
        [-1.8649, -0.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4609626233577728
Epoch 0, Step 2338: train/loss = 0.4600146412849426, train/raw-loss = 0.4038340151309967, train/logprobs = tensor([[-1.3910, -5.8674],
        [-2.9232, -1.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5618059039115906
Epoch 0, Step 2339: train/loss = 0.5832647681236267, train/raw-loss = 0.549262523651123, train/logprobs = tensor([[-1.1973, -2.5349],
        [-3.4767, -2.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3400230407714844
Epoch 0, Step 2340: train/loss = 0.49514883756637573, train/raw-loss = 0.44404953718185425, train/logprobs = tensor([[-1.3333, -4.0605],
        [-2.7301, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.510993242263794
Epoch 0, Step 2341: train/loss = 0.5289419293403625, train/raw-loss = 0.48712053894996643, train/logprobs = tensor([[-1.6189, -2.8971],
        [-2.9650, -1.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182136058807373
Epoch 0, Step 2342: train/loss = 0.5126296281814575, train/raw-loss = 0.4646282494068146, train/logprobs = tensor([[-4.2066, -7.0060],
        [-1.9562, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48001405596733093
Epoch 0, Step 2343: train/loss = 0.3967097997665405, train/raw-loss = 0.3311372995376587, train/logprobs = tensor([[-1.4087, -7.1658],
        [-2.7053, -1.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6557247638702393
Epoch 0, Step 2344: train/loss = 0.5346710681915283, train/raw-loss = 0.4980103671550751, train/logprobs = tensor([[-2.0814, -5.4707],
        [-2.9638, -1.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3666069507598877
Epoch 0, Step 2345: train/loss = 0.5036170482635498, train/raw-loss = 0.45431986451148987, train/logprobs = tensor([[-3.6676, -8.5484],
        [-2.3582, -1.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49297216534614563
Epoch 0, Step 2346: train/loss = 0.506790280342102, train/raw-loss = 0.45705103874206543, train/logprobs = tensor([[-0.9286, -2.3890],
        [-3.1157, -1.2004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49739259481430054
Epoch 0, Step 2347: train/loss = 0.4875921607017517, train/raw-loss = 0.43993693590164185, train/logprobs = tensor([[-1.3328, -5.0327],
        [-2.6970, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47655189037323
Epoch 0, Step 2348: train/loss = 0.6104992628097534, train/raw-loss = 0.590576171875, train/logprobs = tensor([[-2.4345, -4.8506],
        [-1.7931, -1.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1992308348417282
Epoch 0, Step 2349: train/loss = 0.6719756126403809, train/raw-loss = 0.6547175049781799, train/logprobs = tensor([[-2.1038, -3.1017],
        [-1.6175, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17258110642433167
Epoch 0, Step 2350: train/loss = 0.30459073185920715, train/raw-loss = 0.21047167479991913, train/logprobs = tensor([[-0.9041, -7.5050],
        [-3.4007, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9411904811859131
Epoch 0, Step 2351: train/loss = 0.5529593229293823, train/raw-loss = 0.5153740048408508, train/logprobs = tensor([[-1.7527, -3.5681],
        [-2.3200, -1.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3758533000946045
Epoch 0, Step 2352: train/loss = 0.4196084141731262, train/raw-loss = 0.34250643849372864, train/logprobs = tensor([[-1.3367, -5.0913],
        [-3.5641, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7710198163986206
Epoch 0, Step 2353: train/loss = 0.6162444949150085, train/raw-loss = 0.5941959619522095, train/logprobs = tensor([[-3.7029, -4.3063],
        [-1.9128, -1.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22048518061637878
Epoch 0, Step 2354: train/loss = 0.5621626377105713, train/raw-loss = 0.5261821150779724, train/logprobs = tensor([[-2.2698, -3.8230],
        [-3.0238, -2.2962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598047196865082
Epoch 0, Step 2355: train/loss = 0.607885479927063, train/raw-loss = 0.5834742188453674, train/logprobs = tensor([[-2.7578, -4.4797],
        [-1.6345, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24411217868328094
Epoch 0, Step 2356: train/loss = 0.6158846616744995, train/raw-loss = 0.5952770113945007, train/logprobs = tensor([[-2.8275, -4.3379],
        [-1.5527, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2060764729976654
Epoch 0, Step 2357: train/loss = 0.4289722144603729, train/raw-loss = 0.3645012080669403, train/logprobs = tensor([[-1.2061, -6.5704],
        [-2.9629, -1.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.644710123538971
Epoch 0, Step 2358: train/loss = 0.6012753844261169, train/raw-loss = 0.5736730098724365, train/logprobs = tensor([[-3.4115, -5.0273],
        [-1.2858, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27602383494377136
Epoch 0, Step 2359: train/loss = 0.5165865421295166, train/raw-loss = 0.47143125534057617, train/logprobs = tensor([[-1.3700, -6.0341],
        [-2.3370, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4515523314476013
Epoch 0, Step 2360: train/loss = 0.34985679388046265, train/raw-loss = 0.2604166269302368, train/logprobs = tensor([[-1.6055, -9.6327],
        [-2.8867, -1.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.894402027130127
Epoch 0, Step 2361: train/loss = 0.4892555773258209, train/raw-loss = 0.44087982177734375, train/logprobs = tensor([[-1.6672, -3.6393],
        [-2.6932, -1.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4837573170661926
Epoch 0, Step 2362: train/loss = 0.6744610071182251, train/raw-loss = 0.656592607498169, train/logprobs = tensor([[-2.7633, -2.8573],
        [-2.2191, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17868363857269287
Epoch 0, Step 2363: train/loss = 0.41647279262542725, train/raw-loss = 0.3549942970275879, train/logprobs = tensor([[-2.9912, -4.9143],
        [-2.2511, -1.0344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6147847175598145
Epoch 0, Step 2364: train/loss = 0.3770214319229126, train/raw-loss = 0.30349352955818176, train/logprobs = tensor([[-2.8404, -9.4620],
        [-2.6043, -1.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7352793216705322
Epoch 0, Step 2365: train/loss = 0.48966214060783386, train/raw-loss = 0.43371322751045227, train/logprobs = tensor([[-1.8588, -6.0451],
        [-2.0448, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5594888925552368
Epoch 0, Step 2366: train/loss = 0.45916926860809326, train/raw-loss = 0.4001149535179138, train/logprobs = tensor([[-1.0311, -5.6159],
        [-2.4332, -1.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5905430316925049
Epoch 0, Step 2367: train/loss = 0.4373946189880371, train/raw-loss = 0.36841195821762085, train/logprobs = tensor([[-1.2860, -5.5580],
        [-2.4619, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6898266673088074
Epoch 0, Step 2368: train/loss = 0.4609728157520294, train/raw-loss = 0.40413421392440796, train/logprobs = tensor([[-2.5803, -6.3429],
        [-3.1336, -1.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5683858394622803
Epoch 0, Step 2369: train/loss = 0.492150217294693, train/raw-loss = 0.44422370195388794, train/logprobs = tensor([[-1.4033, -6.0266],
        [-2.6018, -1.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4792651832103729
Epoch 0, Step 2370: train/loss = 0.360065221786499, train/raw-loss = 0.2794246971607208, train/logprobs = tensor([[-1.5516, -6.8290],
        [-2.2599, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8064055442810059
Epoch 0, Step 2371: train/loss = 0.4895332157611847, train/raw-loss = 0.436688631772995, train/logprobs = tensor([[-1.7772, -5.5612],
        [-1.9753, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5284462571144104
Epoch 0, Step 2372: train/loss = 0.4495418071746826, train/raw-loss = 0.3952088952064514, train/logprobs = tensor([[-1.2403, -4.1620],
        [-2.4549, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.543329119682312
Epoch 0, Step 2373: train/loss = 0.3357389569282532, train/raw-loss = 0.2557218670845032, train/logprobs = tensor([[-2.0196, -8.2788],
        [-3.0189, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8001707792282104
Epoch 0, Step 2374: train/loss = 0.5521082282066345, train/raw-loss = 0.5168312788009644, train/logprobs = tensor([[-1.5432, -2.9486],
        [-3.1655, -2.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35276979207992554
eval/loss: 0.5149163007736206
[2024-02-21 09:57:43,307][root][INFO] - beta: 0.1
[2024-02-21 09:57:43,307][root][INFO] - max_iter: 100
[2024-02-21 09:57:43,307][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-100
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 10000 training examples...
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-100 after each epoch.
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-100 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-100 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-max-iter-100 after each epoch.
Epoch 0, Step 0: train/loss = 0.713974118232727, train/raw-loss = 0.713974118232727, train/logprobs = tensor([[-0.7455, -1.0226],
        [-0.7364, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7520033121109009, train/raw-loss = 0.7520033121109009, train/logprobs = tensor([[-0.8334, -1.3747],
        [-0.8682, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7133011817932129, train/raw-loss = 0.7133011817932129, train/logprobs = tensor([[-0.7484, -0.8076],
        [-0.7838, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.7275511622428894, train/raw-loss = 0.7275511622428894, train/logprobs = tensor([[-0.8421, -1.3549],
        [-0.8680, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.736117422580719, train/raw-loss = 0.736117422580719, train/logprobs = tensor([[-1.0698, -1.4510],
        [-1.0413, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7204403877258301, train/raw-loss = 0.7204403877258301, train/logprobs = tensor([[-0.7672, -1.0824],
        [-0.7821, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.7513337731361389, train/raw-loss = 0.7513337731361389, train/logprobs = tensor([[-0.7953, -1.0975],
        [-0.8507, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.8787661194801331, train/raw-loss = 0.8787661194801331, train/logprobs = tensor([[-1.0779, -1.1902],
        [-1.1492, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.7739853858947754, train/raw-loss = 0.7739853858947754, train/logprobs = tensor([[-1.1014, -1.1445],
        [-1.1211, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.730787456035614, train/raw-loss = 0.730787456035614, train/logprobs = tensor([[-1.1188, -1.2011],
        [-1.0964, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7592432498931885, train/raw-loss = 0.7592432498931885, train/logprobs = tensor([[-1.2226, -1.6038],
        [-1.1765, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7039390206336975, train/raw-loss = 0.7039390206336975, train/logprobs = tensor([[-0.7342, -1.0580],
        [-0.9309, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7423871159553528, train/raw-loss = 0.7423871159553528, train/logprobs = tensor([[-0.9704, -1.2385],
        [-0.9914, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.8157534003257751, train/raw-loss = 0.8157534003257751, train/logprobs = tensor([[-1.0279, -1.1002],
        [-1.0404, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7233016490936279, train/raw-loss = 0.7233016490936279, train/logprobs = tensor([[-0.9607, -1.3427],
        [-0.9610, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6962568759918213, train/raw-loss = 0.6962568759918213, train/logprobs = tensor([[-0.8196, -0.9555],
        [-0.8241, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.705152153968811, train/raw-loss = 0.705152153968811, train/logprobs = tensor([[-0.8221, -0.9929],
        [-0.8046, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7589231729507446, train/raw-loss = 0.7589231729507446, train/logprobs = tensor([[-0.8956, -1.5347],
        [-0.8674, -1.3455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.7092028856277466, train/raw-loss = 0.7092028856277466, train/logprobs = tensor([[-0.8134, -0.7455],
        [-0.8448, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.7066608667373657, train/raw-loss = 0.7066608667373657, train/logprobs = tensor([[-0.9296, -1.0342],
        [-0.9464, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7093161940574646, train/raw-loss = 0.7093161940574646, train/logprobs = tensor([[-1.3012, -1.2005],
        [-1.1840, -1.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.709783673286438, train/raw-loss = 0.709783673286438, train/logprobs = tensor([[-1.3539, -1.5973],
        [-1.3506, -1.4699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7005627155303955, train/raw-loss = 0.7005627155303955, train/logprobs = tensor([[-0.7490, -1.1321],
        [-0.8108, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6964997053146362, train/raw-loss = 0.6964997053146362, train/logprobs = tensor([[-0.9989, -1.1937],
        [-1.0223, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.7022837996482849, train/raw-loss = 0.7022837996482849, train/logprobs = tensor([[-0.7175, -0.9525],
        [-0.6778, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7019386291503906, train/raw-loss = 0.7019386291503906, train/logprobs = tensor([[-0.8638, -1.1275],
        [-0.8749, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7353554964065552, train/raw-loss = 0.7353554964065552, train/logprobs = tensor([[-0.6463, -1.1039],
        [-0.6486, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7172321081161499, train/raw-loss = 0.7172321081161499, train/logprobs = tensor([[-1.1485, -1.2242],
        [-1.0707, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7442553639411926, train/raw-loss = 0.7442553639411926, train/logprobs = tensor([[-0.9744, -1.1718],
        [-1.0203, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7080447673797607, train/raw-loss = 0.7080447673797607, train/logprobs = tensor([[-1.1477, -1.0259],
        [-1.1191, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.701258659362793, train/raw-loss = 0.701258659362793, train/logprobs = tensor([[-1.1280, -1.2579],
        [-1.1611, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.693264365196228, train/raw-loss = 0.693264365196228, train/logprobs = tensor([[-1.2200, -1.2428],
        [-1.2477, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6988550424575806, train/raw-loss = 0.6988550424575806, train/logprobs = tensor([[-1.1544, -1.2933],
        [-1.2153, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.7183356285095215, train/raw-loss = 0.7183356285095215, train/logprobs = tensor([[-1.0192, -0.8052],
        [-1.0312, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.7210201621055603, train/raw-loss = 0.7210201621055603, train/logprobs = tensor([[-0.5816, -0.8397],
        [-0.5714, -0.7817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.7234370708465576, train/raw-loss = 0.7234370708465576, train/logprobs = tensor([[-0.9061, -0.6373],
        [-0.9531, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.699191689491272, train/raw-loss = 0.699191689491272, train/logprobs = tensor([[-0.9190, -0.9279],
        [-0.9578, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.8110731840133667, train/raw-loss = 0.8110731840133667, train/logprobs = tensor([[-0.9128, -1.6764],
        [-0.8827, -1.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.7210233211517334, train/raw-loss = 0.7210233211517334, train/logprobs = tensor([[-0.9563, -1.2494],
        [-0.9473, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.7364233136177063, train/raw-loss = 0.7364233136177063, train/logprobs = tensor([[-1.1877, -1.0266],
        [-1.1895, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.7228062152862549, train/raw-loss = 0.7228062152862549, train/logprobs = tensor([[-1.0432, -1.0242],
        [-1.1040, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.7266353964805603, train/raw-loss = 0.7266353964805603, train/logprobs = tensor([[-0.6492, -1.1424],
        [-0.6564, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.7219699621200562, train/raw-loss = 0.7219699621200562, train/logprobs = tensor([[-1.0915, -1.6032],
        [-1.1550, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.768346905708313, train/raw-loss = 0.768346905708313, train/logprobs = tensor([[-0.9045, -1.5780],
        [-0.9263, -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.7669239640235901, train/raw-loss = 0.7669239640235901, train/logprobs = tensor([[-0.7626, -1.1490],
        [-0.7788, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.7112200260162354, train/raw-loss = 0.7112200260162354, train/logprobs = tensor([[-0.6316, -0.9687],
        [-0.6322, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.7303959131240845, train/raw-loss = 0.7303959131240845, train/logprobs = tensor([[-0.9770, -1.3808],
        [-1.0208, -1.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.7417773008346558, train/raw-loss = 0.7417773008346558, train/logprobs = tensor([[-1.3705, -1.1575],
        [-1.3663, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.714173436164856, train/raw-loss = 0.714173436164856, train/logprobs = tensor([[-0.8059, -0.9450],
        [-0.8191, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.8120626211166382, train/raw-loss = 0.8120626211166382, train/logprobs = tensor([[-0.8137, -1.6513],
        [-0.8865, -1.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.7227821946144104, train/raw-loss = 0.7227821946144104, train/logprobs = tensor([[-0.9871, -1.3782],
        [-0.9947, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.7082313895225525, train/raw-loss = 0.7082313895225525, train/logprobs = tensor([[-0.8649, -1.2225],
        [-0.8688, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.737745463848114, train/raw-loss = 0.737745463848114, train/logprobs = tensor([[-1.0971, -0.7423],
        [-1.1489, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.7064392566680908, train/raw-loss = 0.7064392566680908, train/logprobs = tensor([[-1.3404, -1.3085],
        [-1.3279, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6971949934959412, train/raw-loss = 0.6971949934959412, train/logprobs = tensor([[-0.9319, -0.9996],
        [-1.0078, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.7213574647903442, train/raw-loss = 0.7213574647903442, train/logprobs = tensor([[-1.0288, -1.1987],
        [-0.9993, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.7000918984413147, train/raw-loss = 0.7000918984413147, train/logprobs = tensor([[-0.8808, -0.7692],
        [-0.8665, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.7425751090049744, train/raw-loss = 0.7425751090049744, train/logprobs = tensor([[-0.8949, -1.2674],
        [-0.9367, -1.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.7090755701065063, train/raw-loss = 0.7090755701065063, train/logprobs = tensor([[-0.6935, -0.9580],
        [-0.7386, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.7432913184165955, train/raw-loss = 0.7432913184165955, train/logprobs = tensor([[-1.2190, -1.1246],
        [-1.2778, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.7427364587783813, train/raw-loss = 0.7427364587783813, train/logprobs = tensor([[-1.0228, -1.0941],
        [-1.1349, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.7869271039962769, train/raw-loss = 0.7869271039962769, train/logprobs = tensor([[-0.7442, -1.3274],
        [-0.7931, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.7196354269981384, train/raw-loss = 0.7196354269981384, train/logprobs = tensor([[-1.0222, -1.2890],
        [-1.0348, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7207245826721191, train/raw-loss = 0.7207245826721191, train/logprobs = tensor([[-1.1953, -1.2005],
        [-1.1689, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.7048115730285645, train/raw-loss = 0.7048096060752869, train/logprobs = tensor([[-0.8861, -1.0966],
        [-0.8975, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9017323211301118e-05
Epoch 0, Step 65: train/loss = 0.7389346361160278, train/raw-loss = 0.7389345169067383, train/logprobs = tensor([[-0.8017, -1.0539],
        [-0.8322, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0246221791021526e-06
Epoch 0, Step 66: train/loss = 0.7460651397705078, train/raw-loss = 0.7460631132125854, train/logprobs = tensor([[-1.2329, -0.7563],
        [-1.3387, -0.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.022674925683532e-05
Epoch 0, Step 67: train/loss = 0.6990824937820435, train/raw-loss = 0.6990823745727539, train/logprobs = tensor([[-0.9329, -0.8436],
        [-0.8907, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.090287696570158e-06
Epoch 0, Step 68: train/loss = 0.8099230527877808, train/raw-loss = 0.8099223971366882, train/logprobs = tensor([[-0.7655, -1.3550],
        [-0.7237, -1.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.792815500171855e-06
Epoch 0, Step 69: train/loss = 0.717008113861084, train/raw-loss = 0.7170016765594482, train/logprobs = tensor([[-1.2607, -1.5061],
        [-1.2365, -1.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.399616540875286e-05
Epoch 0, Step 70: train/loss = 0.7702468633651733, train/raw-loss = 0.7702462077140808, train/logprobs = tensor([[-1.2213, -0.9249],
        [-1.3298, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.189548003021628e-06
Epoch 0, Step 71: train/loss = 0.6943754553794861, train/raw-loss = 0.6943739652633667, train/logprobs = tensor([[-1.1920, -1.3136],
        [-1.1994, -1.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4269506209529936e-05
Epoch 0, Step 72: train/loss = 0.6991084814071655, train/raw-loss = 0.6991079449653625, train/logprobs = tensor([[-0.8087, -1.0332],
        [-0.7662, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.273886927170679e-06
Epoch 0, Step 73: train/loss = 0.8026410341262817, train/raw-loss = 0.8026396036148071, train/logprobs = tensor([[-0.7466, -1.5422],
        [-0.7411, -1.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3866813787899446e-05
Epoch 0, Step 74: train/loss = 0.7412683367729187, train/raw-loss = 0.7412668466567993, train/logprobs = tensor([[-0.7302, -1.2291],
        [-0.7558, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4817938790656626e-05
Epoch 0, Step 75: train/loss = 0.779533863067627, train/raw-loss = 0.7795335054397583, train/logprobs = tensor([[-0.7294, -1.1765],
        [-0.7519, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.632347215898335e-06
Epoch 0, Step 76: train/loss = 0.7506451606750488, train/raw-loss = 0.7506448030471802, train/logprobs = tensor([[-0.6903, -1.3894],
        [-0.6928, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.851282599498518e-06
Epoch 0, Step 77: train/loss = 0.7174006700515747, train/raw-loss = 0.7173992395401001, train/logprobs = tensor([[-1.0136, -1.3134],
        [-1.0013, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3973767636343837e-05
Epoch 0, Step 78: train/loss = 0.6949937343597412, train/raw-loss = 0.6949936747550964, train/logprobs = tensor([[-0.7713, -0.8258],
        [-0.7322, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2212549336254597e-06
Epoch 0, Step 79: train/loss = 0.6947365403175354, train/raw-loss = 0.6947363615036011, train/logprobs = tensor([[-0.8005, -0.8577],
        [-0.8140, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9903818611055613e-06
Epoch 0, Step 80: train/loss = 0.7350464463233948, train/raw-loss = 0.7350434064865112, train/logprobs = tensor([[-0.9647, -1.3045],
        [-0.9282, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.920285623986274e-05
Epoch 0, Step 81: train/loss = 0.721139132976532, train/raw-loss = 0.721137285232544, train/logprobs = tensor([[-1.0897, -1.5054],
        [-1.1211, -1.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.740902371238917e-05
Epoch 0, Step 82: train/loss = 0.7097688913345337, train/raw-loss = 0.7097686529159546, train/logprobs = tensor([[-0.8786, -0.9811],
        [-0.8972, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2729000193066895e-06
Epoch 0, Step 83: train/loss = 0.9482423067092896, train/raw-loss = 0.9482398629188538, train/logprobs = tensor([[-0.9150, -1.7216],
        [-0.9046, -1.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4331588065251708e-05
Epoch 0, Step 84: train/loss = 0.7111750245094299, train/raw-loss = 0.7111746668815613, train/logprobs = tensor([[-1.2150, -1.1545],
        [-1.2611, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.638415364548564e-06
Epoch 0, Step 85: train/loss = 0.6976710557937622, train/raw-loss = 0.6976706981658936, train/logprobs = tensor([[-1.0032, -1.1049],
        [-1.0825, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2899347388593014e-06
Epoch 0, Step 86: train/loss = 0.734916090965271, train/raw-loss = 0.734915554523468, train/logprobs = tensor([[-0.6892, -1.1788],
        [-0.6779, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.579020580626093e-06
Epoch 0, Step 87: train/loss = 0.7023470401763916, train/raw-loss = 0.702346682548523, train/logprobs = tensor([[-0.6935, -0.8483],
        [-0.6867, -0.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0176161089912057e-06
Epoch 0, Step 88: train/loss = 0.706466794013977, train/raw-loss = 0.706466019153595, train/logprobs = tensor([[-0.6454, -0.8894],
        [-0.6209, -0.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.62471609050408e-06
Epoch 0, Step 89: train/loss = 0.7087106704711914, train/raw-loss = 0.7087106704711914, train/logprobs = tensor([[-0.7851, -0.5878],
        [-0.7928, -0.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.955962716237991e-07
Epoch 0, Step 90: train/loss = 0.700486421585083, train/raw-loss = 0.700484037399292, train/logprobs = tensor([[-1.0357, -1.1990],
        [-1.0478, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3805041564628482e-05
Epoch 0, Step 91: train/loss = 0.7274531126022339, train/raw-loss = 0.7274525165557861, train/logprobs = tensor([[-0.8000, -1.2621],
        [-0.7804, -1.1722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.290769306360744e-06
Epoch 0, Step 92: train/loss = 0.7371253967285156, train/raw-loss = 0.7371249198913574, train/logprobs = tensor([[-0.9004, -1.4690],
        [-0.8979, -1.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.430130502441898e-06
Epoch 0, Step 93: train/loss = 0.6953712701797485, train/raw-loss = 0.695371150970459, train/logprobs = tensor([[-0.8664, -0.9935],
        [-0.7883, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.153695721877739e-07
Epoch 0, Step 94: train/loss = 0.7341633439064026, train/raw-loss = 0.7341612577438354, train/logprobs = tensor([[-1.3007, -1.5803],
        [-1.3205, -1.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0523028069874272e-05
Epoch 0, Step 95: train/loss = 0.6926597952842712, train/raw-loss = 0.6926579475402832, train/logprobs = tensor([[-0.8861, -1.0640],
        [-0.9281, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.758983125910163e-05
Epoch 0, Step 96: train/loss = 0.7191351652145386, train/raw-loss = 0.7191230058670044, train/logprobs = tensor([[-0.9056, -1.3452],
        [-0.9669, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012111017713323236
Epoch 0, Step 97: train/loss = 0.7294968962669373, train/raw-loss = 0.7294865846633911, train/logprobs = tensor([[-0.8189, -1.3385],
        [-0.9401, -1.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010270974598824978
Epoch 0, Step 98: train/loss = 0.7098540663719177, train/raw-loss = 0.709846019744873, train/logprobs = tensor([[-0.7303, -0.7764],
        [-0.8149, -0.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.080305997282267e-05
Epoch 0, Step 99: train/loss = 0.6943325996398926, train/raw-loss = 0.6943174600601196, train/logprobs = tensor([[-0.9935, -1.0162],
        [-0.9801, -0.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015191410784609616
Epoch 0, Step 100: train/loss = 0.7137640118598938, train/raw-loss = 0.713761568069458, train/logprobs = tensor([[-0.8050, -1.0923],
        [-0.8056, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4572931579314172e-05
Epoch 0, Step 101: train/loss = 0.7316828966140747, train/raw-loss = 0.7316805124282837, train/logprobs = tensor([[-0.9159, -1.1125],
        [-0.9654, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4219814804382622e-05
Epoch 0, Step 102: train/loss = 0.7172834277153015, train/raw-loss = 0.717261791229248, train/logprobs = tensor([[-0.7797, -1.1421],
        [-0.8161, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002159841824322939
Epoch 0, Step 103: train/loss = 0.7719795107841492, train/raw-loss = 0.7719718217849731, train/logprobs = tensor([[-0.9018, -1.4681],
        [-0.9618, -1.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.622875273227692e-05
Epoch 0, Step 104: train/loss = 0.7110953330993652, train/raw-loss = 0.711080014705658, train/logprobs = tensor([[-0.7489, -1.1112],
        [-0.7401, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015257199993357062
Epoch 0, Step 105: train/loss = 0.709221363067627, train/raw-loss = 0.709220290184021, train/logprobs = tensor([[-1.0753, -1.1924],
        [-1.0958, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0526902769925073e-05
Epoch 0, Step 106: train/loss = 0.7451445460319519, train/raw-loss = 0.7451392412185669, train/logprobs = tensor([[-0.5933, -1.1524],
        [-0.6881, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.3160780225880444e-05
Epoch 0, Step 107: train/loss = 0.698163628578186, train/raw-loss = 0.6981498003005981, train/logprobs = tensor([[-0.9700, -0.9842],
        [-1.0371, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013827935617882758
Epoch 0, Step 108: train/loss = 0.7190924286842346, train/raw-loss = 0.7190890908241272, train/logprobs = tensor([[-1.4030, -1.6928],
        [-1.2290, -1.5251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.353942884132266e-05
Epoch 0, Step 109: train/loss = 0.7476280927658081, train/raw-loss = 0.7475955486297607, train/logprobs = tensor([[-1.0654, -1.8156],
        [-1.0409, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032585824374109507
Epoch 0, Step 110: train/loss = 0.7272725701332092, train/raw-loss = 0.7272658348083496, train/logprobs = tensor([[-1.2090, -1.2216],
        [-1.3441, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.722553371218964e-05
Epoch 0, Step 111: train/loss = 0.702257513999939, train/raw-loss = 0.7022524476051331, train/logprobs = tensor([[-0.7756, -0.7580],
        [-0.8129, -0.7475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.051289917901158e-05
Epoch 0, Step 112: train/loss = 0.694995641708374, train/raw-loss = 0.6949950456619263, train/logprobs = tensor([[-0.6651, -0.7138],
        [-0.6802, -0.6877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4232514230534434e-06
Epoch 0, Step 113: train/loss = 0.7402071356773376, train/raw-loss = 0.7401970624923706, train/logprobs = tensor([[-0.9256, -1.3060],
        [-0.9049, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010043446673080325
Epoch 0, Step 114: train/loss = 0.6945420503616333, train/raw-loss = 0.6945250034332275, train/logprobs = tensor([[-0.9163, -1.0666],
        [-1.0089, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016979948850348592
Epoch 0, Step 115: train/loss = 0.720862865447998, train/raw-loss = 0.720814049243927, train/logprobs = tensor([[-0.9862, -1.2302],
        [-1.0478, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048782071098685265
Epoch 0, Step 116: train/loss = 0.7062494158744812, train/raw-loss = 0.7062473297119141, train/logprobs = tensor([[-0.7786, -1.0595],
        [-0.7944, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0955525542376563e-05
Epoch 0, Step 117: train/loss = 0.699651837348938, train/raw-loss = 0.6996092796325684, train/logprobs = tensor([[-0.7824, -1.0905],
        [-0.8233, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004256737302057445
Epoch 0, Step 118: train/loss = 0.7384310364723206, train/raw-loss = 0.7384267449378967, train/logprobs = tensor([[-1.0036, -0.6703],
        [-1.0241, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.34665271313861e-05
Epoch 0, Step 119: train/loss = 0.7116732597351074, train/raw-loss = 0.7116718292236328, train/logprobs = tensor([[-0.6224, -0.7894],
        [-0.6161, -0.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4275181456469e-05
Epoch 0, Step 120: train/loss = 0.7420992851257324, train/raw-loss = 0.7420276403427124, train/logprobs = tensor([[-0.8933, -1.5856],
        [-0.9455, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007168994634412229
Epoch 0, Step 121: train/loss = 0.7301888465881348, train/raw-loss = 0.7301202416419983, train/logprobs = tensor([[-0.8701, -1.2616],
        [-0.9155, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006857971311546862
Epoch 0, Step 122: train/loss = 0.7128660678863525, train/raw-loss = 0.7128642797470093, train/logprobs = tensor([[-0.6632, -1.0035],
        [-0.7437, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.763856562320143e-05
Epoch 0, Step 123: train/loss = 0.7142402529716492, train/raw-loss = 0.7142360806465149, train/logprobs = tensor([[-0.9911, -0.9410],
        [-0.9833, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.165517748333514e-05
Epoch 0, Step 124: train/loss = 0.6930561065673828, train/raw-loss = 0.6930496692657471, train/logprobs = tensor([[-0.8268, -0.8894],
        [-0.8534, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.37495395494625e-05
Epoch 0, Step 125: train/loss = 0.7423481345176697, train/raw-loss = 0.7423396110534668, train/logprobs = tensor([[-0.9245, -1.5073],
        [-1.0482, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.422296377830207e-05
Epoch 0, Step 126: train/loss = 0.7384679913520813, train/raw-loss = 0.7384305596351624, train/logprobs = tensor([[-0.8696, -1.5043],
        [-0.9117, -1.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037413090467453003
Epoch 0, Step 127: train/loss = 0.7005041837692261, train/raw-loss = 0.7004818320274353, train/logprobs = tensor([[-1.0493, -0.9251],
        [-1.1464, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022331734362524003
Epoch 0, Step 128: train/loss = 0.6996904015541077, train/raw-loss = 0.6994959115982056, train/logprobs = tensor([[-0.9021, -0.9885],
        [-1.0113, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001945498981513083
Epoch 0, Step 129: train/loss = 0.7146078944206238, train/raw-loss = 0.7141833305358887, train/logprobs = tensor([[-0.7028, -1.1641],
        [-0.7385, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004245942458510399
Epoch 0, Step 130: train/loss = 0.7091148495674133, train/raw-loss = 0.709113597869873, train/logprobs = tensor([[-0.6746, -0.6371],
        [-0.6887, -0.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2641619832720608e-05
Epoch 0, Step 131: train/loss = 0.7170339226722717, train/raw-loss = 0.7165302038192749, train/logprobs = tensor([[-1.0428, -1.2886],
        [-1.1124, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005037723109126091
Epoch 0, Step 132: train/loss = 0.7409491539001465, train/raw-loss = 0.7405943274497986, train/logprobs = tensor([[-1.1076, -1.3738],
        [-1.1442, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003548368811607361
Epoch 0, Step 133: train/loss = 0.7295086979866028, train/raw-loss = 0.7291306853294373, train/logprobs = tensor([[-0.8545, -1.4701],
        [-0.9222, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003780466504395008
Epoch 0, Step 134: train/loss = 0.700332522392273, train/raw-loss = 0.7003040313720703, train/logprobs = tensor([[-0.8829, -0.7656],
        [-0.8620, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002846292336471379
Epoch 0, Step 135: train/loss = 0.696825385093689, train/raw-loss = 0.6968165636062622, train/logprobs = tensor([[-0.7270, -0.8168],
        [-0.7423, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.844200056046247e-05
Epoch 0, Step 136: train/loss = 0.7121983766555786, train/raw-loss = 0.7121886014938354, train/logprobs = tensor([[-0.8984, -0.8374],
        [-0.9270, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.8096439614892e-05
Epoch 0, Step 137: train/loss = 0.7054072618484497, train/raw-loss = 0.7053343057632446, train/logprobs = tensor([[-0.8210, -1.0548],
        [-0.8921, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007291276706382632
Epoch 0, Step 138: train/loss = 0.7194071412086487, train/raw-loss = 0.7191170454025269, train/logprobs = tensor([[-0.6534, -1.1412],
        [-0.7219, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029018751811236143
Epoch 0, Step 139: train/loss = 0.7622827291488647, train/raw-loss = 0.7620999217033386, train/logprobs = tensor([[-0.6527, -1.2136],
        [-0.7234, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018282426754012704
Epoch 0, Step 140: train/loss = 0.7289954423904419, train/raw-loss = 0.7289466857910156, train/logprobs = tensor([[-1.1007, -0.9674],
        [-1.1883, -0.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048688158858567476
Epoch 0, Step 141: train/loss = 0.697567343711853, train/raw-loss = 0.6975206136703491, train/logprobs = tensor([[-0.8138, -0.9179],
        [-0.7831, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046734060742892325
Epoch 0, Step 142: train/loss = 0.6966100931167603, train/raw-loss = 0.6965820789337158, train/logprobs = tensor([[-0.8063, -0.7753],
        [-0.8986, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027997896540910006
Epoch 0, Step 143: train/loss = 0.6976891756057739, train/raw-loss = 0.6976754069328308, train/logprobs = tensor([[-0.8258, -0.8837],
        [-0.7899, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013781117741018534
Epoch 0, Step 144: train/loss = 0.8735816478729248, train/raw-loss = 0.8734583854675293, train/logprobs = tensor([[-0.7586, -1.7907],
        [-0.8311, -1.5379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012321032118052244
Epoch 0, Step 145: train/loss = 0.7148922681808472, train/raw-loss = 0.7142401933670044, train/logprobs = tensor([[-1.0190, -1.7735],
        [-1.1463, -1.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00652066245675087
Epoch 0, Step 146: train/loss = 0.7076462507247925, train/raw-loss = 0.7075057029724121, train/logprobs = tensor([[-1.0521, -1.1831],
        [-1.1572, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001404729438945651
Epoch 0, Step 147: train/loss = 0.7093991041183472, train/raw-loss = 0.7092472910881042, train/logprobs = tensor([[-0.7453, -0.9615],
        [-0.7618, -0.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015184840885922313
Epoch 0, Step 148: train/loss = 0.6989263296127319, train/raw-loss = 0.6987081170082092, train/logprobs = tensor([[-0.7005, -0.7299],
        [-0.8241, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002182180993258953
Epoch 0, Step 149: train/loss = 0.6984298229217529, train/raw-loss = 0.6984035968780518, train/logprobs = tensor([[-0.5930, -0.7766],
        [-0.6220, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026186389732174575
Epoch 0, Step 150: train/loss = 0.717872142791748, train/raw-loss = 0.7178037762641907, train/logprobs = tensor([[-1.0981, -0.9394],
        [-1.1278, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006835195235908031
Epoch 0, Step 151: train/loss = 0.7035105228424072, train/raw-loss = 0.7033771276473999, train/logprobs = tensor([[-0.7280, -0.8870],
        [-0.7576, -0.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013335752300918102
Epoch 0, Step 152: train/loss = 0.7183966636657715, train/raw-loss = 0.7179594039916992, train/logprobs = tensor([[-1.0522, -1.0287],
        [-1.1899, -0.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004373138304799795
Epoch 0, Step 153: train/loss = 0.7055874466896057, train/raw-loss = 0.7055244445800781, train/logprobs = tensor([[-0.7419, -1.0171],
        [-0.9278, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006298518273979425
Epoch 0, Step 154: train/loss = 0.8755333423614502, train/raw-loss = 0.8755017518997192, train/logprobs = tensor([[-0.6908, -1.7022],
        [-0.6895, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003154365695081651
Epoch 0, Step 155: train/loss = 0.7423274517059326, train/raw-loss = 0.7422110438346863, train/logprobs = tensor([[-0.7376, -1.4759],
        [-0.7739, -1.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001163863344117999
Epoch 0, Step 156: train/loss = 0.6926147937774658, train/raw-loss = 0.692064642906189, train/logprobs = tensor([[-0.9522, -1.1123],
        [-1.0153, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005501607898622751
Epoch 0, Step 157: train/loss = 0.7413721680641174, train/raw-loss = 0.7412551045417786, train/logprobs = tensor([[-0.8536, -1.3684],
        [-0.8718, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011705432552844286
Epoch 0, Step 158: train/loss = 0.7002739310264587, train/raw-loss = 0.7001516819000244, train/logprobs = tensor([[-0.6263, -0.8683],
        [-0.6832, -0.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001222888589836657
Epoch 0, Step 159: train/loss = 0.6990450620651245, train/raw-loss = 0.6989507079124451, train/logprobs = tensor([[-0.9340, -1.0450],
        [-0.9840, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009439010755158961
Epoch 0, Step 160: train/loss = 0.7085415720939636, train/raw-loss = 0.7085187435150146, train/logprobs = tensor([[-0.7963, -1.0245],
        [-0.8475, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000228514734772034
Epoch 0, Step 161: train/loss = 0.7044779062271118, train/raw-loss = 0.704383373260498, train/logprobs = tensor([[-0.6432, -0.8979],
        [-0.7228, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009448482887819409
Epoch 0, Step 162: train/loss = 0.7082411050796509, train/raw-loss = 0.7081279754638672, train/logprobs = tensor([[-0.7126, -0.8863],
        [-0.8109, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001131656114012003
Epoch 0, Step 163: train/loss = 0.7554119825363159, train/raw-loss = 0.755327045917511, train/logprobs = tensor([[-0.9494, -1.2472],
        [-1.0068, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008492544293403625
Epoch 0, Step 164: train/loss = 0.7116483449935913, train/raw-loss = 0.7116177082061768, train/logprobs = tensor([[-0.5729, -0.9214],
        [-0.5976, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003061760507989675
Epoch 0, Step 165: train/loss = 0.7054989337921143, train/raw-loss = 0.7054704427719116, train/logprobs = tensor([[-0.8867, -0.9906],
        [-1.0533, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002846652641892433
Epoch 0, Step 166: train/loss = 0.7042425274848938, train/raw-loss = 0.7042310237884521, train/logprobs = tensor([[-0.8270, -1.0337],
        [-0.9320, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011516298400238156
Epoch 0, Step 167: train/loss = 0.7041865587234497, train/raw-loss = 0.7040368318557739, train/logprobs = tensor([[-0.7790, -1.1147],
        [-1.0277, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014969344483688474
Epoch 0, Step 168: train/loss = 0.7158938646316528, train/raw-loss = 0.7157284617424011, train/logprobs = tensor([[-0.6326, -1.1583],
        [-0.6953, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016540013020858169
Epoch 0, Step 169: train/loss = 0.7095164060592651, train/raw-loss = 0.7085113525390625, train/logprobs = tensor([[-0.5778, -1.1486],
        [-0.7322, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010051149874925613
Epoch 0, Step 170: train/loss = 0.7389132380485535, train/raw-loss = 0.7387508153915405, train/logprobs = tensor([[-0.7618, -1.3434],
        [-0.8318, -1.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001623373944312334
Epoch 0, Step 171: train/loss = 0.7007299065589905, train/raw-loss = 0.7005687952041626, train/logprobs = tensor([[-0.6593, -0.8059],
        [-0.7563, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016111748991534114
Epoch 0, Step 172: train/loss = 0.7076065540313721, train/raw-loss = 0.7075010538101196, train/logprobs = tensor([[-0.8608, -1.0257],
        [-0.9722, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010544462129473686
Epoch 0, Step 173: train/loss = 0.7125359773635864, train/raw-loss = 0.7125194668769836, train/logprobs = tensor([[-1.0292, -1.4356],
        [-1.0977, -1.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016514805611222982
Epoch 0, Step 174: train/loss = 0.7068662047386169, train/raw-loss = 0.7062253355979919, train/logprobs = tensor([[-0.6806, -1.2580],
        [-0.8217, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064089978113770485
Epoch 0, Step 175: train/loss = 0.7890257239341736, train/raw-loss = 0.7888908982276917, train/logprobs = tensor([[-0.8912, -1.4708],
        [-0.9280, -1.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013482082867994905
Epoch 0, Step 176: train/loss = 0.7042871713638306, train/raw-loss = 0.7040793299674988, train/logprobs = tensor([[-1.0249, -1.2517],
        [-1.0340, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002078347373753786
Epoch 0, Step 177: train/loss = 0.7114409804344177, train/raw-loss = 0.711401641368866, train/logprobs = tensor([[-0.9771, -0.9409],
        [-0.9605, -0.8378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039326236583292484
Epoch 0, Step 178: train/loss = 0.7422513961791992, train/raw-loss = 0.7415579557418823, train/logprobs = tensor([[-0.7083, -1.4934],
        [-0.8836, -1.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006935016717761755
Epoch 0, Step 179: train/loss = 0.6973077058792114, train/raw-loss = 0.6972621083259583, train/logprobs = tensor([[-1.0050, -0.9137],
        [-0.9977, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045561662409454584
Epoch 0, Step 180: train/loss = 0.7016506195068359, train/raw-loss = 0.7015854120254517, train/logprobs = tensor([[-0.7157, -1.0390],
        [-0.7813, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000652020622510463
Epoch 0, Step 181: train/loss = 0.8047192692756653, train/raw-loss = 0.8039588332176208, train/logprobs = tensor([[-1.1759, -1.5302],
        [-1.1103, -1.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007604553364217281
Epoch 0, Step 182: train/loss = 0.6981508135795593, train/raw-loss = 0.6980730295181274, train/logprobs = tensor([[-0.8152, -0.9998],
        [-0.9071, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007781236781738698
Epoch 0, Step 183: train/loss = 0.7525884509086609, train/raw-loss = 0.7521630525588989, train/logprobs = tensor([[-0.8439, -1.5061],
        [-0.9622, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004254163708537817
Epoch 0, Step 184: train/loss = 0.6938179135322571, train/raw-loss = 0.693803071975708, train/logprobs = tensor([[-0.8669, -0.8086],
        [-0.8258, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001476779580116272
Epoch 0, Step 185: train/loss = 0.6994755864143372, train/raw-loss = 0.6994684338569641, train/logprobs = tensor([[-0.6551, -0.7787],
        [-0.7681, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.1483023930341e-05
Epoch 0, Step 186: train/loss = 0.7688228487968445, train/raw-loss = 0.7685075998306274, train/logprobs = tensor([[-1.1452, -1.4797],
        [-1.2182, -1.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031519581098109484
Epoch 0, Step 187: train/loss = 0.7037566900253296, train/raw-loss = 0.7033355236053467, train/logprobs = tensor([[-1.0597, -1.0216],
        [-1.1491, -0.7789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004211442079395056
Epoch 0, Step 188: train/loss = 0.7700842022895813, train/raw-loss = 0.7698197960853577, train/logprobs = tensor([[-1.0667, -1.4884],
        [-1.1889, -1.2526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026439137291163206
Epoch 0, Step 189: train/loss = 0.73779296875, train/raw-loss = 0.7376068830490112, train/logprobs = tensor([[-0.6980, -1.2822],
        [-0.8526, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018614481668919325
Epoch 0, Step 190: train/loss = 0.7032982110977173, train/raw-loss = 0.7030616402626038, train/logprobs = tensor([[-0.8150, -1.0337],
        [-0.9170, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002365018241107464
Epoch 0, Step 191: train/loss = 0.7503713369369507, train/raw-loss = 0.7503458261489868, train/logprobs = tensor([[-0.9889, -1.2151],
        [-1.1327, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000255189515883103
Epoch 0, Step 192: train/loss = 0.6990577578544617, train/raw-loss = 0.699039101600647, train/logprobs = tensor([[-0.7885, -0.9229],
        [-0.8221, -0.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018645665841177106
Epoch 0, Step 193: train/loss = 0.6948011517524719, train/raw-loss = 0.6946898698806763, train/logprobs = tensor([[-0.9943, -1.2134],
        [-1.2555, -1.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011127179022878408
Epoch 0, Step 194: train/loss = 0.7371177077293396, train/raw-loss = 0.7361789345741272, train/logprobs = tensor([[-0.9140, -1.6206],
        [-0.9609, -1.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009387689642608166
Epoch 0, Step 195: train/loss = 0.6958857774734497, train/raw-loss = 0.6958703398704529, train/logprobs = tensor([[-0.6796, -0.8288],
        [-0.7349, -0.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001541363017167896
Epoch 0, Step 196: train/loss = 0.8873358368873596, train/raw-loss = 0.8844577074050903, train/logprobs = tensor([[-0.8245, -2.5343],
        [-0.9611, -1.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028781119734048843
Epoch 0, Step 197: train/loss = 0.7234697341918945, train/raw-loss = 0.7234334349632263, train/logprobs = tensor([[-0.6186, -1.0241],
        [-0.7503, -0.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036283922963775694
Epoch 0, Step 198: train/loss = 0.7165094614028931, train/raw-loss = 0.7162762880325317, train/logprobs = tensor([[-1.0133, -0.9657],
        [-1.1062, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023311579134315252
Epoch 0, Step 199: train/loss = 0.7375538349151611, train/raw-loss = 0.7364457845687866, train/logprobs = tensor([[-0.9413, -1.1289],
        [-1.0983, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011080889962613583
Epoch 0, Step 200: train/loss = 0.7896198034286499, train/raw-loss = 0.788442850112915, train/logprobs = tensor([[-0.7905, -1.5513],
        [-1.0271, -1.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011769442819058895
Epoch 0, Step 201: train/loss = 0.7069441676139832, train/raw-loss = 0.7065976858139038, train/logprobs = tensor([[-0.6432, -1.0514],
        [-0.7422, -0.8916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003464682959020138
Epoch 0, Step 202: train/loss = 0.7000969052314758, train/raw-loss = 0.6997129917144775, train/logprobs = tensor([[-0.7319, -0.9683],
        [-0.9617, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038386492524296045
Epoch 0, Step 203: train/loss = 0.7142269015312195, train/raw-loss = 0.7139866352081299, train/logprobs = tensor([[-1.0208, -1.0013],
        [-1.1162, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002403109800070524
Epoch 0, Step 204: train/loss = 0.698634684085846, train/raw-loss = 0.6985300779342651, train/logprobs = tensor([[-0.7785, -0.7860],
        [-0.9399, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010452191345393658
Epoch 0, Step 205: train/loss = 0.693393349647522, train/raw-loss = 0.6933577656745911, train/logprobs = tensor([[-0.9394, -0.9986],
        [-1.1156, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035517901415005326
Epoch 0, Step 206: train/loss = 0.7007380127906799, train/raw-loss = 0.7007239460945129, train/logprobs = tensor([[-0.7808, -0.9169],
        [-0.8150, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001404803042532876
Epoch 0, Step 207: train/loss = 0.7009632587432861, train/raw-loss = 0.7009600400924683, train/logprobs = tensor([[-0.9555, -1.0149],
        [-0.9853, -0.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.295608621556312e-05
Epoch 0, Step 208: train/loss = 0.6957210302352905, train/raw-loss = 0.6956924796104431, train/logprobs = tensor([[-0.7408, -0.6696],
        [-0.8307, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002848445437848568
Epoch 0, Step 209: train/loss = 0.7204248309135437, train/raw-loss = 0.7197785973548889, train/logprobs = tensor([[-0.9704, -1.5936],
        [-1.1014, -1.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006462675519287586
Epoch 0, Step 210: train/loss = 0.7112745642662048, train/raw-loss = 0.7110418081283569, train/logprobs = tensor([[-0.9211, -0.8725],
        [-1.2588, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023278554435819387
Epoch 0, Step 211: train/loss = 0.715316116809845, train/raw-loss = 0.7151328921318054, train/logprobs = tensor([[-0.6851, -1.0427],
        [-0.8604, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001832528505474329
Epoch 0, Step 212: train/loss = 0.6970560550689697, train/raw-loss = 0.6967942118644714, train/logprobs = tensor([[-0.8702, -0.8331],
        [-1.0350, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002617867197841406
Epoch 0, Step 213: train/loss = 0.7052637338638306, train/raw-loss = 0.7050049304962158, train/logprobs = tensor([[-1.0125, -1.1788],
        [-1.2828, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002588101429864764
Epoch 0, Step 214: train/loss = 0.712593674659729, train/raw-loss = 0.7121423482894897, train/logprobs = tensor([[-0.6910, -1.0069],
        [-0.8378, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045126741752028465
Epoch 0, Step 215: train/loss = 0.7365087866783142, train/raw-loss = 0.736250102519989, train/logprobs = tensor([[-1.2853, -1.0524],
        [-1.4507, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025873114354908466
Epoch 0, Step 216: train/loss = 0.7115504145622253, train/raw-loss = 0.7113826274871826, train/logprobs = tensor([[-1.0293, -1.3278],
        [-1.1111, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016784085892140865
Epoch 0, Step 217: train/loss = 0.6973406076431274, train/raw-loss = 0.696937084197998, train/logprobs = tensor([[-0.7084, -0.9511],
        [-0.7893, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00403559859842062
Epoch 0, Step 218: train/loss = 0.7165289521217346, train/raw-loss = 0.7161769866943359, train/logprobs = tensor([[-0.6961, -1.2191],
        [-0.8688, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035194014199078083
Epoch 0, Step 219: train/loss = 0.7137600183486938, train/raw-loss = 0.7133708000183105, train/logprobs = tensor([[-0.9603, -1.4533],
        [-1.0082, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003891414264217019
Epoch 0, Step 220: train/loss = 0.6962794065475464, train/raw-loss = 0.6962746381759644, train/logprobs = tensor([[-0.7505, -0.8345],
        [-0.7609, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.758962313644588e-05
Epoch 0, Step 221: train/loss = 0.7187216281890869, train/raw-loss = 0.7185098528862, train/logprobs = tensor([[-1.0913, -1.2235],
        [-1.2754, -1.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021170368418097496
Epoch 0, Step 222: train/loss = 0.7024885416030884, train/raw-loss = 0.7022969722747803, train/logprobs = tensor([[-0.6633, -0.8407],
        [-0.8294, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019154567271471024
Epoch 0, Step 223: train/loss = 0.7035016417503357, train/raw-loss = 0.7034903168678284, train/logprobs = tensor([[-0.7438, -0.9825],
        [-0.8824, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011370689026080072
Epoch 0, Step 224: train/loss = 0.7008247375488281, train/raw-loss = 0.7004231214523315, train/logprobs = tensor([[-0.8706, -1.1922],
        [-1.0605, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004016117658466101
Epoch 0, Step 225: train/loss = 0.705234169960022, train/raw-loss = 0.7050410509109497, train/logprobs = tensor([[-0.6991, -0.6710],
        [-0.9056, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019312187796458602
Epoch 0, Step 226: train/loss = 0.7247945666313171, train/raw-loss = 0.7244920134544373, train/logprobs = tensor([[-0.9268, -0.9375],
        [-1.0879, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003025731770321727
Epoch 0, Step 227: train/loss = 0.698959231376648, train/raw-loss = 0.6988744139671326, train/logprobs = tensor([[-0.8681, -0.9761],
        [-1.1441, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008476456860080361
Epoch 0, Step 228: train/loss = 0.7117632031440735, train/raw-loss = 0.7116340398788452, train/logprobs = tensor([[-1.1625, -0.9731],
        [-1.4305, -1.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012914692051708698
Epoch 0, Step 229: train/loss = 0.7554956078529358, train/raw-loss = 0.7553159594535828, train/logprobs = tensor([[-0.7682, -1.2337],
        [-0.8688, -1.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001796605414710939
Epoch 0, Step 230: train/loss = 0.7060120701789856, train/raw-loss = 0.7059469223022461, train/logprobs = tensor([[-0.8853, -0.7735],
        [-1.0878, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006525845383293927
Epoch 0, Step 231: train/loss = 0.7091953158378601, train/raw-loss = 0.7091755270957947, train/logprobs = tensor([[-0.6229, -0.9045],
        [-0.7554, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019736717513296753
Epoch 0, Step 232: train/loss = 0.7081372737884521, train/raw-loss = 0.7079799175262451, train/logprobs = tensor([[-0.6689, -0.6556],
        [-0.8874, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015739328227937222
Epoch 0, Step 233: train/loss = 0.7465054988861084, train/raw-loss = 0.7464429140090942, train/logprobs = tensor([[-0.7012, -1.1024],
        [-0.8371, -1.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006258212961256504
Epoch 0, Step 234: train/loss = 0.7898823022842407, train/raw-loss = 0.7898227572441101, train/logprobs = tensor([[-0.8577, -0.9288],
        [-0.9277, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000595592544414103
Epoch 0, Step 235: train/loss = 0.7232704162597656, train/raw-loss = 0.7229390144348145, train/logprobs = tensor([[-0.7768, -1.0735],
        [-0.9595, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033141460735350847
Epoch 0, Step 236: train/loss = 0.6927800178527832, train/raw-loss = 0.6927205920219421, train/logprobs = tensor([[-0.7712, -0.8314],
        [-0.8788, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005939027760177851
Epoch 0, Step 237: train/loss = 0.6962083578109741, train/raw-loss = 0.696040153503418, train/logprobs = tensor([[-0.9940, -1.0538],
        [-1.2697, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016817261930555105
Epoch 0, Step 238: train/loss = 0.7168998718261719, train/raw-loss = 0.7168855667114258, train/logprobs = tensor([[-0.9351, -0.8915],
        [-1.0965, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014334841398522258
Epoch 0, Step 239: train/loss = 0.6956721544265747, train/raw-loss = 0.6955169439315796, train/logprobs = tensor([[-0.6305, -0.8418],
        [-0.7667, -0.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015525977360084653
Epoch 0, Step 240: train/loss = 0.7308622598648071, train/raw-loss = 0.7302652597427368, train/logprobs = tensor([[-1.2156, -0.9488],
        [-1.5199, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059694554656744
Epoch 0, Step 241: train/loss = 0.6947593688964844, train/raw-loss = 0.6947439312934875, train/logprobs = tensor([[-0.9240, -0.9420],
        [-0.9721, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015446536417584866
Epoch 0, Step 242: train/loss = 0.6963175535202026, train/raw-loss = 0.6962001919746399, train/logprobs = tensor([[-0.7311, -0.8703],
        [-0.9028, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011734443251043558
Epoch 0, Step 243: train/loss = 0.6942175030708313, train/raw-loss = 0.693776547908783, train/logprobs = tensor([[-0.8622, -0.8060],
        [-1.0143, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004409500863403082
Epoch 0, Step 244: train/loss = 0.7096903324127197, train/raw-loss = 0.7096788883209229, train/logprobs = tensor([[-1.0369, -0.8179],
        [-1.1565, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011388467828510329
Epoch 0, Step 245: train/loss = 0.7016385793685913, train/raw-loss = 0.7015646696090698, train/logprobs = tensor([[-0.9783, -1.2495],
        [-1.2344, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007394985877908766
Epoch 0, Step 246: train/loss = 0.6945752501487732, train/raw-loss = 0.6945534944534302, train/logprobs = tensor([[-0.8589, -0.9304],
        [-1.0339, -1.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002175833797082305
Epoch 0, Step 247: train/loss = 0.7175346612930298, train/raw-loss = 0.717127799987793, train/logprobs = tensor([[-0.9495, -1.0528],
        [-1.1648, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004068662412464619
Epoch 0, Step 248: train/loss = 0.7539775371551514, train/raw-loss = 0.7534364461898804, train/logprobs = tensor([[-0.9982, -1.5093],
        [-1.0551, -1.3284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054110269993543625
Epoch 0, Step 249: train/loss = 0.710841715335846, train/raw-loss = 0.7107582092285156, train/logprobs = tensor([[-0.7862, -0.6543],
        [-1.0215, -0.7932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008347450639121234
Epoch 0, Step 250: train/loss = 0.6943274736404419, train/raw-loss = 0.6942001581192017, train/logprobs = tensor([[-0.8326, -0.8302],
        [-0.9950, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012732885079458356
Epoch 0, Step 251: train/loss = 0.7404274940490723, train/raw-loss = 0.7400060892105103, train/logprobs = tensor([[-0.8434, -1.3334],
        [-0.9806, -1.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042144013568758965
Epoch 0, Step 252: train/loss = 0.700488269329071, train/raw-loss = 0.7004568576812744, train/logprobs = tensor([[-0.6896, -0.8440],
        [-0.8574, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003136985469609499
Epoch 0, Step 253: train/loss = 0.695781409740448, train/raw-loss = 0.6957712173461914, train/logprobs = tensor([[-0.6338, -0.7361],
        [-0.7314, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010217539966106415
Epoch 0, Step 254: train/loss = 0.704806387424469, train/raw-loss = 0.704584538936615, train/logprobs = tensor([[-0.8539, -1.1443],
        [-0.9804, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002218080684542656
Epoch 0, Step 255: train/loss = 0.7113251686096191, train/raw-loss = 0.7111374139785767, train/logprobs = tensor([[-0.9974, -0.7218],
        [-1.0050, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001877575647085905
Epoch 0, Step 256: train/loss = 0.7163469791412354, train/raw-loss = 0.7162984609603882, train/logprobs = tensor([[-1.2662, -1.0475],
        [-1.4733, -1.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004855950246565044
Epoch 0, Step 257: train/loss = 0.7350757718086243, train/raw-loss = 0.7350303530693054, train/logprobs = tensor([[-0.9827, -1.4451],
        [-1.1904, -1.5226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004541452508419752
Epoch 0, Step 258: train/loss = 0.7437359690666199, train/raw-loss = 0.743532121181488, train/logprobs = tensor([[-1.0775, -0.6696],
        [-1.3538, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002038724487647414
Epoch 0, Step 259: train/loss = 0.7101983428001404, train/raw-loss = 0.7099723815917969, train/logprobs = tensor([[-1.2280, -1.0097],
        [-1.3220, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002260057721287012
Epoch 0, Step 260: train/loss = 0.7005834579467773, train/raw-loss = 0.7005809545516968, train/logprobs = tensor([[-0.9984, -0.8620],
        [-1.0827, -0.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.602086533443071e-05
Epoch 0, Step 261: train/loss = 0.7136858701705933, train/raw-loss = 0.7136463522911072, train/logprobs = tensor([[-0.7152, -1.1037],
        [-0.8303, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003948159865103662
Epoch 0, Step 262: train/loss = 0.8140935301780701, train/raw-loss = 0.8138408660888672, train/logprobs = tensor([[-1.2723, -0.5719],
        [-1.5413, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025262199342250824
Epoch 0, Step 263: train/loss = 0.7475556135177612, train/raw-loss = 0.7475137710571289, train/logprobs = tensor([[-1.0082, -0.6501],
        [-1.2096, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004184956487733871
Epoch 0, Step 264: train/loss = 0.7243615984916687, train/raw-loss = 0.7240149974822998, train/logprobs = tensor([[-0.8234, -0.6034],
        [-0.8957, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00346641568467021
Epoch 0, Step 265: train/loss = 0.7417181730270386, train/raw-loss = 0.7415100336074829, train/logprobs = tensor([[-0.7859, -1.3584],
        [-0.9314, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020815578754991293
Epoch 0, Step 266: train/loss = 0.6962610483169556, train/raw-loss = 0.6962169408798218, train/logprobs = tensor([[-0.9609, -0.8948],
        [-1.1567, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044088822323828936
Epoch 0, Step 267: train/loss = 0.7267203330993652, train/raw-loss = 0.7263404130935669, train/logprobs = tensor([[-1.1514, -1.0320],
        [-1.3211, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037990366108715534
Epoch 0, Step 268: train/loss = 0.758516252040863, train/raw-loss = 0.7582880258560181, train/logprobs = tensor([[-1.0648, -1.0631],
        [-1.2463, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002281530061736703
Epoch 0, Step 269: train/loss = 0.6949577331542969, train/raw-loss = 0.6948509216308594, train/logprobs = tensor([[-0.8885, -0.9261],
        [-1.0813, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001068287412635982
Epoch 0, Step 270: train/loss = 0.7142391800880432, train/raw-loss = 0.7140495777130127, train/logprobs = tensor([[-0.8832, -0.7190],
        [-1.0201, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001896288595162332
Epoch 0, Step 271: train/loss = 0.7084522843360901, train/raw-loss = 0.708250880241394, train/logprobs = tensor([[-0.9026, -1.1120],
        [-1.2024, -1.2680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002014697529375553
Epoch 0, Step 272: train/loss = 0.7243343591690063, train/raw-loss = 0.7237672805786133, train/logprobs = tensor([[-0.9862, -1.3112],
        [-1.1278, -1.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005670470651239157
Epoch 0, Step 273: train/loss = 0.7233982086181641, train/raw-loss = 0.723234236240387, train/logprobs = tensor([[-0.8713, -1.0877],
        [-1.3044, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016399016603827477
Epoch 0, Step 274: train/loss = 0.6975317001342773, train/raw-loss = 0.6975088119506836, train/logprobs = tensor([[-1.0853, -1.0976],
        [-1.2401, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002294060541316867
Epoch 0, Step 275: train/loss = 0.7097291350364685, train/raw-loss = 0.709554135799408, train/logprobs = tensor([[-1.2198, -0.9512],
        [-1.3902, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001749821356497705
Epoch 0, Step 276: train/loss = 0.6998353004455566, train/raw-loss = 0.6998227834701538, train/logprobs = tensor([[-0.6454, -0.7958],
        [-0.7601, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012527286889962852
Epoch 0, Step 277: train/loss = 0.6954256296157837, train/raw-loss = 0.695193886756897, train/logprobs = tensor([[-0.7874, -0.7557],
        [-0.8550, -0.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023167890030890703
Epoch 0, Step 278: train/loss = 0.7114933133125305, train/raw-loss = 0.7110228538513184, train/logprobs = tensor([[-0.6127, -0.9258],
        [-0.7030, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047046407125890255
Epoch 0, Step 279: train/loss = 0.7040989995002747, train/raw-loss = 0.7039815187454224, train/logprobs = tensor([[-0.9329, -0.8884],
        [-1.0373, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011750301346182823
Epoch 0, Step 280: train/loss = 0.7017649412155151, train/raw-loss = 0.7017357349395752, train/logprobs = tensor([[-0.9070, -0.8796],
        [-1.1147, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002912410709541291
Epoch 0, Step 281: train/loss = 0.7585690021514893, train/raw-loss = 0.7583679556846619, train/logprobs = tensor([[-1.0541, -0.6371],
        [-1.2821, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002010089810937643
Epoch 0, Step 282: train/loss = 0.7000288963317871, train/raw-loss = 0.6998399496078491, train/logprobs = tensor([[-0.8386, -1.0066],
        [-0.9981, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018891659565269947
Epoch 0, Step 283: train/loss = 0.7076513767242432, train/raw-loss = 0.70762699842453, train/logprobs = tensor([[-1.0944, -0.9086],
        [-1.2331, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024368327285628766
Epoch 0, Step 284: train/loss = 0.6889061331748962, train/raw-loss = 0.6878252625465393, train/logprobs = tensor([[-0.8170, -0.9245],
        [-1.0795, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010808449238538742
Epoch 0, Step 285: train/loss = 0.7373490333557129, train/raw-loss = 0.7373412251472473, train/logprobs = tensor([[-0.9372, -0.8496],
        [-1.0579, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.755714614177123e-05
Epoch 0, Step 286: train/loss = 0.6963061094284058, train/raw-loss = 0.6962632536888123, train/logprobs = tensor([[-0.4889, -0.5690],
        [-0.5843, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042853402555920184
Epoch 0, Step 287: train/loss = 0.7019040584564209, train/raw-loss = 0.7018848657608032, train/logprobs = tensor([[-0.7379, -0.7383],
        [-0.8298, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001921678485814482
Epoch 0, Step 288: train/loss = 0.7020174264907837, train/raw-loss = 0.7019150257110596, train/logprobs = tensor([[-0.9446, -0.8185],
        [-1.0527, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001023623044602573
Epoch 0, Step 289: train/loss = 0.7389195561408997, train/raw-loss = 0.7388886213302612, train/logprobs = tensor([[-1.1655, -0.8373],
        [-1.4404, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003086055803578347
Epoch 0, Step 290: train/loss = 0.7393167614936829, train/raw-loss = 0.738024115562439, train/logprobs = tensor([[-1.0256, -1.0994],
        [-1.1297, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012926277704536915
Epoch 0, Step 291: train/loss = 0.7205919027328491, train/raw-loss = 0.7205830216407776, train/logprobs = tensor([[-1.2238, -0.8990],
        [-1.3338, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.875061757862568e-05
Epoch 0, Step 292: train/loss = 0.757016122341156, train/raw-loss = 0.756535530090332, train/logprobs = tensor([[-1.3761, -0.8166],
        [-1.5410, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004806408658623695
Epoch 0, Step 293: train/loss = 0.7245550155639648, train/raw-loss = 0.7243329286575317, train/logprobs = tensor([[-1.2922, -1.2614],
        [-1.3646, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002220700029283762
Epoch 0, Step 294: train/loss = 0.7904267311096191, train/raw-loss = 0.7903124094009399, train/logprobs = tensor([[-1.0167, -0.5398],
        [-1.0993, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011432957835495472
Epoch 0, Step 295: train/loss = 0.7169733047485352, train/raw-loss = 0.7168344259262085, train/logprobs = tensor([[-1.1909, -1.1622],
        [-1.3596, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013884962536394596
Epoch 0, Step 296: train/loss = 0.7402887344360352, train/raw-loss = 0.7402560710906982, train/logprobs = tensor([[-1.0083, -0.7595],
        [-1.1750, -0.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003272203612141311
Epoch 0, Step 297: train/loss = 0.7213132381439209, train/raw-loss = 0.7212624549865723, train/logprobs = tensor([[-0.7702, -1.1786],
        [-0.9089, -1.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005079512484371662
Epoch 0, Step 298: train/loss = 0.7549139261245728, train/raw-loss = 0.7547851204872131, train/logprobs = tensor([[-1.1311, -0.8837],
        [-1.3369, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012884612660855055
Epoch 0, Step 299: train/loss = 0.7414522767066956, train/raw-loss = 0.7413416504859924, train/logprobs = tensor([[-1.3674, -0.8116],
        [-1.5794, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011065874714404345
Epoch 0, Step 300: train/loss = 0.7235968112945557, train/raw-loss = 0.7233709096908569, train/logprobs = tensor([[-1.0538, -0.8108],
        [-1.2703, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022585929837077856
Epoch 0, Step 301: train/loss = 0.7381325960159302, train/raw-loss = 0.7381159067153931, train/logprobs = tensor([[-0.7292, -0.7616],
        [-0.8277, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016660563414916396
Epoch 0, Step 302: train/loss = 0.6954574584960938, train/raw-loss = 0.6954463124275208, train/logprobs = tensor([[-0.8379, -0.7706],
        [-1.0205, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011160288704559207
Epoch 0, Step 303: train/loss = 0.7187839150428772, train/raw-loss = 0.7186686396598816, train/logprobs = tensor([[-1.4093, -1.4285],
        [-1.6225, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011530464980751276
Epoch 0, Step 304: train/loss = 0.710835874080658, train/raw-loss = 0.7107374668121338, train/logprobs = tensor([[-0.9833, -0.9521],
        [-1.0829, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009839480044320226
Epoch 0, Step 305: train/loss = 0.7059319615364075, train/raw-loss = 0.7059165239334106, train/logprobs = tensor([[-0.7197, -0.9532],
        [-0.9803, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015404913574457169
Epoch 0, Step 306: train/loss = 0.6952207684516907, train/raw-loss = 0.6951743960380554, train/logprobs = tensor([[-1.0159, -1.1053],
        [-1.1014, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004640237893909216
Epoch 0, Step 307: train/loss = 0.7349680066108704, train/raw-loss = 0.7349486947059631, train/logprobs = tensor([[-1.3504, -1.0490],
        [-1.5222, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019308878108859062
Epoch 0, Step 308: train/loss = 0.7014257907867432, train/raw-loss = 0.7013932466506958, train/logprobs = tensor([[-0.7309, -0.6260],
        [-0.8503, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003250113222748041
Epoch 0, Step 309: train/loss = 0.7352870106697083, train/raw-loss = 0.7352425456047058, train/logprobs = tensor([[-1.2651, -0.8367],
        [-1.5264, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044534949120134115
Epoch 0, Step 310: train/loss = 0.6933241486549377, train/raw-loss = 0.6931617259979248, train/logprobs = tensor([[-1.1172, -1.1469],
        [-1.3330, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016238851239904761
Epoch 0, Step 311: train/loss = 0.7269244194030762, train/raw-loss = 0.7269120216369629, train/logprobs = tensor([[-0.7620, -1.0376],
        [-0.8998, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001241466379724443
Epoch 0, Step 312: train/loss = 0.7143111824989319, train/raw-loss = 0.7141361236572266, train/logprobs = tensor([[-1.2149, -0.9560],
        [-1.4163, -0.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017504775896668434
Epoch 0, Step 313: train/loss = 0.7359166741371155, train/raw-loss = 0.7359133958816528, train/logprobs = tensor([[-1.0035, -0.7123],
        [-1.1744, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2708063372410834e-05
Epoch 0, Step 314: train/loss = 0.7433952689170837, train/raw-loss = 0.7432519197463989, train/logprobs = tensor([[-0.9629, -0.7923],
        [-1.1574, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014334002044051886
Epoch 0, Step 315: train/loss = 0.7144705653190613, train/raw-loss = 0.7121548056602478, train/logprobs = tensor([[-1.0051, -1.2591],
        [-1.2115, -1.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023157566785812378
Epoch 0, Step 316: train/loss = 0.7043337821960449, train/raw-loss = 0.7039666175842285, train/logprobs = tensor([[-0.9395, -0.9804],
        [-1.0098, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036720549687743187
Epoch 0, Step 317: train/loss = 0.712049126625061, train/raw-loss = 0.7118105292320251, train/logprobs = tensor([[-1.2084, -1.2547],
        [-1.4188, -1.3186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023856949992477894
Epoch 0, Step 318: train/loss = 0.745895266532898, train/raw-loss = 0.7457094192504883, train/logprobs = tensor([[-1.3464, -0.8215],
        [-1.4373, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018577476730570197
Epoch 0, Step 319: train/loss = 0.6981570720672607, train/raw-loss = 0.6977125406265259, train/logprobs = tensor([[-1.1199, -1.2074],
        [-1.3128, -1.1927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004445078782737255
Epoch 0, Step 320: train/loss = 0.7271234393119812, train/raw-loss = 0.7265475988388062, train/logprobs = tensor([[-1.3732, -1.1246],
        [-1.6078, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005758077837526798
Epoch 0, Step 321: train/loss = 0.7288552522659302, train/raw-loss = 0.7287108898162842, train/logprobs = tensor([[-1.0445, -0.7969],
        [-1.3443, -0.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014429014408960938
Epoch 0, Step 322: train/loss = 0.7108047008514404, train/raw-loss = 0.7106530070304871, train/logprobs = tensor([[-0.7160, -0.5181],
        [-0.9184, -0.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015170793049037457
Epoch 0, Step 323: train/loss = 0.7236429452896118, train/raw-loss = 0.7234914898872375, train/logprobs = tensor([[-1.1397, -0.7907],
        [-1.3139, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001514212228357792
Epoch 0, Step 324: train/loss = 0.7316118478775024, train/raw-loss = 0.7316048741340637, train/logprobs = tensor([[-1.1761, -0.7057],
        [-1.1897, -0.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.972043047426268e-05
Epoch 0, Step 325: train/loss = 0.7279193997383118, train/raw-loss = 0.7279008626937866, train/logprobs = tensor([[-0.9747, -0.6514],
        [-1.0829, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018487301713321358
Epoch 0, Step 326: train/loss = 0.7242957353591919, train/raw-loss = 0.724077582359314, train/logprobs = tensor([[-0.6760, -0.9986],
        [-0.8304, -1.2155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021820967085659504
Epoch 0, Step 327: train/loss = 0.7208333611488342, train/raw-loss = 0.720728874206543, train/logprobs = tensor([[-0.6914, -1.0026],
        [-0.8497, -1.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010447994573041797
Epoch 0, Step 328: train/loss = 0.7540029287338257, train/raw-loss = 0.7537497878074646, train/logprobs = tensor([[-1.3705, -0.9438],
        [-1.4292, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00253066373988986
Epoch 0, Step 329: train/loss = 0.775039553642273, train/raw-loss = 0.7748939990997314, train/logprobs = tensor([[-0.9465, -1.1276],
        [-1.0719, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014556299429386854
Epoch 0, Step 330: train/loss = 0.7060489058494568, train/raw-loss = 0.7059098482131958, train/logprobs = tensor([[-0.9907, -0.9073],
        [-1.1269, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013907983666285872
Epoch 0, Step 331: train/loss = 0.699429452419281, train/raw-loss = 0.6993634700775146, train/logprobs = tensor([[-1.0600, -1.0693],
        [-1.2036, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006590491975657642
Epoch 0, Step 332: train/loss = 0.7001861333847046, train/raw-loss = 0.7001725435256958, train/logprobs = tensor([[-0.9704, -0.9088],
        [-1.1107, -0.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013539940118789673
Epoch 0, Step 333: train/loss = 0.6962500810623169, train/raw-loss = 0.6962418556213379, train/logprobs = tensor([[-1.1758, -1.0607],
        [-1.2481, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.2246377132833e-05
Epoch 0, Step 334: train/loss = 0.729057252407074, train/raw-loss = 0.7288411855697632, train/logprobs = tensor([[-1.0856, -1.0771],
        [-1.3112, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021610029507428408
Epoch 0, Step 335: train/loss = 0.7314973473548889, train/raw-loss = 0.7314833402633667, train/logprobs = tensor([[-1.0652, -0.8394],
        [-1.1373, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013984180986881256
Epoch 0, Step 336: train/loss = 0.7044690251350403, train/raw-loss = 0.7043461799621582, train/logprobs = tensor([[-1.0993, -1.3006],
        [-1.1566, -1.2915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012283821124583483
Epoch 0, Step 337: train/loss = 0.6963324546813965, train/raw-loss = 0.696302592754364, train/logprobs = tensor([[-0.8348, -0.8132],
        [-0.9769, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029858341440558434
Epoch 0, Step 338: train/loss = 0.7187154293060303, train/raw-loss = 0.7186833024024963, train/logprobs = tensor([[-1.0122, -0.7497],
        [-1.0456, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032101082615554333
Epoch 0, Step 339: train/loss = 0.6970851421356201, train/raw-loss = 0.6970505118370056, train/logprobs = tensor([[-0.7198, -0.8342],
        [-0.8815, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003457546408753842
Epoch 0, Step 340: train/loss = 0.69637531042099, train/raw-loss = 0.6962578892707825, train/logprobs = tensor([[-1.2724, -1.2215],
        [-1.4539, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011744830990210176
Epoch 0, Step 341: train/loss = 0.6952227354049683, train/raw-loss = 0.6952188014984131, train/logprobs = tensor([[-0.9006, -0.8471],
        [-0.9710, -0.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9565988117828965e-05
Epoch 0, Step 342: train/loss = 0.7062046527862549, train/raw-loss = 0.7060506343841553, train/logprobs = tensor([[-1.0624, -0.8689],
        [-1.2963, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015401731943711638
Epoch 0, Step 343: train/loss = 0.7239187955856323, train/raw-loss = 0.7238969802856445, train/logprobs = tensor([[-0.9622, -1.2567],
        [-1.0537, -1.3206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002175512199755758
Epoch 0, Step 344: train/loss = 0.704918384552002, train/raw-loss = 0.7048919200897217, train/logprobs = tensor([[-1.1736, -0.9595],
        [-1.2831, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002644475316628814
Epoch 0, Step 345: train/loss = 0.7144555449485779, train/raw-loss = 0.714302659034729, train/logprobs = tensor([[-0.9958, -0.8076],
        [-1.2116, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00152931222692132
Epoch 0, Step 346: train/loss = 0.7056621313095093, train/raw-loss = 0.7049605250358582, train/logprobs = tensor([[-1.2833, -1.2415],
        [-1.4666, -1.3801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007016180548816919
Epoch 0, Step 347: train/loss = 0.7118006348609924, train/raw-loss = 0.7111586332321167, train/logprobs = tensor([[-1.1015, -1.1363],
        [-1.2069, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006420067511498928
Epoch 0, Step 348: train/loss = 0.7509447932243347, train/raw-loss = 0.7505866289138794, train/logprobs = tensor([[-1.2777, -1.0912],
        [-1.4332, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035816924646496773
Epoch 0, Step 349: train/loss = 0.7107239961624146, train/raw-loss = 0.710719645023346, train/logprobs = tensor([[-0.9670, -1.1609],
        [-0.9970, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.311483644414693e-05
Epoch 0, Step 350: train/loss = 0.7261988520622253, train/raw-loss = 0.7261641025543213, train/logprobs = tensor([[-1.1969, -0.9089],
        [-1.3485, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034743419382721186
Epoch 0, Step 351: train/loss = 0.7332912087440491, train/raw-loss = 0.7331655025482178, train/logprobs = tensor([[-1.2440, -0.8492],
        [-1.3574, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012567492667585611
Epoch 0, Step 352: train/loss = 0.7051424980163574, train/raw-loss = 0.704964280128479, train/logprobs = tensor([[-0.9123, -1.2085],
        [-1.0333, -1.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017822682857513428
Epoch 0, Step 353: train/loss = 0.6974634528160095, train/raw-loss = 0.6974272131919861, train/logprobs = tensor([[-1.3612, -1.2302],
        [-1.4178, -1.2622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036186393117532134
Epoch 0, Step 354: train/loss = 0.6945488452911377, train/raw-loss = 0.6945464611053467, train/logprobs = tensor([[-0.9538, -0.8820],
        [-1.0129, -0.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3730855900794268e-05
Epoch 0, Step 355: train/loss = 0.7067416310310364, train/raw-loss = 0.706730306148529, train/logprobs = tensor([[-0.7861, -0.7435],
        [-0.8964, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011362170334905386
Epoch 0, Step 356: train/loss = 0.7000318765640259, train/raw-loss = 0.6999837160110474, train/logprobs = tensor([[-0.9436, -0.9644],
        [-1.1513, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048182415775954723
Epoch 0, Step 357: train/loss = 0.7294270396232605, train/raw-loss = 0.7293311357498169, train/logprobs = tensor([[-1.1683, -0.9736],
        [-1.3582, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000958354095928371
Epoch 0, Step 358: train/loss = 0.7025227546691895, train/raw-loss = 0.7024887204170227, train/logprobs = tensor([[-1.1042, -0.9633],
        [-1.2261, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034037293517030776
Epoch 0, Step 359: train/loss = 0.7641298174858093, train/raw-loss = 0.7639612555503845, train/logprobs = tensor([[-1.0801, -1.2158],
        [-1.2426, -1.3679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016853967681527138
Epoch 0, Step 360: train/loss = 0.7282659411430359, train/raw-loss = 0.7281314134597778, train/logprobs = tensor([[-0.9978, -0.7292],
        [-1.1365, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013454300351440907
Epoch 0, Step 361: train/loss = 0.7381472587585449, train/raw-loss = 0.7379347681999207, train/logprobs = tensor([[-0.7529, -1.2051],
        [-0.8173, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021249153651297092
Epoch 0, Step 362: train/loss = 0.7042981386184692, train/raw-loss = 0.7042301893234253, train/logprobs = tensor([[-0.7678, -0.5964],
        [-0.9035, -0.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006786985322833061
Epoch 0, Step 363: train/loss = 0.6980559825897217, train/raw-loss = 0.6980343461036682, train/logprobs = tensor([[-1.0596, -1.2300],
        [-1.2121, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021656847093254328
Epoch 0, Step 364: train/loss = 0.715496838092804, train/raw-loss = 0.7154214978218079, train/logprobs = tensor([[-1.0906, -0.9021],
        [-1.1413, -0.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007537799538113177
Epoch 0, Step 365: train/loss = 0.7210538983345032, train/raw-loss = 0.7209249138832092, train/logprobs = tensor([[-1.1065, -0.8971],
        [-1.4739, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012896585976704955
Epoch 0, Step 366: train/loss = 0.7329583168029785, train/raw-loss = 0.7328564524650574, train/logprobs = tensor([[-1.0721, -1.1500],
        [-1.1428, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010190322063863277
Epoch 0, Step 367: train/loss = 0.7462805509567261, train/raw-loss = 0.7462180256843567, train/logprobs = tensor([[-1.0780, -1.0539],
        [-1.2083, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006253336323425174
Epoch 0, Step 368: train/loss = 0.7079114317893982, train/raw-loss = 0.707756757736206, train/logprobs = tensor([[-1.1140, -0.9739],
        [-1.4179, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015466558979824185
Epoch 0, Step 369: train/loss = 0.7110512256622314, train/raw-loss = 0.7110090851783752, train/logprobs = tensor([[-0.8817, -0.7111],
        [-0.9890, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004213257343508303
Epoch 0, Step 370: train/loss = 0.7151223421096802, train/raw-loss = 0.7150865793228149, train/logprobs = tensor([[-1.0779, -0.9165],
        [-1.1983, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003571846755221486
Epoch 0, Step 371: train/loss = 0.7219374179840088, train/raw-loss = 0.7217507362365723, train/logprobs = tensor([[-1.1388, -0.7974],
        [-1.3468, -0.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018664972158148885
Epoch 0, Step 372: train/loss = 0.7004823088645935, train/raw-loss = 0.700373113155365, train/logprobs = tensor([[-1.0618, -1.0325],
        [-1.1909, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010921319480985403
Epoch 0, Step 373: train/loss = 0.6995472311973572, train/raw-loss = 0.6995174884796143, train/logprobs = tensor([[-0.8232, -0.7527],
        [-0.9042, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029740965692326427
Epoch 0, Step 374: train/loss = 0.703284740447998, train/raw-loss = 0.7031733393669128, train/logprobs = tensor([[-1.1632, -1.2580],
        [-1.3220, -1.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011142661096528172
Epoch 0, Step 375: train/loss = 0.7046515941619873, train/raw-loss = 0.704639732837677, train/logprobs = tensor([[-1.0296, -0.8358],
        [-1.1643, -0.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011889135930687189
Epoch 0, Step 376: train/loss = 0.7164514064788818, train/raw-loss = 0.7164298892021179, train/logprobs = tensor([[-1.3179, -0.9731],
        [-1.3032, -0.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021543161710724235
Epoch 0, Step 377: train/loss = 0.6941080093383789, train/raw-loss = 0.6941002607345581, train/logprobs = tensor([[-0.9979, -0.9452],
        [-1.1820, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.71877821534872e-05
Epoch 0, Step 378: train/loss = 0.7271774411201477, train/raw-loss = 0.7270404100418091, train/logprobs = tensor([[-1.1291, -1.0585],
        [-1.2113, -1.1371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013708773767575622
Epoch 0, Step 379: train/loss = 0.7310893535614014, train/raw-loss = 0.7310526967048645, train/logprobs = tensor([[-0.9394, -0.6513],
        [-1.0329, -0.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036636757431551814
Epoch 0, Step 380: train/loss = 0.7191172242164612, train/raw-loss = 0.7190690040588379, train/logprobs = tensor([[-1.0174, -0.9913],
        [-1.1026, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004826408694498241
Epoch 0, Step 381: train/loss = 0.6962571144104004, train/raw-loss = 0.6962264776229858, train/logprobs = tensor([[-1.1254, -1.2060],
        [-1.1538, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030641391640529037
Epoch 0, Step 382: train/loss = 0.6989823579788208, train/raw-loss = 0.698963463306427, train/logprobs = tensor([[-0.8764, -0.7404],
        [-0.9546, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018852861830964684
Epoch 0, Step 383: train/loss = 0.7010543942451477, train/raw-loss = 0.7009439468383789, train/logprobs = tensor([[-1.1345, -1.0526],
        [-1.3227, -1.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001104480354115367
Epoch 0, Step 384: train/loss = 0.7574191689491272, train/raw-loss = 0.7573798894882202, train/logprobs = tensor([[-0.7279, -0.9649],
        [-0.7870, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003933850093744695
Epoch 0, Step 385: train/loss = 0.7182716727256775, train/raw-loss = 0.7179579734802246, train/logprobs = tensor([[-1.1474, -0.9759],
        [-1.2932, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003137142863124609
Epoch 0, Step 386: train/loss = 0.703752875328064, train/raw-loss = 0.70372474193573, train/logprobs = tensor([[-0.9991, -0.8032],
        [-1.0570, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002813824394252151
Epoch 0, Step 387: train/loss = 0.7315895557403564, train/raw-loss = 0.7315083742141724, train/logprobs = tensor([[-1.0665, -1.0568],
        [-1.2046, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008114416850730777
Epoch 0, Step 388: train/loss = 0.6971129179000854, train/raw-loss = 0.6968762874603271, train/logprobs = tensor([[-1.0358, -1.2236],
        [-1.1751, -1.2173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023665453772991896
Epoch 0, Step 389: train/loss = 0.8535568714141846, train/raw-loss = 0.8534908294677734, train/logprobs = tensor([[-1.3473, -0.5272],
        [-1.5716, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000661355908960104
Epoch 0, Step 390: train/loss = 0.7314472794532776, train/raw-loss = 0.7314132452011108, train/logprobs = tensor([[-1.4518, -1.3125],
        [-1.6336, -1.3277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034047290682792664
Epoch 0, Step 391: train/loss = 0.6987389922142029, train/raw-loss = 0.6986777186393738, train/logprobs = tensor([[-0.8974, -0.7408],
        [-1.0681, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006128338864073157
Epoch 0, Step 392: train/loss = 0.7019662857055664, train/raw-loss = 0.7017030715942383, train/logprobs = tensor([[-0.6994, -0.7670],
        [-0.7906, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002631823066622019
Epoch 0, Step 393: train/loss = 0.7055433988571167, train/raw-loss = 0.7055128812789917, train/logprobs = tensor([[-0.8580, -0.6519],
        [-1.0085, -0.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030446500750258565
Epoch 0, Step 394: train/loss = 0.725119948387146, train/raw-loss = 0.7251102328300476, train/logprobs = tensor([[-1.1638, -0.9823],
        [-1.2170, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.71560220932588e-05
Epoch 0, Step 395: train/loss = 0.7264837026596069, train/raw-loss = 0.7260663509368896, train/logprobs = tensor([[-1.4513, -0.9390],
        [-1.5886, -1.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004173270892351866
Epoch 0, Step 396: train/loss = 0.7421361804008484, train/raw-loss = 0.7419252395629883, train/logprobs = tensor([[-1.1816, -1.0507],
        [-1.3178, -1.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021097208373248577
Epoch 0, Step 397: train/loss = 0.7106648087501526, train/raw-loss = 0.7104708552360535, train/logprobs = tensor([[-0.9051, -1.1200],
        [-1.0255, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019393698312342167
Epoch 0, Step 398: train/loss = 0.7168186902999878, train/raw-loss = 0.7168103456497192, train/logprobs = tensor([[-0.7803, -0.8390],
        [-0.8487, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.3496532170102e-05
Epoch 0, Step 399: train/loss = 0.7440028190612793, train/raw-loss = 0.7439141869544983, train/logprobs = tensor([[-1.4835, -1.2635],
        [-1.6486, -1.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008855644846335053
Epoch 0, Step 400: train/loss = 0.7238087058067322, train/raw-loss = 0.7237870693206787, train/logprobs = tensor([[-1.1160, -0.9635],
        [-1.2829, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021695141913369298
Epoch 0, Step 401: train/loss = 0.705098032951355, train/raw-loss = 0.704981803894043, train/logprobs = tensor([[-1.2799, -1.2021],
        [-1.3765, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011626197956502438
Epoch 0, Step 402: train/loss = 0.733150064945221, train/raw-loss = 0.7330806255340576, train/logprobs = tensor([[-1.1760, -0.7580],
        [-1.3792, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006943880580365658
Epoch 0, Step 403: train/loss = 0.6958872675895691, train/raw-loss = 0.6956123113632202, train/logprobs = tensor([[-0.7839, -0.9427],
        [-0.9041, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002749511506408453
Epoch 0, Step 404: train/loss = 0.7462161779403687, train/raw-loss = 0.7458209991455078, train/logprobs = tensor([[-1.5208, -0.9629],
        [-1.6654, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003950752317905426
Epoch 0, Step 405: train/loss = 0.7062517404556274, train/raw-loss = 0.706147313117981, train/logprobs = tensor([[-0.8775, -1.1111],
        [-0.9674, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001044242875650525
Epoch 0, Step 406: train/loss = 0.7331058979034424, train/raw-loss = 0.7330106496810913, train/logprobs = tensor([[-1.2377, -1.3329],
        [-1.2742, -1.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009517958387732506
Epoch 0, Step 407: train/loss = 0.7117012143135071, train/raw-loss = 0.7116329669952393, train/logprobs = tensor([[-0.7811, -1.0303],
        [-0.8815, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006822772556915879
Epoch 0, Step 408: train/loss = 0.7317540049552917, train/raw-loss = 0.7317447662353516, train/logprobs = tensor([[-1.0209, -0.9365],
        [-1.1808, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.190128184854984e-05
Epoch 0, Step 409: train/loss = 0.7225466966629028, train/raw-loss = 0.7224594354629517, train/logprobs = tensor([[-1.1798, -0.9870],
        [-1.3636, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008725856896489859
Epoch 0, Step 410: train/loss = 0.722959578037262, train/raw-loss = 0.7228725552558899, train/logprobs = tensor([[-1.2210, -0.9789],
        [-1.3280, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008705676882527769
Epoch 0, Step 411: train/loss = 0.7027028203010559, train/raw-loss = 0.7026721239089966, train/logprobs = tensor([[-0.9288, -0.8595],
        [-1.1445, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003069707308895886
Epoch 0, Step 412: train/loss = 0.7194337844848633, train/raw-loss = 0.7194067239761353, train/logprobs = tensor([[-0.6926, -0.9423],
        [-0.7836, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027002397109754384
Epoch 0, Step 413: train/loss = 0.7583810687065125, train/raw-loss = 0.7583104968070984, train/logprobs = tensor([[-1.1468, -0.7160],
        [-1.2039, -0.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000705558224581182
Epoch 0, Step 414: train/loss = 0.7162707448005676, train/raw-loss = 0.715930700302124, train/logprobs = tensor([[-0.7337, -0.7366],
        [-0.8310, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033999867737293243
Epoch 0, Step 415: train/loss = 0.7294877767562866, train/raw-loss = 0.7292897701263428, train/logprobs = tensor([[-0.9638, -1.4271],
        [-1.1490, -1.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001979741035029292
Epoch 0, Step 416: train/loss = 0.7333412170410156, train/raw-loss = 0.7333132028579712, train/logprobs = tensor([[-0.9740, -0.7185],
        [-1.1711, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002801724476739764
Epoch 0, Step 417: train/loss = 0.7062129974365234, train/raw-loss = 0.7056224346160889, train/logprobs = tensor([[-1.2875, -1.1557],
        [-1.4310, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00590504938736558
Epoch 0, Step 418: train/loss = 0.7328008413314819, train/raw-loss = 0.7325458526611328, train/logprobs = tensor([[-0.7862, -0.7128],
        [-0.8812, -0.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025505339726805687
Epoch 0, Step 419: train/loss = 0.6939361095428467, train/raw-loss = 0.693932831287384, train/logprobs = tensor([[-0.8427, -0.8718],
        [-0.9881, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2514974009245634e-05
Epoch 0, Step 420: train/loss = 0.7223407626152039, train/raw-loss = 0.7220481634140015, train/logprobs = tensor([[-1.4611, -1.1042],
        [-1.6296, -1.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002925482112914324
Epoch 0, Step 421: train/loss = 0.7036145925521851, train/raw-loss = 0.7034794092178345, train/logprobs = tensor([[-1.3441, -1.2298],
        [-1.7421, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001351932412944734
Epoch 0, Step 422: train/loss = 0.7614618539810181, train/raw-loss = 0.7609961628913879, train/logprobs = tensor([[-1.4386, -0.7869],
        [-1.6895, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004656525328755379
Epoch 0, Step 423: train/loss = 0.7177935838699341, train/raw-loss = 0.7177908420562744, train/logprobs = tensor([[-1.2809, -1.0446],
        [-1.5339, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7271074941381812e-05
Epoch 0, Step 424: train/loss = 0.7331160306930542, train/raw-loss = 0.733106791973114, train/logprobs = tensor([[-0.9912, -0.6179],
        [-1.1260, -0.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.244296234101057e-05
Epoch 0, Step 425: train/loss = 0.7743887305259705, train/raw-loss = 0.7742322683334351, train/logprobs = tensor([[-1.0830, -0.5095],
        [-1.3719, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001564628561027348
Epoch 0, Step 426: train/loss = 0.6985147595405579, train/raw-loss = 0.6982907056808472, train/logprobs = tensor([[-0.9256, -0.9272],
        [-1.0522, -1.1121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002240994479507208
Epoch 0, Step 427: train/loss = 0.734255313873291, train/raw-loss = 0.734084963798523, train/logprobs = tensor([[-1.1789, -0.7131],
        [-1.2765, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017027967842295766
Epoch 0, Step 428: train/loss = 0.7165173888206482, train/raw-loss = 0.7163438200950623, train/logprobs = tensor([[-0.7990, -0.7140],
        [-0.8052, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017352391732856631
Epoch 0, Step 429: train/loss = 0.6931151747703552, train/raw-loss = 0.6929711103439331, train/logprobs = tensor([[-0.7666, -0.8339],
        [-1.0110, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001441572094336152
Epoch 0, Step 430: train/loss = 0.7682362794876099, train/raw-loss = 0.7681161761283875, train/logprobs = tensor([[-1.3173, -0.8389],
        [-1.4489, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012011246290057898
Epoch 0, Step 431: train/loss = 0.6974210739135742, train/raw-loss = 0.6973536610603333, train/logprobs = tensor([[-0.8090, -0.7337],
        [-1.1858, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006740920944139361
Epoch 0, Step 432: train/loss = 0.7249691486358643, train/raw-loss = 0.7244032621383667, train/logprobs = tensor([[-1.3540, -1.0393],
        [-1.8728, -1.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005659132730215788
Epoch 0, Step 433: train/loss = 0.7223893404006958, train/raw-loss = 0.7222387790679932, train/logprobs = tensor([[-1.2190, -0.9186],
        [-1.4360, -0.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001505242777056992
Epoch 0, Step 434: train/loss = 0.7092967629432678, train/raw-loss = 0.7092008590698242, train/logprobs = tensor([[-0.8972, -0.9317],
        [-1.1001, -1.0448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000958611723035574
Epoch 0, Step 435: train/loss = 0.7139635682106018, train/raw-loss = 0.7137489318847656, train/logprobs = tensor([[-0.8106, -0.9805],
        [-0.9887, -1.1158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021463704761117697
Epoch 0, Step 436: train/loss = 0.7017845511436462, train/raw-loss = 0.7017248868942261, train/logprobs = tensor([[-1.1582, -1.1024],
        [-1.3077, -1.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005960993585176766
Epoch 0, Step 437: train/loss = 0.7045798301696777, train/raw-loss = 0.704430341720581, train/logprobs = tensor([[-0.7702, -0.6619],
        [-0.8403, -0.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014951832126826048
Epoch 0, Step 438: train/loss = 0.7173313498497009, train/raw-loss = 0.717227578163147, train/logprobs = tensor([[-0.8677, -1.0188],
        [-0.9342, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010376002173870802
Epoch 0, Step 439: train/loss = 0.708137035369873, train/raw-loss = 0.7079052925109863, train/logprobs = tensor([[-1.1598, -0.9898],
        [-1.3630, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00231820996850729
Epoch 0, Step 440: train/loss = 0.7057249546051025, train/raw-loss = 0.705559253692627, train/logprobs = tensor([[-0.7756, -0.9976],
        [-0.9956, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016578345093876123
Epoch 0, Step 441: train/loss = 0.7721503376960754, train/raw-loss = 0.7721267938613892, train/logprobs = tensor([[-1.1890, -0.6788],
        [-1.4339, -0.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023545324802398682
Epoch 0, Step 442: train/loss = 0.7083374261856079, train/raw-loss = 0.7079516649246216, train/logprobs = tensor([[-1.0997, -1.3647],
        [-1.2291, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003858014475554228
Epoch 0, Step 443: train/loss = 0.7015603184700012, train/raw-loss = 0.7014147043228149, train/logprobs = tensor([[-1.0310, -1.0524],
        [-1.1783, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014565102756023407
Epoch 0, Step 444: train/loss = 0.7113555669784546, train/raw-loss = 0.7113222479820251, train/logprobs = tensor([[-1.0599, -0.8984],
        [-1.2540, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003329073078930378
Epoch 0, Step 445: train/loss = 0.7369158267974854, train/raw-loss = 0.7368326187133789, train/logprobs = tensor([[-0.8286, -0.6541],
        [-0.8924, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008326946990564466
Epoch 0, Step 446: train/loss = 0.7219147682189941, train/raw-loss = 0.7218880653381348, train/logprobs = tensor([[-1.0370, -0.7759],
        [-1.1582, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002668905071914196
Epoch 0, Step 447: train/loss = 0.7201777696609497, train/raw-loss = 0.7201430201530457, train/logprobs = tensor([[-1.0907, -1.1355],
        [-1.5816, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003480138548184186
Epoch 0, Step 448: train/loss = 0.7041134238243103, train/raw-loss = 0.7037937641143799, train/logprobs = tensor([[-1.1853, -0.9298],
        [-1.2119, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003196339588612318
Epoch 0, Step 449: train/loss = 0.6944469809532166, train/raw-loss = 0.6944258809089661, train/logprobs = tensor([[-1.0700, -1.1974],
        [-1.1776, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021083594765514135
Epoch 0, Step 450: train/loss = 0.734634280204773, train/raw-loss = 0.7345305681228638, train/logprobs = tensor([[-1.2538, -1.1205],
        [-1.5535, -1.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010371485259383917
Epoch 0, Step 451: train/loss = 0.7577459216117859, train/raw-loss = 0.7575457096099854, train/logprobs = tensor([[-1.1907, -0.7850],
        [-1.3769, -0.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020028874278068542
Epoch 0, Step 452: train/loss = 0.7095694541931152, train/raw-loss = 0.7095355987548828, train/logprobs = tensor([[-0.9685, -0.8767],
        [-1.1846, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033763889223337173
Epoch 0, Step 453: train/loss = 0.714909017086029, train/raw-loss = 0.7148884534835815, train/logprobs = tensor([[-0.8895, -0.7300],
        [-1.0347, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020496302749961615
Epoch 0, Step 454: train/loss = 0.716851532459259, train/raw-loss = 0.7167465686798096, train/logprobs = tensor([[-1.2199, -0.9257],
        [-1.3485, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010492908768355846
Epoch 0, Step 455: train/loss = 0.7002665996551514, train/raw-loss = 0.7001590728759766, train/logprobs = tensor([[-0.8585, -0.9353],
        [-0.9228, -0.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001075446023605764
Epoch 0, Step 456: train/loss = 0.703282356262207, train/raw-loss = 0.703273355960846, train/logprobs = tensor([[-1.0849, -0.8879],
        [-1.2394, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.966971654444933e-05
Epoch 0, Step 457: train/loss = 0.6941020488739014, train/raw-loss = 0.693933367729187, train/logprobs = tensor([[-0.8248, -0.8530],
        [-1.0279, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016872722189873457
Epoch 0, Step 458: train/loss = 0.6934650540351868, train/raw-loss = 0.69344162940979, train/logprobs = tensor([[-0.7509, -0.7645],
        [-0.8499, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000234354316489771
Epoch 0, Step 459: train/loss = 0.7213404774665833, train/raw-loss = 0.7211017608642578, train/logprobs = tensor([[-1.1040, -0.8214],
        [-1.2400, -1.0038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023872072342783213
Epoch 0, Step 460: train/loss = 0.7038329839706421, train/raw-loss = 0.7037031650543213, train/logprobs = tensor([[-0.8933, -0.8531],
        [-0.9707, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001298390096053481
Epoch 0, Step 461: train/loss = 0.7339856624603271, train/raw-loss = 0.733972430229187, train/logprobs = tensor([[-1.1057, -0.8146],
        [-1.2881, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001320150913670659
Epoch 0, Step 462: train/loss = 0.7048905491828918, train/raw-loss = 0.7048138976097107, train/logprobs = tensor([[-0.8883, -0.7150],
        [-1.2664, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007669753977097571
Epoch 0, Step 463: train/loss = 0.7060344815254211, train/raw-loss = 0.7059042453765869, train/logprobs = tensor([[-0.8161, -0.8121],
        [-0.9571, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013018633471801877
Epoch 0, Step 464: train/loss = 0.7139461040496826, train/raw-loss = 0.7139060497283936, train/logprobs = tensor([[-1.0254, -0.8253],
        [-1.1354, -0.8161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004007513343822211
Epoch 0, Step 465: train/loss = 0.7052872180938721, train/raw-loss = 0.7051224112510681, train/logprobs = tensor([[-1.1048, -0.9331],
        [-1.4436, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016477785538882017
Epoch 0, Step 466: train/loss = 0.7247942686080933, train/raw-loss = 0.7247905731201172, train/logprobs = tensor([[-1.1391, -0.8692],
        [-1.3235, -0.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.763585118576884e-05
Epoch 0, Step 467: train/loss = 0.7199544310569763, train/raw-loss = 0.7196901440620422, train/logprobs = tensor([[-1.0032, -0.9128],
        [-1.1715, -0.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026423803064972162
Epoch 0, Step 468: train/loss = 0.7263960838317871, train/raw-loss = 0.7263838648796082, train/logprobs = tensor([[-1.1441, -0.8570],
        [-1.5859, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001222906867042184
Epoch 0, Step 469: train/loss = 0.7184526920318604, train/raw-loss = 0.718394935131073, train/logprobs = tensor([[-0.9383, -0.7888],
        [-1.0852, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005775662139058113
Epoch 0, Step 470: train/loss = 0.7116500735282898, train/raw-loss = 0.7115995287895203, train/logprobs = tensor([[-1.0936, -0.8468],
        [-1.2379, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005054725334048271
Epoch 0, Step 471: train/loss = 0.7200783491134644, train/raw-loss = 0.7198764681816101, train/logprobs = tensor([[-0.8616, -0.6823],
        [-1.1134, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002019513864070177
Epoch 0, Step 472: train/loss = 0.7109454870223999, train/raw-loss = 0.7109344601631165, train/logprobs = tensor([[-0.9808, -0.8630],
        [-1.1824, -0.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001103128888644278
Epoch 0, Step 473: train/loss = 0.7198802828788757, train/raw-loss = 0.7198236584663391, train/logprobs = tensor([[-0.9876, -1.1607],
        [-1.1522, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005661891773343086
Epoch 0, Step 474: train/loss = 0.7416942119598389, train/raw-loss = 0.7415598630905151, train/logprobs = tensor([[-0.8932, -0.6455],
        [-0.9337, -0.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013431337429210544
Epoch 0, Step 475: train/loss = 0.7260787487030029, train/raw-loss = 0.7260635495185852, train/logprobs = tensor([[-1.1512, -0.8008],
        [-1.3350, -0.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015192135469987988
Epoch 0, Step 476: train/loss = 0.7135275602340698, train/raw-loss = 0.713100254535675, train/logprobs = tensor([[-0.9506, -0.7256],
        [-1.0564, -0.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004272893071174622
Epoch 0, Step 477: train/loss = 0.7037131786346436, train/raw-loss = 0.7032166719436646, train/logprobs = tensor([[-0.6356, -0.8193],
        [-0.7747, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004964923020452261
Epoch 0, Step 478: train/loss = 0.7122418880462646, train/raw-loss = 0.71216881275177, train/logprobs = tensor([[-0.9844, -0.8416],
        [-1.1382, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007310508517548442
Epoch 0, Step 479: train/loss = 0.7656345367431641, train/raw-loss = 0.7655187845230103, train/logprobs = tensor([[-1.2896, -0.6946],
        [-1.4013, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011581126600503922
Epoch 0, Step 480: train/loss = 0.7132894992828369, train/raw-loss = 0.7132856249809265, train/logprobs = tensor([[-1.0225, -0.7445],
        [-1.2404, -0.8133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.896743874065578e-05
Epoch 0, Step 481: train/loss = 0.7054300308227539, train/raw-loss = 0.7053582072257996, train/logprobs = tensor([[-0.9273, -1.3000],
        [-1.1194, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007185967406257987
Epoch 0, Step 482: train/loss = 0.7008676528930664, train/raw-loss = 0.7008033990859985, train/logprobs = tensor([[-1.0917, -1.1020],
        [-1.2750, -1.2284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006418905104510486
Epoch 0, Step 483: train/loss = 0.7149129509925842, train/raw-loss = 0.714771032333374, train/logprobs = tensor([[-1.0112, -0.6799],
        [-1.2302, -0.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014195408439263701
Epoch 0, Step 484: train/loss = 0.716702401638031, train/raw-loss = 0.7166756987571716, train/logprobs = tensor([[-1.1974, -1.1294],
        [-1.3509, -1.1892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002668921370059252
Epoch 0, Step 485: train/loss = 0.7114006280899048, train/raw-loss = 0.7113407254219055, train/logprobs = tensor([[-0.9608, -0.8721],
        [-1.0187, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005990258068777621
Epoch 0, Step 486: train/loss = 0.7150373458862305, train/raw-loss = 0.7150051593780518, train/logprobs = tensor([[-0.9927, -0.7155],
        [-1.1528, -0.7042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032290536910295486
Epoch 0, Step 487: train/loss = 0.7159081697463989, train/raw-loss = 0.715743899345398, train/logprobs = tensor([[-0.9089, -0.8286],
        [-1.0230, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016419326420873404
Epoch 0, Step 488: train/loss = 0.715508222579956, train/raw-loss = 0.7154964208602905, train/logprobs = tensor([[-1.1442, -1.0972],
        [-1.2681, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011747254757210612
Epoch 0, Step 489: train/loss = 0.7371696829795837, train/raw-loss = 0.737118124961853, train/logprobs = tensor([[-1.2613, -1.0473],
        [-1.4855, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005159528227522969
Epoch 0, Step 490: train/loss = 0.694225013256073, train/raw-loss = 0.6941591501235962, train/logprobs = tensor([[-0.6839, -0.6811],
        [-0.7836, -0.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000658669916447252
Epoch 0, Step 491: train/loss = 0.7174265384674072, train/raw-loss = 0.7173547744750977, train/logprobs = tensor([[-0.8023, -0.8316],
        [-0.9707, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007172452751547098
Epoch 0, Step 492: train/loss = 0.704963207244873, train/raw-loss = 0.7049130201339722, train/logprobs = tensor([[-0.7245, -0.6353],
        [-0.7764, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005016071954742074
Epoch 0, Step 493: train/loss = 0.7027134299278259, train/raw-loss = 0.7020307779312134, train/logprobs = tensor([[-0.9747, -1.0553],
        [-1.0985, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0068266200833022594
Epoch 0, Step 494: train/loss = 0.7083131074905396, train/raw-loss = 0.7079973220825195, train/logprobs = tensor([[-1.0283, -0.9345],
        [-1.1562, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003158513456583023
Epoch 0, Step 495: train/loss = 0.7490099668502808, train/raw-loss = 0.748942494392395, train/logprobs = tensor([[-1.1039, -0.6590],
        [-1.2404, -0.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000674410373903811
Epoch 0, Step 496: train/loss = 0.704226016998291, train/raw-loss = 0.7040896415710449, train/logprobs = tensor([[-0.8531, -0.8045],
        [-1.0101, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013647235464304686
Epoch 0, Step 497: train/loss = 0.6941527128219604, train/raw-loss = 0.693824052810669, train/logprobs = tensor([[-0.8417, -0.8701],
        [-0.9384, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003285970538854599
Epoch 0, Step 498: train/loss = 0.6991877555847168, train/raw-loss = 0.6990790367126465, train/logprobs = tensor([[-1.1444, -1.0790],
        [-1.4349, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001087210956029594
Epoch 0, Step 499: train/loss = 0.7272536754608154, train/raw-loss = 0.7271429300308228, train/logprobs = tensor([[-0.7989, -1.0040],
        [-0.8616, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011074510402977467
eval/loss: 0.7078372240066528
Epoch 0, Step 500: train/loss = 0.7261133790016174, train/raw-loss = 0.7260351777076721, train/logprobs = tensor([[-1.1066, -0.9414],
        [-1.2873, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007823365740478039
Epoch 0, Step 501: train/loss = 0.706028163433075, train/raw-loss = 0.7057331800460815, train/logprobs = tensor([[-0.9487, -0.8977],
        [-1.1444, -1.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002949970308691263
Epoch 0, Step 502: train/loss = 0.7084288597106934, train/raw-loss = 0.7082630395889282, train/logprobs = tensor([[-0.8442, -0.7942],
        [-0.9901, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001658752327784896
Epoch 0, Step 503: train/loss = 0.7218108773231506, train/raw-loss = 0.7217086553573608, train/logprobs = tensor([[-0.9579, -1.0330],
        [-1.0549, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001022118260152638
Epoch 0, Step 504: train/loss = 0.714603841304779, train/raw-loss = 0.7144982814788818, train/logprobs = tensor([[-0.9046, -0.8113],
        [-1.0516, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010558257345110178
Epoch 0, Step 505: train/loss = 0.6942028403282166, train/raw-loss = 0.6940969228744507, train/logprobs = tensor([[-1.0516, -1.1685],
        [-1.2726, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00105879339389503
Epoch 0, Step 506: train/loss = 0.7145905494689941, train/raw-loss = 0.7141886353492737, train/logprobs = tensor([[-1.1692, -1.0108],
        [-1.4164, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004019121639430523
Epoch 0, Step 507: train/loss = 0.6977538466453552, train/raw-loss = 0.6977484226226807, train/logprobs = tensor([[-1.0907, -1.0077],
        [-1.1402, -1.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4612173698842525e-05
Epoch 0, Step 508: train/loss = 0.7056645750999451, train/raw-loss = 0.7056192755699158, train/logprobs = tensor([[-1.2618, -1.0650],
        [-1.5134, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045277050230652094
Epoch 0, Step 509: train/loss = 0.6978302001953125, train/raw-loss = 0.6975771188735962, train/logprobs = tensor([[-0.8813, -0.9027],
        [-1.0700, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002530711004510522
Epoch 0, Step 510: train/loss = 0.7046583294868469, train/raw-loss = 0.7046478390693665, train/logprobs = tensor([[-0.8072, -0.7700],
        [-0.8854, -0.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001047347323037684
Epoch 0, Step 511: train/loss = 0.710950493812561, train/raw-loss = 0.7109353542327881, train/logprobs = tensor([[-0.5597, -0.8979],
        [-0.6303, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001518160424893722
Epoch 0, Step 512: train/loss = 0.6965702176094055, train/raw-loss = 0.6963678598403931, train/logprobs = tensor([[-1.0311, -1.0894],
        [-1.1564, -1.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020234936382621527
Epoch 0, Step 513: train/loss = 0.7104384899139404, train/raw-loss = 0.7103152275085449, train/logprobs = tensor([[-0.9463, -0.7009],
        [-1.0886, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012328862212598324
Epoch 0, Step 514: train/loss = 0.7095249891281128, train/raw-loss = 0.709477424621582, train/logprobs = tensor([[-0.9695, -1.0162],
        [-1.0948, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004754679976031184
Epoch 0, Step 515: train/loss = 0.6957694292068481, train/raw-loss = 0.6954653859138489, train/logprobs = tensor([[-0.7303, -0.7412],
        [-0.8270, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003040848532691598
Epoch 0, Step 516: train/loss = 0.7061807513237, train/raw-loss = 0.7061745524406433, train/logprobs = tensor([[-1.0187, -0.8105],
        [-1.1707, -0.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.258251960389316e-05
Epoch 0, Step 517: train/loss = 0.6996386051177979, train/raw-loss = 0.6995413303375244, train/logprobs = tensor([[-0.8989, -1.0683],
        [-1.0453, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009731707978062332
Epoch 0, Step 518: train/loss = 0.6969146132469177, train/raw-loss = 0.6967837810516357, train/logprobs = tensor([[-1.0110, -0.9477],
        [-1.2724, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013080777134746313
Epoch 0, Step 519: train/loss = 0.7009661793708801, train/raw-loss = 0.7009116411209106, train/logprobs = tensor([[-0.8015, -0.8961],
        [-0.8792, -0.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005455358186736703
Epoch 0, Step 520: train/loss = 0.6948980093002319, train/raw-loss = 0.6947697997093201, train/logprobs = tensor([[-0.8800, -1.0426],
        [-1.0841, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012824778677895665
Epoch 0, Step 521: train/loss = 0.6820123195648193, train/raw-loss = 0.681674063205719, train/logprobs = tensor([[-0.7626, -1.0282],
        [-0.9952, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003382461378350854
Epoch 0, Step 522: train/loss = 0.6997273564338684, train/raw-loss = 0.699635922908783, train/logprobs = tensor([[-1.0840, -1.1647],
        [-1.2649, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009148357203230262
Epoch 0, Step 523: train/loss = 0.7009626030921936, train/raw-loss = 0.7009372711181641, train/logprobs = tensor([[-0.7211, -0.7722],
        [-0.8010, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002534267259761691
Epoch 0, Step 524: train/loss = 0.7709881067276001, train/raw-loss = 0.7705441117286682, train/logprobs = tensor([[-1.4130, -0.7445],
        [-1.5773, -0.8680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044403644278645515
Epoch 0, Step 525: train/loss = 0.6939153671264648, train/raw-loss = 0.6938614249229431, train/logprobs = tensor([[-0.8076, -0.7855],
        [-1.0011, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005397393833845854
Epoch 0, Step 526: train/loss = 0.7040459513664246, train/raw-loss = 0.7040389180183411, train/logprobs = tensor([[-0.9441, -0.8065],
        [-1.0801, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.990702240727842e-05
Epoch 0, Step 527: train/loss = 0.7165718078613281, train/raw-loss = 0.7165610790252686, train/logprobs = tensor([[-1.1531, -0.8827],
        [-1.2174, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010765157639980316
Epoch 0, Step 528: train/loss = 0.7046188116073608, train/raw-loss = 0.7028936147689819, train/logprobs = tensor([[-1.0644, -1.0632],
        [-1.2640, -1.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017252033576369286
Epoch 0, Step 529: train/loss = 0.706660270690918, train/raw-loss = 0.706545352935791, train/logprobs = tensor([[-0.8358, -0.8808],
        [-1.0073, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011492051417008042
Epoch 0, Step 530: train/loss = 0.7020313739776611, train/raw-loss = 0.7019879221916199, train/logprobs = tensor([[-0.9099, -1.1570],
        [-0.9959, -1.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043406864278949797
Epoch 0, Step 531: train/loss = 0.6962423920631409, train/raw-loss = 0.6962291598320007, train/logprobs = tensor([[-0.5955, -0.6997],
        [-0.6639, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013216020306572318
Epoch 0, Step 532: train/loss = 0.7043743133544922, train/raw-loss = 0.7041915655136108, train/logprobs = tensor([[-1.0435, -0.8701],
        [-1.5566, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001827119616791606
Epoch 0, Step 533: train/loss = 0.7154356837272644, train/raw-loss = 0.7153533101081848, train/logprobs = tensor([[-1.1105, -0.8352],
        [-1.2858, -0.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008233601693063974
Epoch 0, Step 534: train/loss = 0.7067322134971619, train/raw-loss = 0.7063475251197815, train/logprobs = tensor([[-0.8854, -1.1133],
        [-1.0075, -1.1579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003846832551062107
Epoch 0, Step 535: train/loss = 0.695610523223877, train/raw-loss = 0.6954435110092163, train/logprobs = tensor([[-0.8079, -0.8600],
        [-0.9217, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016707525355741382
Epoch 0, Step 536: train/loss = 0.7202597856521606, train/raw-loss = 0.7201457023620605, train/logprobs = tensor([[-1.1323, -0.7794],
        [-1.3469, -0.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011412713211029768
Epoch 0, Step 537: train/loss = 0.7105215191841125, train/raw-loss = 0.7104495167732239, train/logprobs = tensor([[-0.8751, -0.9166],
        [-0.9938, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007197190425358713
Epoch 0, Step 538: train/loss = 0.7153269052505493, train/raw-loss = 0.7152791023254395, train/logprobs = tensor([[-0.9288, -0.8900],
        [-1.1275, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047759583685547113
Epoch 0, Step 539: train/loss = 0.6986827850341797, train/raw-loss = 0.6983157992362976, train/logprobs = tensor([[-0.9408, -0.9743],
        [-1.0540, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036704193335026503
Epoch 0, Step 540: train/loss = 0.7151128053665161, train/raw-loss = 0.7150737047195435, train/logprobs = tensor([[-0.9561, -0.8712],
        [-1.1071, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003907534119207412
Epoch 0, Step 541: train/loss = 0.7336591482162476, train/raw-loss = 0.7332042455673218, train/logprobs = tensor([[-0.7579, -1.0166],
        [-0.9060, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004548276774585247
Epoch 0, Step 542: train/loss = 0.7136710286140442, train/raw-loss = 0.7136504650115967, train/logprobs = tensor([[-0.9073, -0.6498],
        [-1.0357, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002058344252873212
Epoch 0, Step 543: train/loss = 0.7037073373794556, train/raw-loss = 0.7036384344100952, train/logprobs = tensor([[-1.1406, -0.8893],
        [-1.2999, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000689250766299665
Epoch 0, Step 544: train/loss = 0.6937665343284607, train/raw-loss = 0.693639874458313, train/logprobs = tensor([[-0.9493, -1.0115],
        [-1.0115, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012661527143791318
Epoch 0, Step 545: train/loss = 0.6941057443618774, train/raw-loss = 0.694037914276123, train/logprobs = tensor([[-0.9155, -1.0215],
        [-1.0859, -1.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006775468355044723
Epoch 0, Step 546: train/loss = 0.7219544649124146, train/raw-loss = 0.7217578291893005, train/logprobs = tensor([[-0.7687, -1.1531],
        [-0.8658, -1.0369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019662382546812296
Epoch 0, Step 547: train/loss = 0.7096877694129944, train/raw-loss = 0.7096638083457947, train/logprobs = tensor([[-1.0377, -1.0950],
        [-1.3112, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023958412930369377
Epoch 0, Step 548: train/loss = 0.6961826086044312, train/raw-loss = 0.6956457495689392, train/logprobs = tensor([[-0.9509, -0.8994],
        [-1.1475, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005368728190660477
Epoch 0, Step 549: train/loss = 0.6952483057975769, train/raw-loss = 0.6951280236244202, train/logprobs = tensor([[-0.8758, -0.8598],
        [-0.9551, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012026927433907986
Epoch 0, Step 550: train/loss = 0.6850267648696899, train/raw-loss = 0.6847128868103027, train/logprobs = tensor([[-0.8220, -1.0785],
        [-1.4093, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031389938667416573
Epoch 0, Step 551: train/loss = 0.7850732803344727, train/raw-loss = 0.7848693132400513, train/logprobs = tensor([[-0.9662, -1.6418],
        [-1.0576, -1.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002038923790678382
Epoch 0, Step 552: train/loss = 0.7045094966888428, train/raw-loss = 0.704240620136261, train/logprobs = tensor([[-0.7972, -0.9888],
        [-0.9712, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002689099172130227
Epoch 0, Step 553: train/loss = 0.6966420412063599, train/raw-loss = 0.696615993976593, train/logprobs = tensor([[-0.9308, -0.8944],
        [-1.0623, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002604039036668837
Epoch 0, Step 554: train/loss = 0.6976845264434814, train/raw-loss = 0.6972783803939819, train/logprobs = tensor([[-0.9819, -0.9895],
        [-1.2667, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004062493331730366
Epoch 0, Step 555: train/loss = 0.7252340316772461, train/raw-loss = 0.7252095937728882, train/logprobs = tensor([[-0.8400, -1.4467],
        [-0.9386, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002444934216327965
Epoch 0, Step 556: train/loss = 0.7000811100006104, train/raw-loss = 0.6999702453613281, train/logprobs = tensor([[-0.8029, -0.8710],
        [-0.9499, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011079837568104267
Epoch 0, Step 557: train/loss = 0.7020910978317261, train/raw-loss = 0.7011057734489441, train/logprobs = tensor([[-0.8794, -0.8532],
        [-0.9817, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00985336396843195
Epoch 0, Step 558: train/loss = 0.6960727572441101, train/raw-loss = 0.695782482624054, train/logprobs = tensor([[-1.1192, -1.1593],
        [-1.3350, -1.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029030314180999994
Epoch 0, Step 559: train/loss = 0.7118942737579346, train/raw-loss = 0.711708664894104, train/logprobs = tensor([[-0.8186, -0.7601],
        [-1.0237, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018560582539066672
Epoch 0, Step 560: train/loss = 0.6942076086997986, train/raw-loss = 0.6941803693771362, train/logprobs = tensor([[-1.0799, -1.1032],
        [-1.2139, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027240943745709956
Epoch 0, Step 561: train/loss = 0.7058702707290649, train/raw-loss = 0.7056884765625, train/logprobs = tensor([[-1.0677, -0.8435],
        [-1.2358, -0.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018183893989771605
Epoch 0, Step 562: train/loss = 0.7112651467323303, train/raw-loss = 0.7112350463867188, train/logprobs = tensor([[-1.1335, -1.1029],
        [-1.2473, -1.0910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003021477023139596
Epoch 0, Step 563: train/loss = 0.6983332633972168, train/raw-loss = 0.6981378793716431, train/logprobs = tensor([[-0.9850, -0.9918],
        [-1.0917, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019540467765182257
Epoch 0, Step 564: train/loss = 0.6983221769332886, train/raw-loss = 0.6983059048652649, train/logprobs = tensor([[-1.0069, -0.9564],
        [-1.0683, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001619243121240288
Epoch 0, Step 565: train/loss = 0.6958127021789551, train/raw-loss = 0.6956409811973572, train/logprobs = tensor([[-0.7254, -0.6593],
        [-0.8187, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001716656144708395
Epoch 0, Step 566: train/loss = 0.6999590992927551, train/raw-loss = 0.6996302604675293, train/logprobs = tensor([[-0.8861, -0.9967],
        [-1.0755, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003288246924057603
Epoch 0, Step 567: train/loss = 0.707893967628479, train/raw-loss = 0.7076928019523621, train/logprobs = tensor([[-1.0867, -0.8477],
        [-1.2435, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002011519856750965
Epoch 0, Step 568: train/loss = 0.70420241355896, train/raw-loss = 0.7040096521377563, train/logprobs = tensor([[-1.1039, -0.9653],
        [-1.2397, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019272365607321262
Epoch 0, Step 569: train/loss = 0.699654757976532, train/raw-loss = 0.6995941996574402, train/logprobs = tensor([[-0.8387, -0.8321],
        [-0.9435, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006051057134754956
Epoch 0, Step 570: train/loss = 0.7028181552886963, train/raw-loss = 0.7027913928031921, train/logprobs = tensor([[-0.8907, -1.0069],
        [-0.9170, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026714266277849674
Epoch 0, Step 571: train/loss = 0.6947144865989685, train/raw-loss = 0.6946730613708496, train/logprobs = tensor([[-0.9302, -1.0186],
        [-0.9920, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004147364816162735
Epoch 0, Step 572: train/loss = 0.7806335091590881, train/raw-loss = 0.7805753350257874, train/logprobs = tensor([[-0.9554, -0.9414],
        [-1.0964, -0.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005814941832795739
Epoch 0, Step 573: train/loss = 0.708925187587738, train/raw-loss = 0.7089147567749023, train/logprobs = tensor([[-0.6801, -1.0090],
        [-0.7507, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010463215585332364
Epoch 0, Step 574: train/loss = 0.713228702545166, train/raw-loss = 0.713201642036438, train/logprobs = tensor([[-0.9814, -0.9823],
        [-1.1203, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027087738271802664
Epoch 0, Step 575: train/loss = 0.6974937915802002, train/raw-loss = 0.6973844766616821, train/logprobs = tensor([[-0.8338, -0.8801],
        [-0.8655, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010939931962639093
Epoch 0, Step 576: train/loss = 0.7106142640113831, train/raw-loss = 0.7103695869445801, train/logprobs = tensor([[-0.9524, -1.1294],
        [-1.0322, -1.3117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002447009552270174
Epoch 0, Step 577: train/loss = 0.7081185579299927, train/raw-loss = 0.7080209255218506, train/logprobs = tensor([[-0.9075, -0.7368],
        [-1.0813, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009764549322426319
Epoch 0, Step 578: train/loss = 0.7041592001914978, train/raw-loss = 0.7037256956100464, train/logprobs = tensor([[-0.7539, -0.9051],
        [-0.9760, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004335125908255577
Epoch 0, Step 579: train/loss = 0.6964983940124512, train/raw-loss = 0.6964595317840576, train/logprobs = tensor([[-0.7774, -0.7654],
        [-0.9107, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000388689455576241
Epoch 0, Step 580: train/loss = 0.697024941444397, train/raw-loss = 0.6969846487045288, train/logprobs = tensor([[-0.7002, -0.7936],
        [-0.8086, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040352653013542295
Epoch 0, Step 581: train/loss = 0.6981082558631897, train/raw-loss = 0.6978416442871094, train/logprobs = tensor([[-0.9205, -1.1080],
        [-1.1010, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026662524323910475
Epoch 0, Step 582: train/loss = 0.7432114481925964, train/raw-loss = 0.7431363463401794, train/logprobs = tensor([[-1.0471, -0.7406],
        [-1.1319, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007510374998673797
Epoch 0, Step 583: train/loss = 0.7051829695701599, train/raw-loss = 0.7051680088043213, train/logprobs = tensor([[-0.9547, -0.8100],
        [-1.1172, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014936299703549594
Epoch 0, Step 584: train/loss = 0.7011838555335999, train/raw-loss = 0.7009543776512146, train/logprobs = tensor([[-0.8523, -0.9123],
        [-0.9885, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022952528670430183
Epoch 0, Step 585: train/loss = 0.7051100730895996, train/raw-loss = 0.7050700187683105, train/logprobs = tensor([[-0.8539, -0.6918],
        [-0.9089, -0.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003998577012680471
Epoch 0, Step 586: train/loss = 0.7029196619987488, train/raw-loss = 0.7024236917495728, train/logprobs = tensor([[-0.8865, -1.2302],
        [-1.0997, -1.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004959053359925747
Epoch 0, Step 587: train/loss = 0.7079392075538635, train/raw-loss = 0.707801342010498, train/logprobs = tensor([[-0.8337, -0.5861],
        [-1.0047, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013782861642539501
Epoch 0, Step 588: train/loss = 0.6959683299064636, train/raw-loss = 0.6958271265029907, train/logprobs = tensor([[-0.7998, -0.9455],
        [-0.9281, -1.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00141240400262177
Epoch 0, Step 589: train/loss = 0.6962618827819824, train/raw-loss = 0.6962027549743652, train/logprobs = tensor([[-0.8547, -0.9077],
        [-0.9498, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005911573534831405
Epoch 0, Step 590: train/loss = 0.6935957074165344, train/raw-loss = 0.6926450729370117, train/logprobs = tensor([[-0.8662, -0.9382],
        [-0.9857, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009507091715931892
Epoch 0, Step 591: train/loss = 0.7031881213188171, train/raw-loss = 0.7031456232070923, train/logprobs = tensor([[-0.9168, -1.0070],
        [-1.1032, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042566569754853845
Epoch 0, Step 592: train/loss = 0.6974763870239258, train/raw-loss = 0.6973980665206909, train/logprobs = tensor([[-0.9121, -0.7960],
        [-0.9673, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007828059606254101
Epoch 0, Step 593: train/loss = 0.6989291310310364, train/raw-loss = 0.6988688707351685, train/logprobs = tensor([[-0.9484, -1.0081],
        [-1.1192, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006028523785062134
Epoch 0, Step 594: train/loss = 0.6877883076667786, train/raw-loss = 0.6877790093421936, train/logprobs = tensor([[-0.8385, -1.1436],
        [-0.8939, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.271362068830058e-05
Epoch 0, Step 595: train/loss = 0.7052240967750549, train/raw-loss = 0.7050581574440002, train/logprobs = tensor([[-0.9779, -1.0343],
        [-1.1051, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001659829868003726
Epoch 0, Step 596: train/loss = 0.6874806880950928, train/raw-loss = 0.6867735385894775, train/logprobs = tensor([[-1.0543, -1.2094],
        [-1.3057, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007071288302540779
Epoch 0, Step 597: train/loss = 0.7031700015068054, train/raw-loss = 0.703150749206543, train/logprobs = tensor([[-1.2270, -1.2212],
        [-1.4152, -1.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019337903358973563
Epoch 0, Step 598: train/loss = 0.6961362361907959, train/raw-loss = 0.696076512336731, train/logprobs = tensor([[-0.9517, -1.0224],
        [-1.0518, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005979759152978659
Epoch 0, Step 599: train/loss = 0.6984268426895142, train/raw-loss = 0.6978587508201599, train/logprobs = tensor([[-0.8159, -1.1028],
        [-0.9445, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005680708680301905
Epoch 0, Step 600: train/loss = 0.7589883804321289, train/raw-loss = 0.7589712738990784, train/logprobs = tensor([[-1.0126, -0.9208],
        [-1.1296, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017096445662900805
Epoch 0, Step 601: train/loss = 0.7100969552993774, train/raw-loss = 0.7100561261177063, train/logprobs = tensor([[-1.0174, -0.8123],
        [-1.3068, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040845241164788604
Epoch 0, Step 602: train/loss = 0.6984251737594604, train/raw-loss = 0.6983835101127625, train/logprobs = tensor([[-0.6799, -0.5297],
        [-0.7944, -0.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004166884464211762
Epoch 0, Step 603: train/loss = 0.6970198154449463, train/raw-loss = 0.6969422698020935, train/logprobs = tensor([[-0.9160, -1.1793],
        [-1.0952, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007755518890917301
Epoch 0, Step 604: train/loss = 0.7444702386856079, train/raw-loss = 0.7444255352020264, train/logprobs = tensor([[-1.4875, -1.4549],
        [-1.7569, -1.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000447025871835649
Epoch 0, Step 605: train/loss = 0.6962989568710327, train/raw-loss = 0.6962951421737671, train/logprobs = tensor([[-0.8825, -0.8693],
        [-0.9212, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.837112308247015e-05
Epoch 0, Step 606: train/loss = 0.7376410961151123, train/raw-loss = 0.7376054525375366, train/logprobs = tensor([[-0.7432, -1.0299],
        [-0.8212, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003562492784112692
Epoch 0, Step 607: train/loss = 0.6961888074874878, train/raw-loss = 0.6961755752563477, train/logprobs = tensor([[-0.9101, -0.8581],
        [-0.9781, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013210310135036707
Epoch 0, Step 608: train/loss = 0.7015900611877441, train/raw-loss = 0.7014990448951721, train/logprobs = tensor([[-1.1044, -1.0830],
        [-1.1835, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009102278272621334
Epoch 0, Step 609: train/loss = 0.7844651937484741, train/raw-loss = 0.7842611074447632, train/logprobs = tensor([[-1.0546, -1.6004],
        [-1.2945, -1.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020416928455233574
Epoch 0, Step 610: train/loss = 0.7040711641311646, train/raw-loss = 0.7040189504623413, train/logprobs = tensor([[-1.0162, -0.9509],
        [-1.0893, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005229386733844876
Epoch 0, Step 611: train/loss = 0.7146634459495544, train/raw-loss = 0.714314341545105, train/logprobs = tensor([[-1.0994, -0.9936],
        [-1.2694, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003490715753287077
Epoch 0, Step 612: train/loss = 0.6933794021606445, train/raw-loss = 0.6933280825614929, train/logprobs = tensor([[-0.8694, -0.8203],
        [-0.9071, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005129572236910462
Epoch 0, Step 613: train/loss = 0.804526686668396, train/raw-loss = 0.8044703006744385, train/logprobs = tensor([[-0.8650, -1.2912],
        [-0.9214, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000563700741622597
Epoch 0, Step 614: train/loss = 0.6944029331207275, train/raw-loss = 0.694375216960907, train/logprobs = tensor([[-0.8439, -0.9586],
        [-0.9056, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002774430613499135
Epoch 0, Step 615: train/loss = 0.7358154058456421, train/raw-loss = 0.7357810735702515, train/logprobs = tensor([[-0.7545, -1.1019],
        [-0.9486, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003420582215767354
Epoch 0, Step 616: train/loss = 0.7150250673294067, train/raw-loss = 0.7149196863174438, train/logprobs = tensor([[-1.0891, -1.0141],
        [-1.2398, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001054437831044197
Epoch 0, Step 617: train/loss = 0.70346999168396, train/raw-loss = 0.7033935785293579, train/logprobs = tensor([[-1.1417, -1.0103],
        [-1.2398, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007640755502507091
Epoch 0, Step 618: train/loss = 0.7055703401565552, train/raw-loss = 0.7055148482322693, train/logprobs = tensor([[-0.8588, -0.6562],
        [-0.9463, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005550178466364741
Epoch 0, Step 619: train/loss = 0.7021322846412659, train/raw-loss = 0.7021111845970154, train/logprobs = tensor([[-0.8989, -0.7645],
        [-0.9373, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021155388094484806
Epoch 0, Step 620: train/loss = 0.7716585397720337, train/raw-loss = 0.7715285420417786, train/logprobs = tensor([[-0.9796, -1.4476],
        [-1.0365, -1.3184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013000626349821687
Epoch 0, Step 621: train/loss = 0.7190791964530945, train/raw-loss = 0.7189823389053345, train/logprobs = tensor([[-1.1857, -0.9394],
        [-1.3099, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009681731462478638
Epoch 0, Step 622: train/loss = 0.7150344848632812, train/raw-loss = 0.714828610420227, train/logprobs = tensor([[-0.9778, -0.9300],
        [-1.0320, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00205864105373621
Epoch 0, Step 623: train/loss = 0.6923114061355591, train/raw-loss = 0.6922767162322998, train/logprobs = tensor([[-0.8832, -0.9040],
        [-1.0205, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034707633312791586
Epoch 0, Step 624: train/loss = 0.6999983787536621, train/raw-loss = 0.6998982429504395, train/logprobs = tensor([[-0.8957, -0.9762],
        [-0.9532, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010001246118918061
Epoch 0, Step 625: train/loss = 0.7214295864105225, train/raw-loss = 0.7212761640548706, train/logprobs = tensor([[-0.9063, -1.2734],
        [-0.9904, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015337478835135698
Epoch 0, Step 626: train/loss = 0.7059354186058044, train/raw-loss = 0.7055755257606506, train/logprobs = tensor([[-0.9812, -1.2013],
        [-1.1681, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00359864579513669
Epoch 0, Step 627: train/loss = 0.6934130787849426, train/raw-loss = 0.6934114694595337, train/logprobs = tensor([[-0.7577, -0.7813],
        [-0.8506, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5744473785161972e-05
Epoch 0, Step 628: train/loss = 0.7011778950691223, train/raw-loss = 0.7009350061416626, train/logprobs = tensor([[-0.9340, -1.0647],
        [-1.0942, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002429352141916752
Epoch 0, Step 629: train/loss = 0.7068201303482056, train/raw-loss = 0.7066941261291504, train/logprobs = tensor([[-0.6323, -0.8966],
        [-0.6880, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012599296169355512
Epoch 0, Step 630: train/loss = 0.7917717695236206, train/raw-loss = 0.7917608618736267, train/logprobs = tensor([[-0.7928, -1.2325],
        [-0.8787, -1.2040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010904890950769186
Epoch 0, Step 631: train/loss = 0.7271043062210083, train/raw-loss = 0.7270941734313965, train/logprobs = tensor([[-0.7135, -1.0699],
        [-0.7453, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010132580064237118
Epoch 0, Step 632: train/loss = 0.7152923345565796, train/raw-loss = 0.7152141332626343, train/logprobs = tensor([[-1.0397, -0.8136],
        [-1.1775, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007824740023352206
Epoch 0, Step 633: train/loss = 0.7059756517410278, train/raw-loss = 0.7059409022331238, train/logprobs = tensor([[-0.9224, -1.1882],
        [-0.9966, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034790526842698455
Epoch 0, Step 634: train/loss = 0.6949028968811035, train/raw-loss = 0.6948974132537842, train/logprobs = tensor([[-0.9051, -0.9994],
        [-0.9273, -1.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4878066293895245e-05
Epoch 0, Step 635: train/loss = 0.7390065789222717, train/raw-loss = 0.7389858961105347, train/logprobs = tensor([[-1.1215, -1.4327],
        [-1.1852, -1.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020640389993786812
Epoch 0, Step 636: train/loss = 0.715322732925415, train/raw-loss = 0.7152066230773926, train/logprobs = tensor([[-0.9248, -1.2453],
        [-0.9937, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011611743830144405
Epoch 0, Step 637: train/loss = 0.7041248679161072, train/raw-loss = 0.7040499448776245, train/logprobs = tensor([[-0.8726, -0.8450],
        [-0.9095, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007498196209780872
Epoch 0, Step 638: train/loss = 0.6991570591926575, train/raw-loss = 0.6991134881973267, train/logprobs = tensor([[-0.9031, -0.9272],
        [-1.0409, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004363630432635546
Epoch 0, Step 639: train/loss = 0.7179692983627319, train/raw-loss = 0.7179335355758667, train/logprobs = tensor([[-1.1364, -1.2328],
        [-1.3012, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003575389855541289
Epoch 0, Step 640: train/loss = 0.7055870890617371, train/raw-loss = 0.705511212348938, train/logprobs = tensor([[-0.9409, -1.0985],
        [-1.0934, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007593983318656683
Epoch 0, Step 641: train/loss = 0.7037472724914551, train/raw-loss = 0.7036030292510986, train/logprobs = tensor([[-0.8083, -0.7516],
        [-0.9492, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001442671287804842
Epoch 0, Step 642: train/loss = 0.6965447068214417, train/raw-loss = 0.696501612663269, train/logprobs = tensor([[-1.1078, -1.0220],
        [-1.1734, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004305866314098239
Epoch 0, Step 643: train/loss = 0.695725679397583, train/raw-loss = 0.6956011056900024, train/logprobs = tensor([[-0.7805, -0.9439],
        [-0.8790, -0.9170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012456164695322514
Epoch 0, Step 644: train/loss = 0.7423383593559265, train/raw-loss = 0.7422983050346375, train/logprobs = tensor([[-1.0326, -1.1156],
        [-1.0702, -0.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004005215014331043
Epoch 0, Step 645: train/loss = 0.6964802742004395, train/raw-loss = 0.69635409116745, train/logprobs = tensor([[-0.9102, -1.0287],
        [-1.0337, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012624997179955244
Epoch 0, Step 646: train/loss = 0.6993484497070312, train/raw-loss = 0.6992261409759521, train/logprobs = tensor([[-0.7403, -0.8906],
        [-0.9074, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012234289897605777
Epoch 0, Step 647: train/loss = 0.7179656028747559, train/raw-loss = 0.7179144024848938, train/logprobs = tensor([[-0.9566, -1.3396],
        [-1.2080, -1.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005119484849274158
Epoch 0, Step 648: train/loss = 0.6999048590660095, train/raw-loss = 0.6997858881950378, train/logprobs = tensor([[-1.0426, -1.1423],
        [-1.0630, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001190569018945098
Epoch 0, Step 649: train/loss = 0.6989656686782837, train/raw-loss = 0.6989161968231201, train/logprobs = tensor([[-0.7960, -0.9662],
        [-0.8529, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004941696533933282
Epoch 0, Step 650: train/loss = 0.6957148313522339, train/raw-loss = 0.695708155632019, train/logprobs = tensor([[-0.9634, -1.0862],
        [-1.1147, -1.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.640207720920444e-05
Epoch 0, Step 651: train/loss = 0.723513126373291, train/raw-loss = 0.7231862545013428, train/logprobs = tensor([[-1.0667, -1.2417],
        [-1.1965, -1.3476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032689073123037815
Epoch 0, Step 652: train/loss = 0.6992686986923218, train/raw-loss = 0.699215292930603, train/logprobs = tensor([[-0.8303, -0.9614],
        [-0.9468, -0.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005339574418030679
Epoch 0, Step 653: train/loss = 0.7008715867996216, train/raw-loss = 0.7007976770401001, train/logprobs = tensor([[-1.0062, -0.8327],
        [-1.0811, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007388966041617095
Epoch 0, Step 654: train/loss = 0.7025479674339294, train/raw-loss = 0.7024828195571899, train/logprobs = tensor([[-0.9457, -1.1341],
        [-1.1295, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006512035615742207
Epoch 0, Step 655: train/loss = 0.6944383382797241, train/raw-loss = 0.6944221258163452, train/logprobs = tensor([[-0.8249, -0.8484],
        [-0.8767, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016158013022504747
Epoch 0, Step 656: train/loss = 0.7010345458984375, train/raw-loss = 0.7009634971618652, train/logprobs = tensor([[-1.0624, -0.9094],
        [-1.1129, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007112938910722733
Epoch 0, Step 657: train/loss = 0.6954972743988037, train/raw-loss = 0.6954323649406433, train/logprobs = tensor([[-0.8329, -0.9448],
        [-0.9071, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006492405664175749
Epoch 0, Step 658: train/loss = 0.7012219429016113, train/raw-loss = 0.7010945081710815, train/logprobs = tensor([[-0.8563, -1.0227],
        [-1.0017, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001274534035474062
Epoch 0, Step 659: train/loss = 0.7466891407966614, train/raw-loss = 0.7466158866882324, train/logprobs = tensor([[-0.8411, -1.3906],
        [-1.0090, -1.4084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007320125587284565
Epoch 0, Step 660: train/loss = 0.7014681100845337, train/raw-loss = 0.7012173533439636, train/logprobs = tensor([[-0.9405, -0.9250],
        [-1.1598, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002507100347429514
Epoch 0, Step 661: train/loss = 0.6944150924682617, train/raw-loss = 0.694344699382782, train/logprobs = tensor([[-0.8758, -0.8888],
        [-1.0351, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000703817349858582
Epoch 0, Step 662: train/loss = 0.6958221793174744, train/raw-loss = 0.695798397064209, train/logprobs = tensor([[-1.0508, -1.0918],
        [-1.1177, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023781321942806244
Epoch 0, Step 663: train/loss = 0.6940027475357056, train/raw-loss = 0.6937010288238525, train/logprobs = tensor([[-0.8328, -0.9202],
        [-1.0683, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030167666263878345
Epoch 0, Step 664: train/loss = 0.7088149785995483, train/raw-loss = 0.7086814641952515, train/logprobs = tensor([[-0.9347, -1.0269],
        [-1.0413, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013347994536161423
Epoch 0, Step 665: train/loss = 0.6960358619689941, train/raw-loss = 0.6959143877029419, train/logprobs = tensor([[-0.9140, -0.9384],
        [-1.0337, -0.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012145016808062792
Epoch 0, Step 666: train/loss = 0.7015640735626221, train/raw-loss = 0.7015351057052612, train/logprobs = tensor([[-0.6757, -0.8830],
        [-0.7446, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002898414386436343
Epoch 0, Step 667: train/loss = 0.7134112119674683, train/raw-loss = 0.7132043838500977, train/logprobs = tensor([[-0.8383, -0.8409],
        [-0.8644, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020677410066127777
Epoch 0, Step 668: train/loss = 0.6953126788139343, train/raw-loss = 0.6952595114707947, train/logprobs = tensor([[-0.8485, -0.8974],
        [-0.9518, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005309029365889728
Epoch 0, Step 669: train/loss = 0.70301753282547, train/raw-loss = 0.7028942704200745, train/logprobs = tensor([[-0.9796, -1.2998],
        [-1.1600, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012329756282269955
Epoch 0, Step 670: train/loss = 0.7120010256767273, train/raw-loss = 0.7118719816207886, train/logprobs = tensor([[-0.8596, -1.0876],
        [-0.9596, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012899995781481266
Epoch 0, Step 671: train/loss = 0.7054548263549805, train/raw-loss = 0.7051286697387695, train/logprobs = tensor([[-0.7480, -1.0548],
        [-0.8090, -1.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032605882734060287
Epoch 0, Step 672: train/loss = 0.7024416923522949, train/raw-loss = 0.7023760080337524, train/logprobs = tensor([[-1.0746, -0.8758],
        [-1.1471, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006572716520167887
Epoch 0, Step 673: train/loss = 0.7166556715965271, train/raw-loss = 0.716606855392456, train/logprobs = tensor([[-0.9989, -1.0917],
        [-1.1362, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004884675145149231
Epoch 0, Step 674: train/loss = 0.6986051201820374, train/raw-loss = 0.698444664478302, train/logprobs = tensor([[-1.1094, -1.2611],
        [-1.1446, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016041395720094442
Epoch 0, Step 675: train/loss = 0.7117336988449097, train/raw-loss = 0.7116495370864868, train/logprobs = tensor([[-1.0792, -1.3210],
        [-1.1111, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008418154902756214
Epoch 0, Step 676: train/loss = 0.6966457366943359, train/raw-loss = 0.6964900493621826, train/logprobs = tensor([[-0.8593, -0.8717],
        [-1.4855, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015576818259432912
Epoch 0, Step 677: train/loss = 0.7008219361305237, train/raw-loss = 0.7007133960723877, train/logprobs = tensor([[-0.9416, -1.0437],
        [-1.0401, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001086191856302321
Epoch 0, Step 678: train/loss = 0.7068095207214355, train/raw-loss = 0.7066715955734253, train/logprobs = tensor([[-1.0311, -1.2745],
        [-1.1840, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013799684820696712
Epoch 0, Step 679: train/loss = 0.7043879628181458, train/raw-loss = 0.7043269872665405, train/logprobs = tensor([[-0.9274, -0.8490],
        [-1.0846, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006097386940382421
Epoch 0, Step 680: train/loss = 0.7015948295593262, train/raw-loss = 0.701579213142395, train/logprobs = tensor([[-0.8950, -1.1704],
        [-0.9425, -1.1648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015553971752524376
Epoch 0, Step 681: train/loss = 0.6908321380615234, train/raw-loss = 0.6908228397369385, train/logprobs = tensor([[-0.7900, -0.9584],
        [-1.2090, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.291953756473958e-05
Epoch 0, Step 682: train/loss = 0.7276504635810852, train/raw-loss = 0.727590799331665, train/logprobs = tensor([[-0.9563, -1.3294],
        [-1.0631, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005970646743662655
Epoch 0, Step 683: train/loss = 0.717414915561676, train/raw-loss = 0.7172994613647461, train/logprobs = tensor([[-0.8843, -0.8569],
        [-1.0010, -0.8595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011542194988578558
Epoch 0, Step 684: train/loss = 0.7284939289093018, train/raw-loss = 0.7283591032028198, train/logprobs = tensor([[-0.9698, -1.3911],
        [-1.0462, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001348210615105927
Epoch 0, Step 685: train/loss = 0.7038428783416748, train/raw-loss = 0.7038309574127197, train/logprobs = tensor([[-0.8428, -0.8081],
        [-0.9331, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001193300704471767
Epoch 0, Step 686: train/loss = 0.6962382793426514, train/raw-loss = 0.6961414813995361, train/logprobs = tensor([[-1.0253, -1.1879],
        [-1.1394, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009677312336862087
Epoch 0, Step 687: train/loss = 0.689710259437561, train/raw-loss = 0.6888880729675293, train/logprobs = tensor([[-1.1055, -1.2400],
        [-1.2551, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008222152478992939
Epoch 0, Step 688: train/loss = 0.7607126832008362, train/raw-loss = 0.7606661319732666, train/logprobs = tensor([[-0.8142, -1.4929],
        [-0.8912, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000464939686935395
Epoch 0, Step 689: train/loss = 0.7026040554046631, train/raw-loss = 0.70259028673172, train/logprobs = tensor([[-0.7174, -0.8639],
        [-0.7922, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013744184980168939
Epoch 0, Step 690: train/loss = 0.7065737247467041, train/raw-loss = 0.7064905166625977, train/logprobs = tensor([[-1.0810, -1.1859],
        [-1.1352, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008323061047121882
Epoch 0, Step 691: train/loss = 0.6948480606079102, train/raw-loss = 0.6948400735855103, train/logprobs = tensor([[-0.8699, -0.8738],
        [-0.8676, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.985034608282149e-05
Epoch 0, Step 692: train/loss = 0.7031680345535278, train/raw-loss = 0.7030421495437622, train/logprobs = tensor([[-0.8467, -1.0225],
        [-1.0025, -1.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012586500961333513
Epoch 0, Step 693: train/loss = 0.6951581835746765, train/raw-loss = 0.6951476335525513, train/logprobs = tensor([[-0.9197, -0.9240],
        [-0.9669, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001060201830114238
Epoch 0, Step 694: train/loss = 0.7071305513381958, train/raw-loss = 0.7070627808570862, train/logprobs = tensor([[-0.8999, -1.1011],
        [-0.9502, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000678241194691509
Epoch 0, Step 695: train/loss = 0.6934431791305542, train/raw-loss = 0.6934374570846558, train/logprobs = tensor([[-0.9676, -0.9996],
        [-1.0202, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.745565431425348e-05
Epoch 0, Step 696: train/loss = 0.7070521712303162, train/raw-loss = 0.7068220973014832, train/logprobs = tensor([[-0.9375, -1.1955],
        [-1.0052, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023006401024758816
Epoch 0, Step 697: train/loss = 0.6979243159294128, train/raw-loss = 0.6977477669715881, train/logprobs = tensor([[-1.0741, -1.0186],
        [-1.2361, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001764888409525156
Epoch 0, Step 698: train/loss = 0.7146754860877991, train/raw-loss = 0.7145430445671082, train/logprobs = tensor([[-1.1139, -1.4003],
        [-1.1297, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013251709751784801
Epoch 0, Step 699: train/loss = 0.7420797944068909, train/raw-loss = 0.7419208288192749, train/logprobs = tensor([[-1.0884, -0.9343],
        [-1.2579, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015895544784143567
Epoch 0, Step 700: train/loss = 0.6947054862976074, train/raw-loss = 0.6946792602539062, train/logprobs = tensor([[-0.8482, -0.9606],
        [-0.9870, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026200685533694923
Epoch 0, Step 701: train/loss = 0.7007408738136292, train/raw-loss = 0.7005167007446289, train/logprobs = tensor([[-0.9042, -1.1226],
        [-1.0812, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022413567639887333
Epoch 0, Step 702: train/loss = 0.7809025645256042, train/raw-loss = 0.7808487415313721, train/logprobs = tensor([[-0.7924, -1.0455],
        [-0.8407, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005380568909458816
Epoch 0, Step 703: train/loss = 0.7055703997612, train/raw-loss = 0.7054479122161865, train/logprobs = tensor([[-0.9578, -1.0211],
        [-1.1346, -0.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012245294637978077
Epoch 0, Step 704: train/loss = 0.7089916467666626, train/raw-loss = 0.7087075710296631, train/logprobs = tensor([[-0.9737, -1.5184],
        [-1.3088, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028411210514605045
Epoch 0, Step 705: train/loss = 0.7038706541061401, train/raw-loss = 0.7038581967353821, train/logprobs = tensor([[-0.9374, -1.0307],
        [-0.9921, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012369373871479183
Epoch 0, Step 706: train/loss = 0.700759768486023, train/raw-loss = 0.7007178068161011, train/logprobs = tensor([[-0.9635, -0.9231],
        [-1.0082, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004195435903966427
Epoch 0, Step 707: train/loss = 0.7249219417572021, train/raw-loss = 0.7247369885444641, train/logprobs = tensor([[-0.9738, -1.3470],
        [-1.0861, -1.2343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018491195514798164
Epoch 0, Step 708: train/loss = 0.6977031826972961, train/raw-loss = 0.6974524259567261, train/logprobs = tensor([[-0.9693, -1.2046],
        [-1.0535, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002507738536223769
Epoch 0, Step 709: train/loss = 0.7395267486572266, train/raw-loss = 0.7394302487373352, train/logprobs = tensor([[-1.1684, -1.0427],
        [-1.3116, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009649526327848434
Epoch 0, Step 710: train/loss = 0.715134859085083, train/raw-loss = 0.7151029109954834, train/logprobs = tensor([[-1.0149, -1.0545],
        [-1.0690, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003192771691828966
Epoch 0, Step 711: train/loss = 0.7132259607315063, train/raw-loss = 0.7131057381629944, train/logprobs = tensor([[-0.8847, -1.1079],
        [-0.9013, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012028539786115289
Epoch 0, Step 712: train/loss = 0.7011439800262451, train/raw-loss = 0.7011241912841797, train/logprobs = tensor([[-0.9541, -0.8827],
        [-1.1330, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001974595943465829
Epoch 0, Step 713: train/loss = 0.708621084690094, train/raw-loss = 0.7085902094841003, train/logprobs = tensor([[-0.9322, -1.1517],
        [-0.9799, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030873354990035295
Epoch 0, Step 714: train/loss = 0.7067260146141052, train/raw-loss = 0.7066608667373657, train/logprobs = tensor([[-1.0272, -1.1054],
        [-1.1710, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006516740540973842
Epoch 0, Step 715: train/loss = 0.6945465803146362, train/raw-loss = 0.6945025324821472, train/logprobs = tensor([[-0.8622, -0.8505],
        [-1.0259, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044067163253203034
Epoch 0, Step 716: train/loss = 0.7074214220046997, train/raw-loss = 0.7072933316230774, train/logprobs = tensor([[-0.9143, -1.1090],
        [-0.9663, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001281490782275796
Epoch 0, Step 717: train/loss = 0.7074037790298462, train/raw-loss = 0.707288384437561, train/logprobs = tensor([[-1.1062, -1.0285],
        [-1.2198, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011535438243299723
Epoch 0, Step 718: train/loss = 0.6983404159545898, train/raw-loss = 0.6983217597007751, train/logprobs = tensor([[-0.9320, -1.1563],
        [-0.9966, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018688768614083529
Epoch 0, Step 719: train/loss = 0.7937910556793213, train/raw-loss = 0.7936927676200867, train/logprobs = tensor([[-0.8101, -1.2998],
        [-0.8213, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009830011986196041
Epoch 0, Step 720: train/loss = 0.7220475673675537, train/raw-loss = 0.7219854593276978, train/logprobs = tensor([[-0.7905, -1.0647],
        [-0.8943, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006209987914189696
Epoch 0, Step 721: train/loss = 0.741804301738739, train/raw-loss = 0.7417213916778564, train/logprobs = tensor([[-0.6286, -0.9692],
        [-0.7331, -0.9842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000829513999633491
Epoch 0, Step 722: train/loss = 0.7102692127227783, train/raw-loss = 0.7102452516555786, train/logprobs = tensor([[-0.8179, -0.8997],
        [-0.8660, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024008809123188257
Epoch 0, Step 723: train/loss = 0.7072345614433289, train/raw-loss = 0.7071734070777893, train/logprobs = tensor([[-0.8606, -0.9728],
        [-1.0139, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006114050047472119
Epoch 0, Step 724: train/loss = 0.6996363401412964, train/raw-loss = 0.6995800733566284, train/logprobs = tensor([[-0.9995, -1.1627],
        [-1.0063, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005628401413559914
Epoch 0, Step 725: train/loss = 0.7129213809967041, train/raw-loss = 0.7128747701644897, train/logprobs = tensor([[-0.9829, -0.9513],
        [-1.0800, -0.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004660380072891712
Epoch 0, Step 726: train/loss = 0.7105563282966614, train/raw-loss = 0.7102354168891907, train/logprobs = tensor([[-0.9518, -1.0945],
        [-0.9893, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032091273460537195
Epoch 0, Step 727: train/loss = 0.7196981310844421, train/raw-loss = 0.7196294069290161, train/logprobs = tensor([[-1.0045, -1.2794],
        [-1.1507, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006875772960484028
Epoch 0, Step 728: train/loss = 0.6993041634559631, train/raw-loss = 0.6992998719215393, train/logprobs = tensor([[-0.9232, -1.1151],
        [-1.0434, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.317195271141827e-05
Epoch 0, Step 729: train/loss = 0.6958065032958984, train/raw-loss = 0.6953735947608948, train/logprobs = tensor([[-0.8719, -1.1455],
        [-0.9583, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004329286981374025
Epoch 0, Step 730: train/loss = 0.7071549892425537, train/raw-loss = 0.7070887088775635, train/logprobs = tensor([[-1.1196, -1.3867],
        [-1.1623, -1.3143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000661823432892561
Epoch 0, Step 731: train/loss = 0.6960568428039551, train/raw-loss = 0.696025550365448, train/logprobs = tensor([[-0.8403, -0.9409],
        [-1.0539, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031244527781382203
Epoch 0, Step 732: train/loss = 0.7056875824928284, train/raw-loss = 0.7054390907287598, train/logprobs = tensor([[-0.9457, -1.1153],
        [-0.9437, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002484676893800497
Epoch 0, Step 733: train/loss = 0.6959819793701172, train/raw-loss = 0.6959818601608276, train/logprobs = tensor([[-0.7484, -0.7906],
        [-0.7801, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.714921381790191e-06
Epoch 0, Step 734: train/loss = 0.6976616978645325, train/raw-loss = 0.6973778605461121, train/logprobs = tensor([[-0.8415, -1.1267],
        [-0.9387, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028381014708429575
Epoch 0, Step 735: train/loss = 0.6958945989608765, train/raw-loss = 0.6957222819328308, train/logprobs = tensor([[-1.0172, -1.1564],
        [-1.1073, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001723013469018042
Epoch 0, Step 736: train/loss = 0.6959906816482544, train/raw-loss = 0.6959800720214844, train/logprobs = tensor([[-0.9146, -0.8395],
        [-0.9677, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010603023110888898
Epoch 0, Step 737: train/loss = 0.6985243558883667, train/raw-loss = 0.698309063911438, train/logprobs = tensor([[-0.8971, -0.9524],
        [-0.9240, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002152883680537343
Epoch 0, Step 738: train/loss = 0.7050424218177795, train/raw-loss = 0.7049316763877869, train/logprobs = tensor([[-1.0598, -1.1861],
        [-1.1748, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011068421881645918
Epoch 0, Step 739: train/loss = 0.7051373720169067, train/raw-loss = 0.7051265239715576, train/logprobs = tensor([[-0.7836, -1.0047],
        [-0.8544, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010935473255813122
Epoch 0, Step 740: train/loss = 0.6948868036270142, train/raw-loss = 0.6948546171188354, train/logprobs = tensor([[-0.8740, -0.9822],
        [-0.9157, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032145646400749683
Epoch 0, Step 741: train/loss = 0.6963343620300293, train/raw-loss = 0.6961567401885986, train/logprobs = tensor([[-0.9273, -1.0467],
        [-0.9530, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017762912902981043
Epoch 0, Step 742: train/loss = 0.6970628499984741, train/raw-loss = 0.6969809532165527, train/logprobs = tensor([[-0.9189, -1.0506],
        [-1.0326, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008190158987417817
Epoch 0, Step 743: train/loss = 0.7127311825752258, train/raw-loss = 0.7126049399375916, train/logprobs = tensor([[-0.9546, -1.1578],
        [-1.2053, -1.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012622164795175195
Epoch 0, Step 744: train/loss = 0.6986310482025146, train/raw-loss = 0.6985814571380615, train/logprobs = tensor([[-1.0048, -1.1091],
        [-1.0808, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004959003999829292
Epoch 0, Step 745: train/loss = 0.6980018615722656, train/raw-loss = 0.697690486907959, train/logprobs = tensor([[-0.8685, -0.8433],
        [-0.9601, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031142039224505424
Epoch 0, Step 746: train/loss = 0.7033867835998535, train/raw-loss = 0.7033541202545166, train/logprobs = tensor([[-0.9777, -0.8862],
        [-1.0325, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003266756539233029
Epoch 0, Step 747: train/loss = 0.7162243723869324, train/raw-loss = 0.71607506275177, train/logprobs = tensor([[-0.8976, -1.2048],
        [-1.0520, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014925176510587335
Epoch 0, Step 748: train/loss = 0.6989648342132568, train/raw-loss = 0.6988837718963623, train/logprobs = tensor([[-1.1099, -1.2423],
        [-1.1507, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008109870250336826
Epoch 0, Step 749: train/loss = 0.7119332551956177, train/raw-loss = 0.7116494178771973, train/logprobs = tensor([[-0.7338, -1.0403],
        [-0.7970, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028388220816850662
Epoch 0, Step 750: train/loss = 0.6950563788414001, train/raw-loss = 0.6950509548187256, train/logprobs = tensor([[-0.7307, -0.8427],
        [-0.7722, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4459451348520815e-05
Epoch 0, Step 751: train/loss = 0.7013375759124756, train/raw-loss = 0.7011661529541016, train/logprobs = tensor([[-0.9118, -0.8988],
        [-1.0116, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017140470445156097
Epoch 0, Step 752: train/loss = 0.7138532400131226, train/raw-loss = 0.7137575149536133, train/logprobs = tensor([[-0.9352, -1.2366],
        [-0.9468, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000957336334977299
Epoch 0, Step 753: train/loss = 0.7082040309906006, train/raw-loss = 0.7080121040344238, train/logprobs = tensor([[-0.9218, -1.2053],
        [-1.0064, -1.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019196029752492905
Epoch 0, Step 754: train/loss = 0.6986172795295715, train/raw-loss = 0.6986076235771179, train/logprobs = tensor([[-0.5584, -0.7159],
        [-0.5877, -0.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.663433593232185e-05
Epoch 0, Step 755: train/loss = 0.6951885223388672, train/raw-loss = 0.6951576471328735, train/logprobs = tensor([[-1.0643, -1.0774],
        [-1.1484, -1.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003092903643846512
Epoch 0, Step 756: train/loss = 0.7195212841033936, train/raw-loss = 0.7192792296409607, train/logprobs = tensor([[-1.0931, -0.8725],
        [-1.1806, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002420842181891203
Epoch 0, Step 757: train/loss = 0.698142945766449, train/raw-loss = 0.6980372667312622, train/logprobs = tensor([[-0.7627, -0.8879],
        [-0.8755, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010568797588348389
Epoch 0, Step 758: train/loss = 0.6984638571739197, train/raw-loss = 0.6982382535934448, train/logprobs = tensor([[-0.9088, -0.8986],
        [-1.0006, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022559165954589844
Epoch 0, Step 759: train/loss = 0.7004277110099792, train/raw-loss = 0.7003667950630188, train/logprobs = tensor([[-0.9066, -1.0329],
        [-0.9769, -0.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006093423580750823
Epoch 0, Step 760: train/loss = 0.6947958469390869, train/raw-loss = 0.6947632431983948, train/logprobs = tensor([[-0.9066, -1.0102],
        [-0.9164, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003261410165578127
Epoch 0, Step 761: train/loss = 0.695369303226471, train/raw-loss = 0.6953482031822205, train/logprobs = tensor([[-0.9124, -0.9844],
        [-0.9448, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021090346854180098
Epoch 0, Step 762: train/loss = 0.7334132790565491, train/raw-loss = 0.7326276302337646, train/logprobs = tensor([[-0.8791, -1.2902],
        [-0.9601, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007856093347072601
Epoch 0, Step 763: train/loss = 0.6985184550285339, train/raw-loss = 0.6983858942985535, train/logprobs = tensor([[-0.8102, -0.8956],
        [-0.8730, -0.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013255201047286391
Epoch 0, Step 764: train/loss = 0.7090784907341003, train/raw-loss = 0.708966851234436, train/logprobs = tensor([[-0.7693, -1.0901],
        [-0.9032, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011169608915224671
Epoch 0, Step 765: train/loss = 0.6964025497436523, train/raw-loss = 0.6963986158370972, train/logprobs = tensor([[-0.9997, -1.1344],
        [-1.0330, -1.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9758975617587566e-05
Epoch 0, Step 766: train/loss = 0.7177570462226868, train/raw-loss = 0.7173646092414856, train/logprobs = tensor([[-0.9570, -1.2663],
        [-1.0903, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003924691118299961
Epoch 0, Step 767: train/loss = 0.7215567827224731, train/raw-loss = 0.7214100360870361, train/logprobs = tensor([[-0.9630, -0.9785],
        [-1.1562, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001467851223424077
Epoch 0, Step 768: train/loss = 0.7075130343437195, train/raw-loss = 0.707405686378479, train/logprobs = tensor([[-0.9833, -0.9583],
        [-1.1433, -0.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010737554403021932
Epoch 0, Step 769: train/loss = 0.6962908506393433, train/raw-loss = 0.6960836052894592, train/logprobs = tensor([[-0.9899, -1.0672],
        [-0.9526, -1.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020721126347780228
Epoch 0, Step 770: train/loss = 0.6948953866958618, train/raw-loss = 0.6948815584182739, train/logprobs = tensor([[-0.8570, -0.9676],
        [-0.9025, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001384081260766834
Epoch 0, Step 771: train/loss = 0.7106393575668335, train/raw-loss = 0.7105486989021301, train/logprobs = tensor([[-1.0600, -0.8090],
        [-1.3241, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009063341422006488
Epoch 0, Step 772: train/loss = 0.7149834036827087, train/raw-loss = 0.7149606347084045, train/logprobs = tensor([[-1.0272, -0.8326],
        [-1.0569, -0.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022736380924470723
Epoch 0, Step 773: train/loss = 0.6932407021522522, train/raw-loss = 0.6931910514831543, train/logprobs = tensor([[-1.0784, -1.1449],
        [-1.1380, -1.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004959239158779383
Epoch 0, Step 774: train/loss = 0.6950673460960388, train/raw-loss = 0.6949691772460938, train/logprobs = tensor([[-0.8309, -0.7983],
        [-0.9466, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009817017707973719
Epoch 0, Step 775: train/loss = 0.7120202779769897, train/raw-loss = 0.7119811177253723, train/logprobs = tensor([[-0.9466, -1.0782],
        [-0.9937, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039178566657938063
Epoch 0, Step 776: train/loss = 0.6967899799346924, train/raw-loss = 0.6967623829841614, train/logprobs = tensor([[-0.9444, -1.1171],
        [-0.9979, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002763791708275676
Epoch 0, Step 777: train/loss = 0.6973260641098022, train/raw-loss = 0.697251558303833, train/logprobs = tensor([[-1.0458, -1.0966],
        [-1.1331, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00074575882172212
Epoch 0, Step 778: train/loss = 0.6973835229873657, train/raw-loss = 0.6973763704299927, train/logprobs = tensor([[-0.9714, -0.8919],
        [-0.9957, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.143193215597421e-05
Epoch 0, Step 779: train/loss = 0.6971967220306396, train/raw-loss = 0.6968750953674316, train/logprobs = tensor([[-0.6773, -0.8097],
        [-0.7861, -0.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032168712932616472
Epoch 0, Step 780: train/loss = 0.7272778749465942, train/raw-loss = 0.7269768714904785, train/logprobs = tensor([[-1.1126, -0.9779],
        [-1.3181, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030100783333182335
Epoch 0, Step 781: train/loss = 0.7027700543403625, train/raw-loss = 0.702668309211731, train/logprobs = tensor([[-0.9929, -0.8499],
        [-1.0374, -0.8680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010177209042012691
Epoch 0, Step 782: train/loss = 0.6934219598770142, train/raw-loss = 0.693414568901062, train/logprobs = tensor([[-0.8072, -0.8755],
        [-0.8723, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.37996306270361e-05
Epoch 0, Step 783: train/loss = 0.6964114904403687, train/raw-loss = 0.696247935295105, train/logprobs = tensor([[-0.9629, -1.2016],
        [-1.0767, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016352905659005046
Epoch 0, Step 784: train/loss = 0.6936130523681641, train/raw-loss = 0.6934320330619812, train/logprobs = tensor([[-0.8939, -1.0456],
        [-1.0174, -0.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018101704772561789
Epoch 0, Step 785: train/loss = 0.7018122673034668, train/raw-loss = 0.7017618417739868, train/logprobs = tensor([[-0.8347, -0.7663],
        [-0.8728, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005045359139330685
Epoch 0, Step 786: train/loss = 0.6990464925765991, train/raw-loss = 0.6990446448326111, train/logprobs = tensor([[-0.8706, -0.8162],
        [-0.9237, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.917194458656013e-05
Epoch 0, Step 787: train/loss = 0.7022192478179932, train/raw-loss = 0.7022019624710083, train/logprobs = tensor([[-0.8638, -0.7074],
        [-0.9008, -0.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017266790382564068
Epoch 0, Step 788: train/loss = 0.6957228183746338, train/raw-loss = 0.6957155466079712, train/logprobs = tensor([[-0.7329, -0.8731],
        [-0.7724, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.32421176508069e-05
Epoch 0, Step 789: train/loss = 0.7172037363052368, train/raw-loss = 0.7170520424842834, train/logprobs = tensor([[-0.8671, -1.1776],
        [-1.0696, -1.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001517514931038022
Epoch 0, Step 790: train/loss = 0.698486864566803, train/raw-loss = 0.69795161485672, train/logprobs = tensor([[-0.9122, -0.9894],
        [-1.0093, -1.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005352447275072336
Epoch 0, Step 791: train/loss = 0.6977329850196838, train/raw-loss = 0.6976762413978577, train/logprobs = tensor([[-0.8217, -1.0187],
        [-0.8541, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005678425077348948
Epoch 0, Step 792: train/loss = 0.6944884061813354, train/raw-loss = 0.6944528818130493, train/logprobs = tensor([[-0.8012, -0.8746],
        [-0.7736, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035510610905475914
Epoch 0, Step 793: train/loss = 0.6936647891998291, train/raw-loss = 0.6933145523071289, train/logprobs = tensor([[-0.8934, -0.8824],
        [-0.9932, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00350265484303236
Epoch 0, Step 794: train/loss = 0.7026203870773315, train/raw-loss = 0.7025512456893921, train/logprobs = tensor([[-0.8727, -0.7162],
        [-0.9279, -0.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006906890776008368
Epoch 0, Step 795: train/loss = 0.698075532913208, train/raw-loss = 0.6980637311935425, train/logprobs = tensor([[-1.0345, -0.9913],
        [-1.1163, -1.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011806696420535445
Epoch 0, Step 796: train/loss = 0.7159016728401184, train/raw-loss = 0.7156830430030823, train/logprobs = tensor([[-0.8978, -0.8564],
        [-0.9326, -0.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021865011658519506
Epoch 0, Step 797: train/loss = 0.6993989944458008, train/raw-loss = 0.6993696689605713, train/logprobs = tensor([[-0.9041, -1.0427],
        [-1.0026, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029284204356372356
Epoch 0, Step 798: train/loss = 0.7030976414680481, train/raw-loss = 0.7030272483825684, train/logprobs = tensor([[-0.9329, -0.8370],
        [-0.9715, -0.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007038044277578592
Epoch 0, Step 799: train/loss = 0.7054440975189209, train/raw-loss = 0.7054389715194702, train/logprobs = tensor([[-1.0244, -1.1044],
        [-1.0846, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.085364682599902e-05
Epoch 0, Step 800: train/loss = 0.7013881802558899, train/raw-loss = 0.7013746500015259, train/logprobs = tensor([[-0.9149, -1.0939],
        [-0.9750, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013512925943359733
Epoch 0, Step 801: train/loss = 0.6947723627090454, train/raw-loss = 0.6947640180587769, train/logprobs = tensor([[-0.7871, -0.7646],
        [-0.8130, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.313845319207758e-05
Epoch 0, Step 802: train/loss = 0.7228306531906128, train/raw-loss = 0.7228265404701233, train/logprobs = tensor([[-0.6709, -0.7967],
        [-0.7042, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.080490907654166e-05
Epoch 0, Step 803: train/loss = 0.6947327852249146, train/raw-loss = 0.6946763396263123, train/logprobs = tensor([[-0.7871, -0.7844],
        [-0.8138, -0.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005641013267450035
Epoch 0, Step 804: train/loss = 0.6971944570541382, train/raw-loss = 0.6971017122268677, train/logprobs = tensor([[-0.8231, -0.7613],
        [-0.8750, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009270115988329053
Epoch 0, Step 805: train/loss = 0.6978754997253418, train/raw-loss = 0.6978699564933777, train/logprobs = tensor([[-0.8743, -0.8287],
        [-0.8840, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.525624146685004e-05
Epoch 0, Step 806: train/loss = 0.6922397613525391, train/raw-loss = 0.6920911073684692, train/logprobs = tensor([[-1.0699, -1.0741],
        [-1.2121, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014865635894238949
Epoch 0, Step 807: train/loss = 0.6945214867591858, train/raw-loss = 0.6944959163665771, train/logprobs = tensor([[-0.8786, -0.8667],
        [-0.9876, -0.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002555328537710011
Epoch 0, Step 808: train/loss = 0.6935834884643555, train/raw-loss = 0.6934356689453125, train/logprobs = tensor([[-0.7941, -0.8887],
        [-0.8489, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014781998470425606
Epoch 0, Step 809: train/loss = 0.7015743255615234, train/raw-loss = 0.7015599608421326, train/logprobs = tensor([[-0.9627, -1.1214],
        [-1.0500, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014344131341204047
Epoch 0, Step 810: train/loss = 0.7138790488243103, train/raw-loss = 0.7137362360954285, train/logprobs = tensor([[-0.9093, -1.0648],
        [-0.9816, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014277249574661255
Epoch 0, Step 811: train/loss = 0.7086644172668457, train/raw-loss = 0.7081001400947571, train/logprobs = tensor([[-1.0487, -0.9758],
        [-1.1259, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005642754957079887
Epoch 0, Step 812: train/loss = 0.6894063353538513, train/raw-loss = 0.6893590688705444, train/logprobs = tensor([[-0.9853, -1.0356],
        [-1.1473, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004727146588265896
Epoch 0, Step 813: train/loss = 0.6933228969573975, train/raw-loss = 0.6933178305625916, train/logprobs = tensor([[-0.8578, -0.9248],
        [-0.9342, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.10186655446887e-05
Epoch 0, Step 814: train/loss = 0.7157278060913086, train/raw-loss = 0.7156935930252075, train/logprobs = tensor([[-0.8663, -1.1040],
        [-0.9256, -1.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003428458876442164
Epoch 0, Step 815: train/loss = 0.7138684391975403, train/raw-loss = 0.7136958241462708, train/logprobs = tensor([[-0.8204, -1.2590],
        [-0.8748, -1.1929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017265323549509048
Epoch 0, Step 816: train/loss = 0.6925182342529297, train/raw-loss = 0.6924023032188416, train/logprobs = tensor([[-0.9251, -1.0264],
        [-1.0155, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001158811734057963
Epoch 0, Step 817: train/loss = 0.6967148780822754, train/raw-loss = 0.6966384053230286, train/logprobs = tensor([[-0.8716, -1.0490],
        [-0.9598, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007645367877557874
Epoch 0, Step 818: train/loss = 0.7153955101966858, train/raw-loss = 0.7153182029724121, train/logprobs = tensor([[-0.8629, -1.1787],
        [-0.8704, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007733345264568925
Epoch 0, Step 819: train/loss = 0.7101879119873047, train/raw-loss = 0.71004319190979, train/logprobs = tensor([[-0.9747, -0.8476],
        [-1.0778, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014485548017546535
Epoch 0, Step 820: train/loss = 0.6978852152824402, train/raw-loss = 0.6978000402450562, train/logprobs = tensor([[-0.7899, -0.5870],
        [-0.8032, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008509778417646885
Epoch 0, Step 821: train/loss = 0.7007473707199097, train/raw-loss = 0.7006880044937134, train/logprobs = tensor([[-0.8782, -1.0598],
        [-0.9305, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000593257078435272
Epoch 0, Step 822: train/loss = 0.7006807923316956, train/raw-loss = 0.7006569504737854, train/logprobs = tensor([[-1.0529, -1.0201],
        [-1.0816, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002384735707892105
Epoch 0, Step 823: train/loss = 0.6938527822494507, train/raw-loss = 0.6937614679336548, train/logprobs = tensor([[-0.7509, -0.7203],
        [-0.7240, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000913296069484204
Epoch 0, Step 824: train/loss = 0.7048840522766113, train/raw-loss = 0.7048053741455078, train/logprobs = tensor([[-0.7972, -1.0106],
        [-0.8407, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007863865466788411
Epoch 0, Step 825: train/loss = 0.7265207171440125, train/raw-loss = 0.7263315916061401, train/logprobs = tensor([[-1.2075, -0.8928],
        [-1.3227, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018908997299149632
Epoch 0, Step 826: train/loss = 0.7183178067207336, train/raw-loss = 0.7181344628334045, train/logprobs = tensor([[-0.9244, -1.3837],
        [-1.0203, -1.3572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018335040658712387
Epoch 0, Step 827: train/loss = 0.6998072266578674, train/raw-loss = 0.6997743248939514, train/logprobs = tensor([[-0.7492, -0.9396],
        [-0.7811, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032910730806179345
Epoch 0, Step 828: train/loss = 0.7003670930862427, train/raw-loss = 0.7001852989196777, train/logprobs = tensor([[-0.8255, -0.9903],
        [-0.9338, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00181842059828341
Epoch 0, Step 829: train/loss = 0.7429852485656738, train/raw-loss = 0.7429717779159546, train/logprobs = tensor([[-0.9978, -1.3200],
        [-1.0314, -1.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013429357204586267
Epoch 0, Step 830: train/loss = 0.7168806195259094, train/raw-loss = 0.7165904641151428, train/logprobs = tensor([[-0.8606, -1.2819],
        [-1.0560, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002901442814618349
Epoch 0, Step 831: train/loss = 0.7121273279190063, train/raw-loss = 0.7119251489639282, train/logprobs = tensor([[-0.9009, -0.8876],
        [-0.9722, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020216102711856365
Epoch 0, Step 832: train/loss = 0.6934053897857666, train/raw-loss = 0.6931799650192261, train/logprobs = tensor([[-0.8876, -0.9229],
        [-1.0948, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002254249295219779
Epoch 0, Step 833: train/loss = 0.6959035992622375, train/raw-loss = 0.695894718170166, train/logprobs = tensor([[-0.9292, -1.0433],
        [-1.0211, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.932074706535786e-05
Epoch 0, Step 834: train/loss = 0.6965939998626709, train/raw-loss = 0.6965537071228027, train/logprobs = tensor([[-0.9601, -0.9443],
        [-1.0092, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004034406738355756
Epoch 0, Step 835: train/loss = 0.7005003690719604, train/raw-loss = 0.7002143859863281, train/logprobs = tensor([[-1.0148, -0.9996],
        [-1.1000, -1.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028591782320290804
Epoch 0, Step 836: train/loss = 0.6932478547096252, train/raw-loss = 0.6931589841842651, train/logprobs = tensor([[-0.9147, -1.0099],
        [-1.0104, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008886405848897994
Epoch 0, Step 837: train/loss = 0.6994466781616211, train/raw-loss = 0.6990267634391785, train/logprobs = tensor([[-0.8260, -1.0573],
        [-0.8850, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004198776558041573
Epoch 0, Step 838: train/loss = 0.7068132758140564, train/raw-loss = 0.7063882946968079, train/logprobs = tensor([[-0.9978, -1.2604],
        [-1.0406, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004250186029821634
Epoch 0, Step 839: train/loss = 0.697679340839386, train/raw-loss = 0.6976197957992554, train/logprobs = tensor([[-0.9189, -1.0652],
        [-1.0424, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005955834640190005
Epoch 0, Step 840: train/loss = 0.7589390873908997, train/raw-loss = 0.7589157819747925, train/logprobs = tensor([[-0.8234, -1.3956],
        [-0.8635, -1.3539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002332009025849402
Epoch 0, Step 841: train/loss = 0.7137115597724915, train/raw-loss = 0.7136127352714539, train/logprobs = tensor([[-0.8279, -1.1254],
        [-0.8994, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000988606596365571
Epoch 0, Step 842: train/loss = 0.6984291076660156, train/raw-loss = 0.6984168291091919, train/logprobs = tensor([[-0.9443, -0.8498],
        [-0.9311, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012236644397489727
Epoch 0, Step 843: train/loss = 0.7042120695114136, train/raw-loss = 0.7038651704788208, train/logprobs = tensor([[-1.1657, -1.1429],
        [-1.2634, -1.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034689968451857567
Epoch 0, Step 844: train/loss = 0.693756639957428, train/raw-loss = 0.6937550902366638, train/logprobs = tensor([[-0.7670, -0.8369],
        [-0.7817, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5393990906886756e-05
Epoch 0, Step 845: train/loss = 0.6952428221702576, train/raw-loss = 0.6951180696487427, train/logprobs = tensor([[-0.9635, -1.0018],
        [-1.0075, -0.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012476823758333921
Epoch 0, Step 846: train/loss = 0.7037250399589539, train/raw-loss = 0.7036370038986206, train/logprobs = tensor([[-0.8429, -1.0913],
        [-0.8544, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008801525691524148
Epoch 0, Step 847: train/loss = 0.696124792098999, train/raw-loss = 0.6961202621459961, train/logprobs = tensor([[-0.8996, -0.8092],
        [-0.9489, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.555779742076993e-05
Epoch 0, Step 848: train/loss = 0.7247745990753174, train/raw-loss = 0.724770724773407, train/logprobs = tensor([[-1.0166, -0.8702],
        [-1.0743, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.872725210385397e-05
Epoch 0, Step 849: train/loss = 0.7078757286071777, train/raw-loss = 0.7076936960220337, train/logprobs = tensor([[-0.9164, -1.0804],
        [-0.9889, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018203447107225657
Epoch 0, Step 850: train/loss = 0.6924829483032227, train/raw-loss = 0.6924493312835693, train/logprobs = tensor([[-0.7163, -0.7437],
        [-0.8338, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033612921833992004
Epoch 0, Step 851: train/loss = 0.7048656940460205, train/raw-loss = 0.7048081755638123, train/logprobs = tensor([[-0.9356, -0.9410],
        [-1.0209, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005752953584305942
Epoch 0, Step 852: train/loss = 0.692990779876709, train/raw-loss = 0.6929004192352295, train/logprobs = tensor([[-1.1703, -1.2209],
        [-1.0736, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009036536212079227
Epoch 0, Step 853: train/loss = 0.7047231197357178, train/raw-loss = 0.7045350670814514, train/logprobs = tensor([[-0.7449, -1.0432],
        [-0.8242, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018804215360432863
Epoch 0, Step 854: train/loss = 0.7028406262397766, train/raw-loss = 0.7028131484985352, train/logprobs = tensor([[-1.0194, -0.8578],
        [-1.0616, -0.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002739242045208812
Epoch 0, Step 855: train/loss = 0.7092598676681519, train/raw-loss = 0.7092475891113281, train/logprobs = tensor([[-1.0991, -0.8538],
        [-1.1012, -0.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012355760554783046
Epoch 0, Step 856: train/loss = 0.7060278654098511, train/raw-loss = 0.7059945464134216, train/logprobs = tensor([[-0.9411, -1.0774],
        [-0.9967, -0.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003332812921144068
Epoch 0, Step 857: train/loss = 0.6966426372528076, train/raw-loss = 0.6966369152069092, train/logprobs = tensor([[-0.7783, -0.8719],
        [-0.8091, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.7504395954310894e-05
Epoch 0, Step 858: train/loss = 0.6980292797088623, train/raw-loss = 0.6978640556335449, train/logprobs = tensor([[-0.8698, -1.0061],
        [-0.9659, -0.9897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016525477403774858
Epoch 0, Step 859: train/loss = 0.6983734965324402, train/raw-loss = 0.6983673572540283, train/logprobs = tensor([[-0.8359, -0.8590],
        [-0.8458, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.07352121733129e-05
Epoch 0, Step 860: train/loss = 0.7057495713233948, train/raw-loss = 0.705671489238739, train/logprobs = tensor([[-0.7780, -1.2369],
        [-0.8125, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007811055984348059
Epoch 0, Step 861: train/loss = 0.7218276262283325, train/raw-loss = 0.7217551469802856, train/logprobs = tensor([[-0.9188, -0.9728],
        [-0.9397, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000725742953363806
Epoch 0, Step 862: train/loss = 0.6927329301834106, train/raw-loss = 0.6927258968353271, train/logprobs = tensor([[-0.9724, -1.0602],
        [-1.1197, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.036781607894227e-05
Epoch 0, Step 863: train/loss = 0.6958107948303223, train/raw-loss = 0.6956042051315308, train/logprobs = tensor([[-1.1205, -1.0829],
        [-1.2226, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002066532615572214
Epoch 0, Step 864: train/loss = 0.7347825169563293, train/raw-loss = 0.7345791459083557, train/logprobs = tensor([[-1.0015, -1.3741],
        [-1.0093, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002033743541687727
Epoch 0, Step 865: train/loss = 0.6988602876663208, train/raw-loss = 0.6988269090652466, train/logprobs = tensor([[-0.8956, -0.9617],
        [-0.9981, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033366208663210273
Epoch 0, Step 866: train/loss = 0.6986263990402222, train/raw-loss = 0.6985874176025391, train/logprobs = tensor([[-0.8258, -0.8759],
        [-0.8829, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003900138253811747
Epoch 0, Step 867: train/loss = 0.7194738388061523, train/raw-loss = 0.7192972898483276, train/logprobs = tensor([[-0.7895, -1.4029],
        [-0.8541, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017652245005592704
Epoch 0, Step 868: train/loss = 0.7176235914230347, train/raw-loss = 0.7176123857498169, train/logprobs = tensor([[-1.0912, -0.9924],
        [-1.1496, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011214079859200865
Epoch 0, Step 869: train/loss = 0.6994088292121887, train/raw-loss = 0.6993381977081299, train/logprobs = tensor([[-0.8983, -0.9479],
        [-0.9145, -0.8579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007063932716846466
Epoch 0, Step 870: train/loss = 0.6968523859977722, train/raw-loss = 0.6968478560447693, train/logprobs = tensor([[-0.7864, -0.8000],
        [-0.8118, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.521897790255025e-05
Epoch 0, Step 871: train/loss = 0.7432218194007874, train/raw-loss = 0.7430681586265564, train/logprobs = tensor([[-0.9829, -1.2577],
        [-1.0698, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015369991306215525
Epoch 0, Step 872: train/loss = 0.6938529014587402, train/raw-loss = 0.6938479542732239, train/logprobs = tensor([[-0.9154, -1.0192],
        [-0.9237, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.933384479954839e-05
Epoch 0, Step 873: train/loss = 0.7140290141105652, train/raw-loss = 0.7139809131622314, train/logprobs = tensor([[-0.9992, -0.9648],
        [-1.0987, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004806338110938668
Epoch 0, Step 874: train/loss = 0.6958232522010803, train/raw-loss = 0.6955744624137878, train/logprobs = tensor([[-1.0388, -1.1168],
        [-1.1148, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024877535179257393
Epoch 0, Step 875: train/loss = 0.7045733332633972, train/raw-loss = 0.7045309543609619, train/logprobs = tensor([[-0.9245, -1.1392],
        [-0.9231, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042290842975489795
Epoch 0, Step 876: train/loss = 0.6981863975524902, train/raw-loss = 0.6981750130653381, train/logprobs = tensor([[-0.9643, -1.0066],
        [-1.0216, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011413788888603449
Epoch 0, Step 877: train/loss = 0.7236952185630798, train/raw-loss = 0.7236888408660889, train/logprobs = tensor([[-0.7475, -0.9508],
        [-0.7833, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.385147571563721e-05
Epoch 0, Step 878: train/loss = 0.7178201675415039, train/raw-loss = 0.7177414298057556, train/logprobs = tensor([[-0.9519, -1.3048],
        [-1.0060, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007877175230532885
Epoch 0, Step 879: train/loss = 0.7073163390159607, train/raw-loss = 0.7072509527206421, train/logprobs = tensor([[-0.7814, -1.0810],
        [-0.8049, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006543984636664391
Epoch 0, Step 880: train/loss = 0.6976953744888306, train/raw-loss = 0.6976654529571533, train/logprobs = tensor([[-1.0556, -0.9602],
        [-1.1741, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029859074857085943
Epoch 0, Step 881: train/loss = 0.6971951723098755, train/raw-loss = 0.6971434354782104, train/logprobs = tensor([[-0.9477, -0.9521],
        [-0.9821, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005176345002837479
Epoch 0, Step 882: train/loss = 0.7059834599494934, train/raw-loss = 0.705894947052002, train/logprobs = tensor([[-0.8744, -1.1609],
        [-0.8602, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008856749627739191
Epoch 0, Step 883: train/loss = 0.7026692628860474, train/raw-loss = 0.7025870084762573, train/logprobs = tensor([[-0.8204, -0.9912],
        [-0.8724, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008221922907978296
Epoch 0, Step 884: train/loss = 0.6961990594863892, train/raw-loss = 0.6961477398872375, train/logprobs = tensor([[-0.8985, -1.0633],
        [-0.8880, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005134126986376941
Epoch 0, Step 885: train/loss = 0.6994288563728333, train/raw-loss = 0.6994163990020752, train/logprobs = tensor([[-0.8736, -1.0544],
        [-0.9694, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012439521378837526
Epoch 0, Step 886: train/loss = 0.7145073413848877, train/raw-loss = 0.7144222259521484, train/logprobs = tensor([[-0.6348, -1.0249],
        [-0.6624, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008511941996403039
Epoch 0, Step 887: train/loss = 0.7861714959144592, train/raw-loss = 0.785961389541626, train/logprobs = tensor([[-1.0500, -1.5370],
        [-1.1056, -1.4442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021008700132369995
Epoch 0, Step 888: train/loss = 0.691882848739624, train/raw-loss = 0.6916254758834839, train/logprobs = tensor([[-0.8158, -1.0479],
        [-0.8930, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002572935540229082
Epoch 0, Step 889: train/loss = 0.7074629068374634, train/raw-loss = 0.7073875665664673, train/logprobs = tensor([[-0.8169, -0.7431],
        [-0.9351, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007541112136095762
Epoch 0, Step 890: train/loss = 0.6974912285804749, train/raw-loss = 0.6974688768386841, train/logprobs = tensor([[-1.0991, -1.0803],
        [-1.1706, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022381404414772987
Epoch 0, Step 891: train/loss = 0.7142778038978577, train/raw-loss = 0.7142521142959595, train/logprobs = tensor([[-0.9595, -0.8963],
        [-1.0204, -0.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002566237235441804
Epoch 0, Step 892: train/loss = 0.7275755405426025, train/raw-loss = 0.7274372577667236, train/logprobs = tensor([[-1.2949, -1.1349],
        [-1.6882, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013835076242685318
Epoch 0, Step 893: train/loss = 0.6954107284545898, train/raw-loss = 0.6953722238540649, train/logprobs = tensor([[-0.8007, -0.8475],
        [-0.8547, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003854016831610352
Epoch 0, Step 894: train/loss = 0.6947165131568909, train/raw-loss = 0.6947009563446045, train/logprobs = tensor([[-0.7371, -0.7846],
        [-0.7870, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015635571617167443
Epoch 0, Step 895: train/loss = 0.7001446485519409, train/raw-loss = 0.6999547481536865, train/logprobs = tensor([[-1.0066, -1.1701],
        [-1.1003, -1.2268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018986923387274146
Epoch 0, Step 896: train/loss = 0.7043862342834473, train/raw-loss = 0.7043678760528564, train/logprobs = tensor([[-0.9676, -0.8639],
        [-1.0421, -0.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018328652367927134
Epoch 0, Step 897: train/loss = 0.7162230014801025, train/raw-loss = 0.7161960005760193, train/logprobs = tensor([[-1.0148, -0.6955],
        [-1.0724, -0.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002702876809053123
Epoch 0, Step 898: train/loss = 0.7033944129943848, train/raw-loss = 0.7033034563064575, train/logprobs = tensor([[-0.9012, -0.9073],
        [-1.1483, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009100846946239471
Epoch 0, Step 899: train/loss = 0.6999874114990234, train/raw-loss = 0.6998839378356934, train/logprobs = tensor([[-0.9211, -0.8251],
        [-1.1120, -0.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001034541754052043
Epoch 0, Step 900: train/loss = 0.6951555013656616, train/raw-loss = 0.6950262188911438, train/logprobs = tensor([[-0.7430, -0.8484],
        [-0.8100, -0.7819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012927161296829581
Epoch 0, Step 901: train/loss = 0.6990132331848145, train/raw-loss = 0.6989744901657104, train/logprobs = tensor([[-0.9889, -0.9369],
        [-1.0890, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038686065818183124
Epoch 0, Step 902: train/loss = 0.7135241031646729, train/raw-loss = 0.71323561668396, train/logprobs = tensor([[-0.9224, -1.3677],
        [-1.0025, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002884146524593234
Epoch 0, Step 903: train/loss = 0.7029905319213867, train/raw-loss = 0.7021830081939697, train/logprobs = tensor([[-1.0544, -1.0715],
        [-1.0450, -1.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008075270801782608
Epoch 0, Step 904: train/loss = 0.69410640001297, train/raw-loss = 0.6940628886222839, train/logprobs = tensor([[-0.9752, -1.0858],
        [-1.1018, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004350790986791253
Epoch 0, Step 905: train/loss = 0.6975831389427185, train/raw-loss = 0.6975524425506592, train/logprobs = tensor([[-0.8606, -0.7706],
        [-0.8504, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030640565091744065
Epoch 0, Step 906: train/loss = 0.6938432455062866, train/raw-loss = 0.6938220858573914, train/logprobs = tensor([[-0.8995, -0.9710],
        [-1.0314, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021190938423387706
Epoch 0, Step 907: train/loss = 0.6930396556854248, train/raw-loss = 0.6929358839988708, train/logprobs = tensor([[-0.7839, -0.8847],
        [-0.8379, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010375690180808306
Epoch 0, Step 908: train/loss = 0.699273943901062, train/raw-loss = 0.6989834308624268, train/logprobs = tensor([[-0.8379, -0.9514],
        [-0.8487, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002905110130086541
Epoch 0, Step 909: train/loss = 0.7048161029815674, train/raw-loss = 0.7048025131225586, train/logprobs = tensor([[-1.0190, -1.1811],
        [-1.1304, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001359255111310631
Epoch 0, Step 910: train/loss = 0.7001070380210876, train/raw-loss = 0.7000890970230103, train/logprobs = tensor([[-0.9581, -1.1046],
        [-0.9272, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001795946154743433
Epoch 0, Step 911: train/loss = 0.6932328939437866, train/raw-loss = 0.693230926990509, train/logprobs = tensor([[-0.9247, -0.9066],
        [-0.9219, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0275161659810692e-05
Epoch 0, Step 912: train/loss = 0.6945888996124268, train/raw-loss = 0.6945575475692749, train/logprobs = tensor([[-1.0536, -1.0927],
        [-1.0912, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031335497624240816
Epoch 0, Step 913: train/loss = 0.6983498334884644, train/raw-loss = 0.6980544924736023, train/logprobs = tensor([[-1.0602, -0.9639],
        [-1.2097, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029530231840908527
Epoch 0, Step 914: train/loss = 0.6947868466377258, train/raw-loss = 0.6947782635688782, train/logprobs = tensor([[-0.8497, -0.8847],
        [-0.8838, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.627191709820181e-05
Epoch 0, Step 915: train/loss = 0.694053053855896, train/raw-loss = 0.6938993334770203, train/logprobs = tensor([[-0.8077, -1.0197],
        [-0.8883, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015372356865555048
Epoch 0, Step 916: train/loss = 0.6946210265159607, train/raw-loss = 0.6945014595985413, train/logprobs = tensor([[-0.9096, -0.9417],
        [-0.9342, -0.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011954958317801356
Epoch 0, Step 917: train/loss = 0.693663477897644, train/raw-loss = 0.6931407451629639, train/logprobs = tensor([[-0.8451, -0.9354],
        [-1.0274, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005227094050496817
Epoch 0, Step 918: train/loss = 0.701299786567688, train/raw-loss = 0.7010682821273804, train/logprobs = tensor([[-0.8492, -0.9184],
        [-0.9720, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002315112855285406
Epoch 0, Step 919: train/loss = 0.7377341985702515, train/raw-loss = 0.7377152442932129, train/logprobs = tensor([[-0.8867, -0.6997],
        [-1.1665, -0.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018894343520514667
Epoch 0, Step 920: train/loss = 0.7634363174438477, train/raw-loss = 0.7632632255554199, train/logprobs = tensor([[-1.0659, -1.5140],
        [-1.0464, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017300895415246487
Epoch 0, Step 921: train/loss = 0.717822253704071, train/raw-loss = 0.717751681804657, train/logprobs = tensor([[-0.8987, -0.9387],
        [-0.9138, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007056511240079999
Epoch 0, Step 922: train/loss = 0.7099701166152954, train/raw-loss = 0.7098929286003113, train/logprobs = tensor([[-0.9896, -1.1857],
        [-1.0387, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007717652479186654
Epoch 0, Step 923: train/loss = 0.7351952195167542, train/raw-loss = 0.7348797917366028, train/logprobs = tensor([[-0.8959, -1.4198],
        [-0.9988, -1.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031549809500575066
Epoch 0, Step 924: train/loss = 0.7010752558708191, train/raw-loss = 0.7009663581848145, train/logprobs = tensor([[-1.0073, -0.8531],
        [-0.9754, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010891337879002094
Epoch 0, Step 925: train/loss = 0.6956900954246521, train/raw-loss = 0.6956480145454407, train/logprobs = tensor([[-1.0016, -0.9058],
        [-0.9277, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004207909805700183
Epoch 0, Step 926: train/loss = 0.6992522478103638, train/raw-loss = 0.6992082595825195, train/logprobs = tensor([[-0.9093, -1.0527],
        [-0.9779, -1.0008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044003326911479235
Epoch 0, Step 927: train/loss = 0.7041677236557007, train/raw-loss = 0.7039965987205505, train/logprobs = tensor([[-1.0715, -0.9534],
        [-1.1575, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017108647152781487
Epoch 0, Step 928: train/loss = 0.7005873918533325, train/raw-loss = 0.700300395488739, train/logprobs = tensor([[-0.8630, -0.9711],
        [-0.9647, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028703040443360806
Epoch 0, Step 929: train/loss = 0.6987518072128296, train/raw-loss = 0.6987021565437317, train/logprobs = tensor([[-0.9876, -1.1676],
        [-0.9520, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004960483638569713
Epoch 0, Step 930: train/loss = 0.7299037575721741, train/raw-loss = 0.7297856211662292, train/logprobs = tensor([[-0.8684, -1.2428],
        [-0.8885, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011818271595984697
Epoch 0, Step 931: train/loss = 0.6993064880371094, train/raw-loss = 0.6992647051811218, train/logprobs = tensor([[-0.7035, -0.9682],
        [-0.7869, -0.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004181510885246098
Epoch 0, Step 932: train/loss = 0.7080096006393433, train/raw-loss = 0.7079614400863647, train/logprobs = tensor([[-0.9006, -1.2481],
        [-0.9189, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004813994746655226
Epoch 0, Step 933: train/loss = 0.7006464004516602, train/raw-loss = 0.7005279660224915, train/logprobs = tensor([[-0.9400, -1.0671],
        [-0.9610, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011843523243442178
Epoch 0, Step 934: train/loss = 0.6996761560440063, train/raw-loss = 0.6996408104896545, train/logprobs = tensor([[-0.7080, -0.8018],
        [-0.7733, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035323062911629677
Epoch 0, Step 935: train/loss = 0.7072216272354126, train/raw-loss = 0.7071630358695984, train/logprobs = tensor([[-0.9082, -0.8032],
        [-0.9671, -0.7754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005850110901519656
Epoch 0, Step 936: train/loss = 0.7084112763404846, train/raw-loss = 0.7082031965255737, train/logprobs = tensor([[-1.1804, -0.9918],
        [-1.2856, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002081463811919093
Epoch 0, Step 937: train/loss = 0.7171059250831604, train/raw-loss = 0.7170907258987427, train/logprobs = tensor([[-0.8843, -1.1137],
        [-0.9236, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015178669127635658
Epoch 0, Step 938: train/loss = 0.7074002027511597, train/raw-loss = 0.7073678970336914, train/logprobs = tensor([[-0.9414, -0.7837],
        [-0.9362, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003233861643821001
Epoch 0, Step 939: train/loss = 0.7006500959396362, train/raw-loss = 0.7005975246429443, train/logprobs = tensor([[-0.9039, -0.9772],
        [-0.9495, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005255699506960809
Epoch 0, Step 940: train/loss = 0.7101815938949585, train/raw-loss = 0.709958553314209, train/logprobs = tensor([[-1.0359, -1.2563],
        [-1.1929, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022297350224107504
Epoch 0, Step 941: train/loss = 0.6942777633666992, train/raw-loss = 0.6942658424377441, train/logprobs = tensor([[-1.0250, -1.0950],
        [-1.0598, -1.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011911008186871186
Epoch 0, Step 942: train/loss = 0.6933627724647522, train/raw-loss = 0.6933205723762512, train/logprobs = tensor([[-0.6651, -0.7118],
        [-0.6726, -0.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042215234134346247
Epoch 0, Step 943: train/loss = 0.7172406315803528, train/raw-loss = 0.7171218991279602, train/logprobs = tensor([[-1.0395, -0.9196],
        [-1.1430, -0.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011872189352288842
Epoch 0, Step 944: train/loss = 0.7037177085876465, train/raw-loss = 0.7036914825439453, train/logprobs = tensor([[-1.1295, -1.4450],
        [-1.1800, -1.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026167556643486023
Epoch 0, Step 945: train/loss = 0.698977530002594, train/raw-loss = 0.6989457607269287, train/logprobs = tensor([[-0.8471, -0.9962],
        [-0.9022, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003171233111061156
Epoch 0, Step 946: train/loss = 0.7161818146705627, train/raw-loss = 0.7161428332328796, train/logprobs = tensor([[-0.9145, -1.0541],
        [-0.9502, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003894719702657312
Epoch 0, Step 947: train/loss = 0.6952576637268066, train/raw-loss = 0.6952136158943176, train/logprobs = tensor([[-0.8829, -0.8158],
        [-0.9614, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004398954624775797
Epoch 0, Step 948: train/loss = 0.6939777731895447, train/raw-loss = 0.6939640045166016, train/logprobs = tensor([[-0.9119, -0.8796],
        [-0.9254, -0.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013765701442025602
Epoch 0, Step 949: train/loss = 0.7036193609237671, train/raw-loss = 0.7036006450653076, train/logprobs = tensor([[-0.8470, -0.7483],
        [-0.9145, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018805314903147519
Epoch 0, Step 950: train/loss = 0.6933309435844421, train/raw-loss = 0.6933006644248962, train/logprobs = tensor([[-0.7672, -0.7819],
        [-0.9259, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030263850931078196
Epoch 0, Step 951: train/loss = 0.7178313136100769, train/raw-loss = 0.717760443687439, train/logprobs = tensor([[-1.1540, -1.3596],
        [-1.0646, -1.1929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007084250682964921
Epoch 0, Step 952: train/loss = 0.7324087619781494, train/raw-loss = 0.7323496341705322, train/logprobs = tensor([[-0.8187, -1.1693],
        [-0.8306, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005913530476391315
Epoch 0, Step 953: train/loss = 0.7298129200935364, train/raw-loss = 0.7297906875610352, train/logprobs = tensor([[-0.9264, -1.1786],
        [-0.9583, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022280466509982944
Epoch 0, Step 954: train/loss = 0.6932344436645508, train/raw-loss = 0.6930401921272278, train/logprobs = tensor([[-0.8532, -0.9569],
        [-0.9355, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001942418864928186
Epoch 0, Step 955: train/loss = 0.6966114044189453, train/raw-loss = 0.6964651346206665, train/logprobs = tensor([[-0.9096, -0.8487],
        [-1.0681, -0.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014625259209424257
Epoch 0, Step 956: train/loss = 0.6982674598693848, train/raw-loss = 0.6981770992279053, train/logprobs = tensor([[-0.7013, -0.8888],
        [-0.8656, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009028235799632967
Epoch 0, Step 957: train/loss = 0.6959683895111084, train/raw-loss = 0.6959233283996582, train/logprobs = tensor([[-0.8704, -0.9923],
        [-0.9294, -0.9103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004503825621213764
Epoch 0, Step 958: train/loss = 0.7087887525558472, train/raw-loss = 0.7087311744689941, train/logprobs = tensor([[-0.8582, -1.0541],
        [-0.8870, -0.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005759292980656028
Epoch 0, Step 959: train/loss = 0.7058547139167786, train/raw-loss = 0.7057753205299377, train/logprobs = tensor([[-0.9162, -0.8489],
        [-1.0253, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007942019728943706
Epoch 0, Step 960: train/loss = 0.7176521420478821, train/raw-loss = 0.7175486087799072, train/logprobs = tensor([[-0.8527, -1.1403],
        [-0.8921, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010352833196520805
Epoch 0, Step 961: train/loss = 0.6964631080627441, train/raw-loss = 0.6964288949966431, train/logprobs = tensor([[-0.9759, -1.0754],
        [-0.9139, -0.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034255324862897396
Epoch 0, Step 962: train/loss = 0.713428258895874, train/raw-loss = 0.7133116722106934, train/logprobs = tensor([[-0.8736, -1.1897],
        [-0.8795, -1.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011658475268632174
Epoch 0, Step 963: train/loss = 0.7094576358795166, train/raw-loss = 0.7092892527580261, train/logprobs = tensor([[-0.7774, -0.7375],
        [-0.8488, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016842989716678858
Epoch 0, Step 964: train/loss = 0.7088566422462463, train/raw-loss = 0.708828866481781, train/logprobs = tensor([[-0.9015, -1.1200],
        [-0.8844, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002774766180664301
Epoch 0, Step 965: train/loss = 0.6938675045967102, train/raw-loss = 0.6938544511795044, train/logprobs = tensor([[-0.8713, -0.9317],
        [-0.9917, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013026813394390047
Epoch 0, Step 966: train/loss = 0.6956493258476257, train/raw-loss = 0.6955919861793518, train/logprobs = tensor([[-0.9811, -0.9335],
        [-1.0741, -0.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005732852732762694
Epoch 0, Step 967: train/loss = 0.7028843760490417, train/raw-loss = 0.7028576135635376, train/logprobs = tensor([[-0.9147, -1.0282],
        [-1.0104, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026741070905700326
Epoch 0, Step 968: train/loss = 0.6938315033912659, train/raw-loss = 0.6938261985778809, train/logprobs = tensor([[-0.7626, -0.6954],
        [-0.8011, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.336978210834786e-05
Epoch 0, Step 969: train/loss = 0.7029531002044678, train/raw-loss = 0.7015775442123413, train/logprobs = tensor([[-0.8340, -1.1320],
        [-0.9412, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01375566516071558
Epoch 0, Step 970: train/loss = 0.6946082711219788, train/raw-loss = 0.694597601890564, train/logprobs = tensor([[-0.9110, -0.9709],
        [-0.9209, -0.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010703258158173412
Epoch 0, Step 971: train/loss = 0.7245967984199524, train/raw-loss = 0.7245612144470215, train/logprobs = tensor([[-0.7991, -0.8272],
        [-0.8954, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035596999805420637
Epoch 0, Step 972: train/loss = 0.7413954734802246, train/raw-loss = 0.7410808801651001, train/logprobs = tensor([[-1.1971, -1.1333],
        [-1.3741, -1.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00314658647403121
Epoch 0, Step 973: train/loss = 0.6935099363327026, train/raw-loss = 0.6934992074966431, train/logprobs = tensor([[-0.8527, -0.8535],
        [-0.8746, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010734074749052525
Epoch 0, Step 974: train/loss = 0.7040805220603943, train/raw-loss = 0.7040597796440125, train/logprobs = tensor([[-0.9125, -1.0284],
        [-0.9158, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020733842393383384
Epoch 0, Step 975: train/loss = 0.6939985752105713, train/raw-loss = 0.6939808130264282, train/logprobs = tensor([[-1.1312, -1.1411],
        [-1.2528, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017757757450453937
Epoch 0, Step 976: train/loss = 0.697119951248169, train/raw-loss = 0.6970992088317871, train/logprobs = tensor([[-1.0532, -1.1315],
        [-1.0992, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020711711840704083
Epoch 0, Step 977: train/loss = 0.6997089982032776, train/raw-loss = 0.6996587514877319, train/logprobs = tensor([[-1.0913, -1.0089],
        [-1.0993, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005024579586461186
Epoch 0, Step 978: train/loss = 0.7063506841659546, train/raw-loss = 0.7062152624130249, train/logprobs = tensor([[-1.1323, -1.4297],
        [-1.2358, -1.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013545611873269081
Epoch 0, Step 979: train/loss = 0.7017927169799805, train/raw-loss = 0.7016791105270386, train/logprobs = tensor([[-0.9944, -1.2326],
        [-1.0582, -1.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011362818768247962
Epoch 0, Step 980: train/loss = 0.7334787845611572, train/raw-loss = 0.7333426475524902, train/logprobs = tensor([[-0.9170, -1.4214],
        [-1.0201, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013609080342575908
Epoch 0, Step 981: train/loss = 0.695309042930603, train/raw-loss = 0.6953085064888, train/logprobs = tensor([[-0.7196, -0.8019],
        [-0.6970, -0.7551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.584786777035333e-06
Epoch 0, Step 982: train/loss = 0.7258284687995911, train/raw-loss = 0.7256682515144348, train/logprobs = tensor([[-0.9348, -1.2938],
        [-1.0266, -1.2790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016020582988858223
Epoch 0, Step 983: train/loss = 0.7021153569221497, train/raw-loss = 0.701816737651825, train/logprobs = tensor([[-0.9514, -1.2257],
        [-0.9899, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029860101640224457
Epoch 0, Step 984: train/loss = 0.6955024003982544, train/raw-loss = 0.6954079866409302, train/logprobs = tensor([[-0.7873, -1.1236],
        [-0.8612, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009441625443287194
Epoch 0, Step 985: train/loss = 0.6911258697509766, train/raw-loss = 0.6908413767814636, train/logprobs = tensor([[-0.9347, -1.0705],
        [-1.0492, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028447210788726807
Epoch 0, Step 986: train/loss = 0.703936755657196, train/raw-loss = 0.7039287090301514, train/logprobs = tensor([[-0.8908, -1.0445],
        [-0.9222, -1.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.071071351878345e-05
Epoch 0, Step 987: train/loss = 0.7192627191543579, train/raw-loss = 0.7191551327705383, train/logprobs = tensor([[-0.8899, -0.7353],
        [-1.1723, -0.7136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010757319396361709
Epoch 0, Step 988: train/loss = 0.7172795534133911, train/raw-loss = 0.7160857319831848, train/logprobs = tensor([[-1.0452, -1.6442],
        [-1.2050, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011938052251935005
Epoch 0, Step 989: train/loss = 0.7055142521858215, train/raw-loss = 0.7055134177207947, train/logprobs = tensor([[-0.8758, -0.7208],
        [-0.9380, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.412636816501617e-06
Epoch 0, Step 990: train/loss = 0.702961266040802, train/raw-loss = 0.702958881855011, train/logprobs = tensor([[-1.0445, -0.9107],
        [-1.0491, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4085416953312233e-05
Epoch 0, Step 991: train/loss = 0.6995024681091309, train/raw-loss = 0.6994761824607849, train/logprobs = tensor([[-0.9691, -1.0228],
        [-0.9951, -1.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002625108463689685
Epoch 0, Step 992: train/loss = 0.6928227543830872, train/raw-loss = 0.6927995681762695, train/logprobs = tensor([[-0.8072, -0.8692],
        [-0.8373, -0.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023208078346215189
Epoch 0, Step 993: train/loss = 0.705157995223999, train/raw-loss = 0.7050934433937073, train/logprobs = tensor([[-0.9590, -0.8893],
        [-0.9561, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006460836157202721
Epoch 0, Step 994: train/loss = 0.721272349357605, train/raw-loss = 0.721260666847229, train/logprobs = tensor([[-0.9674, -0.6054],
        [-1.0272, -0.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001168679737020284
Epoch 0, Step 995: train/loss = 0.7002271413803101, train/raw-loss = 0.7001572847366333, train/logprobs = tensor([[-0.7268, -0.8984],
        [-0.7975, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006986788939684629
Epoch 0, Step 996: train/loss = 0.6992990970611572, train/raw-loss = 0.6992747187614441, train/logprobs = tensor([[-0.9826, -0.9828],
        [-1.0704, -0.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000243861461058259
Epoch 0, Step 997: train/loss = 0.7038809061050415, train/raw-loss = 0.7037789225578308, train/logprobs = tensor([[-1.0965, -0.9808],
        [-1.2505, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010199572425335646
Epoch 0, Step 998: train/loss = 0.6950070858001709, train/raw-loss = 0.6949682235717773, train/logprobs = tensor([[-0.9396, -0.9121],
        [-0.9874, -0.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003887205966748297
Epoch 0, Step 999: train/loss = 0.7007793188095093, train/raw-loss = 0.6998900771141052, train/logprobs = tensor([[-1.0060, -1.3060],
        [-1.1199, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008893141523003578
eval/loss: 0.7045138478279114
Epoch 0, Step 1000: train/loss = 0.6997308731079102, train/raw-loss = 0.6997150778770447, train/logprobs = tensor([[-1.0402, -1.0051],
        [-1.1026, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001580093812663108
Epoch 0, Step 1001: train/loss = 0.6933983564376831, train/raw-loss = 0.693234920501709, train/logprobs = tensor([[-0.8094, -0.9838],
        [-0.9078, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016338085988536477
Epoch 0, Step 1002: train/loss = 0.6943501234054565, train/raw-loss = 0.6943266987800598, train/logprobs = tensor([[-1.0211, -1.0118],
        [-0.9067, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023377087200060487
Epoch 0, Step 1003: train/loss = 0.6961925029754639, train/raw-loss = 0.6961537003517151, train/logprobs = tensor([[-1.2029, -1.1361],
        [-1.1633, -1.0581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003879748983308673
Epoch 0, Step 1004: train/loss = 0.721049964427948, train/raw-loss = 0.7209597826004028, train/logprobs = tensor([[-1.0870, -1.0547],
        [-1.1016, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009015091927722096
Epoch 0, Step 1005: train/loss = 0.7041857838630676, train/raw-loss = 0.7040894031524658, train/logprobs = tensor([[-0.8698, -1.1649],
        [-0.9438, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009630101267248392
Epoch 0, Step 1006: train/loss = 0.6943273544311523, train/raw-loss = 0.6943216919898987, train/logprobs = tensor([[-0.8249, -0.9176],
        [-0.8313, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6903962104115635e-05
Epoch 0, Step 1007: train/loss = 0.8637056946754456, train/raw-loss = 0.8628900051116943, train/logprobs = tensor([[-0.9656, -2.0372],
        [-1.0272, -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008157173171639442
Epoch 0, Step 1008: train/loss = 0.7015067934989929, train/raw-loss = 0.7014858722686768, train/logprobs = tensor([[-0.8232, -0.8967],
        [-0.8885, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020994804799556732
Epoch 0, Step 1009: train/loss = 0.6943625807762146, train/raw-loss = 0.6943080425262451, train/logprobs = tensor([[-0.9038, -0.8948],
        [-0.9301, -0.9718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005450524040497839
Epoch 0, Step 1010: train/loss = 0.6935796737670898, train/raw-loss = 0.6935665607452393, train/logprobs = tensor([[-0.9439, -0.9455],
        [-0.9620, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013145052071195096
Epoch 0, Step 1011: train/loss = 0.6953318119049072, train/raw-loss = 0.6953195333480835, train/logprobs = tensor([[-1.0791, -1.0295],
        [-1.1961, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012231484288349748
Epoch 0, Step 1012: train/loss = 0.697147786617279, train/raw-loss = 0.6968345642089844, train/logprobs = tensor([[-0.8067, -0.9319],
        [-0.8772, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003132488811388612
Epoch 0, Step 1013: train/loss = 0.7013890147209167, train/raw-loss = 0.701250433921814, train/logprobs = tensor([[-0.8471, -0.9364],
        [-0.8896, -0.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001385508687235415
Epoch 0, Step 1014: train/loss = 0.7019308805465698, train/raw-loss = 0.7018418312072754, train/logprobs = tensor([[-0.8869, -0.8903],
        [-0.9129, -0.8173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008902555564418435
Epoch 0, Step 1015: train/loss = 0.6951148509979248, train/raw-loss = 0.6950881481170654, train/logprobs = tensor([[-0.9260, -1.0027],
        [-0.9422, -1.0295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002664363128133118
Epoch 0, Step 1016: train/loss = 0.6976763010025024, train/raw-loss = 0.6974510550498962, train/logprobs = tensor([[-1.1375, -1.1811],
        [-1.1464, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022525202948600054
Epoch 0, Step 1017: train/loss = 0.6946797966957092, train/raw-loss = 0.6946796178817749, train/logprobs = tensor([[-0.8650, -0.8555],
        [-0.8112, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9940307538490742e-06
Epoch 0, Step 1018: train/loss = 0.6983238458633423, train/raw-loss = 0.6982960104942322, train/logprobs = tensor([[-1.0386, -0.9318],
        [-1.1890, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027842517010867596
Epoch 0, Step 1019: train/loss = 0.719233512878418, train/raw-loss = 0.7191658020019531, train/logprobs = tensor([[-1.0440, -0.8432],
        [-1.1594, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006770212203264236
Epoch 0, Step 1020: train/loss = 0.7057090997695923, train/raw-loss = 0.7055814266204834, train/logprobs = tensor([[-1.1089, -1.3219],
        [-1.1450, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012771988986060023
Epoch 0, Step 1021: train/loss = 0.6961145997047424, train/raw-loss = 0.6959529519081116, train/logprobs = tensor([[-0.8587, -1.1024],
        [-0.9531, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016163151012733579
Epoch 0, Step 1022: train/loss = 0.700790286064148, train/raw-loss = 0.7007139921188354, train/logprobs = tensor([[-0.8798, -1.0113],
        [-0.8850, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007636307273060083
Epoch 0, Step 1023: train/loss = 0.7459025979042053, train/raw-loss = 0.7452423572540283, train/logprobs = tensor([[-0.7876, -1.5738],
        [-0.7988, -1.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006602352950721979
Epoch 0, Step 1024: train/loss = 0.7001664638519287, train/raw-loss = 0.6998030543327332, train/logprobs = tensor([[-1.1720, -1.3886],
        [-1.2910, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003634190186858177
Epoch 0, Step 1025: train/loss = 0.6970073580741882, train/raw-loss = 0.6969627141952515, train/logprobs = tensor([[-0.8266, -0.8968],
        [-0.8727, -0.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004468845436349511
Epoch 0, Step 1026: train/loss = 0.7176676392555237, train/raw-loss = 0.7170982956886292, train/logprobs = tensor([[-1.0184, -1.4063],
        [-1.0960, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005693808663636446
Epoch 0, Step 1027: train/loss = 0.7125357389450073, train/raw-loss = 0.7123693227767944, train/logprobs = tensor([[-0.9602, -1.2231],
        [-0.9417, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001663754228502512
Epoch 0, Step 1028: train/loss = 0.6924401521682739, train/raw-loss = 0.6923369765281677, train/logprobs = tensor([[-0.8289, -0.9397],
        [-0.9264, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001032674335874617
Epoch 0, Step 1029: train/loss = 0.7151302099227905, train/raw-loss = 0.7149025201797485, train/logprobs = tensor([[-0.8101, -1.3399],
        [-0.9552, -1.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002277364255860448
Epoch 0, Step 1030: train/loss = 0.7010735273361206, train/raw-loss = 0.7005953192710876, train/logprobs = tensor([[-1.0942, -0.9901],
        [-1.2588, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004782497882843018
Epoch 0, Step 1031: train/loss = 0.6931699514389038, train/raw-loss = 0.6931535005569458, train/logprobs = tensor([[-0.7497, -0.7663],
        [-0.7297, -0.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016455724835395813
Epoch 0, Step 1032: train/loss = 0.7035920023918152, train/raw-loss = 0.7035768032073975, train/logprobs = tensor([[-0.8861, -0.8541],
        [-0.9305, -0.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015213119331747293
Epoch 0, Step 1033: train/loss = 0.7039088606834412, train/raw-loss = 0.7036043405532837, train/logprobs = tensor([[-0.9423, -1.2349],
        [-0.9857, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030447759199887514
Epoch 0, Step 1034: train/loss = 0.6944965720176697, train/raw-loss = 0.6944859027862549, train/logprobs = tensor([[-0.9059, -0.9178],
        [-0.9673, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010672042844817042
Epoch 0, Step 1035: train/loss = 0.6954166889190674, train/raw-loss = 0.6952204704284668, train/logprobs = tensor([[-0.8054, -0.9482],
        [-0.8381, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019622878171503544
Epoch 0, Step 1036: train/loss = 0.7018754482269287, train/raw-loss = 0.7016583681106567, train/logprobs = tensor([[-0.8428, -1.2579],
        [-0.9021, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021710230503231287
Epoch 0, Step 1037: train/loss = 0.7068002223968506, train/raw-loss = 0.706616997718811, train/logprobs = tensor([[-0.9749, -0.9232],
        [-1.2401, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018315371125936508
Epoch 0, Step 1038: train/loss = 0.713507890701294, train/raw-loss = 0.7133734226226807, train/logprobs = tensor([[-1.1005, -1.2134],
        [-1.2217, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013447898672893643
Epoch 0, Step 1039: train/loss = 0.694145917892456, train/raw-loss = 0.6938244104385376, train/logprobs = tensor([[-0.9279, -0.8602],
        [-0.9511, -0.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003215421922504902
Epoch 0, Step 1040: train/loss = 0.7035201787948608, train/raw-loss = 0.7030804753303528, train/logprobs = tensor([[-0.9523, -1.0794],
        [-1.0091, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043969424441456795
Epoch 0, Step 1041: train/loss = 0.7020977139472961, train/raw-loss = 0.7020810842514038, train/logprobs = tensor([[-0.7581, -1.0353],
        [-0.7995, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016630122263450176
Epoch 0, Step 1042: train/loss = 0.6937072277069092, train/raw-loss = 0.6936483383178711, train/logprobs = tensor([[-0.8134, -0.8957],
        [-0.8224, -0.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005888738669455051
Epoch 0, Step 1043: train/loss = 0.6987808346748352, train/raw-loss = 0.698570728302002, train/logprobs = tensor([[-1.0132, -1.2549],
        [-1.0848, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021014451049268246
Epoch 0, Step 1044: train/loss = 0.7095175385475159, train/raw-loss = 0.7093974947929382, train/logprobs = tensor([[-0.7984, -1.0797],
        [-0.9220, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012004139134660363
Epoch 0, Step 1045: train/loss = 0.7056971192359924, train/raw-loss = 0.7056789398193359, train/logprobs = tensor([[-0.9019, -0.7999],
        [-0.9461, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018235549214296043
Epoch 0, Step 1046: train/loss = 0.6933815479278564, train/raw-loss = 0.6933118104934692, train/logprobs = tensor([[-0.9099, -0.9620],
        [-0.9463, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006973477429710329
Epoch 0, Step 1047: train/loss = 0.6914377212524414, train/raw-loss = 0.6913666725158691, train/logprobs = tensor([[-0.8645, -0.9742],
        [-0.9117, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007102269446477294
Epoch 0, Step 1048: train/loss = 0.693268895149231, train/raw-loss = 0.6932061314582825, train/logprobs = tensor([[-0.8536, -0.9242],
        [-0.8697, -0.7844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006278163637034595
Epoch 0, Step 1049: train/loss = 0.697376012802124, train/raw-loss = 0.696879506111145, train/logprobs = tensor([[-0.8033, -1.0183],
        [-0.8771, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004965891130268574
Epoch 0, Step 1050: train/loss = 0.6926825046539307, train/raw-loss = 0.6926203966140747, train/logprobs = tensor([[-0.9362, -1.0597],
        [-1.0336, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006206902908161283
Epoch 0, Step 1051: train/loss = 0.6978617906570435, train/raw-loss = 0.6978456974029541, train/logprobs = tensor([[-0.9687, -1.1401],
        [-1.0155, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016143443644978106
Epoch 0, Step 1052: train/loss = 0.6972809433937073, train/raw-loss = 0.6972717046737671, train/logprobs = tensor([[-0.9185, -0.8607],
        [-1.0113, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.300201782025397e-05
Epoch 0, Step 1053: train/loss = 0.7068707942962646, train/raw-loss = 0.7067126631736755, train/logprobs = tensor([[-0.8609, -1.2072],
        [-0.9494, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015822731656953692
Epoch 0, Step 1054: train/loss = 0.7057449221611023, train/raw-loss = 0.7055822610855103, train/logprobs = tensor([[-1.1482, -1.1649],
        [-1.0769, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016262150602415204
Epoch 0, Step 1055: train/loss = 0.7092281579971313, train/raw-loss = 0.7089172005653381, train/logprobs = tensor([[-0.7498, -1.0778],
        [-0.8127, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031101000495254993
Epoch 0, Step 1056: train/loss = 0.6972987055778503, train/raw-loss = 0.6972249746322632, train/logprobs = tensor([[-0.9314, -0.9475],
        [-1.0325, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007367851212620735
Epoch 0, Step 1057: train/loss = 0.6936566829681396, train/raw-loss = 0.6936371326446533, train/logprobs = tensor([[-0.8991, -0.8891],
        [-0.9119, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019521571812219918
Epoch 0, Step 1058: train/loss = 0.7093979120254517, train/raw-loss = 0.709244966506958, train/logprobs = tensor([[-0.8774, -1.1079],
        [-0.9326, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015297869686037302
Epoch 0, Step 1059: train/loss = 0.6997210383415222, train/raw-loss = 0.6996447443962097, train/logprobs = tensor([[-0.8916, -0.8579],
        [-1.0243, -0.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007630132604390383
Epoch 0, Step 1060: train/loss = 0.6959437131881714, train/raw-loss = 0.695901095867157, train/logprobs = tensor([[-0.8956, -1.0130],
        [-0.9337, -1.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004261188441887498
Epoch 0, Step 1061: train/loss = 0.7397792339324951, train/raw-loss = 0.7395541667938232, train/logprobs = tensor([[-0.9660, -1.1073],
        [-1.0321, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002251073718070984
Epoch 0, Step 1062: train/loss = 0.7053219676017761, train/raw-loss = 0.7051251530647278, train/logprobs = tensor([[-0.9926, -0.8842],
        [-1.0567, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001967555144801736
Epoch 0, Step 1063: train/loss = 0.6970359086990356, train/raw-loss = 0.6969500780105591, train/logprobs = tensor([[-1.0030, -1.0020],
        [-0.9542, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008589826757088304
Epoch 0, Step 1064: train/loss = 0.7098970413208008, train/raw-loss = 0.7098134756088257, train/logprobs = tensor([[-0.9434, -0.8253],
        [-1.2652, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008357252809219062
Epoch 0, Step 1065: train/loss = 0.6942563056945801, train/raw-loss = 0.6942315697669983, train/logprobs = tensor([[-1.0380, -1.0174],
        [-1.1104, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002469154424034059
Epoch 0, Step 1066: train/loss = 0.6934064626693726, train/raw-loss = 0.6933379769325256, train/logprobs = tensor([[-0.8707, -0.9057],
        [-0.9591, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006847514887340367
Epoch 0, Step 1067: train/loss = 0.694493293762207, train/raw-loss = 0.6944341063499451, train/logprobs = tensor([[-0.9307, -1.0325],
        [-1.0587, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005918041570112109
Epoch 0, Step 1068: train/loss = 0.6970751285552979, train/raw-loss = 0.6970423460006714, train/logprobs = tensor([[-0.9705, -0.9971],
        [-1.0196, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032737094443291426
Epoch 0, Step 1069: train/loss = 0.7012508511543274, train/raw-loss = 0.7011082768440247, train/logprobs = tensor([[-0.8801, -0.8402],
        [-0.9919, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014256115537136793
Epoch 0, Step 1070: train/loss = 0.6925551295280457, train/raw-loss = 0.6923099756240845, train/logprobs = tensor([[-0.9205, -0.9887],
        [-1.0227, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00245123403146863
Epoch 0, Step 1071: train/loss = 0.6941947937011719, train/raw-loss = 0.6941256523132324, train/logprobs = tensor([[-0.8592, -1.0142],
        [-0.8524, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006913761608302593
Epoch 0, Step 1072: train/loss = 0.6909506916999817, train/raw-loss = 0.6905651092529297, train/logprobs = tensor([[-0.8456, -1.2405],
        [-1.1018, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038564116694033146
Epoch 0, Step 1073: train/loss = 0.7183021903038025, train/raw-loss = 0.7177437543869019, train/logprobs = tensor([[-0.8317, -1.0375],
        [-0.9223, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005583527032285929
Epoch 0, Step 1074: train/loss = 0.6984347701072693, train/raw-loss = 0.6982215642929077, train/logprobs = tensor([[-0.8257, -0.8314],
        [-0.8780, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002131940796971321
Epoch 0, Step 1075: train/loss = 0.6938055753707886, train/raw-loss = 0.6935468316078186, train/logprobs = tensor([[-0.8917, -1.0216],
        [-0.9971, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025878003798425198
Epoch 0, Step 1076: train/loss = 0.6979765892028809, train/raw-loss = 0.6979738473892212, train/logprobs = tensor([[-0.9356, -0.8365],
        [-1.0095, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.620629675220698e-05
Epoch 0, Step 1077: train/loss = 0.709884524345398, train/raw-loss = 0.709353506565094, train/logprobs = tensor([[-0.8574, -1.4199],
        [-1.1195, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005309975240379572
Epoch 0, Step 1078: train/loss = 0.6944671273231506, train/raw-loss = 0.694395899772644, train/logprobs = tensor([[-1.0518, -1.2201],
        [-1.1265, -1.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007124225958250463
Epoch 0, Step 1079: train/loss = 0.6918184161186218, train/raw-loss = 0.6914654970169067, train/logprobs = tensor([[-1.0156, -1.1271],
        [-1.1153, -1.0245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003529391484335065
Epoch 0, Step 1080: train/loss = 0.699945867061615, train/raw-loss = 0.699834406375885, train/logprobs = tensor([[-1.0015, -1.1455],
        [-1.0969, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011146009201183915
Epoch 0, Step 1081: train/loss = 0.6982088088989258, train/raw-loss = 0.6981759071350098, train/logprobs = tensor([[-0.7528, -1.0095],
        [-0.8627, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032884549000300467
Epoch 0, Step 1082: train/loss = 0.7017573118209839, train/raw-loss = 0.7017523050308228, train/logprobs = tensor([[-0.8837, -0.7773],
        [-0.9178, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.031749606132507e-05
Epoch 0, Step 1083: train/loss = 0.6946956515312195, train/raw-loss = 0.6944551467895508, train/logprobs = tensor([[-0.8926, -1.1344],
        [-1.0087, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024053440429270267
Epoch 0, Step 1084: train/loss = 0.6966083645820618, train/raw-loss = 0.6964298486709595, train/logprobs = tensor([[-1.0894, -1.0311],
        [-1.0621, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017848528223112226
Epoch 0, Step 1085: train/loss = 0.6988936066627502, train/raw-loss = 0.6987062692642212, train/logprobs = tensor([[-0.7981, -0.8418],
        [-1.0292, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001873336499556899
Epoch 0, Step 1086: train/loss = 0.7007601857185364, train/raw-loss = 0.7006884813308716, train/logprobs = tensor([[-0.9927, -0.8443],
        [-1.0416, -0.8082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007169230375438929
Epoch 0, Step 1087: train/loss = 0.6944187879562378, train/raw-loss = 0.6942189335823059, train/logprobs = tensor([[-0.9554, -0.9732],
        [-0.9638, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019986554980278015
Epoch 0, Step 1088: train/loss = 0.6996141672134399, train/raw-loss = 0.6995912790298462, train/logprobs = tensor([[-0.8666, -0.9867],
        [-0.9280, -1.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022856984287500381
Epoch 0, Step 1089: train/loss = 0.7103098630905151, train/raw-loss = 0.710259735584259, train/logprobs = tensor([[-0.9169, -1.0826],
        [-0.9446, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005013372283428907
Epoch 0, Step 1090: train/loss = 0.6804874539375305, train/raw-loss = 0.6776937246322632, train/logprobs = tensor([[-0.8404, -1.2139],
        [-0.9977, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027937255799770355
Epoch 0, Step 1091: train/loss = 0.6933185458183289, train/raw-loss = 0.6929984092712402, train/logprobs = tensor([[-1.1519, -1.1957],
        [-1.2281, -1.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003201728453859687
Epoch 0, Step 1092: train/loss = 0.6993973255157471, train/raw-loss = 0.699370265007019, train/logprobs = tensor([[-0.9389, -0.9033],
        [-0.9621, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027068491908721626
Epoch 0, Step 1093: train/loss = 0.6932482123374939, train/raw-loss = 0.6931930184364319, train/logprobs = tensor([[-0.9450, -0.9692],
        [-1.0684, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005520329577848315
Epoch 0, Step 1094: train/loss = 0.6964985728263855, train/raw-loss = 0.6963707804679871, train/logprobs = tensor([[-0.9272, -0.9942],
        [-0.9681, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001277803210541606
Epoch 0, Step 1095: train/loss = 0.6993592381477356, train/raw-loss = 0.6993311643600464, train/logprobs = tensor([[-0.8902, -0.7484],
        [-0.9717, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002814122417476028
Epoch 0, Step 1096: train/loss = 0.6972125172615051, train/raw-loss = 0.6969859004020691, train/logprobs = tensor([[-0.9204, -0.9355],
        [-0.9355, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022666649892926216
Epoch 0, Step 1097: train/loss = 0.7077978849411011, train/raw-loss = 0.707635223865509, train/logprobs = tensor([[-0.9767, -0.8806],
        [-1.0621, -0.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016270698979496956
Epoch 0, Step 1098: train/loss = 0.7005897760391235, train/raw-loss = 0.7005281448364258, train/logprobs = tensor([[-0.9054, -0.8926],
        [-0.9354, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006158467731438577
Epoch 0, Step 1099: train/loss = 0.693976104259491, train/raw-loss = 0.6938846111297607, train/logprobs = tensor([[-0.8973, -0.9194],
        [-1.0020, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009143901988863945
Epoch 0, Step 1100: train/loss = 0.7086701393127441, train/raw-loss = 0.7086074948310852, train/logprobs = tensor([[-0.9755, -0.9324],
        [-1.0836, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006264072144404054
Epoch 0, Step 1101: train/loss = 0.7016767263412476, train/raw-loss = 0.7016202211380005, train/logprobs = tensor([[-0.8641, -0.8923],
        [-0.9344, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005646746722050011
Epoch 0, Step 1102: train/loss = 0.6924641728401184, train/raw-loss = 0.6923378705978394, train/logprobs = tensor([[-0.9122, -1.1427],
        [-1.0690, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012632563011720777
Epoch 0, Step 1103: train/loss = 0.6947494745254517, train/raw-loss = 0.6947488188743591, train/logprobs = tensor([[-0.7941, -0.8809],
        [-0.8076, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.420064892154187e-06
Epoch 0, Step 1104: train/loss = 0.6931273937225342, train/raw-loss = 0.6930004358291626, train/logprobs = tensor([[-0.8791, -0.9645],
        [-0.9687, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012696979101747274
Epoch 0, Step 1105: train/loss = 0.7075810432434082, train/raw-loss = 0.7074873447418213, train/logprobs = tensor([[-0.8667, -0.9457],
        [-0.9434, -0.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000936693511903286
Epoch 0, Step 1106: train/loss = 0.6955798268318176, train/raw-loss = 0.6955167651176453, train/logprobs = tensor([[-0.8355, -0.9484],
        [-0.8774, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006304606795310974
Epoch 0, Step 1107: train/loss = 0.7051219940185547, train/raw-loss = 0.7050729393959045, train/logprobs = tensor([[-0.8354, -0.9355],
        [-0.9220, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004902288201265037
Epoch 0, Step 1108: train/loss = 0.7016106843948364, train/raw-loss = 0.7015928626060486, train/logprobs = tensor([[-0.7614, -0.8588],
        [-0.7784, -0.8650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001778370642568916
Epoch 0, Step 1109: train/loss = 0.7311611771583557, train/raw-loss = 0.7309904098510742, train/logprobs = tensor([[-0.8818, -1.4702],
        [-0.9508, -1.2615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017076102085411549
Epoch 0, Step 1110: train/loss = 0.6961702108383179, train/raw-loss = 0.6960347294807434, train/logprobs = tensor([[-0.9354, -0.9981],
        [-1.0000, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013541540829464793
Epoch 0, Step 1111: train/loss = 0.7861271500587463, train/raw-loss = 0.7860975861549377, train/logprobs = tensor([[-0.9065, -1.3911],
        [-0.9503, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029524145065806806
Epoch 0, Step 1112: train/loss = 0.7083058953285217, train/raw-loss = 0.7082037925720215, train/logprobs = tensor([[-0.9374, -0.8563],
        [-0.9233, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010208545718342066
Epoch 0, Step 1113: train/loss = 0.6939297318458557, train/raw-loss = 0.6937695741653442, train/logprobs = tensor([[-0.8197, -0.9624],
        [-0.8797, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016011754050850868
Epoch 0, Step 1114: train/loss = 0.6964584589004517, train/raw-loss = 0.6963989734649658, train/logprobs = tensor([[-0.9648, -0.9931],
        [-1.0182, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005950554623268545
Epoch 0, Step 1115: train/loss = 0.6850309371948242, train/raw-loss = 0.6849985122680664, train/logprobs = tensor([[-0.9873, -1.0051],
        [-1.3680, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032441323855891824
Epoch 0, Step 1116: train/loss = 0.7000859975814819, train/raw-loss = 0.700035572052002, train/logprobs = tensor([[-0.9891, -1.0234],
        [-1.1144, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00050397461745888
Epoch 0, Step 1117: train/loss = 0.6921794414520264, train/raw-loss = 0.6919437050819397, train/logprobs = tensor([[-0.9338, -1.0824],
        [-1.1038, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002357139950618148
Epoch 0, Step 1118: train/loss = 0.6999623775482178, train/raw-loss = 0.6997353434562683, train/logprobs = tensor([[-0.8336, -0.7090],
        [-0.9716, -0.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022699455730617046
Epoch 0, Step 1119: train/loss = 0.6984213590621948, train/raw-loss = 0.698332667350769, train/logprobs = tensor([[-0.8129, -1.0209],
        [-0.9672, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008875218336470425
Epoch 0, Step 1120: train/loss = 0.701015055179596, train/raw-loss = 0.7009322643280029, train/logprobs = tensor([[-1.1941, -1.2377],
        [-1.2679, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008283538045361638
Epoch 0, Step 1121: train/loss = 0.6955674886703491, train/raw-loss = 0.6954835057258606, train/logprobs = tensor([[-0.8211, -0.9258],
        [-0.8248, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008399205398745835
Epoch 0, Step 1122: train/loss = 0.7006637454032898, train/raw-loss = 0.7006009221076965, train/logprobs = tensor([[-1.0170, -0.8947],
        [-1.1123, -0.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006279831286519766
Epoch 0, Step 1123: train/loss = 0.6997807025909424, train/raw-loss = 0.699760377407074, train/logprobs = tensor([[-0.9300, -1.1049],
        [-1.0124, -0.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002031995973084122
Epoch 0, Step 1124: train/loss = 0.6987401247024536, train/raw-loss = 0.698535680770874, train/logprobs = tensor([[-0.9822, -1.0267],
        [-1.0127, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002045018132776022
Epoch 0, Step 1125: train/loss = 0.6894128322601318, train/raw-loss = 0.6890372633934021, train/logprobs = tensor([[-0.8518, -1.2271],
        [-1.1966, -1.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037566598039120436
Epoch 0, Step 1126: train/loss = 0.6964946389198303, train/raw-loss = 0.6963194012641907, train/logprobs = tensor([[-0.8960, -0.9746],
        [-0.9797, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017527495510876179
Epoch 0, Step 1127: train/loss = 0.7028610110282898, train/raw-loss = 0.7028477191925049, train/logprobs = tensor([[-0.8453, -1.1053],
        [-0.8974, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013284845044836402
Epoch 0, Step 1128: train/loss = 0.6946572065353394, train/raw-loss = 0.6944848299026489, train/logprobs = tensor([[-0.8402, -0.9134],
        [-0.9566, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001724344678223133
Epoch 0, Step 1129: train/loss = 0.6986786127090454, train/raw-loss = 0.6981487274169922, train/logprobs = tensor([[-0.9773, -0.9162],
        [-1.0530, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052996110171079636
Epoch 0, Step 1130: train/loss = 0.7388835549354553, train/raw-loss = 0.7387919425964355, train/logprobs = tensor([[-0.9477, -1.2244],
        [-1.0520, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009162871865555644
Epoch 0, Step 1131: train/loss = 0.7048979997634888, train/raw-loss = 0.7048747539520264, train/logprobs = tensor([[-0.8736, -0.9685],
        [-0.9181, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023263075854629278
Epoch 0, Step 1132: train/loss = 0.7116253972053528, train/raw-loss = 0.711246132850647, train/logprobs = tensor([[-0.9693, -1.0450],
        [-1.0737, -1.1131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037926589138805866
Epoch 0, Step 1133: train/loss = 0.7080827951431274, train/raw-loss = 0.7074625492095947, train/logprobs = tensor([[-1.1157, -0.9949],
        [-1.2670, -0.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006202912889420986
Epoch 0, Step 1134: train/loss = 0.7084472179412842, train/raw-loss = 0.7083349823951721, train/logprobs = tensor([[-0.8790, -1.2997],
        [-1.0914, -1.2238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011221086606383324
Epoch 0, Step 1135: train/loss = 0.7008694410324097, train/raw-loss = 0.700800895690918, train/logprobs = tensor([[-0.8177, -0.9907],
        [-0.9405, -1.0418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006860789144411683
Epoch 0, Step 1136: train/loss = 0.7277453541755676, train/raw-loss = 0.7275276184082031, train/logprobs = tensor([[-0.8207, -1.1898],
        [-0.8878, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002178043592721224
Epoch 0, Step 1137: train/loss = 0.6999216675758362, train/raw-loss = 0.6995900869369507, train/logprobs = tensor([[-0.8662, -0.8957],
        [-1.0395, -0.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033156403806060553
Epoch 0, Step 1138: train/loss = 0.6991022825241089, train/raw-loss = 0.6990525722503662, train/logprobs = tensor([[-1.0186, -1.1861],
        [-1.1625, -1.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004968025023117661
Epoch 0, Step 1139: train/loss = 0.6931033134460449, train/raw-loss = 0.6930692195892334, train/logprobs = tensor([[-0.8325, -0.9610],
        [-0.9687, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034095466253347695
Epoch 0, Step 1140: train/loss = 0.7112933397293091, train/raw-loss = 0.7112678289413452, train/logprobs = tensor([[-0.9903, -0.8400],
        [-1.0738, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002553138474468142
Epoch 0, Step 1141: train/loss = 0.6981596946716309, train/raw-loss = 0.6980459690093994, train/logprobs = tensor([[-0.9968, -1.0774],
        [-1.1315, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011373714078217745
Epoch 0, Step 1142: train/loss = 0.6977815628051758, train/raw-loss = 0.6976905465126038, train/logprobs = tensor([[-0.8807, -1.0853],
        [-1.0092, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009098837035708129
Epoch 0, Step 1143: train/loss = 0.7182990908622742, train/raw-loss = 0.7182098031044006, train/logprobs = tensor([[-1.2675, -0.9772],
        [-1.3828, -1.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000892598123755306
Epoch 0, Step 1144: train/loss = 0.7045825719833374, train/raw-loss = 0.7044157981872559, train/logprobs = tensor([[-0.6392, -0.7861],
        [-0.7026, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016674196813255548
Epoch 0, Step 1145: train/loss = 0.7090896368026733, train/raw-loss = 0.7089284658432007, train/logprobs = tensor([[-1.1002, -0.8915],
        [-1.2338, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016114606987684965
Epoch 0, Step 1146: train/loss = 0.7048343420028687, train/raw-loss = 0.704739511013031, train/logprobs = tensor([[-0.9990, -0.9709],
        [-1.1485, -0.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009485457558184862
Epoch 0, Step 1147: train/loss = 0.6937971711158752, train/raw-loss = 0.6937880516052246, train/logprobs = tensor([[-0.8699, -0.9077],
        [-0.9491, -0.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.123241761699319e-05
Epoch 0, Step 1148: train/loss = 0.6959299445152283, train/raw-loss = 0.6956617832183838, train/logprobs = tensor([[-0.9293, -0.9736],
        [-0.9587, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026815878227353096
Epoch 0, Step 1149: train/loss = 0.6922008991241455, train/raw-loss = 0.6921567916870117, train/logprobs = tensor([[-0.9457, -0.9855],
        [-1.0783, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044081173837184906
Epoch 0, Step 1150: train/loss = 0.6934316158294678, train/raw-loss = 0.693171501159668, train/logprobs = tensor([[-0.8806, -1.0873],
        [-0.9620, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002601738553494215
Epoch 0, Step 1151: train/loss = 0.7175667881965637, train/raw-loss = 0.7169321775436401, train/logprobs = tensor([[-0.8685, -1.2742],
        [-1.0900, -1.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006345461122691631
Epoch 0, Step 1152: train/loss = 0.6974924206733704, train/raw-loss = 0.6973868608474731, train/logprobs = tensor([[-0.7908, -0.9603],
        [-0.9025, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010559211950749159
Epoch 0, Step 1153: train/loss = 0.7133391499519348, train/raw-loss = 0.7132865786552429, train/logprobs = tensor([[-0.9974, -1.0495],
        [-1.0917, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000525645911693573
Epoch 0, Step 1154: train/loss = 0.6958484649658203, train/raw-loss = 0.6956554651260376, train/logprobs = tensor([[-0.8519, -0.8977],
        [-0.9718, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019296723185107112
Epoch 0, Step 1155: train/loss = 0.7000975012779236, train/raw-loss = 0.7000327706336975, train/logprobs = tensor([[-0.8646, -0.7650],
        [-0.9849, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006471358356066048
Epoch 0, Step 1156: train/loss = 0.702853262424469, train/raw-loss = 0.7027701139450073, train/logprobs = tensor([[-0.8478, -0.8246],
        [-0.9057, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008314324077218771
Epoch 0, Step 1157: train/loss = 0.7030001282691956, train/raw-loss = 0.7029330730438232, train/logprobs = tensor([[-0.7452, -0.9365],
        [-0.8086, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006707130232825875
Epoch 0, Step 1158: train/loss = 0.6946135759353638, train/raw-loss = 0.694595992565155, train/logprobs = tensor([[-0.9752, -1.0433],
        [-1.1035, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017547141760587692
Epoch 0, Step 1159: train/loss = 0.6992272138595581, train/raw-loss = 0.6991977095603943, train/logprobs = tensor([[-1.0019, -0.8683],
        [-0.9502, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029480920056812465
Epoch 0, Step 1160: train/loss = 0.6959278583526611, train/raw-loss = 0.6956860423088074, train/logprobs = tensor([[-0.7906, -0.9199],
        [-0.8723, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002417692681774497
Epoch 0, Step 1161: train/loss = 0.7010090351104736, train/raw-loss = 0.7008241415023804, train/logprobs = tensor([[-0.9340, -1.1918],
        [-0.9831, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018491391092538834
Epoch 0, Step 1162: train/loss = 0.7035940289497375, train/raw-loss = 0.7035242319107056, train/logprobs = tensor([[-1.1358, -0.9812],
        [-1.2179, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006975212600082159
Epoch 0, Step 1163: train/loss = 0.6971727609634399, train/raw-loss = 0.6969597935676575, train/logprobs = tensor([[-0.8027, -0.9183],
        [-0.9251, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021297656930983067
Epoch 0, Step 1164: train/loss = 0.6951210498809814, train/raw-loss = 0.6949557065963745, train/logprobs = tensor([[-1.1579, -1.0987],
        [-1.3975, -1.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001653532381169498
Epoch 0, Step 1165: train/loss = 0.6939642429351807, train/raw-loss = 0.6938079595565796, train/logprobs = tensor([[-0.9762, -1.0734],
        [-1.1082, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015623881481587887
Epoch 0, Step 1166: train/loss = 0.7158849835395813, train/raw-loss = 0.7155581712722778, train/logprobs = tensor([[-0.9384, -1.1401],
        [-1.0548, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032669829670339823
Epoch 0, Step 1167: train/loss = 0.6989476680755615, train/raw-loss = 0.6988993883132935, train/logprobs = tensor([[-0.9258, -1.1435],
        [-0.9980, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048234398127533495
Epoch 0, Step 1168: train/loss = 0.7039088606834412, train/raw-loss = 0.7038421034812927, train/logprobs = tensor([[-1.0575, -1.0849],
        [-1.1375, -1.0821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006674735341221094
Epoch 0, Step 1169: train/loss = 0.696915864944458, train/raw-loss = 0.6969021558761597, train/logprobs = tensor([[-0.8538, -0.9686],
        [-0.9271, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013632094487547874
Epoch 0, Step 1170: train/loss = 0.6970657110214233, train/raw-loss = 0.6970306038856506, train/logprobs = tensor([[-0.8758, -0.8954],
        [-1.0505, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035153806675225496
Epoch 0, Step 1171: train/loss = 0.6930578947067261, train/raw-loss = 0.692733108997345, train/logprobs = tensor([[-1.1070, -1.2186],
        [-1.2932, -1.2355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00324780261144042
Epoch 0, Step 1172: train/loss = 0.6992692947387695, train/raw-loss = 0.6989431977272034, train/logprobs = tensor([[-1.1166, -1.0644],
        [-1.3208, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032617514953017235
Epoch 0, Step 1173: train/loss = 0.6950346827507019, train/raw-loss = 0.6949867010116577, train/logprobs = tensor([[-0.8072, -0.8819],
        [-0.8370, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047916200128383934
Epoch 0, Step 1174: train/loss = 0.6958208680152893, train/raw-loss = 0.6957504749298096, train/logprobs = tensor([[-0.9643, -0.9821],
        [-1.0825, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007046830141916871
Epoch 0, Step 1175: train/loss = 0.698931097984314, train/raw-loss = 0.6987821459770203, train/logprobs = tensor([[-1.0431, -1.0041],
        [-1.1040, -0.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014894128544256091
Epoch 0, Step 1176: train/loss = 0.6936618089675903, train/raw-loss = 0.6936365962028503, train/logprobs = tensor([[-0.9689, -0.9644],
        [-1.0923, -0.9718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002514285733923316
Epoch 0, Step 1177: train/loss = 0.6998053789138794, train/raw-loss = 0.6996649503707886, train/logprobs = tensor([[-0.9501, -0.8653],
        [-1.0011, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014044775161892176
Epoch 0, Step 1178: train/loss = 0.6944676637649536, train/raw-loss = 0.6933249235153198, train/logprobs = tensor([[-1.0612, -1.0806],
        [-1.2459, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011427076533436775
Epoch 0, Step 1179: train/loss = 0.7086415886878967, train/raw-loss = 0.7085381746292114, train/logprobs = tensor([[-1.0328, -1.2419],
        [-1.3733, -1.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001034481916576624
Epoch 0, Step 1180: train/loss = 0.7124698162078857, train/raw-loss = 0.712412416934967, train/logprobs = tensor([[-1.0417, -1.0560],
        [-1.2143, -1.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005740304477512836
Epoch 0, Step 1181: train/loss = 0.7071943283081055, train/raw-loss = 0.7069424986839294, train/logprobs = tensor([[-1.0551, -0.8780],
        [-1.3972, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025183744728565216
Epoch 0, Step 1182: train/loss = 0.7164751291275024, train/raw-loss = 0.7159861922264099, train/logprobs = tensor([[-0.9329, -1.1641],
        [-1.0695, -0.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004890222568064928
Epoch 0, Step 1183: train/loss = 0.8073870539665222, train/raw-loss = 0.8072364330291748, train/logprobs = tensor([[-1.0130, -1.5565],
        [-1.1142, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001506457687355578
Epoch 0, Step 1184: train/loss = 0.6929752230644226, train/raw-loss = 0.6922832727432251, train/logprobs = tensor([[-1.0527, -1.0415],
        [-1.0869, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006919547449797392
Epoch 0, Step 1185: train/loss = 0.6989368200302124, train/raw-loss = 0.6988269090652466, train/logprobs = tensor([[-1.0053, -0.9274],
        [-1.1720, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010986728593707085
Epoch 0, Step 1186: train/loss = 0.6908080577850342, train/raw-loss = 0.6907118558883667, train/logprobs = tensor([[-0.8492, -1.0136],
        [-1.1237, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009621081408113241
Epoch 0, Step 1187: train/loss = 0.6967418789863586, train/raw-loss = 0.6966748833656311, train/logprobs = tensor([[-0.9968, -0.9157],
        [-1.0694, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006704524857923388
Epoch 0, Step 1188: train/loss = 0.7205368280410767, train/raw-loss = 0.720355749130249, train/logprobs = tensor([[-0.8146, -1.2342],
        [-1.0014, -1.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001810912974178791
Epoch 0, Step 1189: train/loss = 0.7043349742889404, train/raw-loss = 0.7039916515350342, train/logprobs = tensor([[-1.0827, -1.0843],
        [-1.2034, -1.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003433174453675747
Epoch 0, Step 1190: train/loss = 0.6937696933746338, train/raw-loss = 0.6937189698219299, train/logprobs = tensor([[-0.8291, -0.8654],
        [-1.0270, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005069002509117126
Epoch 0, Step 1191: train/loss = 0.7123712301254272, train/raw-loss = 0.7121635675430298, train/logprobs = tensor([[-0.9626, -1.1758],
        [-1.1337, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020764078944921494
Epoch 0, Step 1192: train/loss = 0.6958093643188477, train/raw-loss = 0.6958028078079224, train/logprobs = tensor([[-1.1406, -1.1355],
        [-1.2470, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.573364953510463e-05
Epoch 0, Step 1193: train/loss = 0.6961754560470581, train/raw-loss = 0.6961077451705933, train/logprobs = tensor([[-0.7982, -0.9445],
        [-0.8962, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006771968910470605
Epoch 0, Step 1194: train/loss = 0.7016029953956604, train/raw-loss = 0.7014986276626587, train/logprobs = tensor([[-0.8175, -0.5990],
        [-0.8914, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010441341437399387
Epoch 0, Step 1195: train/loss = 0.6929938793182373, train/raw-loss = 0.6928631663322449, train/logprobs = tensor([[-1.0395, -1.0403],
        [-1.1275, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001307372935116291
Epoch 0, Step 1196: train/loss = 0.6990844011306763, train/raw-loss = 0.6989659070968628, train/logprobs = tensor([[-0.8613, -1.1072],
        [-0.9512, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011849836446344852
Epoch 0, Step 1197: train/loss = 0.7176502346992493, train/raw-loss = 0.7175849080085754, train/logprobs = tensor([[-0.9659, -0.7444],
        [-1.1157, -0.7892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006535633001476526
Epoch 0, Step 1198: train/loss = 0.7031500935554504, train/raw-loss = 0.7030209898948669, train/logprobs = tensor([[-1.0703, -0.8986],
        [-1.1808, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012912012171000242
Epoch 0, Step 1199: train/loss = 0.6979241967201233, train/raw-loss = 0.6977664232254028, train/logprobs = tensor([[-1.0300, -1.0150],
        [-1.2062, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015782116679474711
Epoch 0, Step 1200: train/loss = 0.6957911849021912, train/raw-loss = 0.6957865357398987, train/logprobs = tensor([[-0.8519, -0.8114],
        [-1.0528, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.64022159576416e-05
Epoch 0, Step 1201: train/loss = 0.6973620057106018, train/raw-loss = 0.6971327662467957, train/logprobs = tensor([[-0.9349, -0.9242],
        [-1.0394, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022925380617380142
Epoch 0, Step 1202: train/loss = 0.7269531488418579, train/raw-loss = 0.7269288897514343, train/logprobs = tensor([[-1.2078, -0.9587],
        [-1.3598, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024229302653111517
Epoch 0, Step 1203: train/loss = 0.7041189670562744, train/raw-loss = 0.7040538787841797, train/logprobs = tensor([[-0.9881, -1.0774],
        [-1.1559, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006508543156087399
Epoch 0, Step 1204: train/loss = 0.6974273920059204, train/raw-loss = 0.6969935894012451, train/logprobs = tensor([[-0.7961, -0.6905],
        [-0.9076, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004337669350206852
Epoch 0, Step 1205: train/loss = 0.7222228646278381, train/raw-loss = 0.7218537926673889, train/logprobs = tensor([[-1.0730, -0.9653],
        [-1.2076, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036911997012794018
Epoch 0, Step 1206: train/loss = 0.6970036029815674, train/raw-loss = 0.6969655752182007, train/logprobs = tensor([[-0.9198, -1.0729],
        [-1.0718, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037992227589711547
Epoch 0, Step 1207: train/loss = 0.7089623212814331, train/raw-loss = 0.7087933421134949, train/logprobs = tensor([[-1.1101, -0.9507],
        [-1.1828, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016891906270757318
Epoch 0, Step 1208: train/loss = 0.7067385911941528, train/raw-loss = 0.706719160079956, train/logprobs = tensor([[-1.2092, -1.0693],
        [-1.3565, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019435916328802705
Epoch 0, Step 1209: train/loss = 0.6987808346748352, train/raw-loss = 0.6987167000770569, train/logprobs = tensor([[-0.9843, -1.2774],
        [-1.1544, -1.2320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006410026689991355
Epoch 0, Step 1210: train/loss = 0.6961740851402283, train/raw-loss = 0.6961612701416016, train/logprobs = tensor([[-0.8807, -0.8645],
        [-1.0025, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012757276999764144
Epoch 0, Step 1211: train/loss = 0.727021336555481, train/raw-loss = 0.7261534929275513, train/logprobs = tensor([[-1.1613, -0.9505],
        [-1.4121, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008678900077939034
Epoch 0, Step 1212: train/loss = 0.6955517530441284, train/raw-loss = 0.6954538822174072, train/logprobs = tensor([[-1.0095, -0.9696],
        [-1.1279, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009794998914003372
Epoch 0, Step 1213: train/loss = 0.7787883281707764, train/raw-loss = 0.7782179713249207, train/logprobs = tensor([[-1.3458, -0.8289],
        [-1.4757, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005704303737729788
Epoch 0, Step 1214: train/loss = 0.7152772545814514, train/raw-loss = 0.7151905298233032, train/logprobs = tensor([[-0.8337, -1.0434],
        [-1.0171, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008672373369336128
Epoch 0, Step 1215: train/loss = 0.6948150396347046, train/raw-loss = 0.6945961713790894, train/logprobs = tensor([[-0.8828, -1.0778],
        [-0.9510, -0.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021885777823626995
Epoch 0, Step 1216: train/loss = 0.7032799124717712, train/raw-loss = 0.7031328678131104, train/logprobs = tensor([[-1.1736, -1.3245],
        [-1.3535, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014709045644849539
Epoch 0, Step 1217: train/loss = 0.6974594593048096, train/raw-loss = 0.6973980665206909, train/logprobs = tensor([[-0.9792, -1.0530],
        [-1.0021, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006136767333373427
Epoch 0, Step 1218: train/loss = 0.6951993703842163, train/raw-loss = 0.6950810551643372, train/logprobs = tensor([[-1.1170, -1.0531],
        [-1.1777, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011830837465822697
Epoch 0, Step 1219: train/loss = 0.699391782283783, train/raw-loss = 0.6992527842521667, train/logprobs = tensor([[-0.9443, -1.0926],
        [-1.1480, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013900493504479527
Epoch 0, Step 1220: train/loss = 0.7320083975791931, train/raw-loss = 0.7319599390029907, train/logprobs = tensor([[-0.9444, -1.0256],
        [-0.9313, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000483729294501245
Epoch 0, Step 1221: train/loss = 0.6966933012008667, train/raw-loss = 0.6966375112533569, train/logprobs = tensor([[-0.9153, -0.8775],
        [-1.1092, -0.9063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005575282848440111
Epoch 0, Step 1222: train/loss = 0.7072436213493347, train/raw-loss = 0.7071578502655029, train/logprobs = tensor([[-0.9993, -1.2241],
        [-1.0634, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008577499538660049
Epoch 0, Step 1223: train/loss = 0.700611412525177, train/raw-loss = 0.7005603313446045, train/logprobs = tensor([[-1.0795, -0.9805],
        [-1.1023, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000510017154738307
Epoch 0, Step 1224: train/loss = 0.6982444524765015, train/raw-loss = 0.6980842351913452, train/logprobs = tensor([[-0.8301, -1.0721],
        [-0.9232, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016019886825233698
Epoch 0, Step 1225: train/loss = 0.7069218158721924, train/raw-loss = 0.7066116333007812, train/logprobs = tensor([[-0.9108, -0.7360],
        [-1.0914, -0.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031027388758957386
Epoch 0, Step 1226: train/loss = 0.7035201787948608, train/raw-loss = 0.703376293182373, train/logprobs = tensor([[-0.8422, -0.9519],
        [-1.0458, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001438668929040432
Epoch 0, Step 1227: train/loss = 0.7110984921455383, train/raw-loss = 0.7107835412025452, train/logprobs = tensor([[-1.1554, -1.1062],
        [-1.3121, -1.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031489194370806217
Epoch 0, Step 1228: train/loss = 0.7161797881126404, train/raw-loss = 0.7161254286766052, train/logprobs = tensor([[-0.7690, -0.8016],
        [-0.8701, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005438783555291593
Epoch 0, Step 1229: train/loss = 0.7090940475463867, train/raw-loss = 0.7089747190475464, train/logprobs = tensor([[-1.1593, -1.1271],
        [-1.1459, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011939486721530557
Epoch 0, Step 1230: train/loss = 0.6984680891036987, train/raw-loss = 0.6983405947685242, train/logprobs = tensor([[-1.0870, -1.0645],
        [-1.2019, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001274693408049643
Epoch 0, Step 1231: train/loss = 0.7189984917640686, train/raw-loss = 0.718920111656189, train/logprobs = tensor([[-1.0029, -0.7184],
        [-1.1098, -0.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007839701138436794
Epoch 0, Step 1232: train/loss = 0.6984326839447021, train/raw-loss = 0.6983423829078674, train/logprobs = tensor([[-1.0653, -1.0363],
        [-1.2196, -1.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009028545464389026
Epoch 0, Step 1233: train/loss = 0.7056384086608887, train/raw-loss = 0.7050745487213135, train/logprobs = tensor([[-1.2132, -1.0180],
        [-1.4652, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005639101378619671
Epoch 0, Step 1234: train/loss = 0.7177797555923462, train/raw-loss = 0.7176976203918457, train/logprobs = tensor([[-1.1524, -1.0185],
        [-1.4563, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008212156826630235
Epoch 0, Step 1235: train/loss = 0.7002363204956055, train/raw-loss = 0.7000215649604797, train/logprobs = tensor([[-0.7526, -0.6689],
        [-0.9446, -0.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002146748825907707
Epoch 0, Step 1236: train/loss = 0.7084957957267761, train/raw-loss = 0.7084462642669678, train/logprobs = tensor([[-0.9123, -1.1124],
        [-1.0399, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004958061035722494
Epoch 0, Step 1237: train/loss = 0.709416389465332, train/raw-loss = 0.7093658447265625, train/logprobs = tensor([[-1.2166, -1.1597],
        [-1.3229, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005055158399045467
Epoch 0, Step 1238: train/loss = 0.6911989450454712, train/raw-loss = 0.6905477046966553, train/logprobs = tensor([[-1.0116, -1.0935],
        [-1.1709, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006512305233627558
Epoch 0, Step 1239: train/loss = 0.6944264769554138, train/raw-loss = 0.6944180130958557, train/logprobs = tensor([[-0.8439, -0.9023],
        [-0.9774, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.515712397638708e-05
Epoch 0, Step 1240: train/loss = 0.6933388710021973, train/raw-loss = 0.6932419538497925, train/logprobs = tensor([[-0.9400, -0.9685],
        [-1.0439, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000970029563177377
Epoch 0, Step 1241: train/loss = 0.700200080871582, train/raw-loss = 0.7001318335533142, train/logprobs = tensor([[-0.8952, -0.8027],
        [-1.0669, -0.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006822093855589628
Epoch 0, Step 1242: train/loss = 0.7050396203994751, train/raw-loss = 0.7048308253288269, train/logprobs = tensor([[-0.9430, -0.8023],
        [-1.0076, -0.8916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002088201930746436
Epoch 0, Step 1243: train/loss = 0.6939924359321594, train/raw-loss = 0.6937922835350037, train/logprobs = tensor([[-1.1766, -1.2474],
        [-1.2804, -1.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020015437621623278
Epoch 0, Step 1244: train/loss = 0.6917768716812134, train/raw-loss = 0.6917474269866943, train/logprobs = tensor([[-0.9021, -1.0501],
        [-1.0429, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002944824518635869
Epoch 0, Step 1245: train/loss = 0.7060846090316772, train/raw-loss = 0.7059369087219238, train/logprobs = tensor([[-1.1647, -0.9770],
        [-1.2735, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001476988079957664
Epoch 0, Step 1246: train/loss = 0.7150086164474487, train/raw-loss = 0.7148329019546509, train/logprobs = tensor([[-1.0859, -0.8958],
        [-1.2225, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017570463242009282
Epoch 0, Step 1247: train/loss = 0.7143515348434448, train/raw-loss = 0.7142153978347778, train/logprobs = tensor([[-0.9174, -0.6526],
        [-1.0493, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013616039650514722
Epoch 0, Step 1248: train/loss = 0.7069681286811829, train/raw-loss = 0.7067878246307373, train/logprobs = tensor([[-1.0011, -0.9476],
        [-1.1298, -0.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001802424667403102
Epoch 0, Step 1249: train/loss = 0.7051649689674377, train/raw-loss = 0.7050360441207886, train/logprobs = tensor([[-1.0318, -0.9592],
        [-1.0847, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012891539372503757
Epoch 0, Step 1250: train/loss = 0.6960392594337463, train/raw-loss = 0.6958491206169128, train/logprobs = tensor([[-1.1238, -1.1442],
        [-1.3037, -1.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019014333374798298
Epoch 0, Step 1251: train/loss = 0.7149995565414429, train/raw-loss = 0.7146488428115845, train/logprobs = tensor([[-1.2261, -1.6121],
        [-1.4161, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035064229741692543
Epoch 0, Step 1252: train/loss = 0.7036038041114807, train/raw-loss = 0.7035013437271118, train/logprobs = tensor([[-1.1207, -1.0126],
        [-1.2870, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010247137397527695
Epoch 0, Step 1253: train/loss = 0.7343563437461853, train/raw-loss = 0.7342667579650879, train/logprobs = tensor([[-1.0855, -1.2382],
        [-1.3252, -1.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008958125254139304
Epoch 0, Step 1254: train/loss = 0.7013559937477112, train/raw-loss = 0.7012571096420288, train/logprobs = tensor([[-0.8553, -1.0180],
        [-0.8797, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009891983354464173
Epoch 0, Step 1255: train/loss = 0.7139749526977539, train/raw-loss = 0.7139092683792114, train/logprobs = tensor([[-0.9129, -0.7719],
        [-0.9529, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006567083764821291
Epoch 0, Step 1256: train/loss = 0.7146416902542114, train/raw-loss = 0.7146003246307373, train/logprobs = tensor([[-1.1978, -1.0125],
        [-1.2607, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004144409904256463
Epoch 0, Step 1257: train/loss = 0.7002577781677246, train/raw-loss = 0.7000909447669983, train/logprobs = tensor([[-0.9462, -0.8136],
        [-1.0715, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016678874380886555
Epoch 0, Step 1258: train/loss = 0.701535701751709, train/raw-loss = 0.7014612555503845, train/logprobs = tensor([[-1.0953, -0.9376],
        [-1.1429, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007447166717611253
Epoch 0, Step 1259: train/loss = 0.6992069482803345, train/raw-loss = 0.698947012424469, train/logprobs = tensor([[-1.3124, -1.1859],
        [-1.5297, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025990542490035295
Epoch 0, Step 1260: train/loss = 0.7454657554626465, train/raw-loss = 0.745072603225708, train/logprobs = tensor([[-1.1705, -0.7929],
        [-1.9945, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003931444603949785
Epoch 0, Step 1261: train/loss = 0.7038695812225342, train/raw-loss = 0.703417181968689, train/logprobs = tensor([[-1.0552, -1.2227],
        [-1.2539, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004524325951933861
Epoch 0, Step 1262: train/loss = 0.695033609867096, train/raw-loss = 0.6948798894882202, train/logprobs = tensor([[-1.2445, -1.2571],
        [-1.3121, -1.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001536940922960639
Epoch 0, Step 1263: train/loss = 0.6969245672225952, train/raw-loss = 0.6967341899871826, train/logprobs = tensor([[-0.9903, -1.0131],
        [-1.1772, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019032430136576295
Epoch 0, Step 1264: train/loss = 0.7148624658584595, train/raw-loss = 0.7148433923721313, train/logprobs = tensor([[-0.9520, -1.0365],
        [-0.9937, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019020738545805216
Epoch 0, Step 1265: train/loss = 0.7212690114974976, train/raw-loss = 0.7208460569381714, train/logprobs = tensor([[-1.2314, -1.1338],
        [-1.3344, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00423036701977253
Epoch 0, Step 1266: train/loss = 0.7008801698684692, train/raw-loss = 0.7007480263710022, train/logprobs = tensor([[-1.1156, -0.9821],
        [-1.2652, -1.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001321533345617354
Epoch 0, Step 1267: train/loss = 0.6960765719413757, train/raw-loss = 0.6959710121154785, train/logprobs = tensor([[-1.0033, -0.9114],
        [-1.2259, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010554564651101828
Epoch 0, Step 1268: train/loss = 0.7058560252189636, train/raw-loss = 0.705826997756958, train/logprobs = tensor([[-1.2066, -1.1282],
        [-1.2863, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000289351271931082
Epoch 0, Step 1269: train/loss = 0.7006791830062866, train/raw-loss = 0.7006230354309082, train/logprobs = tensor([[-1.0762, -0.9773],
        [-1.1676, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005617974675260484
Epoch 0, Step 1270: train/loss = 0.69704270362854, train/raw-loss = 0.6969139575958252, train/logprobs = tensor([[-1.0027, -1.0829],
        [-1.2281, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012884724419564009
Epoch 0, Step 1271: train/loss = 0.7049030065536499, train/raw-loss = 0.7048668265342712, train/logprobs = tensor([[-0.9921, -1.0535],
        [-1.1423, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003616017347667366
Epoch 0, Step 1272: train/loss = 0.7137643098831177, train/raw-loss = 0.7134824395179749, train/logprobs = tensor([[-1.0789, -1.2729],
        [-1.2990, -1.2175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002818606561049819
Epoch 0, Step 1273: train/loss = 0.7148494720458984, train/raw-loss = 0.714729368686676, train/logprobs = tensor([[-0.9903, -0.8330],
        [-1.1463, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012011665385216475
Epoch 0, Step 1274: train/loss = 0.7209917902946472, train/raw-loss = 0.7207105755805969, train/logprobs = tensor([[-0.9698, -0.6218],
        [-1.1961, -0.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028121457435190678
Epoch 0, Step 1275: train/loss = 0.7006450891494751, train/raw-loss = 0.7005350589752197, train/logprobs = tensor([[-1.0675, -1.0684],
        [-1.2157, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010998649522662163
Epoch 0, Step 1276: train/loss = 0.6947516798973083, train/raw-loss = 0.6947386264801025, train/logprobs = tensor([[-0.9899, -0.9354],
        [-1.0157, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013067945837974548
Epoch 0, Step 1277: train/loss = 0.7123928666114807, train/raw-loss = 0.7123414278030396, train/logprobs = tensor([[-0.8952, -0.8960],
        [-0.9532, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005140581633895636
Epoch 0, Step 1278: train/loss = 0.7025582790374756, train/raw-loss = 0.7023372650146484, train/logprobs = tensor([[-0.8787, -0.9263],
        [-0.9050, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002210259670391679
Epoch 0, Step 1279: train/loss = 0.7165677547454834, train/raw-loss = 0.7161408066749573, train/logprobs = tensor([[-1.0422, -1.0206],
        [-1.1993, -0.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004269671626389027
Epoch 0, Step 1280: train/loss = 0.7089699506759644, train/raw-loss = 0.7086946964263916, train/logprobs = tensor([[-1.1632, -1.0840],
        [-1.3842, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027517275884747505
Epoch 0, Step 1281: train/loss = 0.7453550696372986, train/raw-loss = 0.7451545596122742, train/logprobs = tensor([[-1.2063, -0.8552],
        [-1.4769, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020054811611771584
Epoch 0, Step 1282: train/loss = 0.702736496925354, train/raw-loss = 0.7025573253631592, train/logprobs = tensor([[-1.0425, -1.0966],
        [-1.1479, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017921760445460677
Epoch 0, Step 1283: train/loss = 0.708451509475708, train/raw-loss = 0.7083480954170227, train/logprobs = tensor([[-1.0047, -1.0872],
        [-1.1286, -1.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00103351182769984
Epoch 0, Step 1284: train/loss = 0.6955081224441528, train/raw-loss = 0.6954530477523804, train/logprobs = tensor([[-0.9701, -0.9209],
        [-1.0765, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005508385947905481
Epoch 0, Step 1285: train/loss = 0.7084876298904419, train/raw-loss = 0.7075704336166382, train/logprobs = tensor([[-1.0154, -0.9451],
        [-1.1503, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009171614423394203
Epoch 0, Step 1286: train/loss = 0.6982852220535278, train/raw-loss = 0.6982635259628296, train/logprobs = tensor([[-1.2355, -1.2068],
        [-1.3715, -1.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021720943914260715
Epoch 0, Step 1287: train/loss = 0.7041070461273193, train/raw-loss = 0.7040239572525024, train/logprobs = tensor([[-1.1766, -0.9812],
        [-1.3752, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008307163370773196
Epoch 0, Step 1288: train/loss = 0.7075618505477905, train/raw-loss = 0.7071743011474609, train/logprobs = tensor([[-1.0553, -1.1722],
        [-1.3038, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038757971487939358
Epoch 0, Step 1289: train/loss = 0.7081469893455505, train/raw-loss = 0.7080323696136475, train/logprobs = tensor([[-0.8616, -0.9801],
        [-0.9338, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001145735033787787
Epoch 0, Step 1290: train/loss = 0.7308277487754822, train/raw-loss = 0.7306671142578125, train/logprobs = tensor([[-1.0937, -0.7466],
        [-1.3081, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016054208390414715
Epoch 0, Step 1291: train/loss = 0.7040431499481201, train/raw-loss = 0.703879714012146, train/logprobs = tensor([[-1.1978, -1.1603],
        [-1.3449, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016336634289473295
Epoch 0, Step 1292: train/loss = 0.6982731819152832, train/raw-loss = 0.6978139281272888, train/logprobs = tensor([[-0.9932, -0.9406],
        [-1.1478, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004592128098011017
Epoch 0, Step 1293: train/loss = 0.7009563446044922, train/raw-loss = 0.700954258441925, train/logprobs = tensor([[-0.9653, -0.8525],
        [-1.0378, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0566094462992623e-05
Epoch 0, Step 1294: train/loss = 0.6944277286529541, train/raw-loss = 0.694394588470459, train/logprobs = tensor([[-0.9762, -0.9375],
        [-1.1041, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003320725227240473
Epoch 0, Step 1295: train/loss = 0.6965593695640564, train/raw-loss = 0.6965512037277222, train/logprobs = tensor([[-1.1963, -1.0724],
        [-1.3295, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.117739344015718e-05
Epoch 0, Step 1296: train/loss = 0.6946840882301331, train/raw-loss = 0.6946582198143005, train/logprobs = tensor([[-0.9030, -0.9730],
        [-0.9905, -1.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000258971587754786
Epoch 0, Step 1297: train/loss = 0.6631743907928467, train/raw-loss = 0.6629310250282288, train/logprobs = tensor([[-1.1132, -1.4351],
        [-1.6414, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002434059511870146
Epoch 0, Step 1298: train/loss = 0.6973490715026855, train/raw-loss = 0.6973400115966797, train/logprobs = tensor([[-1.0699, -0.9812],
        [-1.2240, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.111998224398121e-05
Epoch 0, Step 1299: train/loss = 0.7015172243118286, train/raw-loss = 0.7009530067443848, train/logprobs = tensor([[-1.1043, -1.0343],
        [-1.2891, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005641369614750147
Epoch 0, Step 1300: train/loss = 0.6958681344985962, train/raw-loss = 0.6953853368759155, train/logprobs = tensor([[-1.1348, -1.1928],
        [-1.2277, -1.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004827735014259815
Epoch 0, Step 1301: train/loss = 0.6990401148796082, train/raw-loss = 0.6990004777908325, train/logprobs = tensor([[-0.9090, -0.7762],
        [-1.0619, -0.7997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039643188938498497
Epoch 0, Step 1302: train/loss = 0.697608470916748, train/raw-loss = 0.6974200010299683, train/logprobs = tensor([[-0.9551, -0.8526],
        [-1.1616, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018849086482077837
Epoch 0, Step 1303: train/loss = 0.6998878717422485, train/raw-loss = 0.6995470523834229, train/logprobs = tensor([[-1.0816, -0.9066],
        [-1.1578, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034081386402249336
Epoch 0, Step 1304: train/loss = 0.7068402767181396, train/raw-loss = 0.7066445350646973, train/logprobs = tensor([[-0.9709, -0.8287],
        [-1.1710, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019569287542253733
Epoch 0, Step 1305: train/loss = 0.697129487991333, train/raw-loss = 0.6970114707946777, train/logprobs = tensor([[-1.0345, -0.9549],
        [-1.2081, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011792787117883563
Epoch 0, Step 1306: train/loss = 0.7025866508483887, train/raw-loss = 0.702531099319458, train/logprobs = tensor([[-0.8582, -0.8177],
        [-0.9348, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005553829250857234
Epoch 0, Step 1307: train/loss = 0.6943860054016113, train/raw-loss = 0.6943288445472717, train/logprobs = tensor([[-0.9387, -1.0171],
        [-0.9601, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005717787425965071
Epoch 0, Step 1308: train/loss = 0.7020557522773743, train/raw-loss = 0.7020025253295898, train/logprobs = tensor([[-1.0789, -0.9875],
        [-1.1780, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005322227953001857
Epoch 0, Step 1309: train/loss = 0.7083275318145752, train/raw-loss = 0.7083033323287964, train/logprobs = tensor([[-0.9616, -1.0213],
        [-1.0563, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024206464877352118
Epoch 0, Step 1310: train/loss = 0.7146661877632141, train/raw-loss = 0.7146204710006714, train/logprobs = tensor([[-1.1348, -1.1221],
        [-1.1847, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004572605830617249
Epoch 0, Step 1311: train/loss = 0.7039726376533508, train/raw-loss = 0.7039576172828674, train/logprobs = tensor([[-0.7166, -0.7681],
        [-0.7902, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014985783491283655
Epoch 0, Step 1312: train/loss = 0.6952372789382935, train/raw-loss = 0.6949367523193359, train/logprobs = tensor([[-0.9971, -0.9655],
        [-1.0725, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00300514861010015
Epoch 0, Step 1313: train/loss = 0.7028917670249939, train/raw-loss = 0.702501118183136, train/logprobs = tensor([[-1.0548, -0.8857],
        [-1.1452, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003906157100573182
Epoch 0, Step 1314: train/loss = 0.6932387351989746, train/raw-loss = 0.6931391954421997, train/logprobs = tensor([[-1.1011, -1.1379],
        [-1.3327, -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009949197992682457
Epoch 0, Step 1315: train/loss = 0.6972160339355469, train/raw-loss = 0.696941614151001, train/logprobs = tensor([[-1.0845, -1.0329],
        [-1.3505, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027438155375421047
Epoch 0, Step 1316: train/loss = 0.6990134716033936, train/raw-loss = 0.6989219188690186, train/logprobs = tensor([[-0.9967, -1.0677],
        [-1.1341, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009151420090347528
Epoch 0, Step 1317: train/loss = 0.7027610540390015, train/raw-loss = 0.7027262449264526, train/logprobs = tensor([[-0.9834, -0.8705],
        [-1.0863, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003480705199763179
Epoch 0, Step 1318: train/loss = 0.6994566917419434, train/raw-loss = 0.6994113922119141, train/logprobs = tensor([[-1.0707, -0.9818],
        [-1.1947, -1.0219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004532856401056051
Epoch 0, Step 1319: train/loss = 0.6998536586761475, train/raw-loss = 0.699766993522644, train/logprobs = tensor([[-0.9369, -0.8391],
        [-1.0746, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00086707912851125
Epoch 0, Step 1320: train/loss = 0.6977344751358032, train/raw-loss = 0.6974810361862183, train/logprobs = tensor([[-0.9762, -0.8957],
        [-1.0758, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002533789724111557
Epoch 0, Step 1321: train/loss = 0.7661477327346802, train/raw-loss = 0.7659004926681519, train/logprobs = tensor([[-1.2568, -0.7446],
        [-1.3791, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00247202068567276
Epoch 0, Step 1322: train/loss = 0.6941893100738525, train/raw-loss = 0.6941109895706177, train/logprobs = tensor([[-0.8950, -0.9911],
        [-0.9720, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007836759323254228
Epoch 0, Step 1323: train/loss = 0.695121169090271, train/raw-loss = 0.6951016187667847, train/logprobs = tensor([[-0.8475, -0.9735],
        [-0.9656, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019551058358047158
Epoch 0, Step 1324: train/loss = 0.7088977694511414, train/raw-loss = 0.7087445259094238, train/logprobs = tensor([[-1.1426, -1.0342],
        [-1.3375, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015322149265557528
Epoch 0, Step 1325: train/loss = 0.6974457502365112, train/raw-loss = 0.6973885893821716, train/logprobs = tensor([[-0.8550, -0.7653],
        [-0.8766, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005716905579902232
Epoch 0, Step 1326: train/loss = 0.9844093322753906, train/raw-loss = 0.9840368032455444, train/logprobs = tensor([[-1.4083, -2.5681],
        [-1.6056, -2.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003725874237716198
Epoch 0, Step 1327: train/loss = 0.7123528122901917, train/raw-loss = 0.7121407985687256, train/logprobs = tensor([[-1.1475, -0.9961],
        [-1.3140, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002120029414072633
Epoch 0, Step 1328: train/loss = 0.7028423547744751, train/raw-loss = 0.7028117775917053, train/logprobs = tensor([[-0.9385, -1.0329],
        [-1.0577, -1.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030574342235922813
Epoch 0, Step 1329: train/loss = 0.7153631448745728, train/raw-loss = 0.714917778968811, train/logprobs = tensor([[-1.1913, -1.0416],
        [-1.3236, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004453510046005249
Epoch 0, Step 1330: train/loss = 0.7165230512619019, train/raw-loss = 0.716509222984314, train/logprobs = tensor([[-1.1497, -0.8500],
        [-1.2982, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013765641779173166
Epoch 0, Step 1331: train/loss = 0.7118659019470215, train/raw-loss = 0.7118185758590698, train/logprobs = tensor([[-1.0069, -1.0163],
        [-1.1071, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047289248323068023
Epoch 0, Step 1332: train/loss = 0.7181254625320435, train/raw-loss = 0.7181038856506348, train/logprobs = tensor([[-1.1306, -1.0445],
        [-1.1920, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021577777806669474
Epoch 0, Step 1333: train/loss = 0.6948907375335693, train/raw-loss = 0.6947925686836243, train/logprobs = tensor([[-1.0212, -1.1071],
        [-1.1615, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009823159780353308
Epoch 0, Step 1334: train/loss = 0.7137957215309143, train/raw-loss = 0.7137116193771362, train/logprobs = tensor([[-1.3320, -1.0971],
        [-1.4735, -1.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008407223504036665
Epoch 0, Step 1335: train/loss = 0.7095766067504883, train/raw-loss = 0.7094265222549438, train/logprobs = tensor([[-1.2012, -1.1521],
        [-1.3577, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015007273759692907
Epoch 0, Step 1336: train/loss = 0.7150894999504089, train/raw-loss = 0.7150322794914246, train/logprobs = tensor([[-1.2594, -1.0064],
        [-1.3981, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005724146030843258
Epoch 0, Step 1337: train/loss = 0.698652982711792, train/raw-loss = 0.6984193325042725, train/logprobs = tensor([[-1.1758, -1.1695],
        [-1.3730, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023360499180853367
Epoch 0, Step 1338: train/loss = 0.728175699710846, train/raw-loss = 0.7280396223068237, train/logprobs = tensor([[-1.1491, -1.0083],
        [-1.3522, -1.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001360050169751048
Epoch 0, Step 1339: train/loss = 0.732372522354126, train/raw-loss = 0.7321619987487793, train/logprobs = tensor([[-1.0725, -0.8532],
        [-1.2510, -0.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021048998460173607
Epoch 0, Step 1340: train/loss = 0.693600058555603, train/raw-loss = 0.6935198903083801, train/logprobs = tensor([[-1.1179, -1.1660],
        [-1.2064, -1.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008015609928406775
Epoch 0, Step 1341: train/loss = 0.714166522026062, train/raw-loss = 0.7139873504638672, train/logprobs = tensor([[-1.0291, -1.0271],
        [-1.2108, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017917497316375375
Epoch 0, Step 1342: train/loss = 0.7219363451004028, train/raw-loss = 0.7218906879425049, train/logprobs = tensor([[-1.1834, -0.8062],
        [-1.3022, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045690074330195785
Epoch 0, Step 1343: train/loss = 0.7047083377838135, train/raw-loss = 0.7046138644218445, train/logprobs = tensor([[-1.0817, -0.9078],
        [-1.3000, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00094465387519449
Epoch 0, Step 1344: train/loss = 0.7008762359619141, train/raw-loss = 0.7007351517677307, train/logprobs = tensor([[-1.1461, -0.9811],
        [-1.2760, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014113521901890635
Epoch 0, Step 1345: train/loss = 0.7010065913200378, train/raw-loss = 0.7009873390197754, train/logprobs = tensor([[-0.9519, -0.8219],
        [-1.1138, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019287504255771637
Epoch 0, Step 1346: train/loss = 0.6976929903030396, train/raw-loss = 0.6976625919342041, train/logprobs = tensor([[-1.0018, -0.9615],
        [-1.1999, -1.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003039028961211443
Epoch 0, Step 1347: train/loss = 0.6999369859695435, train/raw-loss = 0.6998351812362671, train/logprobs = tensor([[-1.1823, -1.2437],
        [-1.3195, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010181819088757038
Epoch 0, Step 1348: train/loss = 0.6951183676719666, train/raw-loss = 0.695076048374176, train/logprobs = tensor([[-0.9359, -1.0033],
        [-1.0344, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042326253606006503
Epoch 0, Step 1349: train/loss = 0.697853684425354, train/raw-loss = 0.6978001594543457, train/logprobs = tensor([[-1.0099, -1.1756],
        [-1.1220, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000534713501110673
Epoch 0, Step 1350: train/loss = 0.7178923487663269, train/raw-loss = 0.7177798748016357, train/logprobs = tensor([[-1.2865, -0.9463],
        [-1.4662, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011248111259192228
Epoch 0, Step 1351: train/loss = 0.7057033181190491, train/raw-loss = 0.7056417465209961, train/logprobs = tensor([[-0.9252, -0.9603],
        [-0.9696, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006153994472697377
Epoch 0, Step 1352: train/loss = 0.710168719291687, train/raw-loss = 0.710116982460022, train/logprobs = tensor([[-0.9782, -0.9511],
        [-1.1106, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005169693613424897
Epoch 0, Step 1353: train/loss = 0.7082810401916504, train/raw-loss = 0.7081249356269836, train/logprobs = tensor([[-1.0529, -1.2433],
        [-1.2770, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015610221307724714
Epoch 0, Step 1354: train/loss = 0.6971888542175293, train/raw-loss = 0.6963561177253723, train/logprobs = tensor([[-1.0704, -1.1115],
        [-1.2851, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008327695541083813
Epoch 0, Step 1355: train/loss = 0.6983640789985657, train/raw-loss = 0.6982799768447876, train/logprobs = tensor([[-0.9281, -0.8827],
        [-1.0226, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000840295571833849
Epoch 0, Step 1356: train/loss = 0.6961957216262817, train/raw-loss = 0.6961414813995361, train/logprobs = tensor([[-1.0044, -0.9987],
        [-1.1154, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005418399232439697
Epoch 0, Step 1357: train/loss = 0.6937575936317444, train/raw-loss = 0.6937520503997803, train/logprobs = tensor([[-1.0430, -1.0660],
        [-1.0707, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.5637676268815994e-05
Epoch 0, Step 1358: train/loss = 0.685670793056488, train/raw-loss = 0.685321569442749, train/logprobs = tensor([[-1.1098, -1.1950],
        [-1.6404, -1.2571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003491845913231373
Epoch 0, Step 1359: train/loss = 0.6927720904350281, train/raw-loss = 0.6921332478523254, train/logprobs = tensor([[-1.0303, -1.1576],
        [-1.3027, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006388024892657995
Epoch 0, Step 1360: train/loss = 0.697580099105835, train/raw-loss = 0.6974930763244629, train/logprobs = tensor([[-1.2094, -1.4310],
        [-1.3512, -1.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008696872973814607
Epoch 0, Step 1361: train/loss = 0.7216659188270569, train/raw-loss = 0.7212531566619873, train/logprobs = tensor([[-1.1435, -0.8332],
        [-1.3032, -0.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004127823747694492
Epoch 0, Step 1362: train/loss = 0.7418253421783447, train/raw-loss = 0.7416462898254395, train/logprobs = tensor([[-1.3725, -0.9349],
        [-1.4618, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017904385458678007
Epoch 0, Step 1363: train/loss = 0.6993958353996277, train/raw-loss = 0.699325442314148, train/logprobs = tensor([[-0.9589, -0.9095],
        [-0.9944, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007036681054159999
Epoch 0, Step 1364: train/loss = 0.693549394607544, train/raw-loss = 0.693267285823822, train/logprobs = tensor([[-1.2726, -1.2936],
        [-1.5761, -1.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002821306698024273
Epoch 0, Step 1365: train/loss = 0.7205151915550232, train/raw-loss = 0.7204005718231201, train/logprobs = tensor([[-1.1236, -0.8360],
        [-1.1787, -0.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011468182783573866
Epoch 0, Step 1366: train/loss = 0.7049251198768616, train/raw-loss = 0.7048401832580566, train/logprobs = tensor([[-0.6697, -0.8413],
        [-0.6901, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008489605970680714
Epoch 0, Step 1367: train/loss = 0.6991927027702332, train/raw-loss = 0.6978442072868347, train/logprobs = tensor([[-0.9259, -1.4092],
        [-1.1535, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013484214432537556
Epoch 0, Step 1368: train/loss = 0.709346354007721, train/raw-loss = 0.709233283996582, train/logprobs = tensor([[-1.1135, -1.0911],
        [-1.2142, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001130585791543126
Epoch 0, Step 1369: train/loss = 0.7108227014541626, train/raw-loss = 0.7107423543930054, train/logprobs = tensor([[-1.0869, -0.8905],
        [-1.1719, -0.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008038656669668853
Epoch 0, Step 1370: train/loss = 0.717215895652771, train/raw-loss = 0.717106282711029, train/logprobs = tensor([[-0.9119, -0.6935],
        [-0.9701, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010959231294691563
Epoch 0, Step 1371: train/loss = 0.6997246146202087, train/raw-loss = 0.6997098326683044, train/logprobs = tensor([[-1.0829, -0.9525],
        [-1.2735, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014702111366204917
Epoch 0, Step 1372: train/loss = 0.7097756862640381, train/raw-loss = 0.7095876932144165, train/logprobs = tensor([[-1.2314, -1.2026],
        [-1.3708, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018793889321386814
Epoch 0, Step 1373: train/loss = 0.7033684253692627, train/raw-loss = 0.7033166885375977, train/logprobs = tensor([[-0.9948, -0.7808],
        [-1.2271, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005178081337362528
Epoch 0, Step 1374: train/loss = 0.698034405708313, train/raw-loss = 0.6979009509086609, train/logprobs = tensor([[-1.1635, -1.3563],
        [-1.4623, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013338117860257626
Epoch 0, Step 1375: train/loss = 0.7003471851348877, train/raw-loss = 0.7001287937164307, train/logprobs = tensor([[-1.2770, -1.2193],
        [-1.3704, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00218418100848794
Epoch 0, Step 1376: train/loss = 0.6923523545265198, train/raw-loss = 0.692091703414917, train/logprobs = tensor([[-1.0461, -1.1023],
        [-1.2198, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026066889986395836
Epoch 0, Step 1377: train/loss = 0.6934829950332642, train/raw-loss = 0.6934571266174316, train/logprobs = tensor([[-0.8768, -0.8961],
        [-0.9300, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025815528351813555
Epoch 0, Step 1378: train/loss = 0.6993272304534912, train/raw-loss = 0.6988565921783447, train/logprobs = tensor([[-1.2089, -1.1738],
        [-1.3808, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004706461913883686
Epoch 0, Step 1379: train/loss = 0.6984015703201294, train/raw-loss = 0.6983644962310791, train/logprobs = tensor([[-1.0986, -1.0056],
        [-1.3013, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003708342555910349
Epoch 0, Step 1380: train/loss = 0.7024537324905396, train/raw-loss = 0.70244300365448, train/logprobs = tensor([[-0.9390, -0.8773],
        [-1.0409, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001064842872438021
Epoch 0, Step 1381: train/loss = 0.6960369348526001, train/raw-loss = 0.6959347724914551, train/logprobs = tensor([[-0.9654, -1.2271],
        [-1.1766, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001020896015688777
Epoch 0, Step 1382: train/loss = 0.7097485661506653, train/raw-loss = 0.7095553874969482, train/logprobs = tensor([[-1.0459, -0.9473],
        [-1.2817, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001931759063154459
Epoch 0, Step 1383: train/loss = 0.6965928077697754, train/raw-loss = 0.6959141492843628, train/logprobs = tensor([[-0.9185, -0.9193],
        [-1.0556, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067861019633710384
Epoch 0, Step 1384: train/loss = 0.7013258934020996, train/raw-loss = 0.7009808421134949, train/logprobs = tensor([[-1.0011, -0.9400],
        [-1.0805, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003450860269367695
Epoch 0, Step 1385: train/loss = 0.7055536508560181, train/raw-loss = 0.705279529094696, train/logprobs = tensor([[-1.0289, -1.0408],
        [-1.1615, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027415500953793526
Epoch 0, Step 1386: train/loss = 0.6960645914077759, train/raw-loss = 0.6958799362182617, train/logprobs = tensor([[-1.1195, -1.0392],
        [-1.1400, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001846156781539321
Epoch 0, Step 1387: train/loss = 0.6926197409629822, train/raw-loss = 0.6922657489776611, train/logprobs = tensor([[-0.9846, -1.0518],
        [-1.2452, -1.0130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035401058848947287
Epoch 0, Step 1388: train/loss = 0.7107968330383301, train/raw-loss = 0.7107146978378296, train/logprobs = tensor([[-1.1628, -1.1772],
        [-1.3519, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008219932205975056
Epoch 0, Step 1389: train/loss = 0.6984841823577881, train/raw-loss = 0.6984792351722717, train/logprobs = tensor([[-0.9192, -0.9817],
        [-1.0201, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.974822513759136e-05
Epoch 0, Step 1390: train/loss = 0.696660578250885, train/raw-loss = 0.6966533660888672, train/logprobs = tensor([[-1.0989, -1.0164],
        [-1.1232, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.270195055752993e-05
Epoch 0, Step 1391: train/loss = 0.7059903740882874, train/raw-loss = 0.7059537172317505, train/logprobs = tensor([[-1.0870, -1.0303],
        [-1.1139, -1.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036654563155025244
Epoch 0, Step 1392: train/loss = 0.6935253739356995, train/raw-loss = 0.6935073733329773, train/logprobs = tensor([[-1.1107, -1.1120],
        [-1.1794, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017948425374925137
Epoch 0, Step 1393: train/loss = 0.6922142505645752, train/raw-loss = 0.6920763254165649, train/logprobs = tensor([[-0.9914, -1.0289],
        [-1.0844, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013786680065095425
Epoch 0, Step 1394: train/loss = 0.7272956967353821, train/raw-loss = 0.7264417409896851, train/logprobs = tensor([[-0.9198, -1.5534],
        [-1.0971, -1.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008540012873709202
Epoch 0, Step 1395: train/loss = 0.6973795890808105, train/raw-loss = 0.6973397135734558, train/logprobs = tensor([[-1.2101, -1.1689],
        [-1.2626, -1.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039908383041620255
Epoch 0, Step 1396: train/loss = 0.7057355046272278, train/raw-loss = 0.7057024240493774, train/logprobs = tensor([[-0.9766, -0.9183],
        [-1.1329, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033015961525961757
Epoch 0, Step 1397: train/loss = 0.6961807012557983, train/raw-loss = 0.696155846118927, train/logprobs = tensor([[-1.1030, -1.1719],
        [-1.2305, -1.2050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024857139214873314
Epoch 0, Step 1398: train/loss = 0.7310914397239685, train/raw-loss = 0.7310012578964233, train/logprobs = tensor([[-1.2350, -1.0564],
        [-1.4493, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009014187380671501
Epoch 0, Step 1399: train/loss = 0.7080696821212769, train/raw-loss = 0.7078608274459839, train/logprobs = tensor([[-0.9573, -0.9153],
        [-1.0638, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020891581661999226
Epoch 0, Step 1400: train/loss = 0.7468414306640625, train/raw-loss = 0.7464615106582642, train/logprobs = tensor([[-1.1394, -0.7308],
        [-1.4272, -0.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037987693212926388
Epoch 0, Step 1401: train/loss = 0.737662672996521, train/raw-loss = 0.7373847961425781, train/logprobs = tensor([[-1.0865, -0.7310],
        [-1.3539, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027791622560471296
Epoch 0, Step 1402: train/loss = 0.6937629580497742, train/raw-loss = 0.6937161684036255, train/logprobs = tensor([[-1.1357, -1.0838],
        [-1.1965, -1.0189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046698583173565567
Epoch 0, Step 1403: train/loss = 0.6973205208778381, train/raw-loss = 0.696951150894165, train/logprobs = tensor([[-0.9282, -0.9503],
        [-1.2118, -0.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036949252244085073
Epoch 0, Step 1404: train/loss = 0.7023838758468628, train/raw-loss = 0.7023532390594482, train/logprobs = tensor([[-1.0136, -0.9428],
        [-1.0643, -0.9614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003063644398935139
Epoch 0, Step 1405: train/loss = 0.7119708061218262, train/raw-loss = 0.7118735909461975, train/logprobs = tensor([[-1.1744, -0.9664],
        [-1.3624, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009716670028865337
Epoch 0, Step 1406: train/loss = 0.7042927742004395, train/raw-loss = 0.7042461633682251, train/logprobs = tensor([[-1.0161, -0.9366],
        [-1.1821, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004655274096876383
Epoch 0, Step 1407: train/loss = 0.7037169933319092, train/raw-loss = 0.7033135294914246, train/logprobs = tensor([[-1.0798, -1.0888],
        [-1.2710, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004034159239381552
Epoch 0, Step 1408: train/loss = 0.7041593790054321, train/raw-loss = 0.7040567398071289, train/logprobs = tensor([[-1.0733, -1.2888],
        [-1.2185, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010259083937853575
Epoch 0, Step 1409: train/loss = 0.7191818952560425, train/raw-loss = 0.7188925743103027, train/logprobs = tensor([[-0.9328, -0.7778],
        [-1.1966, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002892765449360013
Epoch 0, Step 1410: train/loss = 0.7712868452072144, train/raw-loss = 0.7711262106895447, train/logprobs = tensor([[-1.2656, -0.7853],
        [-1.5215, -0.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001606799429282546
Epoch 0, Step 1411: train/loss = 0.6954582333564758, train/raw-loss = 0.6952486038208008, train/logprobs = tensor([[-1.0673, -1.0960],
        [-1.2408, -1.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020962790586054325
Epoch 0, Step 1412: train/loss = 0.7006564140319824, train/raw-loss = 0.700316309928894, train/logprobs = tensor([[-1.3048, -1.2560],
        [-1.5481, -1.3022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034011462703347206
Epoch 0, Step 1413: train/loss = 0.6973199844360352, train/raw-loss = 0.6972775459289551, train/logprobs = tensor([[-1.0559, -0.9839],
        [-1.1424, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042490049963817
Epoch 0, Step 1414: train/loss = 0.7229810953140259, train/raw-loss = 0.7226204872131348, train/logprobs = tensor([[-1.1509, -1.0784],
        [-1.4736, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036060449201613665
Epoch 0, Step 1415: train/loss = 0.6975635290145874, train/raw-loss = 0.6975572109222412, train/logprobs = tensor([[-0.8713, -0.9498],
        [-1.0021, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.320781540125608e-05
Epoch 0, Step 1416: train/loss = 0.7079139351844788, train/raw-loss = 0.7077058553695679, train/logprobs = tensor([[-1.4766, -1.6103],
        [-1.5164, -1.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00208122911863029
Epoch 0, Step 1417: train/loss = 0.6946728825569153, train/raw-loss = 0.6945736408233643, train/logprobs = tensor([[-1.0529, -1.1047],
        [-1.0801, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009925442282110453
Epoch 0, Step 1418: train/loss = 0.6983965635299683, train/raw-loss = 0.6983201503753662, train/logprobs = tensor([[-1.1393, -1.1533],
        [-1.2009, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007636998780071735
Epoch 0, Step 1419: train/loss = 0.6983243823051453, train/raw-loss = 0.698208749294281, train/logprobs = tensor([[-1.0506, -1.0125],
        [-1.1337, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011564214946702123
Epoch 0, Step 1420: train/loss = 0.7062168717384338, train/raw-loss = 0.705956757068634, train/logprobs = tensor([[-1.0574, -1.2886],
        [-1.3063, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00260075181722641
Epoch 0, Step 1421: train/loss = 0.6983462572097778, train/raw-loss = 0.6983202695846558, train/logprobs = tensor([[-0.8688, -0.8635],
        [-1.0577, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025999045465141535
Epoch 0, Step 1422: train/loss = 0.699051022529602, train/raw-loss = 0.6989559531211853, train/logprobs = tensor([[-0.8541, -0.9797],
        [-0.9515, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009506803471595049
Epoch 0, Step 1423: train/loss = 0.6955388784408569, train/raw-loss = 0.6955356597900391, train/logprobs = tensor([[-0.9815, -0.9683],
        [-1.1015, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2486728741787374e-05
Epoch 0, Step 1424: train/loss = 0.6958363056182861, train/raw-loss = 0.6956061124801636, train/logprobs = tensor([[-1.1466, -1.0380],
        [-1.4130, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002301942091435194
Epoch 0, Step 1425: train/loss = 0.7053796052932739, train/raw-loss = 0.7052007913589478, train/logprobs = tensor([[-1.1197, -0.9950],
        [-1.4152, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017889884766191244
Epoch 0, Step 1426: train/loss = 0.7066987156867981, train/raw-loss = 0.7059062719345093, train/logprobs = tensor([[-0.9366, -1.1070],
        [-1.1882, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007924322970211506
Epoch 0, Step 1427: train/loss = 0.8221582174301147, train/raw-loss = 0.8201366066932678, train/logprobs = tensor([[-1.1496, -1.8322],
        [-1.2319, -1.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020216111093759537
Epoch 0, Step 1428: train/loss = 0.697748064994812, train/raw-loss = 0.6973934769630432, train/logprobs = tensor([[-1.2441, -1.1953],
        [-1.4945, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035453601740300655
Epoch 0, Step 1429: train/loss = 0.7025021910667419, train/raw-loss = 0.7023321986198425, train/logprobs = tensor([[-0.9458, -0.9540],
        [-1.0836, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016996508929878473
Epoch 0, Step 1430: train/loss = 0.7092146277427673, train/raw-loss = 0.7091135382652283, train/logprobs = tensor([[-0.9793, -0.9447],
        [-1.2821, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010109033901244402
Epoch 0, Step 1431: train/loss = 0.6616665124893188, train/raw-loss = 0.6610794067382812, train/logprobs = tensor([[-1.0422, -1.2433],
        [-1.6915, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005870892200618982
Epoch 0, Step 1432: train/loss = 0.7015601992607117, train/raw-loss = 0.7010447382926941, train/logprobs = tensor([[-1.0264, -0.9141],
        [-1.4134, -0.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005154557526111603
Epoch 0, Step 1433: train/loss = 0.6969092488288879, train/raw-loss = 0.6969059109687805, train/logprobs = tensor([[-1.0148, -0.9695],
        [-1.1036, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.299798117950559e-05
Epoch 0, Step 1434: train/loss = 0.6929683685302734, train/raw-loss = 0.6928806900978088, train/logprobs = tensor([[-0.9409, -0.9662],
        [-1.1045, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008764881640672684
Epoch 0, Step 1435: train/loss = 0.7129150032997131, train/raw-loss = 0.7126365900039673, train/logprobs = tensor([[-1.1278, -0.8844],
        [-1.3408, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027838540263473988
Epoch 0, Step 1436: train/loss = 0.7093786597251892, train/raw-loss = 0.7093294858932495, train/logprobs = tensor([[-1.1343, -1.3020],
        [-1.3012, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004921864019706845
Epoch 0, Step 1437: train/loss = 0.7139651775360107, train/raw-loss = 0.713801920413971, train/logprobs = tensor([[-1.0118, -0.8299],
        [-1.1605, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016327154589816928
Epoch 0, Step 1438: train/loss = 0.7095114588737488, train/raw-loss = 0.7093381285667419, train/logprobs = tensor([[-1.3124, -1.2611],
        [-1.4507, -1.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017329854890704155
Epoch 0, Step 1439: train/loss = 0.6953599452972412, train/raw-loss = 0.695172905921936, train/logprobs = tensor([[-1.1158, -1.3147],
        [-1.2785, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001869876403361559
Epoch 0, Step 1440: train/loss = 0.7033470869064331, train/raw-loss = 0.7033088207244873, train/logprobs = tensor([[-1.2101, -1.5293],
        [-1.2916, -1.4277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003837132826447487
Epoch 0, Step 1441: train/loss = 0.7003661394119263, train/raw-loss = 0.6990029811859131, train/logprobs = tensor([[-0.7658, -0.6926],
        [-0.8224, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013631586916744709
Epoch 0, Step 1442: train/loss = 0.7014263868331909, train/raw-loss = 0.7011770606040955, train/logprobs = tensor([[-1.0261, -0.8898],
        [-1.1414, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002493626903742552
Epoch 0, Step 1443: train/loss = 0.7129732966423035, train/raw-loss = 0.712766170501709, train/logprobs = tensor([[-1.2996, -1.0667],
        [-1.5662, -1.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020712828263640404
Epoch 0, Step 1444: train/loss = 0.7095504999160767, train/raw-loss = 0.7095321416854858, train/logprobs = tensor([[-1.2920, -1.2829],
        [-1.4847, -1.2865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001834473223425448
Epoch 0, Step 1445: train/loss = 0.6938624382019043, train/raw-loss = 0.6938233375549316, train/logprobs = tensor([[-1.0639, -1.1072],
        [-1.2950, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039161869790405035
Epoch 0, Step 1446: train/loss = 0.7359341382980347, train/raw-loss = 0.7357355356216431, train/logprobs = tensor([[-1.1493, -0.7674],
        [-1.3080, -0.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019860640168190002
Epoch 0, Step 1447: train/loss = 0.703341543674469, train/raw-loss = 0.7031071782112122, train/logprobs = tensor([[-0.8309, -0.6547],
        [-0.9867, -0.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002343595027923584
Epoch 0, Step 1448: train/loss = 0.6971620321273804, train/raw-loss = 0.6968917846679688, train/logprobs = tensor([[-0.9256, -0.8356],
        [-1.0428, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027032652869820595
Epoch 0, Step 1449: train/loss = 0.7066493630409241, train/raw-loss = 0.7063775062561035, train/logprobs = tensor([[-1.2638, -1.0425],
        [-1.4367, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027188407257199287
Epoch 0, Step 1450: train/loss = 0.7011265754699707, train/raw-loss = 0.7010399103164673, train/logprobs = tensor([[-1.3007, -1.2681],
        [-1.3907, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008670988027006388
Epoch 0, Step 1451: train/loss = 0.7114031314849854, train/raw-loss = 0.7113191485404968, train/logprobs = tensor([[-1.3249, -1.0851],
        [-1.5377, -1.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000840203370898962
Epoch 0, Step 1452: train/loss = 0.7051191926002502, train/raw-loss = 0.7049202919006348, train/logprobs = tensor([[-1.0152, -0.8796],
        [-1.1229, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001989003736525774
Epoch 0, Step 1453: train/loss = 0.695679247379303, train/raw-loss = 0.6956108212471008, train/logprobs = tensor([[-1.0495, -0.9853],
        [-1.2167, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006842662114650011
Epoch 0, Step 1454: train/loss = 0.6940177083015442, train/raw-loss = 0.6937535405158997, train/logprobs = tensor([[-1.1381, -1.3107],
        [-1.3189, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002641514642164111
Epoch 0, Step 1455: train/loss = 0.6992455720901489, train/raw-loss = 0.6986280679702759, train/logprobs = tensor([[-1.1844, -1.1204],
        [-1.5463, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006175224203616381
Epoch 0, Step 1456: train/loss = 0.6960262060165405, train/raw-loss = 0.6958123445510864, train/logprobs = tensor([[-1.0010, -1.3951],
        [-1.3451, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002138232346624136
Epoch 0, Step 1457: train/loss = 0.7090781331062317, train/raw-loss = 0.7088912725448608, train/logprobs = tensor([[-0.9537, -0.9591],
        [-1.5392, -0.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001868946012109518
Epoch 0, Step 1458: train/loss = 0.6957629323005676, train/raw-loss = 0.6957021951675415, train/logprobs = tensor([[-0.9984, -0.9280],
        [-1.1093, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000607621856033802
Epoch 0, Step 1459: train/loss = 0.7224231362342834, train/raw-loss = 0.7223793268203735, train/logprobs = tensor([[-1.0214, -0.7126],
        [-1.1044, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004382479237392545
Epoch 0, Step 1460: train/loss = 0.7040650844573975, train/raw-loss = 0.7039458155632019, train/logprobs = tensor([[-1.2526, -1.1310],
        [-1.5025, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001193037023767829
Epoch 0, Step 1461: train/loss = 0.7007677555084229, train/raw-loss = 0.700666069984436, train/logprobs = tensor([[-1.0450, -1.2179],
        [-1.1416, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001015897374600172
Epoch 0, Step 1462: train/loss = 0.6955095529556274, train/raw-loss = 0.6953824162483215, train/logprobs = tensor([[-1.0916, -1.0296],
        [-1.2124, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012709349393844604
Epoch 0, Step 1463: train/loss = 0.698795735836029, train/raw-loss = 0.6987926959991455, train/logprobs = tensor([[-1.1100, -1.0016],
        [-1.2225, -1.0815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9849790735170245e-05
Epoch 0, Step 1464: train/loss = 0.7092025876045227, train/raw-loss = 0.709121823310852, train/logprobs = tensor([[-1.0696, -1.1993],
        [-1.3200, -1.2521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008074227953329682
Epoch 0, Step 1465: train/loss = 0.7080202102661133, train/raw-loss = 0.7079544067382812, train/logprobs = tensor([[-0.9780, -0.8714],
        [-1.4168, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006582913920283318
Epoch 0, Step 1466: train/loss = 0.7065265774726868, train/raw-loss = 0.7061434984207153, train/logprobs = tensor([[-1.1609, -1.4684],
        [-1.2550, -1.3851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003830875502899289
Epoch 0, Step 1467: train/loss = 0.7081722021102905, train/raw-loss = 0.708081841468811, train/logprobs = tensor([[-1.0181, -1.0713],
        [-1.2750, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009041231824085116
Epoch 0, Step 1468: train/loss = 0.6972007751464844, train/raw-loss = 0.6962862014770508, train/logprobs = tensor([[-1.3275, -1.2387],
        [-1.5399, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009145894087851048
Epoch 0, Step 1469: train/loss = 0.6984597444534302, train/raw-loss = 0.6984421014785767, train/logprobs = tensor([[-1.0524, -1.1850],
        [-1.2758, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017594045493751764
Epoch 0, Step 1470: train/loss = 0.7066752314567566, train/raw-loss = 0.7065377831459045, train/logprobs = tensor([[-1.0944, -0.9554],
        [-1.2691, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013740886934101582
Epoch 0, Step 1471: train/loss = 0.6938012838363647, train/raw-loss = 0.6937496066093445, train/logprobs = tensor([[-1.1395, -1.1261],
        [-1.2555, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005163252353668213
Epoch 0, Step 1472: train/loss = 0.7236566543579102, train/raw-loss = 0.7235853672027588, train/logprobs = tensor([[-1.1360, -1.3571],
        [-1.2146, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007117995410226285
Epoch 0, Step 1473: train/loss = 0.7394399046897888, train/raw-loss = 0.739010214805603, train/logprobs = tensor([[-1.2718, -0.8581],
        [-1.6035, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004296191036701202
Epoch 0, Step 1474: train/loss = 0.7239026427268982, train/raw-loss = 0.7237870693206787, train/logprobs = tensor([[-1.2622, -1.3146],
        [-1.3153, -1.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011563379084691405
Epoch 0, Step 1475: train/loss = 0.7295396327972412, train/raw-loss = 0.7293333411216736, train/logprobs = tensor([[-1.2405, -0.8662],
        [-1.4746, -0.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020633055828511715
Epoch 0, Step 1476: train/loss = 0.7012321949005127, train/raw-loss = 0.701147735118866, train/logprobs = tensor([[-1.0157, -0.8598],
        [-1.0776, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000845187169034034
Epoch 0, Step 1477: train/loss = 0.7027573585510254, train/raw-loss = 0.7026386260986328, train/logprobs = tensor([[-1.0439, -0.8272],
        [-1.1671, -0.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011877149809151888
Epoch 0, Step 1478: train/loss = 0.7251038551330566, train/raw-loss = 0.7250027656555176, train/logprobs = tensor([[-1.0766, -0.7146],
        [-1.1097, -0.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010106259724125266
Epoch 0, Step 1479: train/loss = 0.7080798745155334, train/raw-loss = 0.7078267931938171, train/logprobs = tensor([[-1.1688, -0.9316],
        [-1.3693, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002529812976717949
Epoch 0, Step 1480: train/loss = 0.6952427625656128, train/raw-loss = 0.6952359676361084, train/logprobs = tensor([[-1.1152, -1.0910],
        [-1.1762, -1.1241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.828064215369523e-05
Epoch 0, Step 1481: train/loss = 0.7145358324050903, train/raw-loss = 0.7144673466682434, train/logprobs = tensor([[-1.1359, -0.8481],
        [-1.2278, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000685739447362721
Epoch 0, Step 1482: train/loss = 0.7056164741516113, train/raw-loss = 0.7055151462554932, train/logprobs = tensor([[-0.9442, -0.7298],
        [-1.0011, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010127673158422112
Epoch 0, Step 1483: train/loss = 0.7346699237823486, train/raw-loss = 0.7345010638237, train/logprobs = tensor([[-0.9811, -1.0654],
        [-1.0657, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016887307865545154
Epoch 0, Step 1484: train/loss = 0.7005719542503357, train/raw-loss = 0.7000426054000854, train/logprobs = tensor([[-1.1317, -1.1055],
        [-1.3281, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005294389557093382
Epoch 0, Step 1485: train/loss = 0.6975589990615845, train/raw-loss = 0.6973875761032104, train/logprobs = tensor([[-1.1419, -1.3985],
        [-1.4001, -1.2925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001713752979412675
Epoch 0, Step 1486: train/loss = 0.7018151879310608, train/raw-loss = 0.701697051525116, train/logprobs = tensor([[-1.0730, -1.2236],
        [-1.1377, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00118108163587749
Epoch 0, Step 1487: train/loss = 0.7188559770584106, train/raw-loss = 0.7188011407852173, train/logprobs = tensor([[-0.9268, -0.8784],
        [-1.0440, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005489041795954108
Epoch 0, Step 1488: train/loss = 0.7158827185630798, train/raw-loss = 0.71574866771698, train/logprobs = tensor([[-1.0208, -0.6940],
        [-0.9864, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001340377377346158
Epoch 0, Step 1489: train/loss = 0.695254921913147, train/raw-loss = 0.6951929330825806, train/logprobs = tensor([[-1.2299, -1.1445],
        [-1.3928, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006197481416165829
Epoch 0, Step 1490: train/loss = 0.7325018048286438, train/raw-loss = 0.7324600219726562, train/logprobs = tensor([[-1.2831, -1.0221],
        [-1.4275, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004176833026576787
Epoch 0, Step 1491: train/loss = 0.6851580739021301, train/raw-loss = 0.6849163174629211, train/logprobs = tensor([[-0.9813, -1.3518],
        [-1.4138, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002417468000203371
Epoch 0, Step 1492: train/loss = 0.7027009725570679, train/raw-loss = 0.7026453614234924, train/logprobs = tensor([[-1.1104, -0.9227],
        [-1.1735, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005557972472161055
Epoch 0, Step 1493: train/loss = 0.7226588726043701, train/raw-loss = 0.7223847508430481, train/logprobs = tensor([[-0.9576, -0.9753],
        [-1.1870, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027417726814746857
Epoch 0, Step 1494: train/loss = 0.6961790323257446, train/raw-loss = 0.6961585283279419, train/logprobs = tensor([[-1.0962, -0.9973],
        [-1.1734, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020526035223156214
Epoch 0, Step 1495: train/loss = 0.6990385055541992, train/raw-loss = 0.6989454030990601, train/logprobs = tensor([[-1.0442, -1.1830],
        [-1.1716, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009307667496614158
Epoch 0, Step 1496: train/loss = 0.741702675819397, train/raw-loss = 0.741592288017273, train/logprobs = tensor([[-0.8412, -0.7886],
        [-1.0228, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011042404221370816
Epoch 0, Step 1497: train/loss = 0.7232493162155151, train/raw-loss = 0.7229667901992798, train/logprobs = tensor([[-1.2898, -0.9421],
        [-1.4885, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028252331539988518
Epoch 0, Step 1498: train/loss = 0.7078730463981628, train/raw-loss = 0.7075239419937134, train/logprobs = tensor([[-1.1008, -1.3886],
        [-1.2337, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034910915419459343
Epoch 0, Step 1499: train/loss = 0.7171397805213928, train/raw-loss = 0.7167403697967529, train/logprobs = tensor([[-1.0351, -1.0537],
        [-1.2248, -0.9930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003993961960077286
eval/loss: 0.7041209936141968
Epoch 0, Step 1500: train/loss = 0.7006732225418091, train/raw-loss = 0.7006582021713257, train/logprobs = tensor([[-0.8581, -1.0513],
        [-0.8639, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015036750119179487
Epoch 0, Step 1501: train/loss = 0.7160111665725708, train/raw-loss = 0.7159690856933594, train/logprobs = tensor([[-1.2340, -0.9857],
        [-1.2796, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042097270488739014
Epoch 0, Step 1502: train/loss = 0.7257862687110901, train/raw-loss = 0.7257235050201416, train/logprobs = tensor([[-1.1610, -1.0139],
        [-1.2354, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006272261380217969
Epoch 0, Step 1503: train/loss = 0.7092604041099548, train/raw-loss = 0.7087808847427368, train/logprobs = tensor([[-0.9406, -0.9313],
        [-1.1874, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00479522068053484
Epoch 0, Step 1504: train/loss = 0.6977292895317078, train/raw-loss = 0.6974294185638428, train/logprobs = tensor([[-1.2219, -1.1202],
        [-1.5778, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002998046111315489
Epoch 0, Step 1505: train/loss = 0.7013998627662659, train/raw-loss = 0.7013444900512695, train/logprobs = tensor([[-0.8827, -0.8274],
        [-1.0333, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005536501994356513
Epoch 0, Step 1506: train/loss = 0.710163950920105, train/raw-loss = 0.7097800970077515, train/logprobs = tensor([[-1.0414, -0.9401],
        [-1.3799, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038390480913221836
Epoch 0, Step 1507: train/loss = 0.699100136756897, train/raw-loss = 0.6986128687858582, train/logprobs = tensor([[-0.9630, -0.9481],
        [-1.0935, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0048728869296610355
Epoch 0, Step 1508: train/loss = 0.7198335528373718, train/raw-loss = 0.7196818590164185, train/logprobs = tensor([[-0.9248, -0.8151],
        [-0.9948, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015171428676694632
Epoch 0, Step 1509: train/loss = 0.7068606019020081, train/raw-loss = 0.7064586877822876, train/logprobs = tensor([[-0.9464, -1.2995],
        [-1.0838, -1.1774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004019212443381548
Epoch 0, Step 1510: train/loss = 0.7253267765045166, train/raw-loss = 0.7252533435821533, train/logprobs = tensor([[-1.1615, -0.7887],
        [-1.2926, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007345426711253822
Epoch 0, Step 1511: train/loss = 0.6986257433891296, train/raw-loss = 0.6984691619873047, train/logprobs = tensor([[-0.9907, -0.9166],
        [-1.2088, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015660574426874518
Epoch 0, Step 1512: train/loss = 0.6971009969711304, train/raw-loss = 0.6969395875930786, train/logprobs = tensor([[-1.1289, -1.1214],
        [-1.3250, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016139461658895016
Epoch 0, Step 1513: train/loss = 0.6986619830131531, train/raw-loss = 0.6985301375389099, train/logprobs = tensor([[-0.9264, -0.8054],
        [-1.0135, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013186237774789333
Epoch 0, Step 1514: train/loss = 0.6945461630821228, train/raw-loss = 0.6942853927612305, train/logprobs = tensor([[-1.1019, -1.2087],
        [-1.3160, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002607984934002161
Epoch 0, Step 1515: train/loss = 0.6975877285003662, train/raw-loss = 0.6972733736038208, train/logprobs = tensor([[-0.9646, -1.1561],
        [-1.2163, -1.0929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003143162000924349
Epoch 0, Step 1516: train/loss = 0.7002536654472351, train/raw-loss = 0.7001492381095886, train/logprobs = tensor([[-0.9186, -0.9542],
        [-0.9787, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010446881642565131
Epoch 0, Step 1517: train/loss = 0.7021439671516418, train/raw-loss = 0.701820969581604, train/logprobs = tensor([[-0.9884, -0.9666],
        [-1.1779, -1.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003229893743991852
Epoch 0, Step 1518: train/loss = 0.7050887942314148, train/raw-loss = 0.705081582069397, train/logprobs = tensor([[-1.1317, -1.1969],
        [-1.2567, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.261768041644245e-05
Epoch 0, Step 1519: train/loss = 0.7020063996315002, train/raw-loss = 0.7019426226615906, train/logprobs = tensor([[-0.8871, -1.1887],
        [-0.9010, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006378809339366853
Epoch 0, Step 1520: train/loss = 0.6923502087593079, train/raw-loss = 0.6922807693481445, train/logprobs = tensor([[-1.0729, -1.0974],
        [-1.1622, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006946010398678482
Epoch 0, Step 1521: train/loss = 0.710064172744751, train/raw-loss = 0.7099611163139343, train/logprobs = tensor([[-1.2014, -0.9832],
        [-1.3278, -0.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010306666372343898
Epoch 0, Step 1522: train/loss = 0.7039276361465454, train/raw-loss = 0.7038707733154297, train/logprobs = tensor([[-1.1092, -0.9636],
        [-1.2024, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000569315510801971
Epoch 0, Step 1523: train/loss = 0.6995753645896912, train/raw-loss = 0.6995660066604614, train/logprobs = tensor([[-1.0998, -1.0616],
        [-1.2106, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.362859418615699e-05
Epoch 0, Step 1524: train/loss = 0.6991169452667236, train/raw-loss = 0.6989758610725403, train/logprobs = tensor([[-1.1633, -1.1390],
        [-1.2868, -1.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014109970070421696
Epoch 0, Step 1525: train/loss = 0.7068275213241577, train/raw-loss = 0.7065415382385254, train/logprobs = tensor([[-0.9687, -0.9036],
        [-1.1550, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028600823134183884
Epoch 0, Step 1526: train/loss = 0.7005172371864319, train/raw-loss = 0.7004747986793518, train/logprobs = tensor([[-0.9840, -0.8415],
        [-0.9846, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042433227645233274
Epoch 0, Step 1527: train/loss = 0.6988345384597778, train/raw-loss = 0.6984966993331909, train/logprobs = tensor([[-1.1577, -1.2419],
        [-1.5183, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033789267763495445
Epoch 0, Step 1528: train/loss = 0.7043433785438538, train/raw-loss = 0.7042908668518066, train/logprobs = tensor([[-1.1281, -0.9901],
        [-1.2167, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005255969008430839
Epoch 0, Step 1529: train/loss = 0.7080872058868408, train/raw-loss = 0.7080239057540894, train/logprobs = tensor([[-1.0971, -0.9589],
        [-1.1692, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006333688506856561
Epoch 0, Step 1530: train/loss = 0.6965456008911133, train/raw-loss = 0.6965129971504211, train/logprobs = tensor([[-0.8711, -1.0085],
        [-1.0028, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003257187199778855
Epoch 0, Step 1531: train/loss = 0.708656370639801, train/raw-loss = 0.7084997892379761, train/logprobs = tensor([[-0.7873, -0.7207],
        [-0.9841, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015655448660254478
Epoch 0, Step 1532: train/loss = 0.6974453926086426, train/raw-loss = 0.6970231533050537, train/logprobs = tensor([[-1.0188, -1.1521],
        [-1.2203, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004222184419631958
Epoch 0, Step 1533: train/loss = 0.6940425038337708, train/raw-loss = 0.6939700841903687, train/logprobs = tensor([[-1.1171, -1.2034],
        [-1.2867, -1.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007244910229928792
Epoch 0, Step 1534: train/loss = 0.720517635345459, train/raw-loss = 0.7204057574272156, train/logprobs = tensor([[-1.4102, -1.1182],
        [-1.6836, -1.2952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011188266798853874
Epoch 0, Step 1535: train/loss = 0.695740818977356, train/raw-loss = 0.6957376003265381, train/logprobs = tensor([[-1.1977, -1.1304],
        [-1.3654, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2171876227948815e-05
Epoch 0, Step 1536: train/loss = 0.6898144483566284, train/raw-loss = 0.689684271812439, train/logprobs = tensor([[-1.0599, -1.1878],
        [-1.1591, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013018175959587097
Epoch 0, Step 1537: train/loss = 0.7044527530670166, train/raw-loss = 0.7040045857429504, train/logprobs = tensor([[-1.0970, -0.8589],
        [-1.2509, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004481036216020584
Epoch 0, Step 1538: train/loss = 0.6980404853820801, train/raw-loss = 0.6977260708808899, train/logprobs = tensor([[-0.9806, -0.9505],
        [-1.1687, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003143924754112959
Epoch 0, Step 1539: train/loss = 0.6978827118873596, train/raw-loss = 0.6976240873336792, train/logprobs = tensor([[-1.0468, -1.3189],
        [-1.2301, -1.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002585933543741703
Epoch 0, Step 1540: train/loss = 0.7051243782043457, train/raw-loss = 0.704926609992981, train/logprobs = tensor([[-1.0123, -1.0299],
        [-1.1550, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019778262358158827
Epoch 0, Step 1541: train/loss = 0.6942979693412781, train/raw-loss = 0.694216787815094, train/logprobs = tensor([[-0.8841, -0.8124],
        [-0.8617, -0.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008118252735584974
Epoch 0, Step 1542: train/loss = 0.7056882381439209, train/raw-loss = 0.7055895328521729, train/logprobs = tensor([[-0.9233, -1.2306],
        [-1.0341, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009867030894383788
Epoch 0, Step 1543: train/loss = 0.7055975794792175, train/raw-loss = 0.7054650783538818, train/logprobs = tensor([[-1.1198, -0.9996],
        [-1.1900, -0.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013249468756839633
Epoch 0, Step 1544: train/loss = 0.7177219390869141, train/raw-loss = 0.7172455787658691, train/logprobs = tensor([[-1.1359, -1.0390],
        [-1.3553, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047631338238716125
Epoch 0, Step 1545: train/loss = 0.6985676884651184, train/raw-loss = 0.6985019445419312, train/logprobs = tensor([[-1.0329, -1.0070],
        [-1.1563, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000657315191347152
Epoch 0, Step 1546: train/loss = 0.7078270316123962, train/raw-loss = 0.7074084281921387, train/logprobs = tensor([[-0.9653, -1.0982],
        [-1.1638, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004186677280813456
Epoch 0, Step 1547: train/loss = 0.6967043876647949, train/raw-loss = 0.6966930031776428, train/logprobs = tensor([[-1.0170, -0.9797],
        [-1.0516, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011373258894309402
Epoch 0, Step 1548: train/loss = 0.7181329131126404, train/raw-loss = 0.718085527420044, train/logprobs = tensor([[-0.6843, -0.9856],
        [-0.7601, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047463527880609035
Epoch 0, Step 1549: train/loss = 0.6908743381500244, train/raw-loss = 0.6903440952301025, train/logprobs = tensor([[-1.0885, -1.1382],
        [-1.2722, -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053021833300590515
Epoch 0, Step 1550: train/loss = 0.7443411350250244, train/raw-loss = 0.7440798282623291, train/logprobs = tensor([[-1.0237, -1.5407],
        [-1.1203, -1.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026127679739147425
Epoch 0, Step 1551: train/loss = 0.6923873424530029, train/raw-loss = 0.6923749446868896, train/logprobs = tensor([[-1.0957, -1.2487],
        [-1.2379, -1.1648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012433581287041306
Epoch 0, Step 1552: train/loss = 0.7207197546958923, train/raw-loss = 0.7205554842948914, train/logprobs = tensor([[-0.9510, -0.7840],
        [-1.0413, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016424028435721993
Epoch 0, Step 1553: train/loss = 0.709736704826355, train/raw-loss = 0.7096936106681824, train/logprobs = tensor([[-0.8519, -1.1107],
        [-0.9086, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043079524766653776
Epoch 0, Step 1554: train/loss = 0.7050169706344604, train/raw-loss = 0.7050005197525024, train/logprobs = tensor([[-1.2064, -1.3966],
        [-1.3558, -1.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001644054427742958
Epoch 0, Step 1555: train/loss = 0.7081001400947571, train/raw-loss = 0.7079610228538513, train/logprobs = tensor([[-0.9311, -0.8208],
        [-1.1459, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013911582063883543
Epoch 0, Step 1556: train/loss = 0.7139068841934204, train/raw-loss = 0.7138776779174805, train/logprobs = tensor([[-1.1874, -0.9129],
        [-1.2981, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002924200380221009
Epoch 0, Step 1557: train/loss = 0.6923331022262573, train/raw-loss = 0.6920793056488037, train/logprobs = tensor([[-1.0920, -1.1012],
        [-1.3850, -1.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025367802008986473
Epoch 0, Step 1558: train/loss = 0.7069143056869507, train/raw-loss = 0.7068085074424744, train/logprobs = tensor([[-1.0563, -1.0654],
        [-1.2313, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010573654435575008
Epoch 0, Step 1559: train/loss = 0.699989914894104, train/raw-loss = 0.6999396085739136, train/logprobs = tensor([[-1.0425, -0.8935],
        [-1.1922, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005040244432166219
Epoch 0, Step 1560: train/loss = 0.6986303329467773, train/raw-loss = 0.6985872387886047, train/logprobs = tensor([[-0.9522, -0.9073],
        [-1.0876, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043149234261363745
Epoch 0, Step 1561: train/loss = 0.7012931108474731, train/raw-loss = 0.7010276913642883, train/logprobs = tensor([[-1.2765, -1.2216],
        [-1.5577, -1.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00265386700630188
Epoch 0, Step 1562: train/loss = 0.6994141340255737, train/raw-loss = 0.699394702911377, train/logprobs = tensor([[-1.0514, -1.0802],
        [-1.1502, -1.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001937772030942142
Epoch 0, Step 1563: train/loss = 0.6968293786048889, train/raw-loss = 0.6966527104377747, train/logprobs = tensor([[-0.9169, -0.8934],
        [-1.0590, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017663083272054791
Epoch 0, Step 1564: train/loss = 0.7111513614654541, train/raw-loss = 0.7109950184822083, train/logprobs = tensor([[-1.1345, -1.0202],
        [-1.2035, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015631532296538353
Epoch 0, Step 1565: train/loss = 0.6799729466438293, train/raw-loss = 0.6798379421234131, train/logprobs = tensor([[-0.9741, -1.1498],
        [-1.6895, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001350409584119916
Epoch 0, Step 1566: train/loss = 0.6956993937492371, train/raw-loss = 0.6955606937408447, train/logprobs = tensor([[-1.1174, -1.0725],
        [-1.3910, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001387427793815732
Epoch 0, Step 1567: train/loss = 0.7040773630142212, train/raw-loss = 0.7039578557014465, train/logprobs = tensor([[-1.1178, -1.0094],
        [-1.1434, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001195501652546227
Epoch 0, Step 1568: train/loss = 0.7258530855178833, train/raw-loss = 0.725744366645813, train/logprobs = tensor([[-0.9173, -1.2861],
        [-1.1286, -1.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010869732359424233
Epoch 0, Step 1569: train/loss = 0.7037773728370667, train/raw-loss = 0.7036657929420471, train/logprobs = tensor([[-0.9320, -0.7944],
        [-1.1444, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011163214221596718
Epoch 0, Step 1570: train/loss = 0.7086620330810547, train/raw-loss = 0.7083727121353149, train/logprobs = tensor([[-1.0314, -1.3524],
        [-1.3678, -1.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002892959862947464
Epoch 0, Step 1571: train/loss = 0.6947862505912781, train/raw-loss = 0.6944797039031982, train/logprobs = tensor([[-1.0436, -1.0443],
        [-1.2036, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030654617585241795
Epoch 0, Step 1572: train/loss = 0.7043653726577759, train/raw-loss = 0.704285204410553, train/logprobs = tensor([[-0.9958, -0.8535],
        [-1.0892, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008018244989216328
Epoch 0, Step 1573: train/loss = 0.6944290399551392, train/raw-loss = 0.6943723559379578, train/logprobs = tensor([[-1.0482, -1.1158],
        [-1.2761, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000567171024158597
Epoch 0, Step 1574: train/loss = 0.691497802734375, train/raw-loss = 0.6907919049263, train/logprobs = tensor([[-0.9475, -1.0648],
        [-1.2093, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0070589277893304825
Epoch 0, Step 1575: train/loss = 0.711133599281311, train/raw-loss = 0.7104887366294861, train/logprobs = tensor([[-0.9799, -0.8645],
        [-1.5195, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006448068656027317
Epoch 0, Step 1576: train/loss = 0.7223554253578186, train/raw-loss = 0.7222728729248047, train/logprobs = tensor([[-1.0233, -0.7106],
        [-1.1452, -0.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008251928957179189
Epoch 0, Step 1577: train/loss = 0.6928132772445679, train/raw-loss = 0.692570149898529, train/logprobs = tensor([[-0.9828, -1.1240],
        [-1.0664, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002431207336485386
Epoch 0, Step 1578: train/loss = 0.6935266256332397, train/raw-loss = 0.6933407783508301, train/logprobs = tensor([[-0.9675, -0.9455],
        [-1.1952, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018581495387479663
Epoch 0, Step 1579: train/loss = 0.7068727016448975, train/raw-loss = 0.7068538069725037, train/logprobs = tensor([[-0.9888, -0.7876],
        [-1.0809, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018977373838424683
Epoch 0, Step 1580: train/loss = 0.6967753767967224, train/raw-loss = 0.6967498660087585, train/logprobs = tensor([[-0.9786, -0.9793],
        [-0.9981, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002549799391999841
Epoch 0, Step 1581: train/loss = 0.6967733502388, train/raw-loss = 0.6967717409133911, train/logprobs = tensor([[-0.9208, -1.0444],
        [-1.0066, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5267942217178643e-05
Epoch 0, Step 1582: train/loss = 0.6909219026565552, train/raw-loss = 0.6907296776771545, train/logprobs = tensor([[-0.9852, -1.1348],
        [-1.1530, -1.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019223233684897423
Epoch 0, Step 1583: train/loss = 0.6981303691864014, train/raw-loss = 0.6979692578315735, train/logprobs = tensor([[-1.2278, -1.2944],
        [-1.4505, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016113135498017073
Epoch 0, Step 1584: train/loss = 0.6963346600532532, train/raw-loss = 0.6962178945541382, train/logprobs = tensor([[-1.0401, -1.1124],
        [-1.2071, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011682690819725394
Epoch 0, Step 1585: train/loss = 0.6980814933776855, train/raw-loss = 0.6980316638946533, train/logprobs = tensor([[-1.1036, -1.0380],
        [-1.1791, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004978760844096541
Epoch 0, Step 1586: train/loss = 0.7121974229812622, train/raw-loss = 0.7121291756629944, train/logprobs = tensor([[-0.9926, -0.6808],
        [-1.1393, -0.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006824795855209231
Epoch 0, Step 1587: train/loss = 0.6986187100410461, train/raw-loss = 0.698580265045166, train/logprobs = tensor([[-1.0013, -0.9147],
        [-1.1223, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000384159036912024
Epoch 0, Step 1588: train/loss = 0.7020794153213501, train/raw-loss = 0.7019971609115601, train/logprobs = tensor([[-1.0415, -0.9753],
        [-1.1793, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000822701957076788
Epoch 0, Step 1589: train/loss = 0.7194854617118835, train/raw-loss = 0.7188860177993774, train/logprobs = tensor([[-0.9543, -1.1989],
        [-1.1457, -1.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005994114093482494
Epoch 0, Step 1590: train/loss = 0.6913579702377319, train/raw-loss = 0.6903706192970276, train/logprobs = tensor([[-0.9438, -1.0203],
        [-1.2411, -0.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00987339299172163
Epoch 0, Step 1591: train/loss = 0.718433678150177, train/raw-loss = 0.7179440259933472, train/logprobs = tensor([[-1.1888, -0.9826],
        [-1.4136, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004896773491054773
Epoch 0, Step 1592: train/loss = 0.7004029154777527, train/raw-loss = 0.7000449895858765, train/logprobs = tensor([[-1.0454, -1.1085],
        [-1.1294, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003579579759389162
Epoch 0, Step 1593: train/loss = 0.7002554535865784, train/raw-loss = 0.6999329924583435, train/logprobs = tensor([[-1.1204, -1.0072],
        [-1.3055, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003224549815058708
Epoch 0, Step 1594: train/loss = 0.7026256322860718, train/raw-loss = 0.7024660706520081, train/logprobs = tensor([[-1.0119, -0.9314],
        [-1.2946, -1.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015956452116370201
Epoch 0, Step 1595: train/loss = 0.7037259340286255, train/raw-loss = 0.7035497426986694, train/logprobs = tensor([[-1.1055, -0.9310],
        [-1.1825, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017619517166167498
Epoch 0, Step 1596: train/loss = 0.6981291770935059, train/raw-loss = 0.6977899074554443, train/logprobs = tensor([[-0.7474, -0.8760],
        [-0.8759, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033920726273208857
Epoch 0, Step 1597: train/loss = 0.7270560264587402, train/raw-loss = 0.7268161773681641, train/logprobs = tensor([[-1.0111, -0.7935],
        [-1.0655, -0.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023983607534319162
Epoch 0, Step 1598: train/loss = 0.6954639554023743, train/raw-loss = 0.6942437887191772, train/logprobs = tensor([[-1.0573, -1.0957],
        [-1.4342, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012201634235680103
Epoch 0, Step 1599: train/loss = 0.6953588724136353, train/raw-loss = 0.6948434114456177, train/logprobs = tensor([[-0.9400, -1.0612],
        [-1.1436, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005154310259968042
Epoch 0, Step 1600: train/loss = 0.6965391635894775, train/raw-loss = 0.69636470079422, train/logprobs = tensor([[-1.0885, -1.1449],
        [-1.2160, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001744697568938136
Epoch 0, Step 1601: train/loss = 0.714687705039978, train/raw-loss = 0.7145642042160034, train/logprobs = tensor([[-1.2228, -0.8861],
        [-1.3350, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012350426986813545
Epoch 0, Step 1602: train/loss = 0.6957449913024902, train/raw-loss = 0.6954637169837952, train/logprobs = tensor([[-1.2321, -1.2396],
        [-1.3131, -1.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002812675666064024
Epoch 0, Step 1603: train/loss = 0.6882892847061157, train/raw-loss = 0.6875557899475098, train/logprobs = tensor([[-1.0797, -1.3848],
        [-1.3567, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007335605099797249
Epoch 0, Step 1604: train/loss = 0.7038822770118713, train/raw-loss = 0.7036569118499756, train/logprobs = tensor([[-0.9906, -1.1412],
        [-1.0895, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002253766870126128
Epoch 0, Step 1605: train/loss = 0.7174227237701416, train/raw-loss = 0.7168271541595459, train/logprobs = tensor([[-1.2383, -1.2250],
        [-1.4782, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005955616943538189
Epoch 0, Step 1606: train/loss = 0.7041033506393433, train/raw-loss = 0.703997790813446, train/logprobs = tensor([[-1.1098, -1.1141],
        [-1.3295, -1.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001056402805261314
Epoch 0, Step 1607: train/loss = 0.7232407331466675, train/raw-loss = 0.7231193780899048, train/logprobs = tensor([[-1.2105, -0.8339],
        [-1.4194, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001213936833664775
Epoch 0, Step 1608: train/loss = 0.7138633728027344, train/raw-loss = 0.713742733001709, train/logprobs = tensor([[-1.0087, -0.7814],
        [-1.2032, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001205262029543519
Epoch 0, Step 1609: train/loss = 0.6941276788711548, train/raw-loss = 0.6932889819145203, train/logprobs = tensor([[-1.1192, -1.2675],
        [-1.3826, -1.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008386628702282906
Epoch 0, Step 1610: train/loss = 0.6977618336677551, train/raw-loss = 0.6972162127494812, train/logprobs = tensor([[-1.2708, -1.3676],
        [-1.5728, -1.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054562753066420555
Epoch 0, Step 1611: train/loss = 0.6949578523635864, train/raw-loss = 0.694892406463623, train/logprobs = tensor([[-0.9480, -0.9365],
        [-1.0380, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006547663360834122
Epoch 0, Step 1612: train/loss = 0.7067542672157288, train/raw-loss = 0.7063362002372742, train/logprobs = tensor([[-1.0837, -0.9626],
        [-1.3711, -0.9103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004180553834885359
Epoch 0, Step 1613: train/loss = 0.7156918048858643, train/raw-loss = 0.7156091928482056, train/logprobs = tensor([[-1.2286, -1.2636],
        [-1.3694, -1.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008262057090178132
Epoch 0, Step 1614: train/loss = 0.7083673477172852, train/raw-loss = 0.7083193063735962, train/logprobs = tensor([[-1.2687, -1.0709],
        [-1.4348, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048044754657894373
Epoch 0, Step 1615: train/loss = 0.696414589881897, train/raw-loss = 0.6960838437080383, train/logprobs = tensor([[-1.0395, -1.1003],
        [-1.2600, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033077842090278864
Epoch 0, Step 1616: train/loss = 0.7061396837234497, train/raw-loss = 0.7060399055480957, train/logprobs = tensor([[-1.0385, -0.9299],
        [-1.2009, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009976278524845839
Epoch 0, Step 1617: train/loss = 0.6854106187820435, train/raw-loss = 0.6845051050186157, train/logprobs = tensor([[-0.9831, -1.1216],
        [-1.1205, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009055591188371181
Epoch 0, Step 1618: train/loss = 0.7217287421226501, train/raw-loss = 0.7216486930847168, train/logprobs = tensor([[-1.1474, -0.8027],
        [-1.3071, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008009118027985096
Epoch 0, Step 1619: train/loss = 0.7463212013244629, train/raw-loss = 0.7460981607437134, train/logprobs = tensor([[-1.0641, -0.8715],
        [-1.1308, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00222942978143692
Epoch 0, Step 1620: train/loss = 0.7096999883651733, train/raw-loss = 0.7083302736282349, train/logprobs = tensor([[-1.1286, -1.0707],
        [-1.5354, -0.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013697082176804543
Epoch 0, Step 1621: train/loss = 0.6957674622535706, train/raw-loss = 0.6953641772270203, train/logprobs = tensor([[-0.9863, -0.9983],
        [-1.0682, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004032475408166647
Epoch 0, Step 1622: train/loss = 0.6891899108886719, train/raw-loss = 0.6883763074874878, train/logprobs = tensor([[-1.1918, -1.2804],
        [-1.5160, -0.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00813717395067215
Epoch 0, Step 1623: train/loss = 0.7278006672859192, train/raw-loss = 0.7276797294616699, train/logprobs = tensor([[-1.1519, -1.1995],
        [-1.4393, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012093817349523306
Epoch 0, Step 1624: train/loss = 0.6954313516616821, train/raw-loss = 0.6948156356811523, train/logprobs = tensor([[-1.0500, -1.0430],
        [-1.1471, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006156894378364086
Epoch 0, Step 1625: train/loss = 0.6948977112770081, train/raw-loss = 0.6948699951171875, train/logprobs = tensor([[-1.1753, -1.1570],
        [-1.3183, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002776923356577754
Epoch 0, Step 1626: train/loss = 0.6934032440185547, train/raw-loss = 0.693398118019104, train/logprobs = tensor([[-1.0665, -1.0614],
        [-1.0506, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.175343540031463e-05
Epoch 0, Step 1627: train/loss = 0.6999704837799072, train/raw-loss = 0.6995232701301575, train/logprobs = tensor([[-1.2175, -1.3135],
        [-1.4888, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004471954423934221
Epoch 0, Step 1628: train/loss = 0.719618022441864, train/raw-loss = 0.7188208103179932, train/logprobs = tensor([[-1.3140, -1.1448],
        [-1.6533, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007971415296196938
Epoch 0, Step 1629: train/loss = 0.698898434638977, train/raw-loss = 0.698558509349823, train/logprobs = tensor([[-1.0696, -1.1793],
        [-1.3309, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033989311195909977
Epoch 0, Step 1630: train/loss = 0.6971287131309509, train/raw-loss = 0.6970881223678589, train/logprobs = tensor([[-0.9512, -0.9138],
        [-0.9716, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004058710765093565
Epoch 0, Step 1631: train/loss = 0.7003851532936096, train/raw-loss = 0.7003659009933472, train/logprobs = tensor([[-1.0316, -1.1471],
        [-1.1477, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019290480122435838
Epoch 0, Step 1632: train/loss = 0.697263240814209, train/raw-loss = 0.6972000598907471, train/logprobs = tensor([[-0.9699, -1.1917],
        [-0.9972, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006319800158962607
Epoch 0, Step 1633: train/loss = 0.6944213509559631, train/raw-loss = 0.6937193870544434, train/logprobs = tensor([[-1.1939, -1.1415],
        [-1.5823, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00701942341402173
Epoch 0, Step 1634: train/loss = 0.7503743767738342, train/raw-loss = 0.7502069473266602, train/logprobs = tensor([[-0.9022, -1.2809],
        [-1.0633, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016739267157390714
Epoch 0, Step 1635: train/loss = 0.6997056603431702, train/raw-loss = 0.699103832244873, train/logprobs = tensor([[-0.9413, -1.0183],
        [-1.1987, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060183824971318245
Epoch 0, Step 1636: train/loss = 0.6968507170677185, train/raw-loss = 0.6967487335205078, train/logprobs = tensor([[-1.1349, -1.1424],
        [-1.2520, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010201012482866645
Epoch 0, Step 1637: train/loss = 0.704043447971344, train/raw-loss = 0.7039691805839539, train/logprobs = tensor([[-1.0079, -0.9255],
        [-1.2383, -0.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007417354499921203
Epoch 0, Step 1638: train/loss = 0.6969977021217346, train/raw-loss = 0.6968656182289124, train/logprobs = tensor([[-1.0757, -1.1228],
        [-1.2165, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013212230987846851
Epoch 0, Step 1639: train/loss = 0.7072503566741943, train/raw-loss = 0.7069610357284546, train/logprobs = tensor([[-0.9776, -1.0411],
        [-1.1309, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00289317243732512
Epoch 0, Step 1640: train/loss = 0.7192281484603882, train/raw-loss = 0.7190815806388855, train/logprobs = tensor([[-1.0395, -0.6913],
        [-1.2653, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014659897424280643
Epoch 0, Step 1641: train/loss = 0.6997852921485901, train/raw-loss = 0.6993156671524048, train/logprobs = tensor([[-0.8973, -0.8787],
        [-1.1801, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004695755895227194
Epoch 0, Step 1642: train/loss = 0.7010124921798706, train/raw-loss = 0.7006554007530212, train/logprobs = tensor([[-0.8045, -0.8755],
        [-0.8975, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003571412991732359
Epoch 0, Step 1643: train/loss = 0.6938004493713379, train/raw-loss = 0.6937174797058105, train/logprobs = tensor([[-0.9315, -1.0416],
        [-1.0094, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008302950300276279
Epoch 0, Step 1644: train/loss = 0.6952035427093506, train/raw-loss = 0.6951407790184021, train/logprobs = tensor([[-0.7994, -0.8153],
        [-0.9677, -0.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006274220068007708
Epoch 0, Step 1645: train/loss = 0.7038822174072266, train/raw-loss = 0.7038598656654358, train/logprobs = tensor([[-1.1322, -1.4190],
        [-1.3879, -1.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022387993521988392
Epoch 0, Step 1646: train/loss = 0.7202978730201721, train/raw-loss = 0.7201407551765442, train/logprobs = tensor([[-1.1276, -0.9513],
        [-1.3088, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015717907808721066
Epoch 0, Step 1647: train/loss = 0.7087448835372925, train/raw-loss = 0.7086609601974487, train/logprobs = tensor([[-0.9247, -0.7594],
        [-1.0385, -0.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000839460757561028
Epoch 0, Step 1648: train/loss = 0.7020466327667236, train/raw-loss = 0.7019490599632263, train/logprobs = tensor([[-1.1730, -1.0699],
        [-1.0999, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009762081317603588
Epoch 0, Step 1649: train/loss = 0.7000325322151184, train/raw-loss = 0.6999092102050781, train/logprobs = tensor([[-1.1481, -1.0886],
        [-1.1263, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001233396353200078
Epoch 0, Step 1650: train/loss = 0.7130135297775269, train/raw-loss = 0.7125959396362305, train/logprobs = tensor([[-1.1317, -1.2178],
        [-1.3255, -1.2200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004176401533186436
Epoch 0, Step 1651: train/loss = 0.6907867193222046, train/raw-loss = 0.6907401084899902, train/logprobs = tensor([[-0.9959, -1.0800],
        [-1.2531, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004661283455789089
Epoch 0, Step 1652: train/loss = 0.7006475925445557, train/raw-loss = 0.7003989219665527, train/logprobs = tensor([[-0.9758, -1.0131],
        [-1.0999, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002486415673047304
Epoch 0, Step 1653: train/loss = 0.6947503089904785, train/raw-loss = 0.6947444677352905, train/logprobs = tensor([[-0.8951, -0.8463],
        [-0.9291, -0.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.812098606838845e-05
Epoch 0, Step 1654: train/loss = 0.7037121057510376, train/raw-loss = 0.7033301591873169, train/logprobs = tensor([[-0.9954, -0.9409],
        [-1.2043, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038195003289729357
Epoch 0, Step 1655: train/loss = 0.6924601197242737, train/raw-loss = 0.6923056840896606, train/logprobs = tensor([[-0.8592, -0.9133],
        [-1.0159, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015442855656147003
Epoch 0, Step 1656: train/loss = 0.7485724687576294, train/raw-loss = 0.74800044298172, train/logprobs = tensor([[-1.0287, -0.7847],
        [-1.1261, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005720232613384724
Epoch 0, Step 1657: train/loss = 0.6929627656936646, train/raw-loss = 0.6926740407943726, train/logprobs = tensor([[-1.0840, -1.1873],
        [-1.1679, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028869546949863434
Epoch 0, Step 1658: train/loss = 0.70136958360672, train/raw-loss = 0.700943112373352, train/logprobs = tensor([[-1.1425, -1.0640],
        [-1.2539, -0.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042646219953894615
Epoch 0, Step 1659: train/loss = 0.7455370426177979, train/raw-loss = 0.7453227043151855, train/logprobs = tensor([[-1.0511, -0.6112],
        [-1.2314, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021429245825856924
Epoch 0, Step 1660: train/loss = 0.6988171935081482, train/raw-loss = 0.6982793807983398, train/logprobs = tensor([[-0.9786, -1.0377],
        [-1.4102, -1.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005377498921006918
Epoch 0, Step 1661: train/loss = 0.6941877007484436, train/raw-loss = 0.6938650608062744, train/logprobs = tensor([[-0.8430, -0.8316],
        [-1.0163, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032261344604194164
Epoch 0, Step 1662: train/loss = 0.6979608535766602, train/raw-loss = 0.6978492736816406, train/logprobs = tensor([[-1.0575, -1.0581],
        [-1.1314, -1.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011156901018694043
Epoch 0, Step 1663: train/loss = 0.6999298334121704, train/raw-loss = 0.6998916864395142, train/logprobs = tensor([[-1.1901, -1.1198],
        [-1.3612, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003816266544163227
Epoch 0, Step 1664: train/loss = 0.7341950535774231, train/raw-loss = 0.7333463430404663, train/logprobs = tensor([[-1.1562, -0.9677],
        [-1.4863, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008487330749630928
Epoch 0, Step 1665: train/loss = 0.6969771385192871, train/raw-loss = 0.6968922019004822, train/logprobs = tensor([[-0.9340, -0.9646],
        [-1.0269, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008500297553837299
Epoch 0, Step 1666: train/loss = 0.6974665522575378, train/raw-loss = 0.6973052620887756, train/logprobs = tensor([[-0.8579, -0.7189],
        [-0.9544, -0.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016122714150696993
Epoch 0, Step 1667: train/loss = 0.6983323097229004, train/raw-loss = 0.6981894373893738, train/logprobs = tensor([[-1.0253, -1.1819],
        [-1.2153, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014283494092524052
Epoch 0, Step 1668: train/loss = 0.702875554561615, train/raw-loss = 0.7024632692337036, train/logprobs = tensor([[-1.0707, -0.9488],
        [-1.2110, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004122787155210972
Epoch 0, Step 1669: train/loss = 0.6926481127738953, train/raw-loss = 0.6920782327651978, train/logprobs = tensor([[-1.0050, -1.2375],
        [-1.0696, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00569900032132864
Epoch 0, Step 1670: train/loss = 0.697208046913147, train/raw-loss = 0.6968543529510498, train/logprobs = tensor([[-1.0630, -1.0690],
        [-1.2274, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035362436901777983
Epoch 0, Step 1671: train/loss = 0.6973479986190796, train/raw-loss = 0.6973127126693726, train/logprobs = tensor([[-0.8727, -1.0370],
        [-0.9544, -1.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003531486727297306
Epoch 0, Step 1672: train/loss = 0.7113246321678162, train/raw-loss = 0.7111948132514954, train/logprobs = tensor([[-1.1392, -0.9562],
        [-1.2040, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001297978451475501
Epoch 0, Step 1673: train/loss = 0.6922351717948914, train/raw-loss = 0.6920398473739624, train/logprobs = tensor([[-1.0594, -1.0757],
        [-1.4632, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019529564306139946
Epoch 0, Step 1674: train/loss = 0.7012891173362732, train/raw-loss = 0.7006304264068604, train/logprobs = tensor([[-1.0103, -1.3955],
        [-1.2486, -1.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006586902774870396
Epoch 0, Step 1675: train/loss = 0.6932878494262695, train/raw-loss = 0.6932291984558105, train/logprobs = tensor([[-0.9701, -0.9637],
        [-1.1027, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000586950802244246
Epoch 0, Step 1676: train/loss = 0.6957761645317078, train/raw-loss = 0.6956355571746826, train/logprobs = tensor([[-0.9949, -0.9102],
        [-1.0978, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014060609973967075
Epoch 0, Step 1677: train/loss = 0.704646646976471, train/raw-loss = 0.7045516967773438, train/logprobs = tensor([[-1.2411, -1.4052],
        [-1.3682, -1.3811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009499123552814126
Epoch 0, Step 1678: train/loss = 0.7298325896263123, train/raw-loss = 0.7296000719070435, train/logprobs = tensor([[-1.0091, -0.9040],
        [-1.1966, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002325789537280798
Epoch 0, Step 1679: train/loss = 0.7029821872711182, train/raw-loss = 0.702742338180542, train/logprobs = tensor([[-1.2230, -1.1799],
        [-1.3734, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023985952138900757
Epoch 0, Step 1680: train/loss = 0.6928587555885315, train/raw-loss = 0.6927816867828369, train/logprobs = tensor([[-1.0496, -1.0484],
        [-1.0970, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007705874159000814
Epoch 0, Step 1681: train/loss = 0.7184810042381287, train/raw-loss = 0.7177994251251221, train/logprobs = tensor([[-1.1073, -0.9977],
        [-1.3451, -0.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006815420929342508
Epoch 0, Step 1682: train/loss = 0.7032309770584106, train/raw-loss = 0.7031565308570862, train/logprobs = tensor([[-1.1988, -1.0326],
        [-1.2206, -0.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007445088704116642
Epoch 0, Step 1683: train/loss = 0.6951001286506653, train/raw-loss = 0.694945216178894, train/logprobs = tensor([[-0.9067, -0.9945],
        [-1.0625, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001549628796055913
Epoch 0, Step 1684: train/loss = 0.6892151236534119, train/raw-loss = 0.6886434555053711, train/logprobs = tensor([[-0.8903, -1.0732],
        [-1.0842, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005716536659747362
Epoch 0, Step 1685: train/loss = 0.6980041265487671, train/raw-loss = 0.697799801826477, train/logprobs = tensor([[-1.0259, -0.9689],
        [-1.1452, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002043486572802067
Epoch 0, Step 1686: train/loss = 0.6957770586013794, train/raw-loss = 0.6955009698867798, train/logprobs = tensor([[-0.9452, -0.9659],
        [-1.1884, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027604347560554743
Epoch 0, Step 1687: train/loss = 0.7097505331039429, train/raw-loss = 0.7096526622772217, train/logprobs = tensor([[-0.9040, -0.7310],
        [-1.0514, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009784696158021688
Epoch 0, Step 1688: train/loss = 0.7001932859420776, train/raw-loss = 0.7001394629478455, train/logprobs = tensor([[-1.0610, -1.0418],
        [-1.0772, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005381751689128578
Epoch 0, Step 1689: train/loss = 0.7075938582420349, train/raw-loss = 0.706817626953125, train/logprobs = tensor([[-0.9734, -0.8789],
        [-1.1563, -0.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007761714980006218
Epoch 0, Step 1690: train/loss = 0.6933562159538269, train/raw-loss = 0.6929037570953369, train/logprobs = tensor([[-0.9633, -1.0459],
        [-1.1322, -0.9215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045243799686431885
Epoch 0, Step 1691: train/loss = 0.7041981220245361, train/raw-loss = 0.7039316296577454, train/logprobs = tensor([[-1.0618, -0.9664],
        [-1.2566, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026650798972696066
Epoch 0, Step 1692: train/loss = 0.696830153465271, train/raw-loss = 0.696548581123352, train/logprobs = tensor([[-0.9376, -0.9640],
        [-1.1178, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002815842628479004
Epoch 0, Step 1693: train/loss = 0.6920289397239685, train/raw-loss = 0.6918726563453674, train/logprobs = tensor([[-1.0367, -1.0522],
        [-1.1598, -1.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015624435618519783
Epoch 0, Step 1694: train/loss = 0.6973596811294556, train/raw-loss = 0.6972326040267944, train/logprobs = tensor([[-1.2103, -1.3785],
        [-1.3669, -1.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012708845315501094
Epoch 0, Step 1695: train/loss = 0.6936479806900024, train/raw-loss = 0.6926817893981934, train/logprobs = tensor([[-1.0266, -1.2445],
        [-1.2108, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009661676362156868
Epoch 0, Step 1696: train/loss = 0.6966860294342041, train/raw-loss = 0.6966762542724609, train/logprobs = tensor([[-1.0810, -1.0070],
        [-1.1823, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.748531738296151e-05
Epoch 0, Step 1697: train/loss = 0.7164490818977356, train/raw-loss = 0.7159718871116638, train/logprobs = tensor([[-0.9996, -0.7940],
        [-1.1301, -0.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004771553911268711
Epoch 0, Step 1698: train/loss = 0.7247353196144104, train/raw-loss = 0.724632978439331, train/logprobs = tensor([[-1.2695, -1.0555],
        [-1.4197, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010230968473479152
Epoch 0, Step 1699: train/loss = 0.6986812353134155, train/raw-loss = 0.698615312576294, train/logprobs = tensor([[-1.1440, -1.1223],
        [-1.2524, -1.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006590136326849461
Epoch 0, Step 1700: train/loss = 0.7122128009796143, train/raw-loss = 0.7119113206863403, train/logprobs = tensor([[-1.0962, -1.2464],
        [-1.4083, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00301449466496706
Epoch 0, Step 1701: train/loss = 0.6982424259185791, train/raw-loss = 0.6975278854370117, train/logprobs = tensor([[-1.1170, -1.3079],
        [-1.5037, -1.2384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007145931012928486
Epoch 0, Step 1702: train/loss = 0.702897310256958, train/raw-loss = 0.7027068734169006, train/logprobs = tensor([[-0.9699, -0.9370],
        [-1.0812, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00190420588478446
Epoch 0, Step 1703: train/loss = 0.7035117745399475, train/raw-loss = 0.7034765481948853, train/logprobs = tensor([[-1.2805, -1.1304],
        [-1.2994, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003521866165101528
Epoch 0, Step 1704: train/loss = 0.6940465569496155, train/raw-loss = 0.6940407752990723, train/logprobs = tensor([[-1.2276, -1.2635],
        [-1.3418, -1.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.793213495053351e-05
Epoch 0, Step 1705: train/loss = 0.6939491629600525, train/raw-loss = 0.6939183473587036, train/logprobs = tensor([[-1.1474, -1.1945],
        [-1.2457, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003081484173890203
Epoch 0, Step 1706: train/loss = 0.7310742139816284, train/raw-loss = 0.7307978868484497, train/logprobs = tensor([[-1.1305, -0.7743],
        [-1.3565, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027627162635326385
Epoch 0, Step 1707: train/loss = 0.7140899896621704, train/raw-loss = 0.7138949632644653, train/logprobs = tensor([[-0.6374, -0.7194],
        [-0.7347, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019503554794937372
Epoch 0, Step 1708: train/loss = 0.6961493492126465, train/raw-loss = 0.6961185932159424, train/logprobs = tensor([[-1.0065, -1.0352],
        [-1.0478, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030748057179152966
Epoch 0, Step 1709: train/loss = 0.6954249143600464, train/raw-loss = 0.6953017115592957, train/logprobs = tensor([[-0.9218, -1.0286],
        [-0.9031, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012316721258684993
Epoch 0, Step 1710: train/loss = 0.6988394260406494, train/raw-loss = 0.6980329751968384, train/logprobs = tensor([[-1.0644, -1.0150],
        [-1.3573, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008065237663686275
Epoch 0, Step 1711: train/loss = 0.6951719522476196, train/raw-loss = 0.694543719291687, train/logprobs = tensor([[-0.9017, -0.8863],
        [-1.2830, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006282362155616283
Epoch 0, Step 1712: train/loss = 0.6876046657562256, train/raw-loss = 0.6861546039581299, train/logprobs = tensor([[-1.1025, -1.3574],
        [-1.3290, -1.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014499299228191376
Epoch 0, Step 1713: train/loss = 0.7000375986099243, train/raw-loss = 0.6999138593673706, train/logprobs = tensor([[-0.9948, -1.0113],
        [-1.0950, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012379203690215945
Epoch 0, Step 1714: train/loss = 0.7263014912605286, train/raw-loss = 0.7260478138923645, train/logprobs = tensor([[-0.9384, -1.3482],
        [-0.8771, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00253704353235662
Epoch 0, Step 1715: train/loss = 0.6962562799453735, train/raw-loss = 0.6956578493118286, train/logprobs = tensor([[-0.8422, -0.8763],
        [-1.0139, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059844255447387695
Epoch 0, Step 1716: train/loss = 0.6957167983055115, train/raw-loss = 0.695462703704834, train/logprobs = tensor([[-0.9392, -1.1696],
        [-0.9948, -0.8886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025411611422896385
Epoch 0, Step 1717: train/loss = 0.6991766691207886, train/raw-loss = 0.6988685131072998, train/logprobs = tensor([[-1.1372, -1.0821],
        [-1.2441, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003081689588725567
Epoch 0, Step 1718: train/loss = 0.695287823677063, train/raw-loss = 0.6950439214706421, train/logprobs = tensor([[-0.7793, -0.8895],
        [-0.9036, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024390649050474167
Epoch 0, Step 1719: train/loss = 0.6998562812805176, train/raw-loss = 0.6993023753166199, train/logprobs = tensor([[-1.1013, -1.0716],
        [-1.3024, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055391076020896435
Epoch 0, Step 1720: train/loss = 0.7151806950569153, train/raw-loss = 0.7149632573127747, train/logprobs = tensor([[-1.1198, -1.1705],
        [-1.3238, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021747229620814323
Epoch 0, Step 1721: train/loss = 0.6970067024230957, train/raw-loss = 0.6968830823898315, train/logprobs = tensor([[-0.6716, -0.6236],
        [-0.7788, -0.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001236509531736374
Epoch 0, Step 1722: train/loss = 0.7273801565170288, train/raw-loss = 0.7273700833320618, train/logprobs = tensor([[-1.1543, -1.2691],
        [-1.2543, -1.3062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010022724018199369
Epoch 0, Step 1723: train/loss = 0.696811318397522, train/raw-loss = 0.6965866684913635, train/logprobs = tensor([[-1.1320, -1.0556],
        [-1.3128, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022466741502285004
Epoch 0, Step 1724: train/loss = 0.6940149664878845, train/raw-loss = 0.6934185028076172, train/logprobs = tensor([[-0.9754, -1.0335],
        [-1.0456, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059644849970936775
Epoch 0, Step 1725: train/loss = 0.7327672243118286, train/raw-loss = 0.732572615146637, train/logprobs = tensor([[-1.1041, -0.8049],
        [-1.2401, -0.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019461727933958173
Epoch 0, Step 1726: train/loss = 0.6971538066864014, train/raw-loss = 0.6970586776733398, train/logprobs = tensor([[-1.0129, -1.0669],
        [-1.0422, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009519104496575892
Epoch 0, Step 1727: train/loss = 0.7077385783195496, train/raw-loss = 0.7065192461013794, train/logprobs = tensor([[-1.1024, -1.1431],
        [-1.2202, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012193791568279266
Epoch 0, Step 1728: train/loss = 0.7034207582473755, train/raw-loss = 0.7033823728561401, train/logprobs = tensor([[-1.0450, -0.8308],
        [-1.1049, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038400833727791905
Epoch 0, Step 1729: train/loss = 0.7019034028053284, train/raw-loss = 0.7016934156417847, train/logprobs = tensor([[-0.9204, -0.9853],
        [-1.0325, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002100120298564434
Epoch 0, Step 1730: train/loss = 0.6965278387069702, train/raw-loss = 0.6960617303848267, train/logprobs = tensor([[-0.9461, -0.9603],
        [-1.1257, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004661079961806536
Epoch 0, Step 1731: train/loss = 0.704789936542511, train/raw-loss = 0.704436182975769, train/logprobs = tensor([[-0.9829, -1.3236],
        [-1.2778, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035379016771912575
Epoch 0, Step 1732: train/loss = 0.7500582933425903, train/raw-loss = 0.749017596244812, train/logprobs = tensor([[-1.4125, -1.4227],
        [-1.6874, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010407386347651482
Epoch 0, Step 1733: train/loss = 0.6943367123603821, train/raw-loss = 0.6942088007926941, train/logprobs = tensor([[-0.9709, -1.1801],
        [-1.0760, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012787686428055167
Epoch 0, Step 1734: train/loss = 0.6916933655738831, train/raw-loss = 0.6907021999359131, train/logprobs = tensor([[-0.9775, -1.0717],
        [-1.1572, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009911157190799713
Epoch 0, Step 1735: train/loss = 0.6941146850585938, train/raw-loss = 0.6941037178039551, train/logprobs = tensor([[-0.7257, -0.7882],
        [-0.7355, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010925682727247477
Epoch 0, Step 1736: train/loss = 0.6969646215438843, train/raw-loss = 0.6958142518997192, train/logprobs = tensor([[-0.9799, -1.1309],
        [-1.2304, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011503740213811398
Epoch 0, Step 1737: train/loss = 0.6942111849784851, train/raw-loss = 0.6935697793960571, train/logprobs = tensor([[-0.9278, -0.9890],
        [-1.2012, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006414107978343964
Epoch 0, Step 1738: train/loss = 0.694097638130188, train/raw-loss = 0.693901777267456, train/logprobs = tensor([[-0.8790, -0.9459],
        [-0.9958, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001958895241841674
Epoch 0, Step 1739: train/loss = 0.6963268518447876, train/raw-loss = 0.6960418820381165, train/logprobs = tensor([[-1.0173, -1.0713],
        [-1.1913, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028502042405307293
Epoch 0, Step 1740: train/loss = 0.6835443377494812, train/raw-loss = 0.6811286807060242, train/logprobs = tensor([[-1.1890, -1.2321],
        [-1.3753, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024156413972377777
Epoch 0, Step 1741: train/loss = 0.7023155093193054, train/raw-loss = 0.7023075819015503, train/logprobs = tensor([[-0.8964, -0.9152],
        [-0.9845, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.953015301609412e-05
Epoch 0, Step 1742: train/loss = 0.7101830244064331, train/raw-loss = 0.7100275158882141, train/logprobs = tensor([[-1.2837, -1.0908],
        [-1.4652, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015551229007542133
Epoch 0, Step 1743: train/loss = 0.699740469455719, train/raw-loss = 0.6996057033538818, train/logprobs = tensor([[-0.9759, -0.9275],
        [-1.1576, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013469639234244823
Epoch 0, Step 1744: train/loss = 0.6930029392242432, train/raw-loss = 0.6924105286598206, train/logprobs = tensor([[-1.1053, -1.2045],
        [-1.3018, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005923514254391193
Epoch 0, Step 1745: train/loss = 0.701675295829773, train/raw-loss = 0.7016298770904541, train/logprobs = tensor([[-0.7999, -1.0832],
        [-0.9740, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004539056681096554
Epoch 0, Step 1746: train/loss = 0.7268339395523071, train/raw-loss = 0.7268046736717224, train/logprobs = tensor([[-0.8830, -0.7983],
        [-0.9397, -0.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002923949505202472
Epoch 0, Step 1747: train/loss = 0.6861441731452942, train/raw-loss = 0.6851742267608643, train/logprobs = tensor([[-1.0796, -1.2415],
        [-1.6529, -1.1408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009699063375592232
Epoch 0, Step 1748: train/loss = 0.7004057765007019, train/raw-loss = 0.7001961469650269, train/logprobs = tensor([[-0.9027, -0.8688],
        [-1.0346, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020962117705494165
Epoch 0, Step 1749: train/loss = 0.7107812762260437, train/raw-loss = 0.710704505443573, train/logprobs = tensor([[-1.1054, -0.9357],
        [-1.1714, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007670201594009995
Epoch 0, Step 1750: train/loss = 0.6918652057647705, train/raw-loss = 0.6916501522064209, train/logprobs = tensor([[-1.0945, -1.1898],
        [-1.1871, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021504510659724474
Epoch 0, Step 1751: train/loss = 0.6963980793952942, train/raw-loss = 0.6963787078857422, train/logprobs = tensor([[-1.0508, -1.0031],
        [-1.0730, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019347993656992912
Epoch 0, Step 1752: train/loss = 0.6959108710289001, train/raw-loss = 0.695688009262085, train/logprobs = tensor([[-1.0007, -0.9710],
        [-1.0335, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002229152014479041
Epoch 0, Step 1753: train/loss = 0.6990786790847778, train/raw-loss = 0.6989378333091736, train/logprobs = tensor([[-1.1540, -1.1972],
        [-1.3945, -1.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001408313401043415
Epoch 0, Step 1754: train/loss = 0.7081279754638672, train/raw-loss = 0.7075331807136536, train/logprobs = tensor([[-1.0755, -0.9188],
        [-1.3178, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005948122590780258
Epoch 0, Step 1755: train/loss = 0.7047238349914551, train/raw-loss = 0.704603910446167, train/logprobs = tensor([[-1.0785, -0.9429],
        [-1.2273, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011992843355983496
Epoch 0, Step 1756: train/loss = 0.7166783809661865, train/raw-loss = 0.7165870666503906, train/logprobs = tensor([[-1.1765, -1.0856],
        [-1.2856, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009130575926974416
Epoch 0, Step 1757: train/loss = 0.6861361861228943, train/raw-loss = 0.6823412775993347, train/logprobs = tensor([[-1.0871, -1.5261],
        [-1.4947, -1.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037949398159980774
Epoch 0, Step 1758: train/loss = 0.6930904388427734, train/raw-loss = 0.6923137903213501, train/logprobs = tensor([[-1.1429, -1.3207],
        [-1.3058, -1.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007766552735120058
Epoch 0, Step 1759: train/loss = 0.6964515447616577, train/raw-loss = 0.6961077451705933, train/logprobs = tensor([[-1.0498, -1.0189],
        [-1.1469, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034382857847958803
Epoch 0, Step 1760: train/loss = 0.7222150564193726, train/raw-loss = 0.7218828201293945, train/logprobs = tensor([[-1.2623, -0.9872],
        [-1.4750, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033229428809136152
Epoch 0, Step 1761: train/loss = 0.7054510712623596, train/raw-loss = 0.7053537368774414, train/logprobs = tensor([[-0.9177, -1.0582],
        [-1.0696, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009728380828164518
Epoch 0, Step 1762: train/loss = 0.6911161541938782, train/raw-loss = 0.6903356313705444, train/logprobs = tensor([[-0.9524, -1.1040],
        [-1.1490, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0078055947087705135
Epoch 0, Step 1763: train/loss = 0.6994845867156982, train/raw-loss = 0.6991176009178162, train/logprobs = tensor([[-0.9230, -1.1707],
        [-1.1006, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036697862669825554
Epoch 0, Step 1764: train/loss = 0.7032676339149475, train/raw-loss = 0.7032241821289062, train/logprobs = tensor([[-1.1854, -1.3603],
        [-1.3228, -1.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043474050471559167
Epoch 0, Step 1765: train/loss = 0.7000687122344971, train/raw-loss = 0.6987239718437195, train/logprobs = tensor([[-1.0416, -1.2088],
        [-1.5006, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013447620905935764
Epoch 0, Step 1766: train/loss = 0.7052088379859924, train/raw-loss = 0.7052028179168701, train/logprobs = tensor([[-1.0118, -0.8175],
        [-0.9813, -0.7611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.022486195433885e-05
Epoch 0, Step 1767: train/loss = 0.6986134052276611, train/raw-loss = 0.6978038549423218, train/logprobs = tensor([[-0.9713, -1.1020],
        [-1.1882, -0.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0080956369638443
Epoch 0, Step 1768: train/loss = 0.6959660649299622, train/raw-loss = 0.6956824064254761, train/logprobs = tensor([[-0.9723, -1.1905],
        [-1.1337, -1.0902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028364581521600485
Epoch 0, Step 1769: train/loss = 0.6988264918327332, train/raw-loss = 0.6987831592559814, train/logprobs = tensor([[-1.0708, -0.9832],
        [-1.1593, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043337111128494143
Epoch 0, Step 1770: train/loss = 0.6929186582565308, train/raw-loss = 0.6927965879440308, train/logprobs = tensor([[-0.9355, -0.9987],
        [-1.1017, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001220243750140071
Epoch 0, Step 1771: train/loss = 0.6992778182029724, train/raw-loss = 0.6992351412773132, train/logprobs = tensor([[-0.8555, -0.8411],
        [-0.8793, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004261693684384227
Epoch 0, Step 1772: train/loss = 0.69727623462677, train/raw-loss = 0.6972516179084778, train/logprobs = tensor([[-1.0586, -1.0076],
        [-1.2004, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002456062356941402
Epoch 0, Step 1773: train/loss = 0.7116751670837402, train/raw-loss = 0.7116082906723022, train/logprobs = tensor([[-1.0623, -0.8904],
        [-1.1683, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006685177213512361
Epoch 0, Step 1774: train/loss = 0.7077240943908691, train/raw-loss = 0.7076610922813416, train/logprobs = tensor([[-1.0120, -1.2494],
        [-1.0695, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006307419389486313
Epoch 0, Step 1775: train/loss = 0.700598955154419, train/raw-loss = 0.7005329132080078, train/logprobs = tensor([[-1.1178, -0.9762],
        [-1.2139, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006606574170291424
Epoch 0, Step 1776: train/loss = 0.6881470084190369, train/raw-loss = 0.6874068379402161, train/logprobs = tensor([[-1.1126, -1.1324],
        [-1.3325, -1.0294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007401497568935156
Epoch 0, Step 1777: train/loss = 0.6947516202926636, train/raw-loss = 0.6946269273757935, train/logprobs = tensor([[-1.0864, -1.0414],
        [-1.2335, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001247127540409565
Epoch 0, Step 1778: train/loss = 0.6970399022102356, train/raw-loss = 0.6966098546981812, train/logprobs = tensor([[-1.0576, -1.0136],
        [-1.2946, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004301140550523996
Epoch 0, Step 1779: train/loss = 0.7010853290557861, train/raw-loss = 0.701059103012085, train/logprobs = tensor([[-0.9473, -0.9540],
        [-1.0188, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002619953884277493
Epoch 0, Step 1780: train/loss = 0.7094357013702393, train/raw-loss = 0.709209680557251, train/logprobs = tensor([[-0.9948, -0.9786],
        [-1.1286, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002260848181322217
Epoch 0, Step 1781: train/loss = 0.7138357162475586, train/raw-loss = 0.7132865190505981, train/logprobs = tensor([[-1.2419, -0.9851],
        [-1.5837, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005491455085575581
Epoch 0, Step 1782: train/loss = 0.710529088973999, train/raw-loss = 0.7099900841712952, train/logprobs = tensor([[-1.1028, -0.8867],
        [-1.2814, -0.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00539011275395751
Epoch 0, Step 1783: train/loss = 0.6949056386947632, train/raw-loss = 0.6948837637901306, train/logprobs = tensor([[-0.9295, -0.9457],
        [-0.9853, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021875846141483635
Epoch 0, Step 1784: train/loss = 0.7424395680427551, train/raw-loss = 0.742345929145813, train/logprobs = tensor([[-0.9617, -1.0537],
        [-1.2186, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009365244768559933
Epoch 0, Step 1785: train/loss = 0.7037924528121948, train/raw-loss = 0.7035397887229919, train/logprobs = tensor([[-0.7569, -1.1084],
        [-1.0019, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025267633609473705
Epoch 0, Step 1786: train/loss = 0.6902768611907959, train/raw-loss = 0.6899633407592773, train/logprobs = tensor([[-1.0141, -1.0569],
        [-1.0621, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003134740050882101
Epoch 0, Step 1787: train/loss = 0.7271357774734497, train/raw-loss = 0.7270132303237915, train/logprobs = tensor([[-0.8761, -1.1719],
        [-1.0920, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012250696308910847
Epoch 0, Step 1788: train/loss = 0.7075057625770569, train/raw-loss = 0.7071561217308044, train/logprobs = tensor([[-1.0390, -0.9154],
        [-1.2363, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034962217323482037
Epoch 0, Step 1789: train/loss = 0.7008958458900452, train/raw-loss = 0.7007491588592529, train/logprobs = tensor([[-1.0599, -1.2593],
        [-1.0552, -1.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014672874240204692
Epoch 0, Step 1790: train/loss = 0.7474391460418701, train/raw-loss = 0.7459419965744019, train/logprobs = tensor([[-1.2033, -1.5356],
        [-1.3198, -1.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014970951713621616
Epoch 0, Step 1791: train/loss = 0.7127863168716431, train/raw-loss = 0.7088440656661987, train/logprobs = tensor([[-1.0285, -1.7718],
        [-1.3075, -1.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03942260518670082
Epoch 0, Step 1792: train/loss = 0.7077670693397522, train/raw-loss = 0.7076547145843506, train/logprobs = tensor([[-1.2347, -1.1506],
        [-1.4242, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011236791033297777
Epoch 0, Step 1793: train/loss = 0.7123679518699646, train/raw-loss = 0.7122988700866699, train/logprobs = tensor([[-0.9961, -0.7514],
        [-1.1594, -0.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006910883239470422
Epoch 0, Step 1794: train/loss = 0.7181662917137146, train/raw-loss = 0.7178500294685364, train/logprobs = tensor([[-1.2024, -1.0155],
        [-1.3241, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003162780310958624
Epoch 0, Step 1795: train/loss = 0.6997773051261902, train/raw-loss = 0.6992760896682739, train/logprobs = tensor([[-1.1153, -1.1096],
        [-1.3355, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00501207634806633
Epoch 0, Step 1796: train/loss = 0.7203128337860107, train/raw-loss = 0.7202558517456055, train/logprobs = tensor([[-1.0350, -0.7270],
        [-1.1625, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005699493922293186
Epoch 0, Step 1797: train/loss = 0.7087842226028442, train/raw-loss = 0.7086370587348938, train/logprobs = tensor([[-1.0173, -1.0470],
        [-1.0263, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001471295952796936
Epoch 0, Step 1798: train/loss = 0.712861180305481, train/raw-loss = 0.7128263711929321, train/logprobs = tensor([[-0.6822, -0.6617],
        [-0.7656, -0.6727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003481938038021326
Epoch 0, Step 1799: train/loss = 0.6961274147033691, train/raw-loss = 0.6958256959915161, train/logprobs = tensor([[-1.0185, -0.9793],
        [-1.0746, -0.8474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00301745324395597
Epoch 0, Step 1800: train/loss = 0.6958836317062378, train/raw-loss = 0.6954754590988159, train/logprobs = tensor([[-1.0359, -1.0516],
        [-1.2498, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004081304185092449
Epoch 0, Step 1801: train/loss = 0.698875904083252, train/raw-loss = 0.698674201965332, train/logprobs = tensor([[-1.0564, -1.2313],
        [-1.1429, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002016449812799692
Epoch 0, Step 1802: train/loss = 0.703057050704956, train/raw-loss = 0.7027193307876587, train/logprobs = tensor([[-1.0441, -1.0360],
        [-1.2957, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033775835763663054
Epoch 0, Step 1803: train/loss = 0.7002728581428528, train/raw-loss = 0.7001839876174927, train/logprobs = tensor([[-1.0718, -1.3575],
        [-1.0739, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008879189845174551
Epoch 0, Step 1804: train/loss = 0.6964420080184937, train/raw-loss = 0.6948347091674805, train/logprobs = tensor([[-1.1894, -1.2061],
        [-1.4228, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016072437167167664
Epoch 0, Step 1805: train/loss = 0.7032719850540161, train/raw-loss = 0.7032159566879272, train/logprobs = tensor([[-0.9887, -1.1503],
        [-1.0453, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005607227794826031
Epoch 0, Step 1806: train/loss = 0.6951882839202881, train/raw-loss = 0.6951051950454712, train/logprobs = tensor([[-1.0641, -1.1592],
        [-1.2187, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008306661620736122
Epoch 0, Step 1807: train/loss = 0.7000545263290405, train/raw-loss = 0.6998767852783203, train/logprobs = tensor([[-1.2410, -1.1483],
        [-1.3827, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017779315821826458
Epoch 0, Step 1808: train/loss = 0.7019566297531128, train/raw-loss = 0.7018974423408508, train/logprobs = tensor([[-0.7450, -0.9900],
        [-0.8371, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005916667869314551
Epoch 0, Step 1809: train/loss = 0.6972569227218628, train/raw-loss = 0.6964137554168701, train/logprobs = tensor([[-0.9348, -1.2309],
        [-1.0886, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008431056514382362
Epoch 0, Step 1810: train/loss = 0.6932042837142944, train/raw-loss = 0.6931202411651611, train/logprobs = tensor([[-1.0107, -1.0973],
        [-1.1932, -1.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008404483087360859
Epoch 0, Step 1811: train/loss = 0.6949052810668945, train/raw-loss = 0.6948577165603638, train/logprobs = tensor([[-0.8740, -0.8218],
        [-1.0354, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004756409034598619
Epoch 0, Step 1812: train/loss = 0.7075909376144409, train/raw-loss = 0.7072745561599731, train/logprobs = tensor([[-0.9730, -0.9516],
        [-1.2047, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031639609951525927
Epoch 0, Step 1813: train/loss = 0.6985539793968201, train/raw-loss = 0.6979299187660217, train/logprobs = tensor([[-0.9776, -1.1637],
        [-1.1317, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006240773480385542
Epoch 0, Step 1814: train/loss = 0.692402720451355, train/raw-loss = 0.6921704411506653, train/logprobs = tensor([[-1.0343, -1.1875],
        [-1.2361, -1.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002321856562048197
Epoch 0, Step 1815: train/loss = 0.6926479935646057, train/raw-loss = 0.6924898624420166, train/logprobs = tensor([[-0.9929, -1.1476],
        [-1.1738, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015813661739230156
Epoch 0, Step 1816: train/loss = 0.6924471855163574, train/raw-loss = 0.6919454336166382, train/logprobs = tensor([[-1.0933, -1.2054],
        [-1.4131, -1.1668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005017194896936417
Epoch 0, Step 1817: train/loss = 0.6922956705093384, train/raw-loss = 0.6919296979904175, train/logprobs = tensor([[-0.8735, -0.8720],
        [-1.0189, -0.7820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036598430015146732
Epoch 0, Step 1818: train/loss = 0.6982475519180298, train/raw-loss = 0.6980635523796082, train/logprobs = tensor([[-0.9845, -0.9396],
        [-1.2198, -0.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018393821083009243
Epoch 0, Step 1819: train/loss = 0.6944723725318909, train/raw-loss = 0.6944241523742676, train/logprobs = tensor([[-0.9906, -1.0043],
        [-1.0944, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004819790192414075
Epoch 0, Step 1820: train/loss = 0.6972572803497314, train/raw-loss = 0.6970611810684204, train/logprobs = tensor([[-1.2620, -1.3364],
        [-1.3147, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019616291392594576
Epoch 0, Step 1821: train/loss = 0.7160615921020508, train/raw-loss = 0.7155884504318237, train/logprobs = tensor([[-0.9752, -0.9187],
        [-1.1593, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004730452783405781
Epoch 0, Step 1822: train/loss = 0.6901763677597046, train/raw-loss = 0.6891116499900818, train/logprobs = tensor([[-1.0358, -1.2239],
        [-1.1645, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010647268034517765
Epoch 0, Step 1823: train/loss = 0.6979907751083374, train/raw-loss = 0.6973808407783508, train/logprobs = tensor([[-1.1846, -1.1641],
        [-1.5295, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006100002210587263
Epoch 0, Step 1824: train/loss = 0.7029002904891968, train/raw-loss = 0.702667772769928, train/logprobs = tensor([[-0.9250, -1.0540],
        [-1.1238, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023244796320796013
Epoch 0, Step 1825: train/loss = 0.6969637870788574, train/raw-loss = 0.6968235373497009, train/logprobs = tensor([[-1.1269, -1.0361],
        [-1.1342, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014026826247572899
Epoch 0, Step 1826: train/loss = 0.6966648101806641, train/raw-loss = 0.6962308883666992, train/logprobs = tensor([[-0.9387, -1.1323],
        [-1.0302, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004339123144745827
Epoch 0, Step 1827: train/loss = 0.6927593946456909, train/raw-loss = 0.692607045173645, train/logprobs = tensor([[-1.0638, -1.1215],
        [-1.2792, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015235902974382043
Epoch 0, Step 1828: train/loss = 0.7056865692138672, train/raw-loss = 0.7052887678146362, train/logprobs = tensor([[-0.8660, -0.8873],
        [-1.1622, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003978130407631397
Epoch 0, Step 1829: train/loss = 0.6970548629760742, train/raw-loss = 0.6970472931861877, train/logprobs = tensor([[-1.1663, -1.2074],
        [-1.2999, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.522944360971451e-05
Epoch 0, Step 1830: train/loss = 0.6991539001464844, train/raw-loss = 0.6988890171051025, train/logprobs = tensor([[-0.9992, -0.9102],
        [-1.1049, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002648858819156885
Epoch 0, Step 1831: train/loss = 0.7384910583496094, train/raw-loss = 0.7384400367736816, train/logprobs = tensor([[-1.0207, -1.4993],
        [-1.1722, -1.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005105362506583333
Epoch 0, Step 1832: train/loss = 0.6999307870864868, train/raw-loss = 0.6998865604400635, train/logprobs = tensor([[-0.9735, -0.8868],
        [-1.0582, -0.8381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004420000477693975
Epoch 0, Step 1833: train/loss = 0.7001695036888123, train/raw-loss = 0.6990659236907959, train/logprobs = tensor([[-1.0717, -1.2032],
        [-1.2122, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011035392992198467
Epoch 0, Step 1834: train/loss = 0.7010396122932434, train/raw-loss = 0.7007346749305725, train/logprobs = tensor([[-1.1990, -1.1253],
        [-1.2002, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030494369566440582
Epoch 0, Step 1835: train/loss = 0.6919276714324951, train/raw-loss = 0.6915574073791504, train/logprobs = tensor([[-0.8870, -1.0317],
        [-1.0617, -0.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037028419319540262
Epoch 0, Step 1836: train/loss = 0.6926454305648804, train/raw-loss = 0.691897451877594, train/logprobs = tensor([[-0.9408, -1.0433],
        [-1.1655, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00748016033321619
Epoch 0, Step 1837: train/loss = 0.691309928894043, train/raw-loss = 0.6896581649780273, train/logprobs = tensor([[-1.1137, -1.2689],
        [-1.5323, -1.0314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016516536474227905
Epoch 0, Step 1838: train/loss = 0.7165466547012329, train/raw-loss = 0.7165446281433105, train/logprobs = tensor([[-0.8440, -0.9522],
        [-0.8313, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0516396034508944e-05
Epoch 0, Step 1839: train/loss = 0.6989965438842773, train/raw-loss = 0.6989647150039673, train/logprobs = tensor([[-1.0647, -1.0618],
        [-1.2258, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000317924190312624
Epoch 0, Step 1840: train/loss = 0.7094166874885559, train/raw-loss = 0.709140956401825, train/logprobs = tensor([[-1.3415, -1.6040],
        [-1.3636, -1.3847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027573476545512676
Epoch 0, Step 1841: train/loss = 0.6962945461273193, train/raw-loss = 0.6955592632293701, train/logprobs = tensor([[-0.9987, -1.0257],
        [-1.1625, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00735305855050683
Epoch 0, Step 1842: train/loss = 0.7030482888221741, train/raw-loss = 0.7029352784156799, train/logprobs = tensor([[-0.9364, -1.0430],
        [-1.0423, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011300848564133048
Epoch 0, Step 1843: train/loss = 0.6931846737861633, train/raw-loss = 0.6928591132164001, train/logprobs = tensor([[-0.9419, -1.0676],
        [-1.0739, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032556476071476936
Epoch 0, Step 1844: train/loss = 0.6987422108650208, train/raw-loss = 0.6983579397201538, train/logprobs = tensor([[-1.1798, -1.2325],
        [-1.3493, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038427994586527348
Epoch 0, Step 1845: train/loss = 0.694098949432373, train/raw-loss = 0.6940761208534241, train/logprobs = tensor([[-1.2259, -1.2102],
        [-1.2874, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022858503507450223
Epoch 0, Step 1846: train/loss = 0.6966842412948608, train/raw-loss = 0.6961966753005981, train/logprobs = tensor([[-1.1641, -1.0267],
        [-1.2607, -0.9811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004875400103628635
Epoch 0, Step 1847: train/loss = 0.7118701338768005, train/raw-loss = 0.7112893462181091, train/logprobs = tensor([[-1.1526, -0.8931],
        [-1.3465, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005808085203170776
Epoch 0, Step 1848: train/loss = 0.694940984249115, train/raw-loss = 0.6948121786117554, train/logprobs = tensor([[-0.9393, -0.8831],
        [-0.9573, -0.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012877249391749501
Epoch 0, Step 1849: train/loss = 0.6921769380569458, train/raw-loss = 0.6919893622398376, train/logprobs = tensor([[-0.8667, -1.0186],
        [-0.8801, -0.8526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018752580508589745
Epoch 0, Step 1850: train/loss = 0.6992661952972412, train/raw-loss = 0.6978732347488403, train/logprobs = tensor([[-0.9819, -0.9968],
        [-1.2982, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013929820619523525
Epoch 0, Step 1851: train/loss = 0.708521842956543, train/raw-loss = 0.7077432870864868, train/logprobs = tensor([[-1.0109, -0.8687],
        [-1.1903, -0.7771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007785211317241192
Epoch 0, Step 1852: train/loss = 0.7032532691955566, train/raw-loss = 0.7032017707824707, train/logprobs = tensor([[-0.9679, -0.8180],
        [-1.1443, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000515009684022516
Epoch 0, Step 1853: train/loss = 0.6972790956497192, train/raw-loss = 0.6970164179801941, train/logprobs = tensor([[-1.0820, -1.1315],
        [-1.1894, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026274260599166155
Epoch 0, Step 1854: train/loss = 0.6998715400695801, train/raw-loss = 0.6996934413909912, train/logprobs = tensor([[-0.8949, -1.0629],
        [-1.0792, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017806411487981677
Epoch 0, Step 1855: train/loss = 0.7169132232666016, train/raw-loss = 0.7168899774551392, train/logprobs = tensor([[-1.1557, -0.9821],
        [-1.3020, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023211061488837004
Epoch 0, Step 1856: train/loss = 0.7531077861785889, train/raw-loss = 0.753018856048584, train/logprobs = tensor([[-1.0661, -0.7792],
        [-1.1906, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000889263697899878
Epoch 0, Step 1857: train/loss = 0.6908957958221436, train/raw-loss = 0.6896784901618958, train/logprobs = tensor([[-1.1192, -1.4661],
        [-1.4202, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012173459865152836
Epoch 0, Step 1858: train/loss = 0.6963638663291931, train/raw-loss = 0.6961994171142578, train/logprobs = tensor([[-0.8540, -1.0489],
        [-0.9313, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016446944791823626
Epoch 0, Step 1859: train/loss = 0.7062035799026489, train/raw-loss = 0.7058249711990356, train/logprobs = tensor([[-1.0664, -1.0809],
        [-1.2071, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003786410205066204
Epoch 0, Step 1860: train/loss = 0.6947312355041504, train/raw-loss = 0.6943508386611938, train/logprobs = tensor([[-0.9082, -1.1458],
        [-1.0610, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003804164007306099
Epoch 0, Step 1861: train/loss = 0.6945279836654663, train/raw-loss = 0.694195568561554, train/logprobs = tensor([[-0.9096, -0.9436],
        [-1.0558, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033241529017686844
Epoch 0, Step 1862: train/loss = 0.6973541975021362, train/raw-loss = 0.6961168050765991, train/logprobs = tensor([[-1.1454, -1.1557],
        [-1.3540, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012373942881822586
Epoch 0, Step 1863: train/loss = 0.6877874732017517, train/raw-loss = 0.6868604421615601, train/logprobs = tensor([[-0.9635, -1.2509],
        [-1.3030, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009269991889595985
Epoch 0, Step 1864: train/loss = 0.7068710923194885, train/raw-loss = 0.706642746925354, train/logprobs = tensor([[-1.0148, -0.8093],
        [-1.0269, -0.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002283793408423662
Epoch 0, Step 1865: train/loss = 0.6990128755569458, train/raw-loss = 0.6988463401794434, train/logprobs = tensor([[-1.1380, -1.0951],
        [-1.3037, -1.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016650594770908356
Epoch 0, Step 1866: train/loss = 0.697520911693573, train/raw-loss = 0.6974552869796753, train/logprobs = tensor([[-1.0301, -0.9448],
        [-0.9718, -0.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006562108756043017
Epoch 0, Step 1867: train/loss = 0.6937031745910645, train/raw-loss = 0.6933591365814209, train/logprobs = tensor([[-0.9290, -0.9089],
        [-1.0662, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034406764898449183
Epoch 0, Step 1868: train/loss = 0.6947377324104309, train/raw-loss = 0.6944330930709839, train/logprobs = tensor([[-1.0222, -1.0659],
        [-1.2217, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030458879191428423
Epoch 0, Step 1869: train/loss = 0.6981102228164673, train/raw-loss = 0.6977755427360535, train/logprobs = tensor([[-0.8384, -1.1151],
        [-1.0986, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033470806665718555
Epoch 0, Step 1870: train/loss = 0.696262001991272, train/raw-loss = 0.6962550282478333, train/logprobs = tensor([[-0.9801, -0.9511],
        [-1.0622, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.985772051848471e-05
Epoch 0, Step 1871: train/loss = 0.6913187503814697, train/raw-loss = 0.6911600828170776, train/logprobs = tensor([[-1.1132, -1.2267],
        [-1.2548, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015871527139097452
Epoch 0, Step 1872: train/loss = 0.7041374444961548, train/raw-loss = 0.7038370370864868, train/logprobs = tensor([[-1.0400, -1.2619],
        [-1.3000, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030041285790503025
Epoch 0, Step 1873: train/loss = 0.6969147324562073, train/raw-loss = 0.69687420129776, train/logprobs = tensor([[-1.1286, -1.1847],
        [-0.9777, -1.0038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040539581095799804
Epoch 0, Step 1874: train/loss = 0.6929391622543335, train/raw-loss = 0.6903499364852905, train/logprobs = tensor([[-1.4307, -1.6058],
        [-1.5836, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025892287492752075
Epoch 0, Step 1875: train/loss = 0.7000847458839417, train/raw-loss = 0.7000373601913452, train/logprobs = tensor([[-0.9750, -1.0881],
        [-1.0938, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004736086120828986
Epoch 0, Step 1876: train/loss = 0.69304358959198, train/raw-loss = 0.692997932434082, train/logprobs = tensor([[-0.7300, -0.7652],
        [-0.8397, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045658479211851954
Epoch 0, Step 1877: train/loss = 0.6942002773284912, train/raw-loss = 0.6938035488128662, train/logprobs = tensor([[-0.9324, -1.2716],
        [-1.0609, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003966717980802059
Epoch 0, Step 1878: train/loss = 0.7132288217544556, train/raw-loss = 0.7131538391113281, train/logprobs = tensor([[-1.1010, -0.9814],
        [-1.2735, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007493540178984404
Epoch 0, Step 1879: train/loss = 0.6899369955062866, train/raw-loss = 0.6880953311920166, train/logprobs = tensor([[-0.9746, -1.1745],
        [-1.3860, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018416259437799454
Epoch 0, Step 1880: train/loss = 0.7005683183670044, train/raw-loss = 0.7003511190414429, train/logprobs = tensor([[-1.1812, -1.0386],
        [-1.2562, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021717892959713936
Epoch 0, Step 1881: train/loss = 0.6927920579910278, train/raw-loss = 0.6925222873687744, train/logprobs = tensor([[-1.0388, -1.1590],
        [-1.3591, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026977311354130507
Epoch 0, Step 1882: train/loss = 0.6992273330688477, train/raw-loss = 0.6991307735443115, train/logprobs = tensor([[-1.1086, -1.1232],
        [-1.1812, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009656338952481747
Epoch 0, Step 1883: train/loss = 0.6932177543640137, train/raw-loss = 0.6931445002555847, train/logprobs = tensor([[-1.0016, -1.0048],
        [-1.1679, -1.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007323425961658359
Epoch 0, Step 1884: train/loss = 0.6976882815361023, train/raw-loss = 0.6975075006484985, train/logprobs = tensor([[-1.0648, -0.9972],
        [-1.2299, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018079036381095648
Epoch 0, Step 1885: train/loss = 0.7009670734405518, train/raw-loss = 0.699815034866333, train/logprobs = tensor([[-0.9514, -1.4600],
        [-1.0831, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01152030285447836
Epoch 0, Step 1886: train/loss = 0.7070396542549133, train/raw-loss = 0.7068703174591064, train/logprobs = tensor([[-1.0162, -0.8944],
        [-1.2024, -0.9215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016933317529037595
Epoch 0, Step 1887: train/loss = 0.6961363554000854, train/raw-loss = 0.6943379044532776, train/logprobs = tensor([[-1.1786, -1.2543],
        [-1.3398, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017984354868531227
Epoch 0, Step 1888: train/loss = 0.6871230602264404, train/raw-loss = 0.6840497255325317, train/logprobs = tensor([[-1.0917, -1.2297],
        [-1.4247, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03073357418179512
Epoch 0, Step 1889: train/loss = 0.6986215114593506, train/raw-loss = 0.6982532143592834, train/logprobs = tensor([[-1.1134, -0.9989],
        [-1.2795, -0.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036829859018325806
Epoch 0, Step 1890: train/loss = 0.6962313055992126, train/raw-loss = 0.6957876682281494, train/logprobs = tensor([[-0.9865, -1.0009],
        [-1.1999, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004436086863279343
Epoch 0, Step 1891: train/loss = 0.6900335550308228, train/raw-loss = 0.688923716545105, train/logprobs = tensor([[-1.0262, -1.1936],
        [-1.1230, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011099174618721008
Epoch 0, Step 1892: train/loss = 0.7336959838867188, train/raw-loss = 0.7335236072540283, train/logprobs = tensor([[-0.7584, -1.1953],
        [-0.8960, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017245756462216377
Epoch 0, Step 1893: train/loss = 0.6974244713783264, train/raw-loss = 0.6969962120056152, train/logprobs = tensor([[-1.2135, -1.2357],
        [-1.2533, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042820824310183525
Epoch 0, Step 1894: train/loss = 0.6891152858734131, train/raw-loss = 0.6873318552970886, train/logprobs = tensor([[-1.0174, -1.2864],
        [-1.3336, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017834212630987167
Epoch 0, Step 1895: train/loss = 0.693925142288208, train/raw-loss = 0.6935750246047974, train/logprobs = tensor([[-0.8376, -0.8644],
        [-1.1574, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003501377534121275
Epoch 0, Step 1896: train/loss = 0.6802414655685425, train/raw-loss = 0.6784554719924927, train/logprobs = tensor([[-1.1234, -1.3055],
        [-1.3510, -0.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017860226333141327
Epoch 0, Step 1897: train/loss = 0.6943672895431519, train/raw-loss = 0.694132387638092, train/logprobs = tensor([[-0.9621, -1.1120],
        [-1.1076, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023493757471442223
Epoch 0, Step 1898: train/loss = 0.6927967667579651, train/raw-loss = 0.6924715638160706, train/logprobs = tensor([[-1.1024, -1.2890],
        [-1.2273, -1.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003251808462664485
Epoch 0, Step 1899: train/loss = 0.6923314929008484, train/raw-loss = 0.6915522217750549, train/logprobs = tensor([[-0.8745, -1.3011],
        [-1.0571, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0077923559583723545
Epoch 0, Step 1900: train/loss = 0.6919887065887451, train/raw-loss = 0.6917173266410828, train/logprobs = tensor([[-0.9351, -0.9952],
        [-0.9662, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002714018803089857
Epoch 0, Step 1901: train/loss = 0.696412205696106, train/raw-loss = 0.696205198764801, train/logprobs = tensor([[-1.1744, -1.2650],
        [-1.3685, -1.3589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002069868380203843
Epoch 0, Step 1902: train/loss = 0.6899576187133789, train/raw-loss = 0.6881536245346069, train/logprobs = tensor([[-0.8806, -1.4115],
        [-1.1001, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01804005354642868
Epoch 0, Step 1903: train/loss = 0.693218469619751, train/raw-loss = 0.6922911405563354, train/logprobs = tensor([[-0.9906, -1.2443],
        [-1.1747, -1.1906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009273725561797619
Epoch 0, Step 1904: train/loss = 0.6938980221748352, train/raw-loss = 0.6926769018173218, train/logprobs = tensor([[-0.7336, -1.0494],
        [-0.7916, -0.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012211323715746403
Epoch 0, Step 1905: train/loss = 0.6933071613311768, train/raw-loss = 0.6927558183670044, train/logprobs = tensor([[-1.0612, -1.0804],
        [-1.1683, -0.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055138906463980675
Epoch 0, Step 1906: train/loss = 0.6922252774238586, train/raw-loss = 0.692000150680542, train/logprobs = tensor([[-0.9170, -0.9235],
        [-0.9327, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002250832039862871
Epoch 0, Step 1907: train/loss = 0.6977922916412354, train/raw-loss = 0.6976748704910278, train/logprobs = tensor([[-1.0812, -1.0493],
        [-1.2848, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001174252131022513
Epoch 0, Step 1908: train/loss = 0.7000656127929688, train/raw-loss = 0.6998816132545471, train/logprobs = tensor([[-0.7840, -1.0828],
        [-0.8601, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001839597593061626
Epoch 0, Step 1909: train/loss = 0.695610523223877, train/raw-loss = 0.695560097694397, train/logprobs = tensor([[-0.8068, -0.7982],
        [-0.9298, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005048576276749372
Epoch 0, Step 1910: train/loss = 0.710105836391449, train/raw-loss = 0.7099988460540771, train/logprobs = tensor([[-1.0365, -1.0985],
        [-1.1505, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010699895210564137
Epoch 0, Step 1911: train/loss = 0.6999615430831909, train/raw-loss = 0.6995158195495605, train/logprobs = tensor([[-0.8162, -0.9493],
        [-0.8943, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044565265998244286
Epoch 0, Step 1912: train/loss = 0.6993006467819214, train/raw-loss = 0.698898196220398, train/logprobs = tensor([[-1.0535, -1.0175],
        [-1.3501, -0.9648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004024952184408903
Epoch 0, Step 1913: train/loss = 0.6820231676101685, train/raw-loss = 0.6802299618721008, train/logprobs = tensor([[-0.8731, -1.3268],
        [-1.0508, -0.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017932571470737457
Epoch 0, Step 1914: train/loss = 0.6970022320747375, train/raw-loss = 0.6968398690223694, train/logprobs = tensor([[-1.0005, -0.8850],
        [-1.0737, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016245939768850803
Epoch 0, Step 1915: train/loss = 0.6963590383529663, train/raw-loss = 0.6959279775619507, train/logprobs = tensor([[-0.8627, -1.0220],
        [-1.0351, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004310435615479946
Epoch 0, Step 1916: train/loss = 0.7080016732215881, train/raw-loss = 0.707806408405304, train/logprobs = tensor([[-0.9444, -1.1360],
        [-1.1107, -1.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019524474628269672
Epoch 0, Step 1917: train/loss = 0.7077805995941162, train/raw-loss = 0.7071316242218018, train/logprobs = tensor([[-1.0493, -1.0831],
        [-1.2302, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006489391904324293
Epoch 0, Step 1918: train/loss = 0.7126904726028442, train/raw-loss = 0.7109983563423157, train/logprobs = tensor([[-0.9641, -1.0215],
        [-1.1718, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016921833157539368
Epoch 0, Step 1919: train/loss = 0.6968604922294617, train/raw-loss = 0.6963480710983276, train/logprobs = tensor([[-1.0282, -1.0396],
        [-1.1252, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005124307703226805
Epoch 0, Step 1920: train/loss = 0.6928427219390869, train/raw-loss = 0.69221431016922, train/logprobs = tensor([[-1.0832, -1.1596],
        [-1.2524, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006284006871283054
Epoch 0, Step 1921: train/loss = 0.6884377002716064, train/raw-loss = 0.6876208782196045, train/logprobs = tensor([[-0.9574, -1.0830],
        [-1.1944, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008168707601726055
Epoch 0, Step 1922: train/loss = 0.7033244371414185, train/raw-loss = 0.7030289769172668, train/logprobs = tensor([[-0.8992, -0.9890],
        [-1.0156, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029545482248067856
Epoch 0, Step 1923: train/loss = 0.6988224983215332, train/raw-loss = 0.6981750726699829, train/logprobs = tensor([[-0.8262, -0.9743],
        [-1.0091, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006473586894571781
Epoch 0, Step 1924: train/loss = 0.6923431754112244, train/raw-loss = 0.6920984387397766, train/logprobs = tensor([[-0.9240, -1.0285],
        [-1.0141, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024471753276884556
Epoch 0, Step 1925: train/loss = 0.6974391341209412, train/raw-loss = 0.697157084941864, train/logprobs = tensor([[-0.9456, -1.0235],
        [-1.2105, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002820220310240984
Epoch 0, Step 1926: train/loss = 0.6986175775527954, train/raw-loss = 0.6984530091285706, train/logprobs = tensor([[-1.1230, -1.1237],
        [-1.3226, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016456660814583302
Epoch 0, Step 1927: train/loss = 0.721861720085144, train/raw-loss = 0.7216383218765259, train/logprobs = tensor([[-0.9321, -0.9843],
        [-0.9653, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022341543808579445
Epoch 0, Step 1928: train/loss = 0.7020260691642761, train/raw-loss = 0.7016779184341431, train/logprobs = tensor([[-1.0825, -0.9781],
        [-1.2761, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003481891006231308
Epoch 0, Step 1929: train/loss = 0.6944214105606079, train/raw-loss = 0.6940544843673706, train/logprobs = tensor([[-1.6058, -1.7297],
        [-1.8820, -1.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036698265466839075
Epoch 0, Step 1930: train/loss = 0.704663097858429, train/raw-loss = 0.7045530080795288, train/logprobs = tensor([[-1.1548, -1.0022],
        [-1.3677, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011003592517226934
Epoch 0, Step 1931: train/loss = 0.6928622722625732, train/raw-loss = 0.6926640868186951, train/logprobs = tensor([[-0.8687, -0.9222],
        [-1.0105, -0.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019816854037344456
Epoch 0, Step 1932: train/loss = 0.6985472440719604, train/raw-loss = 0.6981884241104126, train/logprobs = tensor([[-0.8786, -0.7972],
        [-1.0306, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003588660852983594
Epoch 0, Step 1933: train/loss = 0.697754442691803, train/raw-loss = 0.6976574659347534, train/logprobs = tensor([[-0.8926, -1.1248],
        [-0.9258, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000970352441072464
Epoch 0, Step 1934: train/loss = 0.6994829773902893, train/raw-loss = 0.6994386911392212, train/logprobs = tensor([[-1.0053, -0.9814],
        [-1.1097, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044264341704547405
Epoch 0, Step 1935: train/loss = 0.6999835968017578, train/raw-loss = 0.6989156007766724, train/logprobs = tensor([[-0.8895, -0.9106],
        [-1.0738, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010679432190954685
Epoch 0, Step 1936: train/loss = 0.7222222089767456, train/raw-loss = 0.7216879725456238, train/logprobs = tensor([[-0.8718, -1.4161],
        [-0.9683, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005343233235180378
Epoch 0, Step 1937: train/loss = 0.6956570744514465, train/raw-loss = 0.6951481103897095, train/logprobs = tensor([[-0.9890, -0.9301],
        [-0.9307, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005089086946099997
Epoch 0, Step 1938: train/loss = 0.6952719688415527, train/raw-loss = 0.6949482560157776, train/logprobs = tensor([[-0.8499, -0.8535],
        [-0.9630, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032377063762396574
Epoch 0, Step 1939: train/loss = 0.6746104955673218, train/raw-loss = 0.6722052097320557, train/logprobs = tensor([[-0.9888, -1.3929],
        [-1.1467, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024052457883954048
Epoch 0, Step 1940: train/loss = 0.6996875405311584, train/raw-loss = 0.6990313529968262, train/logprobs = tensor([[-0.9095, -1.3236],
        [-1.2513, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006562248338013887
Epoch 0, Step 1941: train/loss = 0.7158244252204895, train/raw-loss = 0.7157477736473083, train/logprobs = tensor([[-1.1456, -1.0274],
        [-1.2614, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00076596240978688
Epoch 0, Step 1942: train/loss = 0.6968407034873962, train/raw-loss = 0.6967746019363403, train/logprobs = tensor([[-0.8726, -1.0176],
        [-0.9075, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006611343706026673
Epoch 0, Step 1943: train/loss = 0.7050373554229736, train/raw-loss = 0.7044344544410706, train/logprobs = tensor([[-0.9949, -1.0097],
        [-1.1205, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006028699688613415
Epoch 0, Step 1944: train/loss = 0.695777952671051, train/raw-loss = 0.6954035758972168, train/logprobs = tensor([[-1.0435, -0.9987],
        [-1.2253, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037438380531966686
Epoch 0, Step 1945: train/loss = 0.6946752071380615, train/raw-loss = 0.6944437623023987, train/logprobs = tensor([[-0.8798, -0.9119],
        [-1.0806, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023143989965319633
Epoch 0, Step 1946: train/loss = 0.7057064771652222, train/raw-loss = 0.7053623199462891, train/logprobs = tensor([[-0.9710, -1.1658],
        [-1.1203, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034417500719428062
Epoch 0, Step 1947: train/loss = 0.6953437924385071, train/raw-loss = 0.6952254772186279, train/logprobs = tensor([[-1.1431, -1.1725],
        [-1.0766, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011831221636384726
Epoch 0, Step 1948: train/loss = 0.6984015107154846, train/raw-loss = 0.6983392238616943, train/logprobs = tensor([[-0.9894, -1.0145],
        [-1.1152, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006224783137440681
Epoch 0, Step 1949: train/loss = 0.7018874883651733, train/raw-loss = 0.6961289048194885, train/logprobs = tensor([[-1.1007, -1.7280],
        [-1.2857, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057585764676332474
Epoch 0, Step 1950: train/loss = 0.69560307264328, train/raw-loss = 0.6950622797012329, train/logprobs = tensor([[-1.1003, -1.0869],
        [-1.3320, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005407602991908789
Epoch 0, Step 1951: train/loss = 0.6944804191589355, train/raw-loss = 0.693730354309082, train/logprobs = tensor([[-0.9059, -1.2501],
        [-1.0335, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0075000859797000885
Epoch 0, Step 1952: train/loss = 0.6898308992385864, train/raw-loss = 0.6892459392547607, train/logprobs = tensor([[-0.9714, -1.0874],
        [-1.2313, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005849131383001804
Epoch 0, Step 1953: train/loss = 0.7068947553634644, train/raw-loss = 0.7066810727119446, train/logprobs = tensor([[-1.1009, -1.0780],
        [-1.2385, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002136831171810627
Epoch 0, Step 1954: train/loss = 0.708368182182312, train/raw-loss = 0.7082551717758179, train/logprobs = tensor([[-0.9489, -1.1921],
        [-1.0761, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011296472512185574
Epoch 0, Step 1955: train/loss = 0.6990051865577698, train/raw-loss = 0.6964778304100037, train/logprobs = tensor([[-0.9391, -1.4632],
        [-1.0384, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025273727253079414
Epoch 0, Step 1956: train/loss = 0.6780434846878052, train/raw-loss = 0.6752974987030029, train/logprobs = tensor([[-1.1729, -1.4739],
        [-1.4518, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027460262179374695
Epoch 0, Step 1957: train/loss = 0.6923379898071289, train/raw-loss = 0.6918341517448425, train/logprobs = tensor([[-0.9010, -1.1823],
        [-1.0098, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005038455128669739
Epoch 0, Step 1958: train/loss = 0.6988613605499268, train/raw-loss = 0.6980734467506409, train/logprobs = tensor([[-0.9728, -1.3401],
        [-1.0792, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00787902157753706
Epoch 0, Step 1959: train/loss = 0.6935173273086548, train/raw-loss = 0.6934691667556763, train/logprobs = tensor([[-0.8428, -0.8610],
        [-0.8048, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048200899618677795
Epoch 0, Step 1960: train/loss = 0.7278667688369751, train/raw-loss = 0.7277402877807617, train/logprobs = tensor([[-0.9535, -0.7803],
        [-1.0991, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012648901902139187
Epoch 0, Step 1961: train/loss = 0.7269343137741089, train/raw-loss = 0.7265241742134094, train/logprobs = tensor([[-0.9473, -0.8743],
        [-1.2773, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00410119816660881
Epoch 0, Step 1962: train/loss = 0.7039761543273926, train/raw-loss = 0.703611433506012, train/logprobs = tensor([[-0.9071, -1.0029],
        [-1.0896, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036469148471951485
Epoch 0, Step 1963: train/loss = 0.6775758862495422, train/raw-loss = 0.6744499206542969, train/logprobs = tensor([[-0.8628, -1.2397],
        [-1.2247, -1.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03125906363129616
Epoch 0, Step 1964: train/loss = 0.7100249528884888, train/raw-loss = 0.7085779905319214, train/logprobs = tensor([[-1.3188, -1.4227],
        [-1.5208, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014469505287706852
Epoch 0, Step 1965: train/loss = 0.6813632249832153, train/raw-loss = 0.679694652557373, train/logprobs = tensor([[-1.1968, -1.6081],
        [-1.4944, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016686053946614265
Epoch 0, Step 1966: train/loss = 0.69974285364151, train/raw-loss = 0.6997354030609131, train/logprobs = tensor([[-0.9916, -0.8583],
        [-1.0995, -0.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.384107448160648e-05
Epoch 0, Step 1967: train/loss = 0.698708176612854, train/raw-loss = 0.6986687183380127, train/logprobs = tensor([[-0.9866, -1.1159],
        [-1.0149, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003938624286092818
Epoch 0, Step 1968: train/loss = 0.6967122554779053, train/raw-loss = 0.6960146427154541, train/logprobs = tensor([[-0.8645, -1.0023],
        [-0.9738, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006976000033318996
Epoch 0, Step 1969: train/loss = 0.7383370399475098, train/raw-loss = 0.7379225492477417, train/logprobs = tensor([[-1.1520, -0.7939],
        [-1.3511, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004145508166402578
Epoch 0, Step 1970: train/loss = 0.6953244209289551, train/raw-loss = 0.6951470375061035, train/logprobs = tensor([[-1.4434, -1.3653],
        [-1.4225, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017738601891323924
Epoch 0, Step 1971: train/loss = 0.6931745409965515, train/raw-loss = 0.6929298043251038, train/logprobs = tensor([[-0.9931, -1.0571],
        [-1.0922, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024467618204653263
Epoch 0, Step 1972: train/loss = 0.6877614259719849, train/raw-loss = 0.6858557462692261, train/logprobs = tensor([[-1.0384, -1.1882],
        [-1.2192, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019056640565395355
Epoch 0, Step 1973: train/loss = 0.7391749620437622, train/raw-loss = 0.7388505935668945, train/logprobs = tensor([[-0.8514, -1.1378],
        [-1.0598, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032431911677122116
Epoch 0, Step 1974: train/loss = 0.6950674653053284, train/raw-loss = 0.6948808431625366, train/logprobs = tensor([[-0.9352, -0.9122],
        [-0.8558, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001866210368461907
Epoch 0, Step 1975: train/loss = 0.6893895864486694, train/raw-loss = 0.6880452632904053, train/logprobs = tensor([[-0.8009, -0.9831],
        [-1.1723, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013442790135741234
Epoch 0, Step 1976: train/loss = 0.6870885491371155, train/raw-loss = 0.6865090131759644, train/logprobs = tensor([[-1.0311, -1.1308],
        [-1.1219, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005796078126877546
Epoch 0, Step 1977: train/loss = 0.6889351606369019, train/raw-loss = 0.6884457468986511, train/logprobs = tensor([[-0.7723, -0.9296],
        [-0.8034, -0.6650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004894517362117767
Epoch 0, Step 1978: train/loss = 0.6928346753120422, train/raw-loss = 0.6919054985046387, train/logprobs = tensor([[-1.1754, -1.1600],
        [-1.3500, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009291485883295536
Epoch 0, Step 1979: train/loss = 0.7140821814537048, train/raw-loss = 0.7138999104499817, train/logprobs = tensor([[-1.1394, -1.3533],
        [-1.3157, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018227712716907263
Epoch 0, Step 1980: train/loss = 0.6908354759216309, train/raw-loss = 0.6892382502555847, train/logprobs = tensor([[-1.0006, -1.1892],
        [-1.1837, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015972448512911797
Epoch 0, Step 1981: train/loss = 0.6908954977989197, train/raw-loss = 0.6902927756309509, train/logprobs = tensor([[-0.9287, -0.9960],
        [-1.0481, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006027547176927328
Epoch 0, Step 1982: train/loss = 0.6971766948699951, train/raw-loss = 0.6968666911125183, train/logprobs = tensor([[-0.8176, -1.0873],
        [-0.9883, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003099509747698903
Epoch 0, Step 1983: train/loss = 0.6888576149940491, train/raw-loss = 0.6867913007736206, train/logprobs = tensor([[-0.9327, -1.5017],
        [-1.2692, -1.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02066277712583542
Epoch 0, Step 1984: train/loss = 0.692346453666687, train/raw-loss = 0.6906493902206421, train/logprobs = tensor([[-1.1141, -1.4660],
        [-1.3479, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016971219331026077
Epoch 0, Step 1985: train/loss = 0.6867825984954834, train/raw-loss = 0.6859995126724243, train/logprobs = tensor([[-0.7981, -0.9372],
        [-0.9469, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00783052109181881
Epoch 0, Step 1986: train/loss = 0.6974361538887024, train/raw-loss = 0.6973878741264343, train/logprobs = tensor([[-0.8872, -0.9205],
        [-0.9977, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048355726175941527
Epoch 0, Step 1987: train/loss = 0.6944313049316406, train/raw-loss = 0.694048285484314, train/logprobs = tensor([[-0.7418, -0.9985],
        [-0.7767, -0.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003830498084425926
Epoch 0, Step 1988: train/loss = 0.6961811184883118, train/raw-loss = 0.6956155300140381, train/logprobs = tensor([[-0.9364, -1.0458],
        [-1.1880, -0.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005655455403029919
Epoch 0, Step 1989: train/loss = 0.7071617245674133, train/raw-loss = 0.7067328691482544, train/logprobs = tensor([[-0.9788, -1.1275],
        [-1.0148, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004288403317332268
Epoch 0, Step 1990: train/loss = 0.6958674192428589, train/raw-loss = 0.6958602070808411, train/logprobs = tensor([[-1.0754, -1.2226],
        [-1.0274, -1.0821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.221498526632786e-05
Epoch 0, Step 1991: train/loss = 0.6904622316360474, train/raw-loss = 0.6897047758102417, train/logprobs = tensor([[-1.1467, -1.2820],
        [-1.2499, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007574637420475483
Epoch 0, Step 1992: train/loss = 0.6853530406951904, train/raw-loss = 0.683053731918335, train/logprobs = tensor([[-0.8958, -1.3036],
        [-1.1477, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022992879152297974
Epoch 0, Step 1993: train/loss = 0.6910174489021301, train/raw-loss = 0.6901758313179016, train/logprobs = tensor([[-0.8491, -0.9444],
        [-0.9571, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008416038937866688
Epoch 0, Step 1994: train/loss = 0.6943216323852539, train/raw-loss = 0.6941821575164795, train/logprobs = tensor([[-1.0329, -0.9817],
        [-1.0912, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013939929194748402
Epoch 0, Step 1995: train/loss = 0.6919665932655334, train/raw-loss = 0.6914646029472351, train/logprobs = tensor([[-0.8815, -1.2312],
        [-1.1103, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00502006197348237
Epoch 0, Step 1996: train/loss = 0.6913014054298401, train/raw-loss = 0.6901252269744873, train/logprobs = tensor([[-0.9532, -1.0116],
        [-1.1930, -0.9103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011761277914047241
Epoch 0, Step 1997: train/loss = 0.6815239191055298, train/raw-loss = 0.680546224117279, train/logprobs = tensor([[-0.9098, -1.1225],
        [-1.1686, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009776950813829899
Epoch 0, Step 1998: train/loss = 0.6942735910415649, train/raw-loss = 0.694195032119751, train/logprobs = tensor([[-1.0048, -1.0066],
        [-1.1098, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007848616223782301
Epoch 0, Step 1999: train/loss = 0.691198468208313, train/raw-loss = 0.6904807090759277, train/logprobs = tensor([[-0.8905, -1.0107],
        [-1.0500, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007178143598139286
eval/loss: 0.6952932476997375
Epoch 0, Step 2000: train/loss = 0.682347297668457, train/raw-loss = 0.6808288097381592, train/logprobs = tensor([[-1.0081, -1.2531],
        [-1.0976, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015185481868684292
Epoch 0, Step 2001: train/loss = 0.6932665109634399, train/raw-loss = 0.6929227709770203, train/logprobs = tensor([[-0.9227, -1.0154],
        [-1.1305, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003437561448663473
Epoch 0, Step 2002: train/loss = 0.6941053867340088, train/raw-loss = 0.6938053965568542, train/logprobs = tensor([[-0.8134, -0.9749],
        [-1.0437, -0.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003000230761244893
Epoch 0, Step 2003: train/loss = 0.6975243091583252, train/raw-loss = 0.6971417665481567, train/logprobs = tensor([[-1.1283, -1.1977],
        [-1.0922, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038249343633651733
Epoch 0, Step 2004: train/loss = 0.6901848912239075, train/raw-loss = 0.6891831159591675, train/logprobs = tensor([[-0.8018, -0.9559],
        [-0.9238, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010017827153205872
Epoch 0, Step 2005: train/loss = 0.6935057044029236, train/raw-loss = 0.687731146812439, train/logprobs = tensor([[-0.9303, -1.5606],
        [-1.0836, -0.8579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05774540454149246
Epoch 0, Step 2006: train/loss = 0.6959424614906311, train/raw-loss = 0.6958614587783813, train/logprobs = tensor([[-0.8891, -0.9241],
        [-0.9454, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008099350961856544
Epoch 0, Step 2007: train/loss = 0.6930739879608154, train/raw-loss = 0.6924514770507812, train/logprobs = tensor([[-0.8216, -0.9469],
        [-0.9035, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062255412340164185
Epoch 0, Step 2008: train/loss = 0.6895571947097778, train/raw-loss = 0.6884504556655884, train/logprobs = tensor([[-0.9104, -1.0717],
        [-1.1277, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011068061925470829
Epoch 0, Step 2009: train/loss = 0.6964209079742432, train/raw-loss = 0.696085512638092, train/logprobs = tensor([[-1.0025, -1.0573],
        [-1.1546, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033531230874359608
Epoch 0, Step 2010: train/loss = 0.6916221976280212, train/raw-loss = 0.6905342936515808, train/logprobs = tensor([[-1.0695, -1.2098],
        [-1.2044, -0.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010878965258598328
Epoch 0, Step 2011: train/loss = 0.6925044059753418, train/raw-loss = 0.6922169923782349, train/logprobs = tensor([[-1.0940, -1.1288],
        [-1.0850, -0.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028742263093590736
Epoch 0, Step 2012: train/loss = 0.6858737468719482, train/raw-loss = 0.6843541860580444, train/logprobs = tensor([[-0.9180, -1.1309],
        [-1.1614, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015194570645689964
Epoch 0, Step 2013: train/loss = 0.6900882720947266, train/raw-loss = 0.6885537505149841, train/logprobs = tensor([[-1.1751, -1.6819],
        [-1.4188, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015344955958425999
Epoch 0, Step 2014: train/loss = 0.6976642608642578, train/raw-loss = 0.6974958181381226, train/logprobs = tensor([[-0.9013, -0.8233],
        [-0.9807, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016849352978169918
Epoch 0, Step 2015: train/loss = 0.6943329572677612, train/raw-loss = 0.6941883563995361, train/logprobs = tensor([[-1.0614, -1.0176],
        [-1.2831, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014459501253440976
Epoch 0, Step 2016: train/loss = 0.6904076337814331, train/raw-loss = 0.6897462010383606, train/logprobs = tensor([[-1.1379, -1.1591],
        [-1.1544, -0.7837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006614192854613066
Epoch 0, Step 2017: train/loss = 0.695581316947937, train/raw-loss = 0.6952410340309143, train/logprobs = tensor([[-1.0701, -1.4684],
        [-1.1214, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003403556765988469
Epoch 0, Step 2018: train/loss = 0.6898239850997925, train/raw-loss = 0.6871646046638489, train/logprobs = tensor([[-0.9670, -1.1725],
        [-1.1965, -0.7823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026593497022986412
Epoch 0, Step 2019: train/loss = 0.6945206522941589, train/raw-loss = 0.6944442391395569, train/logprobs = tensor([[-0.8404, -0.8843],
        [-0.8422, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007636600639671087
Epoch 0, Step 2020: train/loss = 0.6934586763381958, train/raw-loss = 0.6934568881988525, train/logprobs = tensor([[-0.8678, -0.9531],
        [-1.0120, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8728082068264484e-05
Epoch 0, Step 2021: train/loss = 0.6867225170135498, train/raw-loss = 0.6848920583724976, train/logprobs = tensor([[-0.9714, -1.1141],
        [-1.2531, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018304431810975075
Epoch 0, Step 2022: train/loss = 0.7119569778442383, train/raw-loss = 0.7108228206634521, train/logprobs = tensor([[-0.9082, -1.5909],
        [-1.1584, -1.2336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011342184618115425
Epoch 0, Step 2023: train/loss = 0.6956826448440552, train/raw-loss = 0.6956741809844971, train/logprobs = tensor([[-0.8475, -0.8309],
        [-0.9410, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.425029227510095e-05
Epoch 0, Step 2024: train/loss = 0.701296329498291, train/raw-loss = 0.7008387446403503, train/logprobs = tensor([[-1.0152, -1.0580],
        [-1.0437, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004575890023261309
Epoch 0, Step 2025: train/loss = 0.7037546634674072, train/raw-loss = 0.7024254202842712, train/logprobs = tensor([[-0.9473, -1.1522],
        [-1.2142, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013292639516294003
Epoch 0, Step 2026: train/loss = 0.6975093483924866, train/raw-loss = 0.6970546245574951, train/logprobs = tensor([[-1.2081, -1.4864],
        [-1.1606, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004547245800495148
Epoch 0, Step 2027: train/loss = 0.7010564804077148, train/raw-loss = 0.7009612321853638, train/logprobs = tensor([[-0.8979, -1.1393],
        [-0.8995, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009531032992526889
Epoch 0, Step 2028: train/loss = 0.6937078237533569, train/raw-loss = 0.6903476715087891, train/logprobs = tensor([[-0.8801, -1.1772],
        [-1.0609, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0336017981171608
Epoch 0, Step 2029: train/loss = 0.6954752802848816, train/raw-loss = 0.6934727430343628, train/logprobs = tensor([[-0.9515, -1.2433],
        [-1.1335, -0.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020024949684739113
Epoch 0, Step 2030: train/loss = 0.6928130388259888, train/raw-loss = 0.6910830736160278, train/logprobs = tensor([[-0.9011, -1.4357],
        [-1.1301, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017298968508839607
Epoch 0, Step 2031: train/loss = 0.6925910711288452, train/raw-loss = 0.6915479898452759, train/logprobs = tensor([[-0.9938, -0.9746],
        [-1.2410, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01043060701340437
Epoch 0, Step 2032: train/loss = 0.7028207182884216, train/raw-loss = 0.7025290131568909, train/logprobs = tensor([[-1.2433, -1.1885],
        [-1.2617, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029166671447455883
Epoch 0, Step 2033: train/loss = 0.6880274415016174, train/raw-loss = 0.6864852905273438, train/logprobs = tensor([[-1.0087, -1.0797],
        [-1.2452, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015421650372445583
Epoch 0, Step 2034: train/loss = 0.6835067272186279, train/raw-loss = 0.6820584535598755, train/logprobs = tensor([[-0.8966, -1.1084],
        [-1.1805, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014482415281236172
Epoch 0, Step 2035: train/loss = 0.700212836265564, train/raw-loss = 0.6990259289741516, train/logprobs = tensor([[-1.1019, -1.0073],
        [-1.3149, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011869038455188274
Epoch 0, Step 2036: train/loss = 0.703188419342041, train/raw-loss = 0.7027694582939148, train/logprobs = tensor([[-0.8596, -1.2874],
        [-0.9779, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041891466826200485
Epoch 0, Step 2037: train/loss = 0.6955947279930115, train/raw-loss = 0.6950369477272034, train/logprobs = tensor([[-0.8395, -0.9949],
        [-1.1547, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005577860865741968
Epoch 0, Step 2038: train/loss = 0.6938253045082092, train/raw-loss = 0.6932165622711182, train/logprobs = tensor([[-0.9067, -0.9080],
        [-0.9212, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00608679186552763
Epoch 0, Step 2039: train/loss = 0.6913934946060181, train/raw-loss = 0.6899023056030273, train/logprobs = tensor([[-1.1239, -1.2238],
        [-1.2566, -0.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014912165701389313
Epoch 0, Step 2040: train/loss = 0.6977396607398987, train/raw-loss = 0.6974263191223145, train/logprobs = tensor([[-1.1257, -1.1828],
        [-1.2236, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031331656500697136
Epoch 0, Step 2041: train/loss = 0.7034690976142883, train/raw-loss = 0.70319664478302, train/logprobs = tensor([[-0.9536, -0.7810],
        [-1.2013, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027249210979789495
Epoch 0, Step 2042: train/loss = 0.6690042018890381, train/raw-loss = 0.6631027460098267, train/logprobs = tensor([[-0.8550, -1.4900],
        [-1.1178, -0.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05901443213224411
Epoch 0, Step 2043: train/loss = 0.7090256214141846, train/raw-loss = 0.7059623003005981, train/logprobs = tensor([[-1.0339, -1.1306],
        [-1.1992, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030633151531219482
Epoch 0, Step 2044: train/loss = 0.7151819467544556, train/raw-loss = 0.7149598598480225, train/logprobs = tensor([[-1.0477, -1.0105],
        [-1.1969, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022208013106137514
Epoch 0, Step 2045: train/loss = 0.7029364705085754, train/raw-loss = 0.7003737688064575, train/logprobs = tensor([[-0.9884, -1.4051],
        [-1.1327, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02562691643834114
Epoch 0, Step 2046: train/loss = 0.695713996887207, train/raw-loss = 0.6940819025039673, train/logprobs = tensor([[-1.0391, -1.2661],
        [-1.1740, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016321107745170593
Epoch 0, Step 2047: train/loss = 0.6989263892173767, train/raw-loss = 0.6988362669944763, train/logprobs = tensor([[-1.2025, -1.1203],
        [-1.3929, -1.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009014012757688761
Epoch 0, Step 2048: train/loss = 0.6940610408782959, train/raw-loss = 0.6933176517486572, train/logprobs = tensor([[-1.1053, -1.4066],
        [-1.2072, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007434291765093803
Epoch 0, Step 2049: train/loss = 0.693148136138916, train/raw-loss = 0.6908798217773438, train/logprobs = tensor([[-1.0318, -1.5445],
        [-1.2754, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022683244198560715
Epoch 0, Step 2050: train/loss = 0.6920211315155029, train/raw-loss = 0.6910870671272278, train/logprobs = tensor([[-1.1355, -1.5918],
        [-1.1682, -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00933986809104681
Epoch 0, Step 2051: train/loss = 0.6681958436965942, train/raw-loss = 0.6666005849838257, train/logprobs = tensor([[-1.0843, -1.3043],
        [-1.2607, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015952397137880325
Epoch 0, Step 2052: train/loss = 0.6977299451828003, train/raw-loss = 0.6967706680297852, train/logprobs = tensor([[-1.1334, -1.1222],
        [-1.2145, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009593606926500797
Epoch 0, Step 2053: train/loss = 0.6894193887710571, train/raw-loss = 0.6888154745101929, train/logprobs = tensor([[-0.9213, -1.0657],
        [-1.0023, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006039431784301996
Epoch 0, Step 2054: train/loss = 0.7137249112129211, train/raw-loss = 0.713580846786499, train/logprobs = tensor([[-0.9609, -1.0312],
        [-1.0797, -1.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014405838446691632
Epoch 0, Step 2055: train/loss = 0.7062290906906128, train/raw-loss = 0.7003828883171082, train/logprobs = tensor([[-1.0173, -1.5792],
        [-1.1299, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05846214294433594
Epoch 0, Step 2056: train/loss = 0.6972310543060303, train/raw-loss = 0.6960643529891968, train/logprobs = tensor([[-0.9161, -1.2692],
        [-1.1125, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011667168699204922
Epoch 0, Step 2057: train/loss = 0.7303029894828796, train/raw-loss = 0.7287161350250244, train/logprobs = tensor([[-1.0427, -1.2646],
        [-1.2997, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01586882770061493
Epoch 0, Step 2058: train/loss = 0.6844103932380676, train/raw-loss = 0.6830340623855591, train/logprobs = tensor([[-0.9719, -1.1182],
        [-1.2460, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01376325823366642
Epoch 0, Step 2059: train/loss = 0.6947305798530579, train/raw-loss = 0.6946943998336792, train/logprobs = tensor([[-1.0664, -1.0085],
        [-1.0723, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003614102606661618
Epoch 0, Step 2060: train/loss = 0.6939001679420471, train/raw-loss = 0.6938815712928772, train/logprobs = tensor([[-1.1203, -1.0927],
        [-1.0814, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018549623200669885
Epoch 0, Step 2061: train/loss = 0.6894444227218628, train/raw-loss = 0.6885157823562622, train/logprobs = tensor([[-0.8956, -1.1114],
        [-1.0315, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009286606684327126
Epoch 0, Step 2062: train/loss = 0.696121335029602, train/raw-loss = 0.6956744194030762, train/logprobs = tensor([[-1.0384, -1.0523],
        [-0.9381, -0.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004468825645744801
Epoch 0, Step 2063: train/loss = 0.689441442489624, train/raw-loss = 0.6888577342033386, train/logprobs = tensor([[-0.9484, -1.1949],
        [-1.1053, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005837049800902605
Epoch 0, Step 2064: train/loss = 0.6797538995742798, train/raw-loss = 0.6773332357406616, train/logprobs = tensor([[-0.8455, -1.2394],
        [-1.0773, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02420618012547493
Epoch 0, Step 2065: train/loss = 0.6906269788742065, train/raw-loss = 0.6892595291137695, train/logprobs = tensor([[-0.9505, -1.4082],
        [-1.1408, -0.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01367521844804287
Epoch 0, Step 2066: train/loss = 0.6961984634399414, train/raw-loss = 0.6959121227264404, train/logprobs = tensor([[-1.0146, -1.1080],
        [-1.0629, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002863524714484811
Epoch 0, Step 2067: train/loss = 0.6924786567687988, train/raw-loss = 0.6923269033432007, train/logprobs = tensor([[-1.1959, -1.2201],
        [-0.9721, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015183106297627091
Epoch 0, Step 2068: train/loss = 0.6897222399711609, train/raw-loss = 0.6892249584197998, train/logprobs = tensor([[-1.2760, -1.8385],
        [-1.3504, -1.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004972666501998901
Epoch 0, Step 2069: train/loss = 0.6970440745353699, train/raw-loss = 0.6968792676925659, train/logprobs = tensor([[-0.9282, -0.9373],
        [-1.1423, -0.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016478807665407658
Epoch 0, Step 2070: train/loss = 0.6873888373374939, train/raw-loss = 0.685778021812439, train/logprobs = tensor([[-0.9606, -1.0989],
        [-1.2276, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016108419746160507
Epoch 0, Step 2071: train/loss = 0.6946366429328918, train/raw-loss = 0.6945279836654663, train/logprobs = tensor([[-0.8524, -0.7871],
        [-0.9105, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010860521579161286
Epoch 0, Step 2072: train/loss = 0.690762460231781, train/raw-loss = 0.6898790001869202, train/logprobs = tensor([[-1.0141, -1.1066],
        [-1.0217, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008834602311253548
Epoch 0, Step 2073: train/loss = 0.6941804885864258, train/raw-loss = 0.6940096616744995, train/logprobs = tensor([[-1.0952, -1.0715],
        [-0.9690, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017077515367418528
Epoch 0, Step 2074: train/loss = 0.6999086737632751, train/raw-loss = 0.6992790699005127, train/logprobs = tensor([[-0.8641, -1.1576],
        [-1.0046, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006296023726463318
Epoch 0, Step 2075: train/loss = 0.691393256187439, train/raw-loss = 0.691197395324707, train/logprobs = tensor([[-0.9850, -1.1259],
        [-1.0244, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019581629894673824
Epoch 0, Step 2076: train/loss = 0.684960126876831, train/raw-loss = 0.6834946870803833, train/logprobs = tensor([[-1.1338, -1.2903],
        [-1.3877, -1.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014654790051281452
Epoch 0, Step 2077: train/loss = 0.690295398235321, train/raw-loss = 0.6893966197967529, train/logprobs = tensor([[-1.0491, -1.2217],
        [-1.2956, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008987639099359512
Epoch 0, Step 2078: train/loss = 0.6849012970924377, train/raw-loss = 0.6835891008377075, train/logprobs = tensor([[-1.1989, -1.4578],
        [-1.5089, -1.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013121561147272587
Epoch 0, Step 2079: train/loss = 0.716401219367981, train/raw-loss = 0.7162836790084839, train/logprobs = tensor([[-0.9833, -0.7881],
        [-1.2831, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001175524783320725
Epoch 0, Step 2080: train/loss = 0.696370005607605, train/raw-loss = 0.6960955262184143, train/logprobs = tensor([[-1.1979, -1.2842],
        [-1.0436, -1.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027449666522443295
Epoch 0, Step 2081: train/loss = 0.7083287835121155, train/raw-loss = 0.7075458765029907, train/logprobs = tensor([[-1.2748, -1.4069],
        [-1.1305, -0.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007828867062926292
Epoch 0, Step 2082: train/loss = 0.702384889125824, train/raw-loss = 0.7014565467834473, train/logprobs = tensor([[-0.8962, -0.8500],
        [-1.2361, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009283484891057014
Epoch 0, Step 2083: train/loss = 0.7060226202011108, train/raw-loss = 0.705891489982605, train/logprobs = tensor([[-1.1179, -1.0328],
        [-1.1447, -0.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013112151063978672
Epoch 0, Step 2084: train/loss = 0.68202805519104, train/raw-loss = 0.680055558681488, train/logprobs = tensor([[-1.2785, -1.5769],
        [-1.1950, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01972525380551815
Epoch 0, Step 2085: train/loss = 0.6589815020561218, train/raw-loss = 0.6539338827133179, train/logprobs = tensor([[-0.9753, -1.4648],
        [-1.3663, -0.8416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05047593638300896
Epoch 0, Step 2086: train/loss = 0.6973878741264343, train/raw-loss = 0.6970577239990234, train/logprobs = tensor([[-0.9501, -0.8909],
        [-1.1057, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003301224671304226
Epoch 0, Step 2087: train/loss = 0.6914612650871277, train/raw-loss = 0.6908618211746216, train/logprobs = tensor([[-1.1330, -1.2649],
        [-1.1427, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005994846578687429
Epoch 0, Step 2088: train/loss = 0.6953938603401184, train/raw-loss = 0.6952273845672607, train/logprobs = tensor([[-1.0873, -1.0934],
        [-0.9816, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016650739125907421
Epoch 0, Step 2089: train/loss = 0.7053384780883789, train/raw-loss = 0.7050184011459351, train/logprobs = tensor([[-1.5712, -1.8535],
        [-1.2942, -1.3603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032008704729378223
Epoch 0, Step 2090: train/loss = 0.6935309171676636, train/raw-loss = 0.6933397054672241, train/logprobs = tensor([[-0.8542, -0.8620],
        [-0.8958, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001911104191094637
Epoch 0, Step 2091: train/loss = 0.6970840692520142, train/raw-loss = 0.6963144540786743, train/logprobs = tensor([[-0.9993, -1.0989],
        [-1.0321, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007696080952882767
Epoch 0, Step 2092: train/loss = 0.699211835861206, train/raw-loss = 0.6989109516143799, train/logprobs = tensor([[-0.9754, -1.2686],
        [-1.1616, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030082850717008114
Epoch 0, Step 2093: train/loss = 0.7348417639732361, train/raw-loss = 0.7340519428253174, train/logprobs = tensor([[-1.2359, -1.6426],
        [-1.2693, -1.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007897610776126385
Epoch 0, Step 2094: train/loss = 0.6933466196060181, train/raw-loss = 0.6930440068244934, train/logprobs = tensor([[-0.9472, -1.0545],
        [-1.3402, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003026579273864627
Epoch 0, Step 2095: train/loss = 0.696774959564209, train/raw-loss = 0.6964625716209412, train/logprobs = tensor([[-1.3925, -1.3388],
        [-1.0592, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031239651143550873
Epoch 0, Step 2096: train/loss = 0.6837775707244873, train/raw-loss = 0.6822017431259155, train/logprobs = tensor([[-1.0112, -1.5914],
        [-1.1218, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015758467838168144
Epoch 0, Step 2097: train/loss = 0.6906421780586243, train/raw-loss = 0.6900336146354675, train/logprobs = tensor([[-1.0466, -1.2219],
        [-0.9713, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060858880169689655
Epoch 0, Step 2098: train/loss = 0.6899479627609253, train/raw-loss = 0.6896886229515076, train/logprobs = tensor([[-0.9953, -1.0813],
        [-1.3338, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025938230101019144
Epoch 0, Step 2099: train/loss = 0.6753973960876465, train/raw-loss = 0.6714749336242676, train/logprobs = tensor([[-1.2053, -1.6691],
        [-1.3700, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039223942905664444
Epoch 0, Step 2100: train/loss = 0.6837723255157471, train/raw-loss = 0.6811507940292358, train/logprobs = tensor([[-1.3504, -1.8758],
        [-1.5762, -1.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026215991005301476
Epoch 0, Step 2101: train/loss = 0.6988326907157898, train/raw-loss = 0.6988182663917542, train/logprobs = tensor([[-1.1937, -1.1761],
        [-1.0647, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014422531239688396
Epoch 0, Step 2102: train/loss = 0.6934764981269836, train/raw-loss = 0.6926400065422058, train/logprobs = tensor([[-0.9454, -1.1363],
        [-1.0146, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008364913053810596
Epoch 0, Step 2103: train/loss = 0.6875304579734802, train/raw-loss = 0.6862044334411621, train/logprobs = tensor([[-1.0493, -1.2172],
        [-1.1384, -0.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01326067466288805
Epoch 0, Step 2104: train/loss = 0.6978341341018677, train/raw-loss = 0.6975703239440918, train/logprobs = tensor([[-1.1717, -1.3833],
        [-1.1586, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002638397039845586
Epoch 0, Step 2105: train/loss = 0.6874125599861145, train/raw-loss = 0.6848760843276978, train/logprobs = tensor([[-1.0374, -1.3073],
        [-1.3657, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025365235283970833
Epoch 0, Step 2106: train/loss = 0.6919378042221069, train/raw-loss = 0.689424991607666, train/logprobs = tensor([[-0.9483, -1.1976],
        [-1.2481, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02512817643582821
Epoch 0, Step 2107: train/loss = 0.6918238401412964, train/raw-loss = 0.6911554932594299, train/logprobs = tensor([[-0.8967, -1.1287],
        [-1.2030, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0066831898875534534
Epoch 0, Step 2108: train/loss = 0.6994403600692749, train/raw-loss = 0.6992476582527161, train/logprobs = tensor([[-1.0143, -1.0283],
        [-1.0364, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019268624018877745
Epoch 0, Step 2109: train/loss = 0.7044506072998047, train/raw-loss = 0.7042542695999146, train/logprobs = tensor([[-0.9448, -1.0210],
        [-1.0964, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001964015420526266
Epoch 0, Step 2110: train/loss = 0.6918122172355652, train/raw-loss = 0.6902021169662476, train/logprobs = tensor([[-0.9171, -1.4851],
        [-1.1406, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016100987792015076
Epoch 0, Step 2111: train/loss = 0.6866368055343628, train/raw-loss = 0.6856709718704224, train/logprobs = tensor([[-0.9584, -1.1218],
        [-1.1232, -0.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00965825654566288
Epoch 0, Step 2112: train/loss = 0.6994441747665405, train/raw-loss = 0.6982479691505432, train/logprobs = tensor([[-1.1066, -1.2897],
        [-1.3319, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011962429620325565
Epoch 0, Step 2113: train/loss = 0.7094496488571167, train/raw-loss = 0.708667516708374, train/logprobs = tensor([[-0.9743, -1.0763],
        [-1.1846, -0.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007821710780262947
Epoch 0, Step 2114: train/loss = 0.7062197923660278, train/raw-loss = 0.7060614824295044, train/logprobs = tensor([[-0.7188, -1.0686],
        [-0.9872, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015824830625206232
Epoch 0, Step 2115: train/loss = 0.6838592290878296, train/raw-loss = 0.6821660399436951, train/logprobs = tensor([[-1.1994, -1.3562],
        [-1.3953, -1.0190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016931841149926186
Epoch 0, Step 2116: train/loss = 0.6901544332504272, train/raw-loss = 0.6898146867752075, train/logprobs = tensor([[-0.8641, -1.0949],
        [-1.1765, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033972621895372868
Epoch 0, Step 2117: train/loss = 0.6880731582641602, train/raw-loss = 0.6875576972961426, train/logprobs = tensor([[-0.9578, -1.2325],
        [-1.2061, -1.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005155072081834078
Epoch 0, Step 2118: train/loss = 0.6892338395118713, train/raw-loss = 0.688372015953064, train/logprobs = tensor([[-0.9364, -1.1530],
        [-1.0295, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008617829531431198
Epoch 0, Step 2119: train/loss = 0.6824540495872498, train/raw-loss = 0.6805204153060913, train/logprobs = tensor([[-0.9760, -1.3385],
        [-1.3240, -1.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019336458295583725
Epoch 0, Step 2120: train/loss = 0.6904776096343994, train/raw-loss = 0.689557671546936, train/logprobs = tensor([[-0.8696, -1.1136],
        [-1.0372, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0091991713270545
Epoch 0, Step 2121: train/loss = 0.8082751631736755, train/raw-loss = 0.80741286277771, train/logprobs = tensor([[-1.5524, -0.9809],
        [-1.7614, -0.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008623186498880386
Epoch 0, Step 2122: train/loss = 0.6371054649353027, train/raw-loss = 0.6342427730560303, train/logprobs = tensor([[-0.8520, -1.9676],
        [-1.6520, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02862659841775894
Epoch 0, Step 2123: train/loss = 0.7129529714584351, train/raw-loss = 0.7127461433410645, train/logprobs = tensor([[-0.8809, -1.2696],
        [-1.0375, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020686141215264797
Epoch 0, Step 2124: train/loss = 0.6942541599273682, train/raw-loss = 0.6937594413757324, train/logprobs = tensor([[-0.8914, -1.1139],
        [-1.0807, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004947961308062077
Epoch 0, Step 2125: train/loss = 0.7074824571609497, train/raw-loss = 0.7074049711227417, train/logprobs = tensor([[-1.0910, -0.8891],
        [-1.1133, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007747601484879851
Epoch 0, Step 2126: train/loss = 0.6828039288520813, train/raw-loss = 0.6806245446205139, train/logprobs = tensor([[-1.0428, -1.5267],
        [-1.3492, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021793846040964127
Epoch 0, Step 2127: train/loss = 0.6860551834106445, train/raw-loss = 0.6843547224998474, train/logprobs = tensor([[-0.9381, -1.2301],
        [-1.1022, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017003804445266724
Epoch 0, Step 2128: train/loss = 0.7012374401092529, train/raw-loss = 0.7010239362716675, train/logprobs = tensor([[-0.9180, -1.1864],
        [-0.9960, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002135769696906209
Epoch 0, Step 2129: train/loss = 0.6950124502182007, train/raw-loss = 0.6948604583740234, train/logprobs = tensor([[-1.0587, -1.1017],
        [-1.1786, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015193475410342216
Epoch 0, Step 2130: train/loss = 0.6843259334564209, train/raw-loss = 0.6825098395347595, train/logprobs = tensor([[-1.1630, -1.4790],
        [-1.2687, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018161147832870483
Epoch 0, Step 2131: train/loss = 0.689516544342041, train/raw-loss = 0.6886321902275085, train/logprobs = tensor([[-0.8250, -0.9617],
        [-1.1005, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008843773975968361
Epoch 0, Step 2132: train/loss = 0.6777505874633789, train/raw-loss = 0.6744393706321716, train/logprobs = tensor([[-1.0064, -1.2417],
        [-1.2217, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033111572265625
Epoch 0, Step 2133: train/loss = 0.7137168645858765, train/raw-loss = 0.7131883502006531, train/logprobs = tensor([[-0.9055, -1.2646],
        [-0.8910, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005285127088427544
Epoch 0, Step 2134: train/loss = 0.718327522277832, train/raw-loss = 0.7178338766098022, train/logprobs = tensor([[-1.1027, -1.3213],
        [-1.1839, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004936350975185633
Epoch 0, Step 2135: train/loss = 0.704800546169281, train/raw-loss = 0.7041689157485962, train/logprobs = tensor([[-0.8110, -1.1001],
        [-0.9089, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006315522827208042
Epoch 0, Step 2136: train/loss = 0.6898100972175598, train/raw-loss = 0.6894526481628418, train/logprobs = tensor([[-1.1051, -1.2144],
        [-1.0988, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035743501503020525
Epoch 0, Step 2137: train/loss = 0.7363412380218506, train/raw-loss = 0.7351950407028198, train/logprobs = tensor([[-1.0916, -1.0975],
        [-1.3205, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011461865156888962
Epoch 0, Step 2138: train/loss = 0.7670372724533081, train/raw-loss = 0.765121579170227, train/logprobs = tensor([[-1.1571, -1.4911],
        [-1.6079, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01915648952126503
Epoch 0, Step 2139: train/loss = 0.7021156549453735, train/raw-loss = 0.7015863656997681, train/logprobs = tensor([[-1.0116, -1.0825],
        [-1.3528, -1.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052925413474440575
Epoch 0, Step 2140: train/loss = 0.6932221055030823, train/raw-loss = 0.6931915283203125, train/logprobs = tensor([[-1.5286, -1.5668],
        [-1.0783, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030618521850556135
Epoch 0, Step 2141: train/loss = 0.6953235268592834, train/raw-loss = 0.6950448155403137, train/logprobs = tensor([[-0.8625, -0.9142],
        [-0.9701, -0.8474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027872093487530947
Epoch 0, Step 2142: train/loss = 0.6872854232788086, train/raw-loss = 0.686164915561676, train/logprobs = tensor([[-0.9220, -1.1565],
        [-1.1146, -0.9897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011204931885004044
Epoch 0, Step 2143: train/loss = 0.7057243585586548, train/raw-loss = 0.7052457332611084, train/logprobs = tensor([[-0.8077, -1.1915],
        [-0.9229, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004786004312336445
Epoch 0, Step 2144: train/loss = 0.7165433764457703, train/raw-loss = 0.7163528203964233, train/logprobs = tensor([[-1.0463, -0.7940],
        [-1.1901, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019052575808018446
Epoch 0, Step 2145: train/loss = 0.689964771270752, train/raw-loss = 0.689159631729126, train/logprobs = tensor([[-0.9527, -1.0587],
        [-1.2176, -0.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008051196113228798
Epoch 0, Step 2146: train/loss = 0.7061859369277954, train/raw-loss = 0.7059924006462097, train/logprobs = tensor([[-0.9546, -1.1941],
        [-0.9310, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019353647949174047
Epoch 0, Step 2147: train/loss = 0.7062098383903503, train/raw-loss = 0.7055612206459045, train/logprobs = tensor([[-0.8065, -1.0653],
        [-1.0282, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006486168131232262
Epoch 0, Step 2148: train/loss = 0.6943140625953674, train/raw-loss = 0.6943105459213257, train/logprobs = tensor([[-1.0257, -1.0299],
        [-1.1200, -1.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.535277210175991e-05
Epoch 0, Step 2149: train/loss = 0.6904568076133728, train/raw-loss = 0.6890655755996704, train/logprobs = tensor([[-0.8277, -1.1670],
        [-1.1346, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01391141302883625
Epoch 0, Step 2150: train/loss = 0.6774968504905701, train/raw-loss = 0.6723016500473022, train/logprobs = tensor([[-1.0902, -1.7641],
        [-1.6232, -1.2806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05195177346467972
Epoch 0, Step 2151: train/loss = 0.6819800734519958, train/raw-loss = 0.6790300011634827, train/logprobs = tensor([[-0.9359, -1.4209],
        [-1.0534, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029500523582100868
Epoch 0, Step 2152: train/loss = 0.687250018119812, train/raw-loss = 0.6862963438034058, train/logprobs = tensor([[-0.7460, -1.0154],
        [-0.9279, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009536294266581535
Epoch 0, Step 2153: train/loss = 0.6898402571678162, train/raw-loss = 0.6894035935401917, train/logprobs = tensor([[-0.8677, -1.0281],
        [-1.0095, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004366607405245304
Epoch 0, Step 2154: train/loss = 0.695345938205719, train/raw-loss = 0.6951791048049927, train/logprobs = tensor([[-0.8355, -0.9301],
        [-1.0417, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001668059965595603
Epoch 0, Step 2155: train/loss = 0.7066678404808044, train/raw-loss = 0.7045851945877075, train/logprobs = tensor([[-0.9779, -1.4047],
        [-1.3638, -1.2785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02082645893096924
Epoch 0, Step 2156: train/loss = 0.6877037286758423, train/raw-loss = 0.6843835115432739, train/logprobs = tensor([[-1.2488, -1.3624],
        [-1.4043, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033202096819877625
Epoch 0, Step 2157: train/loss = 0.711066484451294, train/raw-loss = 0.7101378440856934, train/logprobs = tensor([[-1.2707, -1.5123],
        [-1.4622, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00928547140210867
Epoch 0, Step 2158: train/loss = 0.6966286897659302, train/raw-loss = 0.6959447860717773, train/logprobs = tensor([[-0.9542, -1.1637],
        [-1.0817, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006839805748313665
Epoch 0, Step 2159: train/loss = 0.6891593933105469, train/raw-loss = 0.6882755756378174, train/logprobs = tensor([[-1.0047, -1.2372],
        [-1.2194, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00883787963539362
Epoch 0, Step 2160: train/loss = 0.7033519148826599, train/raw-loss = 0.7031024098396301, train/logprobs = tensor([[-0.9862, -0.9032],
        [-1.1742, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002495035296306014
Epoch 0, Step 2161: train/loss = 0.7761068344116211, train/raw-loss = 0.7743853330612183, train/logprobs = tensor([[-0.9283, -1.5323],
        [-1.2739, -1.5104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017214853316545486
Epoch 0, Step 2162: train/loss = 0.68677818775177, train/raw-loss = 0.6856127381324768, train/logprobs = tensor([[-1.2739, -1.4702],
        [-1.4435, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011654011905193329
Epoch 0, Step 2163: train/loss = 0.7121869921684265, train/raw-loss = 0.7115150690078735, train/logprobs = tensor([[-1.1702, -1.4761],
        [-0.9997, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006719421129673719
Epoch 0, Step 2164: train/loss = 0.6971482038497925, train/raw-loss = 0.6963224411010742, train/logprobs = tensor([[-0.9850, -1.4562],
        [-1.1348, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008257299661636353
Epoch 0, Step 2165: train/loss = 0.6952019333839417, train/raw-loss = 0.6929739713668823, train/logprobs = tensor([[-1.0472, -1.7485],
        [-1.2398, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02227938175201416
Epoch 0, Step 2166: train/loss = 0.745571494102478, train/raw-loss = 0.7439578771591187, train/logprobs = tensor([[-0.8535, -1.3926],
        [-1.0147, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016135789453983307
Epoch 0, Step 2167: train/loss = 0.7173178791999817, train/raw-loss = 0.7164208889007568, train/logprobs = tensor([[-0.7231, -1.2790],
        [-0.8608, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008970184251666069
Epoch 0, Step 2168: train/loss = 0.6954526901245117, train/raw-loss = 0.6940605640411377, train/logprobs = tensor([[-1.2554, -1.3099],
        [-1.3586, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01392009761184454
Epoch 0, Step 2169: train/loss = 0.6968291997909546, train/raw-loss = 0.6968239545822144, train/logprobs = tensor([[-1.3072, -1.1688],
        [-1.1241, -0.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.226713255979121e-05
Epoch 0, Step 2170: train/loss = 0.6898398995399475, train/raw-loss = 0.6871992945671082, train/logprobs = tensor([[-0.9857, -1.4110],
        [-1.2553, -1.2628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026405462995171547
Epoch 0, Step 2171: train/loss = 0.7078186273574829, train/raw-loss = 0.7077295780181885, train/logprobs = tensor([[-0.7835, -1.0004],
        [-0.9615, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00089014892000705
Epoch 0, Step 2172: train/loss = 0.6823780536651611, train/raw-loss = 0.67940354347229, train/logprobs = tensor([[-1.2738, -1.3881],
        [-1.5441, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029745128005743027
Epoch 0, Step 2173: train/loss = 0.6931844353675842, train/raw-loss = 0.6926619410514832, train/logprobs = tensor([[-0.9806, -1.1308],
        [-1.1730, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052246409468352795
Epoch 0, Step 2174: train/loss = 0.6786043643951416, train/raw-loss = 0.6744664311408997, train/logprobs = tensor([[-0.9227, -1.5496],
        [-1.3043, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04137939214706421
Epoch 0, Step 2175: train/loss = 0.7081303000450134, train/raw-loss = 0.7080642580986023, train/logprobs = tensor([[-0.9591, -0.8995],
        [-1.3345, -1.0436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006603075889870524
Epoch 0, Step 2176: train/loss = 0.6954518556594849, train/raw-loss = 0.6951757669448853, train/logprobs = tensor([[-0.8313, -1.0722],
        [-1.0103, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002760161878541112
Epoch 0, Step 2177: train/loss = 0.7487484812736511, train/raw-loss = 0.7473271489143372, train/logprobs = tensor([[-1.1866, -0.7344],
        [-1.0021, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014213809743523598
Epoch 0, Step 2178: train/loss = 0.7077577114105225, train/raw-loss = 0.7073510885238647, train/logprobs = tensor([[-1.0350, -0.9539],
        [-1.2459, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004066054709255695
Epoch 0, Step 2179: train/loss = 0.6921602487564087, train/raw-loss = 0.69134122133255, train/logprobs = tensor([[-1.1259, -1.2684],
        [-1.0833, -0.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008189882151782513
Epoch 0, Step 2180: train/loss = 0.6843690276145935, train/raw-loss = 0.6773024201393127, train/logprobs = tensor([[-0.9204, -1.8156],
        [-1.2971, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07066579163074493
Epoch 0, Step 2181: train/loss = 0.6898913979530334, train/raw-loss = 0.6886157393455505, train/logprobs = tensor([[-0.8198, -0.9755],
        [-1.0676, -0.7945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012756354175508022
Epoch 0, Step 2182: train/loss = 0.6819732189178467, train/raw-loss = 0.680213451385498, train/logprobs = tensor([[-0.8390, -1.0334],
        [-1.1092, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017598452046513557
Epoch 0, Step 2183: train/loss = 0.6844146251678467, train/raw-loss = 0.683625340461731, train/logprobs = tensor([[-0.9874, -1.2971],
        [-1.2945, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007892605848610401
Epoch 0, Step 2184: train/loss = 0.7210983633995056, train/raw-loss = 0.7189815044403076, train/logprobs = tensor([[-1.1852, -1.1873],
        [-1.6307, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021168293431401253
Epoch 0, Step 2185: train/loss = 0.6918444633483887, train/raw-loss = 0.6899461150169373, train/logprobs = tensor([[-1.1258, -1.1181],
        [-1.4049, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018983449786901474
Epoch 0, Step 2186: train/loss = 0.6967129707336426, train/raw-loss = 0.6966858506202698, train/logprobs = tensor([[-0.9537, -1.0037],
        [-0.9485, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002709792461246252
Epoch 0, Step 2187: train/loss = 0.6966079473495483, train/raw-loss = 0.6957889795303345, train/logprobs = tensor([[-1.0448, -1.0595],
        [-1.2940, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008189424872398376
Epoch 0, Step 2188: train/loss = 0.6998717188835144, train/raw-loss = 0.6992862820625305, train/logprobs = tensor([[-1.0008, -1.1697],
        [-1.2335, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005855051800608635
Epoch 0, Step 2189: train/loss = 0.694797158241272, train/raw-loss = 0.6943060755729675, train/logprobs = tensor([[-1.0994, -1.1092],
        [-1.1939, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004911038093268871
Epoch 0, Step 2190: train/loss = 0.7603044509887695, train/raw-loss = 0.7599129676818848, train/logprobs = tensor([[-0.8862, -0.7768],
        [-1.3047, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003915485460311174
Epoch 0, Step 2191: train/loss = 0.6659458875656128, train/raw-loss = 0.6638222336769104, train/logprobs = tensor([[-1.3996, -1.7303],
        [-1.1131, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021236438304185867
Epoch 0, Step 2192: train/loss = 0.72189861536026, train/raw-loss = 0.7213910818099976, train/logprobs = tensor([[-1.0075, -0.9128],
        [-1.2102, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005076031666249037
Epoch 0, Step 2193: train/loss = 0.722392737865448, train/raw-loss = 0.720036506652832, train/logprobs = tensor([[-0.9899, -1.3274],
        [-1.2844, -1.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023562580347061157
Epoch 0, Step 2194: train/loss = 0.6515682935714722, train/raw-loss = 0.6452970504760742, train/logprobs = tensor([[-0.9679, -1.8681],
        [-1.2679, -0.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06271223723888397
Epoch 0, Step 2195: train/loss = 0.6871860027313232, train/raw-loss = 0.6851766705513, train/logprobs = tensor([[-1.0600, -1.4316],
        [-1.0624, -0.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02009330317378044
Epoch 0, Step 2196: train/loss = 0.6792595386505127, train/raw-loss = 0.6766803860664368, train/logprobs = tensor([[-1.0105, -1.3737],
        [-1.2725, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025791110470891
Epoch 0, Step 2197: train/loss = 0.7092515230178833, train/raw-loss = 0.7081230878829956, train/logprobs = tensor([[-1.2281, -1.4718],
        [-1.2491, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01128418743610382
Epoch 0, Step 2198: train/loss = 0.6823688745498657, train/raw-loss = 0.6807366013526917, train/logprobs = tensor([[-1.1547, -1.4279],
        [-1.5405, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01632264256477356
Epoch 0, Step 2199: train/loss = 0.6930423974990845, train/raw-loss = 0.6918123960494995, train/logprobs = tensor([[-0.7952, -1.0628],
        [-1.1878, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012299347668886185
Epoch 0, Step 2200: train/loss = 0.705976128578186, train/raw-loss = 0.7056950330734253, train/logprobs = tensor([[-0.8949, -0.9430],
        [-1.0150, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002810752484947443
Epoch 0, Step 2201: train/loss = 0.706296443939209, train/raw-loss = 0.7049211859703064, train/logprobs = tensor([[-0.8653, -1.3551],
        [-0.9517, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013752689585089684
Epoch 0, Step 2202: train/loss = 0.8118003010749817, train/raw-loss = 0.8096186518669128, train/logprobs = tensor([[-1.0335, -1.5069],
        [-1.2356, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021816659718751907
Epoch 0, Step 2203: train/loss = 0.665807843208313, train/raw-loss = 0.6571913361549377, train/logprobs = tensor([[-1.1168, -1.7324],
        [-1.2279, -0.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08616473525762558
Epoch 0, Step 2204: train/loss = 0.6979019045829773, train/raw-loss = 0.6967244148254395, train/logprobs = tensor([[-1.0335, -1.1310],
        [-1.4666, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011775043793022633
Epoch 0, Step 2205: train/loss = 0.6982924938201904, train/raw-loss = 0.6981467008590698, train/logprobs = tensor([[-0.8571, -0.8239],
        [-0.8161, -0.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014581368304789066
Epoch 0, Step 2206: train/loss = 0.683729350566864, train/raw-loss = 0.6805646419525146, train/logprobs = tensor([[-0.9571, -1.4634],
        [-1.0932, -0.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03164692223072052
Epoch 0, Step 2207: train/loss = 0.6910240054130554, train/raw-loss = 0.6896812915802002, train/logprobs = tensor([[-0.7903, -0.8129],
        [-1.0804, -0.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013427453115582466
Epoch 0, Step 2208: train/loss = 0.6769001483917236, train/raw-loss = 0.6734289526939392, train/logprobs = tensor([[-0.9782, -1.2259],
        [-1.2055, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034712016582489014
Epoch 0, Step 2209: train/loss = 0.7197301387786865, train/raw-loss = 0.7193900346755981, train/logprobs = tensor([[-1.1766, -0.9411],
        [-1.5589, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034008873626589775
Epoch 0, Step 2210: train/loss = 0.7368783354759216, train/raw-loss = 0.7333213090896606, train/logprobs = tensor([[-1.0213, -1.8539],
        [-1.0498, -1.2687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035570353269577026
Epoch 0, Step 2211: train/loss = 0.6934324502944946, train/raw-loss = 0.6919703483581543, train/logprobs = tensor([[-1.1093, -1.2914],
        [-1.3873, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014620784670114517
Epoch 0, Step 2212: train/loss = 0.7024636268615723, train/raw-loss = 0.7018122673034668, train/logprobs = tensor([[-1.2367, -1.4371],
        [-0.9429, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006513848900794983
Epoch 0, Step 2213: train/loss = 0.691392719745636, train/raw-loss = 0.6886797547340393, train/logprobs = tensor([[-1.0026, -1.5289],
        [-1.1337, -1.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027129769325256348
Epoch 0, Step 2214: train/loss = 0.6865450739860535, train/raw-loss = 0.6837259531021118, train/logprobs = tensor([[-1.1730, -1.3760],
        [-1.3238, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02819129079580307
Epoch 0, Step 2215: train/loss = 0.6742416024208069, train/raw-loss = 0.6736315488815308, train/logprobs = tensor([[-0.9071, -1.0813],
        [-1.4698, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006100548896938562
Epoch 0, Step 2216: train/loss = 0.6713207364082336, train/raw-loss = 0.6683085560798645, train/logprobs = tensor([[-0.7553, -1.4537],
        [-1.3219, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03012198396027088
Epoch 0, Step 2217: train/loss = 0.7039170265197754, train/raw-loss = 0.7037829160690308, train/logprobs = tensor([[-0.8929, -1.0470],
        [-1.0384, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001341595547273755
Epoch 0, Step 2218: train/loss = 0.6975094079971313, train/raw-loss = 0.6974892616271973, train/logprobs = tensor([[-1.1347, -1.1135],
        [-1.3054, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020186806796118617
Epoch 0, Step 2219: train/loss = 0.6930536031723022, train/raw-loss = 0.6925888061523438, train/logprobs = tensor([[-0.9821, -1.1468],
        [-1.0345, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004648647271096706
Epoch 0, Step 2220: train/loss = 0.6917818784713745, train/raw-loss = 0.6914398670196533, train/logprobs = tensor([[-0.9606, -1.0208],
        [-1.0132, -0.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003419956425204873
Epoch 0, Step 2221: train/loss = 0.6834678053855896, train/raw-loss = 0.6816459894180298, train/logprobs = tensor([[-0.9723, -1.2077],
        [-1.2716, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018218327313661575
Epoch 0, Step 2222: train/loss = 0.6824966669082642, train/raw-loss = 0.6822220087051392, train/logprobs = tensor([[-1.1092, -1.3269],
        [-1.4606, -1.1928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027457906398922205
Epoch 0, Step 2223: train/loss = 0.6834496259689331, train/raw-loss = 0.6821855902671814, train/logprobs = tensor([[-0.9386, -1.3194],
        [-1.0451, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012639911845326424
Epoch 0, Step 2224: train/loss = 0.6949400901794434, train/raw-loss = 0.6936187744140625, train/logprobs = tensor([[-1.0819, -1.2712],
        [-1.2734, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013213071972131729
Epoch 0, Step 2225: train/loss = 0.6909080743789673, train/raw-loss = 0.6901946663856506, train/logprobs = tensor([[-0.9430, -1.2690],
        [-1.0085, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007134010083973408
Epoch 0, Step 2226: train/loss = 0.7653107643127441, train/raw-loss = 0.7643119096755981, train/logprobs = tensor([[-1.2308, -0.9825],
        [-1.3012, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009988831356167793
Epoch 0, Step 2227: train/loss = 0.6931428909301758, train/raw-loss = 0.6927233934402466, train/logprobs = tensor([[-0.9191, -0.9971],
        [-1.0099, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041953870095312595
Epoch 0, Step 2228: train/loss = 0.7021167874336243, train/raw-loss = 0.7004812359809875, train/logprobs = tensor([[-1.0932, -1.0448],
        [-1.4498, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016355471685528755
Epoch 0, Step 2229: train/loss = 0.6946598887443542, train/raw-loss = 0.6932342052459717, train/logprobs = tensor([[-1.1075, -1.2598],
        [-1.2518, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014256482943892479
Epoch 0, Step 2230: train/loss = 0.6997383832931519, train/raw-loss = 0.6996044516563416, train/logprobs = tensor([[-1.0289, -1.2375],
        [-1.0836, -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013402793556451797
Epoch 0, Step 2231: train/loss = 0.6801249980926514, train/raw-loss = 0.6776302456855774, train/logprobs = tensor([[-0.7988, -1.2274],
        [-1.1609, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024947475641965866
Epoch 0, Step 2232: train/loss = 0.6874140501022339, train/raw-loss = 0.6846681833267212, train/logprobs = tensor([[-0.9825, -1.4313],
        [-1.4051, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02745828591287136
Epoch 0, Step 2233: train/loss = 0.6788524985313416, train/raw-loss = 0.6749586462974548, train/logprobs = tensor([[-0.9908, -1.5485],
        [-1.1476, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038938794285058975
Epoch 0, Step 2234: train/loss = 0.6907461285591125, train/raw-loss = 0.6892380714416504, train/logprobs = tensor([[-1.0138, -1.1370],
        [-1.0969, -0.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015080585144460201
Epoch 0, Step 2235: train/loss = 0.6863675713539124, train/raw-loss = 0.6847645044326782, train/logprobs = tensor([[-0.9892, -1.2508],
        [-1.1795, -0.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016030915081501007
Epoch 0, Step 2236: train/loss = 0.6811073422431946, train/raw-loss = 0.6793006658554077, train/logprobs = tensor([[-0.9718, -1.3363],
        [-1.0875, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01806682161986828
Epoch 0, Step 2237: train/loss = 0.6824339032173157, train/raw-loss = 0.6783248782157898, train/logprobs = tensor([[-0.9982, -1.5001],
        [-1.0899, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04108994081616402
Epoch 0, Step 2238: train/loss = 0.687237024307251, train/raw-loss = 0.6857223510742188, train/logprobs = tensor([[-1.0919, -1.2414],
        [-1.2502, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015146903693675995
Epoch 0, Step 2239: train/loss = 0.6548705101013184, train/raw-loss = 0.6532328128814697, train/logprobs = tensor([[-0.7628, -1.3670],
        [-1.3799, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016377199441194534
Epoch 0, Step 2240: train/loss = 0.685700535774231, train/raw-loss = 0.6850985288619995, train/logprobs = tensor([[-1.2343, -1.5230],
        [-1.2778, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006020190194249153
Epoch 0, Step 2241: train/loss = 0.686134934425354, train/raw-loss = 0.6768109202384949, train/logprobs = tensor([[-0.9116, -1.7888],
        [-1.1432, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323989599943161
Epoch 0, Step 2242: train/loss = 0.6813427209854126, train/raw-loss = 0.6780941486358643, train/logprobs = tensor([[-0.8145, -1.2703],
        [-1.0300, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032485805451869965
Epoch 0, Step 2243: train/loss = 0.6906464695930481, train/raw-loss = 0.6898883581161499, train/logprobs = tensor([[-0.9694, -1.2864],
        [-1.1261, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007580811623483896
Epoch 0, Step 2244: train/loss = 0.6943919658660889, train/raw-loss = 0.69404137134552, train/logprobs = tensor([[-1.0285, -1.0346],
        [-1.2203, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003505986649543047
Epoch 0, Step 2245: train/loss = 0.6905102729797363, train/raw-loss = 0.6898477077484131, train/logprobs = tensor([[-0.7461, -0.9993],
        [-0.9717, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006625563371926546
Epoch 0, Step 2246: train/loss = 0.7011362314224243, train/raw-loss = 0.7008970975875854, train/logprobs = tensor([[-1.3009, -1.3803],
        [-1.0528, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023915828205645084
Epoch 0, Step 2247: train/loss = 0.6935026049613953, train/raw-loss = 0.690888524055481, train/logprobs = tensor([[-1.0072, -1.5550],
        [-1.2957, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026140838861465454
Epoch 0, Step 2248: train/loss = 0.6942307353019714, train/raw-loss = 0.6941460967063904, train/logprobs = tensor([[-1.1401, -1.1818],
        [-1.2276, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000846452487166971
Epoch 0, Step 2249: train/loss = 0.6885486841201782, train/raw-loss = 0.6874485611915588, train/logprobs = tensor([[-0.7686, -0.8491],
        [-0.7771, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011001166887581348
Epoch 0, Step 2250: train/loss = 0.6991744041442871, train/raw-loss = 0.698516845703125, train/logprobs = tensor([[-0.7710, -1.1459],
        [-1.0324, -1.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065752784721553326
Epoch 0, Step 2251: train/loss = 0.699093759059906, train/raw-loss = 0.697786271572113, train/logprobs = tensor([[-0.7671, -1.2322],
        [-1.0597, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01307459082454443
Epoch 0, Step 2252: train/loss = 0.6934508085250854, train/raw-loss = 0.6921848654747009, train/logprobs = tensor([[-0.7779, -1.1091],
        [-1.0094, -1.0513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01265951432287693
Epoch 0, Step 2253: train/loss = 0.7172136306762695, train/raw-loss = 0.7161272764205933, train/logprobs = tensor([[-0.9476, -1.4386],
        [-1.0356, -1.0195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01086434070020914
Epoch 0, Step 2254: train/loss = 0.7062084078788757, train/raw-loss = 0.7058106660842896, train/logprobs = tensor([[-0.9491, -1.3227],
        [-1.0742, -1.0515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003977120853960514
Epoch 0, Step 2255: train/loss = 0.7384432554244995, train/raw-loss = 0.7372134923934937, train/logprobs = tensor([[-1.0151, -1.5154],
        [-1.1580, -1.2662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012297531589865685
Epoch 0, Step 2256: train/loss = 0.6927388906478882, train/raw-loss = 0.6925958395004272, train/logprobs = tensor([[-0.9766, -1.0037],
        [-1.0146, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014305927325040102
Epoch 0, Step 2257: train/loss = 0.6947526931762695, train/raw-loss = 0.6941802501678467, train/logprobs = tensor([[-0.9950, -1.0492],
        [-1.0120, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005724798887968063
Epoch 0, Step 2258: train/loss = 0.6898752450942993, train/raw-loss = 0.6883644461631775, train/logprobs = tensor([[-1.1457, -1.3267],
        [-1.0717, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015107890591025352
Epoch 0, Step 2259: train/loss = 0.703950047492981, train/raw-loss = 0.7030665874481201, train/logprobs = tensor([[-0.9640, -1.2708],
        [-1.3451, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008834832347929478
Epoch 0, Step 2260: train/loss = 0.6731919646263123, train/raw-loss = 0.6670205593109131, train/logprobs = tensor([[-0.8885, -1.4901],
        [-1.3084, -0.6857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06171403080224991
Epoch 0, Step 2261: train/loss = 0.6888738870620728, train/raw-loss = 0.685129702091217, train/logprobs = tensor([[-0.8832, -1.5945],
        [-1.0300, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03744146227836609
Epoch 0, Step 2262: train/loss = 0.7030064463615417, train/raw-loss = 0.7023272514343262, train/logprobs = tensor([[-0.9552, -1.1961],
        [-1.0478, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006791704334318638
Epoch 0, Step 2263: train/loss = 0.7721058130264282, train/raw-loss = 0.7693604230880737, train/logprobs = tensor([[-0.9891, -1.8278],
        [-1.2294, -1.4184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02745256945490837
Epoch 0, Step 2264: train/loss = 0.6924981474876404, train/raw-loss = 0.6916699409484863, train/logprobs = tensor([[-0.9949, -1.3651],
        [-1.1370, -1.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008282079361379147
Epoch 0, Step 2265: train/loss = 0.6980900764465332, train/raw-loss = 0.6979303359985352, train/logprobs = tensor([[-1.0059, -1.0908],
        [-1.0267, -0.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015972463879734278
Epoch 0, Step 2266: train/loss = 0.6788968443870544, train/raw-loss = 0.6761629581451416, train/logprobs = tensor([[-1.1312, -1.4474],
        [-1.3755, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027339236810803413
Epoch 0, Step 2267: train/loss = 0.693761944770813, train/raw-loss = 0.6919291019439697, train/logprobs = tensor([[-1.1489, -1.3005],
        [-1.1301, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01832864060997963
Epoch 0, Step 2268: train/loss = 0.679323673248291, train/raw-loss = 0.677402675151825, train/logprobs = tensor([[-0.8838, -1.0758],
        [-1.0404, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019209979102015495
Epoch 0, Step 2269: train/loss = 0.6977342367172241, train/raw-loss = 0.6976263523101807, train/logprobs = tensor([[-1.1662, -1.0455],
        [-0.8510, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010798022849485278
Epoch 0, Step 2270: train/loss = 0.698273777961731, train/raw-loss = 0.6980981826782227, train/logprobs = tensor([[-0.8908, -1.1346],
        [-0.9642, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017565215239301324
Epoch 0, Step 2271: train/loss = 0.6976410746574402, train/raw-loss = 0.6968883275985718, train/logprobs = tensor([[-0.9266, -1.3124],
        [-1.1084, -1.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007527636364102364
Epoch 0, Step 2272: train/loss = 0.7017813920974731, train/raw-loss = 0.7001684308052063, train/logprobs = tensor([[-0.9459, -1.5935],
        [-0.9558, -1.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016129478812217712
Epoch 0, Step 2273: train/loss = 0.7074121236801147, train/raw-loss = 0.7071133852005005, train/logprobs = tensor([[-0.7112, -1.0091],
        [-0.8767, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029871477745473385
Epoch 0, Step 2274: train/loss = 0.6994600892066956, train/raw-loss = 0.6974616050720215, train/logprobs = tensor([[-1.3614, -1.8510],
        [-1.4372, -1.2492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019984563812613487
Epoch 0, Step 2275: train/loss = 0.694146454334259, train/raw-loss = 0.694049060344696, train/logprobs = tensor([[-0.9981, -1.1288],
        [-1.0438, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009736156789585948
Epoch 0, Step 2276: train/loss = 0.6964588165283203, train/raw-loss = 0.6959776878356934, train/logprobs = tensor([[-1.2126, -1.3290],
        [-1.1254, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0048110526986420155
Epoch 0, Step 2277: train/loss = 0.6943277716636658, train/raw-loss = 0.6943109035491943, train/logprobs = tensor([[-0.9141, -1.0037],
        [-1.0135, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016936576867010444
Epoch 0, Step 2278: train/loss = 0.6852097511291504, train/raw-loss = 0.6834180355072021, train/logprobs = tensor([[-0.9632, -1.2612],
        [-1.2380, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01791759952902794
Epoch 0, Step 2279: train/loss = 0.688875675201416, train/raw-loss = 0.6870176196098328, train/logprobs = tensor([[-0.7693, -1.0316],
        [-0.9090, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01858074590563774
Epoch 0, Step 2280: train/loss = 0.6881032586097717, train/raw-loss = 0.6857240200042725, train/logprobs = tensor([[-0.9276, -1.0443],
        [-1.0946, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02379259467124939
Epoch 0, Step 2281: train/loss = 0.699195384979248, train/raw-loss = 0.697778046131134, train/logprobs = tensor([[-0.9770, -1.4143],
        [-0.9393, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014172956347465515
Epoch 0, Step 2282: train/loss = 0.6825945377349854, train/raw-loss = 0.6813974380493164, train/logprobs = tensor([[-0.9052, -1.3321],
        [-1.2029, -1.0506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011970828287303448
Epoch 0, Step 2283: train/loss = 0.695769190788269, train/raw-loss = 0.6956637501716614, train/logprobs = tensor([[-1.1061, -1.0728],
        [-1.2273, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010536650661379099
Epoch 0, Step 2284: train/loss = 0.6935679316520691, train/raw-loss = 0.6912652254104614, train/logprobs = tensor([[-0.8753, -1.3889],
        [-0.9329, -0.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023027077317237854
Epoch 0, Step 2285: train/loss = 0.6417118906974792, train/raw-loss = 0.6330823302268982, train/logprobs = tensor([[-0.9414, -1.6844],
        [-1.3656, -0.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08629576116800308
Epoch 0, Step 2286: train/loss = 0.6895830035209656, train/raw-loss = 0.6888662576675415, train/logprobs = tensor([[-0.8752, -1.0189],
        [-0.9883, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00716815423220396
Epoch 0, Step 2287: train/loss = 0.6970088481903076, train/raw-loss = 0.6946934461593628, train/logprobs = tensor([[-0.9346, -1.3566],
        [-1.1213, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023153342306613922
Epoch 0, Step 2288: train/loss = 0.7062966823577881, train/raw-loss = 0.7049002051353455, train/logprobs = tensor([[-1.0325, -1.1341],
        [-1.2248, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013965060003101826
Epoch 0, Step 2289: train/loss = 0.6858844757080078, train/raw-loss = 0.6841298341751099, train/logprobs = tensor([[-1.0855, -1.5161],
        [-1.2402, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017546454444527626
Epoch 0, Step 2290: train/loss = 0.6972643136978149, train/raw-loss = 0.6967567205429077, train/logprobs = tensor([[-0.9777, -1.1567],
        [-1.0637, -0.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005076168570667505
Epoch 0, Step 2291: train/loss = 0.6983659267425537, train/raw-loss = 0.6979988217353821, train/logprobs = tensor([[-1.0614, -1.3606],
        [-1.0080, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003670699428766966
Epoch 0, Step 2292: train/loss = 0.6948002576828003, train/raw-loss = 0.6944894194602966, train/logprobs = tensor([[-1.1656, -1.1835],
        [-1.1450, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031086131930351257
Epoch 0, Step 2293: train/loss = 0.697036623954773, train/raw-loss = 0.6964289546012878, train/logprobs = tensor([[-0.8752, -0.9345],
        [-1.0850, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006076769437640905
Epoch 0, Step 2294: train/loss = 0.6977185010910034, train/raw-loss = 0.6972436308860779, train/logprobs = tensor([[-0.9163, -1.1232],
        [-0.9465, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004749010317027569
Epoch 0, Step 2295: train/loss = 0.7024564743041992, train/raw-loss = 0.7011775970458984, train/logprobs = tensor([[-1.0336, -1.2624],
        [-1.1740, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012788612395524979
Epoch 0, Step 2296: train/loss = 0.7778652310371399, train/raw-loss = 0.7772628664970398, train/logprobs = tensor([[-0.9674, -1.4838],
        [-1.0600, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006023715250194073
Epoch 0, Step 2297: train/loss = 0.6957002282142639, train/raw-loss = 0.6947808265686035, train/logprobs = tensor([[-1.3577, -1.3787],
        [-1.6645, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009193629026412964
Epoch 0, Step 2298: train/loss = 0.696904182434082, train/raw-loss = 0.6968933343887329, train/logprobs = tensor([[-0.9974, -1.0341],
        [-0.8321, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010958086932078004
Epoch 0, Step 2299: train/loss = 0.6843858957290649, train/raw-loss = 0.6815009713172913, train/logprobs = tensor([[-0.8548, -1.3952],
        [-1.1233, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02884962037205696
Epoch 0, Step 2300: train/loss = 0.7032749056816101, train/raw-loss = 0.7024762034416199, train/logprobs = tensor([[-1.1191, -1.0830],
        [-1.4078, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00798752997070551
Epoch 0, Step 2301: train/loss = 0.669731855392456, train/raw-loss = 0.6655275821685791, train/logprobs = tensor([[-1.0120, -1.4159],
        [-1.3124, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042042747139930725
Epoch 0, Step 2302: train/loss = 0.7011562585830688, train/raw-loss = 0.6998204588890076, train/logprobs = tensor([[-1.1336, -1.0657],
        [-1.3116, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013358285650610924
Epoch 0, Step 2303: train/loss = 0.7019200325012207, train/raw-loss = 0.6984403729438782, train/logprobs = tensor([[-0.8987, -1.5599],
        [-1.1301, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034796591848134995
Epoch 0, Step 2304: train/loss = 0.6784387826919556, train/raw-loss = 0.6765209436416626, train/logprobs = tensor([[-0.9354, -1.3109],
        [-1.2181, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01917901821434498
Epoch 0, Step 2305: train/loss = 0.7105810046195984, train/raw-loss = 0.709006667137146, train/logprobs = tensor([[-1.0189, -1.1664],
        [-1.0188, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01574375480413437
Epoch 0, Step 2306: train/loss = 0.7034748196601868, train/raw-loss = 0.7034088373184204, train/logprobs = tensor([[-0.9385, -1.1964],
        [-1.0578, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006593751604668796
Epoch 0, Step 2307: train/loss = 0.6808899641036987, train/raw-loss = 0.6757019758224487, train/logprobs = tensor([[-0.9088, -1.5569],
        [-1.2751, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05188041552901268
Epoch 0, Step 2308: train/loss = 0.7039995193481445, train/raw-loss = 0.7036580443382263, train/logprobs = tensor([[-1.0292, -1.0994],
        [-1.1085, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034140050411224365
Epoch 0, Step 2309: train/loss = 0.689863383769989, train/raw-loss = 0.6889406442642212, train/logprobs = tensor([[-1.1619, -1.2599],
        [-0.9536, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009226792491972446
Epoch 0, Step 2310: train/loss = 0.6909593343734741, train/raw-loss = 0.6878389120101929, train/logprobs = tensor([[-0.7949, -1.3444],
        [-1.1183, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03120351955294609
Epoch 0, Step 2311: train/loss = 0.697581946849823, train/raw-loss = 0.6973999738693237, train/logprobs = tensor([[-0.9807, -0.7965],
        [-0.8960, -0.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018201894126832485
Epoch 0, Step 2312: train/loss = 0.6920369863510132, train/raw-loss = 0.6913869976997375, train/logprobs = tensor([[-0.9777, -1.2421],
        [-1.0407, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006500489078462124
Epoch 0, Step 2313: train/loss = 0.6931588053703308, train/raw-loss = 0.6931502819061279, train/logprobs = tensor([[-0.8040, -0.8403],
        [-0.8158, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.477165829390287e-05
Epoch 0, Step 2314: train/loss = 0.7598111033439636, train/raw-loss = 0.7580664157867432, train/logprobs = tensor([[-1.0764, -1.5319],
        [-1.5629, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017446909099817276
Epoch 0, Step 2315: train/loss = 0.6844493746757507, train/raw-loss = 0.6821573972702026, train/logprobs = tensor([[-0.8906, -1.2157],
        [-1.0927, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022919584065675735
Epoch 0, Step 2316: train/loss = 0.7039282321929932, train/raw-loss = 0.7031733989715576, train/logprobs = tensor([[-0.9305, -1.0461],
        [-1.1376, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007548360154032707
Epoch 0, Step 2317: train/loss = 0.6979616284370422, train/raw-loss = 0.6978425979614258, train/logprobs = tensor([[-1.1167, -1.1018],
        [-0.9286, -0.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011906609870493412
Epoch 0, Step 2318: train/loss = 0.6883924007415771, train/raw-loss = 0.6873988509178162, train/logprobs = tensor([[-1.0488, -1.1769],
        [-1.3080, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009936098009347916
Epoch 0, Step 2319: train/loss = 0.6931429505348206, train/raw-loss = 0.6919726133346558, train/logprobs = tensor([[-0.8005, -0.9807],
        [-0.9807, -0.7611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011703495867550373
Epoch 0, Step 2320: train/loss = 0.7366349101066589, train/raw-loss = 0.7343159914016724, train/logprobs = tensor([[-1.2338, -2.0562],
        [-1.2159, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023189395666122437
Epoch 0, Step 2321: train/loss = 0.696678876876831, train/raw-loss = 0.6964406967163086, train/logprobs = tensor([[-1.0829, -1.2078],
        [-1.1222, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002381766214966774
Epoch 0, Step 2322: train/loss = 0.7144336700439453, train/raw-loss = 0.7132700681686401, train/logprobs = tensor([[-0.8797, -1.2609],
        [-1.1707, -1.2063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011636706069111824
Epoch 0, Step 2323: train/loss = 0.6943255066871643, train/raw-loss = 0.6942312717437744, train/logprobs = tensor([[-0.8803, -0.8865],
        [-0.9634, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009422492585144937
Epoch 0, Step 2324: train/loss = 0.7093167304992676, train/raw-loss = 0.7085896134376526, train/logprobs = tensor([[-1.2087, -1.1799],
        [-1.1809, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00727092195302248
Epoch 0, Step 2325: train/loss = 0.7023152709007263, train/raw-loss = 0.7018643021583557, train/logprobs = tensor([[-0.6995, -1.0083],
        [-0.8005, -0.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004509627819061279
Epoch 0, Step 2326: train/loss = 0.6953656673431396, train/raw-loss = 0.6953458189964294, train/logprobs = tensor([[-1.1199, -1.2152],
        [-1.0673, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001985406270250678
Epoch 0, Step 2327: train/loss = 0.6700434684753418, train/raw-loss = 0.6642556190490723, train/logprobs = tensor([[-0.7612, -1.3990],
        [-0.9923, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0578792579472065
Epoch 0, Step 2328: train/loss = 0.7356221675872803, train/raw-loss = 0.7354739308357239, train/logprobs = tensor([[-1.2785, -1.1756],
        [-1.3224, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001482508610934019
Epoch 0, Step 2329: train/loss = 0.6958107352256775, train/raw-loss = 0.6953455805778503, train/logprobs = tensor([[-0.8260, -0.9199],
        [-0.8488, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004651192110031843
Epoch 0, Step 2330: train/loss = 0.6729166507720947, train/raw-loss = 0.6696831583976746, train/logprobs = tensor([[-1.0466, -1.4382],
        [-1.3135, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03233465179800987
Epoch 0, Step 2331: train/loss = 0.6954737901687622, train/raw-loss = 0.6951555609703064, train/logprobs = tensor([[-1.1778, -1.3749],
        [-1.1388, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003182068932801485
Epoch 0, Step 2332: train/loss = 0.6921347975730896, train/raw-loss = 0.6915831565856934, train/logprobs = tensor([[-1.1355, -1.3948],
        [-1.2105, -1.1584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005516023375093937
Epoch 0, Step 2333: train/loss = 0.792615532875061, train/raw-loss = 0.7920730113983154, train/logprobs = tensor([[-1.3141, -0.9204],
        [-1.3245, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005425062030553818
Epoch 0, Step 2334: train/loss = 0.6816560626029968, train/raw-loss = 0.6786437630653381, train/logprobs = tensor([[-0.9718, -1.4154],
        [-1.2424, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03012307733297348
Epoch 0, Step 2335: train/loss = 0.6941476464271545, train/raw-loss = 0.691412627696991, train/logprobs = tensor([[-0.8610, -1.2832],
        [-1.2337, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027350308373570442
Epoch 0, Step 2336: train/loss = 0.7077494859695435, train/raw-loss = 0.7075073719024658, train/logprobs = tensor([[-0.8422, -0.9655],
        [-1.0693, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024219017941504717
Epoch 0, Step 2337: train/loss = 0.695338249206543, train/raw-loss = 0.6948357820510864, train/logprobs = tensor([[-0.8588, -0.9150],
        [-0.9474, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005024869926273823
Epoch 0, Step 2338: train/loss = 0.7103562951087952, train/raw-loss = 0.7092210650444031, train/logprobs = tensor([[-1.0737, -1.4931],
        [-1.1951, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011352230794727802
Epoch 0, Step 2339: train/loss = 0.7080032825469971, train/raw-loss = 0.7076476812362671, train/logprobs = tensor([[-0.8785, -1.1624],
        [-1.2115, -1.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003556361887603998
Epoch 0, Step 2340: train/loss = 0.6819685697555542, train/raw-loss = 0.6794723868370056, train/logprobs = tensor([[-0.9168, -1.1036],
        [-1.1195, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024961121380329132
Epoch 0, Step 2341: train/loss = 0.6978996992111206, train/raw-loss = 0.696080207824707, train/logprobs = tensor([[-0.9267, -1.1677],
        [-1.2704, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018194016069173813
Epoch 0, Step 2342: train/loss = 0.7017840147018433, train/raw-loss = 0.7008545994758606, train/logprobs = tensor([[-1.0516, -1.2582],
        [-1.1006, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00929371640086174
Epoch 0, Step 2343: train/loss = 0.7250450849533081, train/raw-loss = 0.7241001725196838, train/logprobs = tensor([[-0.9449, -1.0023],
        [-1.1459, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009448599070310593
Epoch 0, Step 2344: train/loss = 0.6768291592597961, train/raw-loss = 0.6739386320114136, train/logprobs = tensor([[-0.9601, -1.5047],
        [-1.2615, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02890584245324135
Epoch 0, Step 2345: train/loss = 0.6625479459762573, train/raw-loss = 0.6577192544937134, train/logprobs = tensor([[-1.1932, -1.6506],
        [-1.3077, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048286695033311844
Epoch 0, Step 2346: train/loss = 0.7112669944763184, train/raw-loss = 0.7109376788139343, train/logprobs = tensor([[-0.9477, -0.6995],
        [-1.1042, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003293209010735154
Epoch 0, Step 2347: train/loss = 0.6864190101623535, train/raw-loss = 0.685439944267273, train/logprobs = tensor([[-0.8706, -1.0154],
        [-1.1526, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009791286662220955
Epoch 0, Step 2348: train/loss = 0.6980090141296387, train/raw-loss = 0.6978356838226318, train/logprobs = tensor([[-1.0099, -1.1511],
        [-1.0039, -1.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017334294971078634
Epoch 0, Step 2349: train/loss = 0.6956294775009155, train/raw-loss = 0.6952306032180786, train/logprobs = tensor([[-0.9386, -1.0311],
        [-0.9615, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003988401964306831
Epoch 0, Step 2350: train/loss = 0.7026532292366028, train/raw-loss = 0.7006723880767822, train/logprobs = tensor([[-1.0278, -1.3345],
        [-1.3059, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01980762556195259
Epoch 0, Step 2351: train/loss = 0.6936464905738831, train/raw-loss = 0.6933629512786865, train/logprobs = tensor([[-0.8375, -0.9326],
        [-0.9771, -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002836032770574093
Epoch 0, Step 2352: train/loss = 0.708079993724823, train/raw-loss = 0.7059805989265442, train/logprobs = tensor([[-0.9014, -1.1380],
        [-1.1781, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02099406160414219
Epoch 0, Step 2353: train/loss = 0.6939144730567932, train/raw-loss = 0.6935136318206787, train/logprobs = tensor([[-1.1022, -1.2666],
        [-1.1875, -1.1381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004007923416793346
Epoch 0, Step 2354: train/loss = 0.6929359436035156, train/raw-loss = 0.6923038959503174, train/logprobs = tensor([[-1.2227, -1.3000],
        [-1.3352, -1.1540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006319827400147915
Epoch 0, Step 2355: train/loss = 0.693925678730011, train/raw-loss = 0.6935836672782898, train/logprobs = tensor([[-0.8666, -0.9908],
        [-0.9384, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034199391957372427
Epoch 0, Step 2356: train/loss = 0.691757321357727, train/raw-loss = 0.6911622285842896, train/logprobs = tensor([[-0.8441, -1.0350],
        [-0.9181, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005951047409325838
Epoch 0, Step 2357: train/loss = 0.6726059913635254, train/raw-loss = 0.667816698551178, train/logprobs = tensor([[-0.8837, -1.4834],
        [-1.0836, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04789239913225174
Epoch 0, Step 2358: train/loss = 0.7069422006607056, train/raw-loss = 0.7065364122390747, train/logprobs = tensor([[-0.9023, -1.0643],
        [-0.9027, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004057813435792923
Epoch 0, Step 2359: train/loss = 0.6905781626701355, train/raw-loss = 0.6897745132446289, train/logprobs = tensor([[-0.8840, -1.0077],
        [-1.0895, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008036399260163307
Epoch 0, Step 2360: train/loss = 0.6924822330474854, train/raw-loss = 0.6901019811630249, train/logprobs = tensor([[-1.1346, -1.5476],
        [-1.2943, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023802392184734344
Epoch 0, Step 2361: train/loss = 0.6992868185043335, train/raw-loss = 0.6986618041992188, train/logprobs = tensor([[-1.0630, -1.1015],
        [-1.2578, -0.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006250969599932432
Epoch 0, Step 2362: train/loss = 0.7119885683059692, train/raw-loss = 0.7117315530776978, train/logprobs = tensor([[-1.0911, -0.9095],
        [-1.1285, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025701760314404964
Epoch 0, Step 2363: train/loss = 0.6887934803962708, train/raw-loss = 0.6877464056015015, train/logprobs = tensor([[-0.9128, -1.2353],
        [-1.0916, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010470833629369736
Epoch 0, Step 2364: train/loss = 0.6980093717575073, train/raw-loss = 0.693318247795105, train/logprobs = tensor([[-0.9521, -1.8427],
        [-1.0801, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046910811215639114
Epoch 0, Step 2365: train/loss = 0.6901124119758606, train/raw-loss = 0.6883465051651001, train/logprobs = tensor([[-0.8750, -1.1101],
        [-0.9395, -0.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017658788710832596
Epoch 0, Step 2366: train/loss = 0.6856558322906494, train/raw-loss = 0.6842502355575562, train/logprobs = tensor([[-0.8682, -1.2189],
        [-1.0458, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014054903760552406
Epoch 0, Step 2367: train/loss = 0.706902265548706, train/raw-loss = 0.7049449682235718, train/logprobs = tensor([[-0.9467, -1.1781],
        [-1.1180, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01957257091999054
Epoch 0, Step 2368: train/loss = 0.6860974431037903, train/raw-loss = 0.684278666973114, train/logprobs = tensor([[-1.0709, -1.3066],
        [-1.3547, -0.9899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01818816177546978
Epoch 0, Step 2369: train/loss = 0.6850616335868835, train/raw-loss = 0.6835379004478455, train/logprobs = tensor([[-0.9418, -1.0760],
        [-1.1278, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015236761420965195
Epoch 0, Step 2370: train/loss = 0.7105758190155029, train/raw-loss = 0.7095117568969727, train/logprobs = tensor([[-0.8838, -1.4077],
        [-0.9894, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010640189982950687
Epoch 0, Step 2371: train/loss = 0.7246221899986267, train/raw-loss = 0.7220673561096191, train/logprobs = tensor([[-0.8465, -1.6181],
        [-0.8855, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025548448786139488
Epoch 0, Step 2372: train/loss = 0.6834529042243958, train/raw-loss = 0.6819390058517456, train/logprobs = tensor([[-0.7957, -1.1287],
        [-0.9765, -0.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015138808637857437
Epoch 0, Step 2373: train/loss = 0.6842687726020813, train/raw-loss = 0.6826943755149841, train/logprobs = tensor([[-1.1638, -1.3926],
        [-1.4634, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015743985772132874
Epoch 0, Step 2374: train/loss = 0.693851888179779, train/raw-loss = 0.6936206221580505, train/logprobs = tensor([[-1.0432, -1.2706],
        [-1.2092, -1.2820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023124581202864647
eval/loss: 0.6924851536750793
