[2024-03-01 15:45:31,384][root][INFO] - beta: 0.25
[2024-03-01 15:45:31,384][root][INFO] - loss no_reference
[2024-03-01 15:45:31,384][root][INFO] - max_iter: 0
[2024-03-01 15:45:31,384][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 1870
n harmless: 1173
tokenized 1776 training examples...
train dataset has 1776 examples.
eval dataset has 94 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Epoch 0, Step 0: train/loss = 0.691168487071991, train/raw-loss = 0.691168487071991, train/logprobs = tensor([[-0.5706, -0.8947],
        [-0.5884, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6914133429527283, train/raw-loss = 0.6914133429527283, train/logprobs = tensor([[-0.4531, -0.6281],
        [-0.4579, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6514632105827332, train/raw-loss = 0.6514632105827332, train/logprobs = tensor([[-0.4815, -1.8998],
        [-0.4921, -1.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.684298574924469, train/raw-loss = 0.684298574924469, train/logprobs = tensor([[-0.5683, -2.2087],
        [-0.5737, -2.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6806185841560364, train/raw-loss = 0.6806185841560364, train/logprobs = tensor([[-0.4501, -0.9317],
        [-0.4524, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6818892955780029, train/raw-loss = 0.6818892955780029, train/logprobs = tensor([[-0.5194, -1.3384],
        [-0.5245, -1.2980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6323404312133789, train/raw-loss = 0.6323404312133789, train/logprobs = tensor([[-0.3065, -2.2226],
        [-0.3075, -1.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6588633060455322, train/raw-loss = 0.6588633060455322, train/logprobs = tensor([[-0.4188, -1.9635],
        [-0.4214, -1.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6751775741577148, train/raw-loss = 0.6751775741577148, train/logprobs = tensor([[-0.5600, -1.0486],
        [-0.5659, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6863553524017334, train/raw-loss = 0.6863553524017334, train/logprobs = tensor([[-0.5418, -1.3805],
        [-0.5354, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6920734643936157, train/raw-loss = 0.6920734643936157, train/logprobs = tensor([[-0.4725, -1.2523],
        [-0.4761, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6817732453346252, train/raw-loss = 0.6817732453346252, train/logprobs = tensor([[-0.4965, -1.2112],
        [-0.5123, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6841890811920166, train/raw-loss = 0.6841890811920166, train/logprobs = tensor([[-0.4480, -0.7413],
        [-0.4433, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6892263293266296, train/raw-loss = 0.6892263293266296, train/logprobs = tensor([[-0.6424, -1.4638],
        [-0.6504, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.690991222858429, train/raw-loss = 0.690991222858429, train/logprobs = tensor([[-0.5512, -1.1008],
        [-0.5519, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6878229975700378, train/raw-loss = 0.6878229975700378, train/logprobs = tensor([[-0.5526, -0.8018],
        [-0.5484, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6888250708580017, train/raw-loss = 0.6888250708580017, train/logprobs = tensor([[-0.6245, -1.1522],
        [-0.6246, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6923377513885498, train/raw-loss = 0.6923377513885498, train/logprobs = tensor([[-0.6946, -0.8476],
        [-0.6862, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6461166143417358, train/raw-loss = 0.6461166143417358, train/logprobs = tensor([[-0.4243, -2.0105],
        [-0.4247, -1.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6872643232345581, train/raw-loss = 0.6872643232345581, train/logprobs = tensor([[-0.8183, -1.2543],
        [-0.8097, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6881037950515747, train/raw-loss = 0.6881037950515747, train/logprobs = tensor([[-0.5630, -0.6275],
        [-0.5608, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6813585758209229, train/raw-loss = 0.6813585758209229, train/logprobs = tensor([[-0.5133, -1.2954],
        [-0.4958, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6904762983322144, train/raw-loss = 0.6904762983322144, train/logprobs = tensor([[-0.4790, -0.8023],
        [-0.4770, -0.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6661308407783508, train/raw-loss = 0.6661308407783508, train/logprobs = tensor([[-0.9560, -1.2218],
        [-0.9616, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6525288820266724, train/raw-loss = 0.6525288820266724, train/logprobs = tensor([[-0.5501, -2.0784],
        [-0.5423, -1.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6834758520126343, train/raw-loss = 0.6834758520126343, train/logprobs = tensor([[-0.5855, -1.2581],
        [-0.5847, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6939085125923157, train/raw-loss = 0.6939085125923157, train/logprobs = tensor([[-0.5270, -1.2218],
        [-0.5256, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6855214238166809, train/raw-loss = 0.6855214238166809, train/logprobs = tensor([[-0.5594, -1.1913],
        [-0.5540, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6883843541145325, train/raw-loss = 0.6883843541145325, train/logprobs = tensor([[-0.6161, -1.2269],
        [-0.6157, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6704338788986206, train/raw-loss = 0.6704338788986206, train/logprobs = tensor([[-0.5070, -1.4604],
        [-0.5081, -1.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6890362501144409, train/raw-loss = 0.6890362501144409, train/logprobs = tensor([[-0.5486, -0.9842],
        [-0.5522, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6586874127388, train/raw-loss = 0.6586874127388, train/logprobs = tensor([[-0.5142, -2.2095],
        [-0.5153, -2.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6801116466522217, train/raw-loss = 0.679732084274292, train/logprobs = tensor([[-0.4567, -0.8874],
        [-0.4558, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015182180795818567
Epoch 0, Step 33: train/loss = 0.6861557960510254, train/raw-loss = 0.6857651472091675, train/logprobs = tensor([[-0.6953, -0.6664],
        [-0.6845, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015623901272192597
Epoch 0, Step 34: train/loss = 0.6807127594947815, train/raw-loss = 0.6803770661354065, train/logprobs = tensor([[-0.5548, -0.8308],
        [-0.5569, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013428118545562029
Epoch 0, Step 35: train/loss = 0.684134304523468, train/raw-loss = 0.6836419105529785, train/logprobs = tensor([[-0.5973, -0.8310],
        [-0.5918, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001969509292393923
Epoch 0, Step 36: train/loss = 0.6855545043945312, train/raw-loss = 0.6851051449775696, train/logprobs = tensor([[-0.4735, -0.9083],
        [-0.4739, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017974353395402431
Epoch 0, Step 37: train/loss = 0.6952246427536011, train/raw-loss = 0.6947314739227295, train/logprobs = tensor([[-0.6597, -0.9977],
        [-0.6715, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019726569298654795
Epoch 0, Step 38: train/loss = 0.6582103371620178, train/raw-loss = 0.6578117609024048, train/logprobs = tensor([[-0.5880, -1.4889],
        [-0.5869, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015942207537591457
Epoch 0, Step 39: train/loss = 0.63563472032547, train/raw-loss = 0.6352586150169373, train/logprobs = tensor([[-0.3460, -2.4172],
        [-0.3386, -2.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015045762993395329
Epoch 0, Step 40: train/loss = 0.6412580013275146, train/raw-loss = 0.6409123539924622, train/logprobs = tensor([[-0.5183, -1.7503],
        [-0.5112, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013825568603351712
Epoch 0, Step 41: train/loss = 0.6255369782447815, train/raw-loss = 0.6251381039619446, train/logprobs = tensor([[-0.6775, -2.5672],
        [-0.6688, -2.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015956570859998465
Epoch 0, Step 42: train/loss = 0.6860793232917786, train/raw-loss = 0.6857226490974426, train/logprobs = tensor([[-0.5243, -1.3463],
        [-0.5137, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001426572329364717
Epoch 0, Step 43: train/loss = 0.6892358064651489, train/raw-loss = 0.6887784004211426, train/logprobs = tensor([[-0.6994, -0.9554],
        [-0.7020, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018292568856850266
Epoch 0, Step 44: train/loss = 0.6571746468544006, train/raw-loss = 0.6568008661270142, train/logprobs = tensor([[-0.4029, -1.5337],
        [-0.3999, -1.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014952318742871284
Epoch 0, Step 45: train/loss = 0.5433152318000793, train/raw-loss = 0.5428742170333862, train/logprobs = tensor([[-0.6768, -2.7534],
        [-0.6642, -1.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001763972919434309
Epoch 0, Step 46: train/loss = 0.6053742170333862, train/raw-loss = 0.6049338579177856, train/logprobs = tensor([[-0.4341, -2.2839],
        [-0.4385, -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001761380466632545
Epoch 0, Step 47: train/loss = 0.6349757313728333, train/raw-loss = 0.6345229148864746, train/logprobs = tensor([[-0.6784, -2.1566],
        [-0.6779, -1.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018112361431121826
Epoch 0, Step 48: train/loss = 0.6505680680274963, train/raw-loss = 0.6483008861541748, train/logprobs = tensor([[-0.5829, -1.3636],
        [-0.5719, -1.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00906892865896225
Epoch 0, Step 49: train/loss = 0.6843992471694946, train/raw-loss = 0.6815369129180908, train/logprobs = tensor([[-0.6012, -1.1898],
        [-0.5732, -1.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01144940871745348
Epoch 0, Step 50: train/loss = 0.6596136093139648, train/raw-loss = 0.6570746898651123, train/logprobs = tensor([[-0.6212, -1.2094],
        [-0.6179, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010155529715120792
Epoch 0, Step 51: train/loss = 0.6754242777824402, train/raw-loss = 0.673086941242218, train/logprobs = tensor([[-0.5729, -1.0541],
        [-0.5632, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009349143132567406
Epoch 0, Step 52: train/loss = 0.6655163168907166, train/raw-loss = 0.6633525490760803, train/logprobs = tensor([[-0.5782, -1.1977],
        [-0.5542, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008655061013996601
Epoch 0, Step 53: train/loss = 0.6935020685195923, train/raw-loss = 0.6911152601242065, train/logprobs = tensor([[-0.8233, -0.8910],
        [-0.7883, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00954726804047823
Epoch 0, Step 54: train/loss = 0.5486888885498047, train/raw-loss = 0.5463225841522217, train/logprobs = tensor([[-0.8592, -3.3346],
        [-0.8244, -2.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00946520734578371
Epoch 0, Step 55: train/loss = 0.6856237053871155, train/raw-loss = 0.6827412843704224, train/logprobs = tensor([[-0.8496, -1.1346],
        [-0.8065, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01152955461293459
Epoch 0, Step 56: train/loss = 0.6567086577415466, train/raw-loss = 0.6538642644882202, train/logprobs = tensor([[-0.6304, -1.2266],
        [-0.5836, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011377301067113876
Epoch 0, Step 57: train/loss = 0.6426385045051575, train/raw-loss = 0.6397674679756165, train/logprobs = tensor([[-0.5261, -1.6766],
        [-0.5267, -1.4499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011484041810035706
Epoch 0, Step 58: train/loss = 0.6489459276199341, train/raw-loss = 0.647025465965271, train/logprobs = tensor([[-0.4482, -0.9030],
        [-0.4380, -0.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007681780960410833
Epoch 0, Step 59: train/loss = 0.6420053243637085, train/raw-loss = 0.6389266848564148, train/logprobs = tensor([[-0.8210, -1.8075],
        [-0.8181, -1.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012314390391111374
Epoch 0, Step 60: train/loss = 0.6108750104904175, train/raw-loss = 0.6082297563552856, train/logprobs = tensor([[-0.4944, -1.9841],
        [-0.4872, -1.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010581023059785366
Epoch 0, Step 61: train/loss = 0.6602621078491211, train/raw-loss = 0.6581915616989136, train/logprobs = tensor([[-0.5458, -1.1365],
        [-0.5376, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008282331749796867
Epoch 0, Step 62: train/loss = 0.6661935448646545, train/raw-loss = 0.6639026403427124, train/logprobs = tensor([[-0.5206, -1.6281],
        [-0.5079, -1.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00916358269751072
Epoch 0, Step 63: train/loss = 0.657385528087616, train/raw-loss = 0.6552958488464355, train/logprobs = tensor([[-0.4365, -1.5109],
        [-0.4343, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008358576335012913
Epoch 0, Step 64: train/loss = 0.6074551343917847, train/raw-loss = 0.5965924859046936, train/logprobs = tensor([[-0.4992, -1.4556],
        [-0.5572, -1.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043450359255075455
Epoch 0, Step 65: train/loss = 0.6096241474151611, train/raw-loss = 0.5969969034194946, train/logprobs = tensor([[-0.5632, -1.4793],
        [-0.5173, -0.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05050894618034363
Epoch 0, Step 66: train/loss = 0.6724150776863098, train/raw-loss = 0.6618301868438721, train/logprobs = tensor([[-0.7315, -1.2580],
        [-0.6499, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04233941808342934
Epoch 0, Step 67: train/loss = 0.6412510871887207, train/raw-loss = 0.6306492686271667, train/logprobs = tensor([[-0.4645, -1.1311],
        [-0.4550, -0.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042407114058732986
Epoch 0, Step 68: train/loss = 0.5762020945549011, train/raw-loss = 0.5656194686889648, train/logprobs = tensor([[-0.4101, -1.8901],
        [-0.3949, -1.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04233060032129288
Epoch 0, Step 69: train/loss = 0.5447642803192139, train/raw-loss = 0.5346091389656067, train/logprobs = tensor([[-0.4953, -3.2302],
        [-0.4848, -2.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04062032327055931
Epoch 0, Step 70: train/loss = 0.6864663362503052, train/raw-loss = 0.6749386787414551, train/logprobs = tensor([[-0.6014, -0.7771],
        [-0.5920, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04611065611243248
Epoch 0, Step 71: train/loss = 0.5825523138046265, train/raw-loss = 0.5721415281295776, train/logprobs = tensor([[-0.3782, -1.5079],
        [-0.3598, -0.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04164294898509979
Epoch 0, Step 72: train/loss = 0.6639409065246582, train/raw-loss = 0.6537482142448425, train/logprobs = tensor([[-2.0025, -1.0120],
        [-1.8423, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0407707616686821
Epoch 0, Step 73: train/loss = 0.6724376678466797, train/raw-loss = 0.6627745032310486, train/logprobs = tensor([[-0.5308, -0.9709],
        [-0.5087, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0386524572968483
Epoch 0, Step 74: train/loss = 0.6450024843215942, train/raw-loss = 0.635133683681488, train/logprobs = tensor([[-0.5711, -1.0686],
        [-0.5531, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03947514668107033
Epoch 0, Step 75: train/loss = 0.5352768898010254, train/raw-loss = 0.5241708755493164, train/logprobs = tensor([[-0.6334, -2.6692],
        [-0.5861, -1.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04442399740219116
Epoch 0, Step 76: train/loss = 0.6590800285339355, train/raw-loss = 0.6497211456298828, train/logprobs = tensor([[-0.5492, -0.8709],
        [-0.5329, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03743559122085571
Epoch 0, Step 77: train/loss = 0.5465086102485657, train/raw-loss = 0.5348751544952393, train/logprobs = tensor([[-0.4972, -2.4971],
        [-0.4790, -1.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0465337336063385
Epoch 0, Step 78: train/loss = 0.6377149820327759, train/raw-loss = 0.626301109790802, train/logprobs = tensor([[-0.5295, -0.9667],
        [-0.5061, -0.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04565552994608879
Epoch 0, Step 79: train/loss = 0.6346888542175293, train/raw-loss = 0.623253583908081, train/logprobs = tensor([[-0.5602, -1.1003],
        [-0.5241, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04574126377701759
Epoch 0, Step 80: train/loss = 0.5038936138153076, train/raw-loss = 0.4872314929962158, train/logprobs = tensor([[-0.5649, -4.1590],
        [-0.5372, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06664860248565674
Epoch 0, Step 81: train/loss = 0.540132462978363, train/raw-loss = 0.5242782235145569, train/logprobs = tensor([[-0.3189, -1.9694],
        [-0.3164, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063416987657547
Epoch 0, Step 82: train/loss = 0.5722935199737549, train/raw-loss = 0.5570688843727112, train/logprobs = tensor([[-0.4094, -4.1323],
        [-0.4133, -2.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06089845299720764
Epoch 0, Step 83: train/loss = 0.6102694869041443, train/raw-loss = 0.5989431142807007, train/logprobs = tensor([[-0.4436, -1.4155],
        [-0.4098, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045305803418159485
Epoch 0, Step 84: train/loss = 0.5880050659179688, train/raw-loss = 0.5764883756637573, train/logprobs = tensor([[-0.3890, -1.5750],
        [-0.3520, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04606686532497406
Epoch 0, Step 85: train/loss = 0.5298208594322205, train/raw-loss = 0.5133816599845886, train/logprobs = tensor([[-0.6675, -2.2180],
        [-0.6510, -1.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06575687229633331
Epoch 0, Step 86: train/loss = 0.5396682620048523, train/raw-loss = 0.5241138935089111, train/logprobs = tensor([[-0.5333, -2.3015],
        [-0.5111, -1.2980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06221751496195793
Epoch 0, Step 87: train/loss = 0.50885409116745, train/raw-loss = 0.49298378825187683, train/logprobs = tensor([[-0.5437, -3.2514],
        [-0.5108, -2.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06348114460706711
Epoch 0, Step 88: train/loss = 0.6329411268234253, train/raw-loss = 0.6205012798309326, train/logprobs = tensor([[-0.4468, -0.9781],
        [-0.4351, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04975951090455055
Epoch 0, Step 89: train/loss = 0.5863259434700012, train/raw-loss = 0.5723111033439636, train/logprobs = tensor([[-0.5036, -1.4699],
        [-0.4809, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05605925992131233
Epoch 0, Step 90: train/loss = 0.5249362587928772, train/raw-loss = 0.5076131224632263, train/logprobs = tensor([[-0.7184, -2.4788],
        [-0.5650, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06929244846105576
Epoch 0, Step 91: train/loss = 0.6532226800918579, train/raw-loss = 0.6386592984199524, train/logprobs = tensor([[-0.3966, -0.9176],
        [-0.3697, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05825376138091087
Epoch 0, Step 92: train/loss = 0.5349506735801697, train/raw-loss = 0.5197863578796387, train/logprobs = tensor([[-0.7154, -2.6349],
        [-0.6410, -1.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060657259076833725
Epoch 0, Step 93: train/loss = 0.6487008333206177, train/raw-loss = 0.6348872184753418, train/logprobs = tensor([[-0.6020, -1.4979],
        [-0.5867, -1.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05525447428226471
Epoch 0, Step 94: train/loss = 0.6525635123252869, train/raw-loss = 0.6393592357635498, train/logprobs = tensor([[-0.6514, -1.2071],
        [-0.5923, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052817218005657196
Epoch 0, Step 95: train/loss = 0.6616416573524475, train/raw-loss = 0.6489198803901672, train/logprobs = tensor([[-0.4186, -0.6353],
        [-0.3998, -0.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050886884331703186
Epoch 0, Step 96: train/loss = 0.650632917881012, train/raw-loss = 0.6346484422683716, train/logprobs = tensor([[-0.7443, -1.5984],
        [-0.6670, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06393802165985107
Epoch 0, Step 97: train/loss = 0.5930095314979553, train/raw-loss = 0.5764700174331665, train/logprobs = tensor([[-0.4516, -1.6635],
        [-0.4248, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06615807116031647
Epoch 0, Step 98: train/loss = 0.6282523274421692, train/raw-loss = 0.612045168876648, train/logprobs = tensor([[-0.6423, -1.6161],
        [-0.6055, -1.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06482844054698944
Epoch 0, Step 99: train/loss = 0.5236127972602844, train/raw-loss = 0.5059815049171448, train/logprobs = tensor([[-0.5952, -3.4968],
        [-0.5392, -1.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07052504271268845
Epoch 0, Step 100: train/loss = 0.5788396000862122, train/raw-loss = 0.5610177516937256, train/logprobs = tensor([[-0.5946, -1.3650],
        [-0.5643, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128725200891495
Epoch 0, Step 101: train/loss = 0.45494183897972107, train/raw-loss = 0.4371567666530609, train/logprobs = tensor([[-0.4274, -3.8479],
        [-0.3844, -2.3958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07114031165838242
Epoch 0, Step 102: train/loss = 0.5961694121360779, train/raw-loss = 0.5804039835929871, train/logprobs = tensor([[-0.5986, -5.1002],
        [-0.5703, -4.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06306175887584686
Epoch 0, Step 103: train/loss = 0.6290380358695984, train/raw-loss = 0.6115931272506714, train/logprobs = tensor([[-0.6852, -1.1352],
        [-0.6068, -0.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06977977603673935
Epoch 0, Step 104: train/loss = 0.5280587077140808, train/raw-loss = 0.5100823044776917, train/logprobs = tensor([[-0.6590, -2.2041],
        [-0.5985, -1.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07190567255020142
Epoch 0, Step 105: train/loss = 0.5725910067558289, train/raw-loss = 0.5541660785675049, train/logprobs = tensor([[-0.6486, -1.5075],
        [-0.5706, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07369981706142426
Epoch 0, Step 106: train/loss = 0.6276302337646484, train/raw-loss = 0.6131507754325867, train/logprobs = tensor([[-0.5008, -0.9508],
        [-0.4406, -0.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791766196489334
Epoch 0, Step 107: train/loss = 0.5900847315788269, train/raw-loss = 0.5714653134346008, train/logprobs = tensor([[-0.6722, -1.8631],
        [-0.5785, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07447761297225952
Epoch 0, Step 108: train/loss = 0.5837135910987854, train/raw-loss = 0.5642822980880737, train/logprobs = tensor([[-0.5190, -1.6645],
        [-0.4877, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0777251124382019
Epoch 0, Step 109: train/loss = 0.5817512273788452, train/raw-loss = 0.5652263760566711, train/logprobs = tensor([[-0.5806, -1.8007],
        [-0.5238, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0660996064543724
Epoch 0, Step 110: train/loss = 0.5952687859535217, train/raw-loss = 0.5764768123626709, train/logprobs = tensor([[-0.7293, -1.8552],
        [-0.6072, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07516792416572571
Epoch 0, Step 111: train/loss = 0.6219357252120972, train/raw-loss = 0.6063612699508667, train/logprobs = tensor([[-0.5333, -1.9897],
        [-0.4588, -1.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06229785084724426
Epoch 0, Step 112: train/loss = 0.46906718611717224, train/raw-loss = 0.44644349813461304, train/logprobs = tensor([[-0.8494, -3.6820],
        [-0.7560, -1.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09049484133720398
Epoch 0, Step 113: train/loss = 0.5387955904006958, train/raw-loss = 0.5127387642860413, train/logprobs = tensor([[-0.7644, -2.7336],
        [-0.5951, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422750562429428
Epoch 0, Step 114: train/loss = 0.5115886926651001, train/raw-loss = 0.48298951983451843, train/logprobs = tensor([[-0.9581, -2.6776],
        [-0.6728, -0.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11439677327871323
Epoch 0, Step 115: train/loss = 0.5755628347396851, train/raw-loss = 0.5515413284301758, train/logprobs = tensor([[-0.6311, -1.6151],
        [-0.5354, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608633816242218
Epoch 0, Step 116: train/loss = 0.4955856204032898, train/raw-loss = 0.4724780321121216, train/logprobs = tensor([[-0.8976, -3.1552],
        [-0.7011, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09243036806583405
Epoch 0, Step 117: train/loss = 0.5638929605484009, train/raw-loss = 0.538910984992981, train/logprobs = tensor([[-0.8497, -2.3734],
        [-0.6985, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09992790222167969
Epoch 0, Step 118: train/loss = 0.6221304535865784, train/raw-loss = 0.6009222269058228, train/logprobs = tensor([[-0.6823, -1.4699],
        [-0.5181, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483292162418365
Epoch 0, Step 119: train/loss = 0.47876977920532227, train/raw-loss = 0.45574626326560974, train/logprobs = tensor([[-0.5713, -2.8083],
        [-0.4989, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0920940712094307
Epoch 0, Step 120: train/loss = 0.5341463088989258, train/raw-loss = 0.5112701654434204, train/logprobs = tensor([[-0.5700, -2.1584],
        [-0.4721, -0.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150447696447372
Epoch 0, Step 121: train/loss = 0.6707955598831177, train/raw-loss = 0.6467392444610596, train/logprobs = tensor([[-1.2061, -2.7399],
        [-0.5806, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622527658939362
Epoch 0, Step 122: train/loss = 0.5388673543930054, train/raw-loss = 0.5133213996887207, train/logprobs = tensor([[-0.9189, -3.3656],
        [-0.7037, -1.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1021837592124939
Epoch 0, Step 123: train/loss = 0.5013745427131653, train/raw-loss = 0.4745669364929199, train/logprobs = tensor([[-0.7126, -2.6147],
        [-0.5395, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072303056716919
Epoch 0, Step 124: train/loss = 0.6378822922706604, train/raw-loss = 0.6140639781951904, train/logprobs = tensor([[-0.7548, -1.2658],
        [-0.5940, -0.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09527353197336197
Epoch 0, Step 125: train/loss = 0.5881162881851196, train/raw-loss = 0.5633383989334106, train/logprobs = tensor([[-0.6509, -1.5071],
        [-0.5321, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09911169111728668
Epoch 0, Step 126: train/loss = 0.43638065457344055, train/raw-loss = 0.4098670482635498, train/logprobs = tensor([[-0.6700, -3.5496],
        [-0.4852, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10605443269014359
Epoch 0, Step 127: train/loss = 0.6415530443191528, train/raw-loss = 0.6228561997413635, train/logprobs = tensor([[-0.3352, -0.9071],
        [-0.3005, -0.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07478750497102737
Epoch 0, Step 128: train/loss = 0.6452965140342712, train/raw-loss = 0.6184802055358887, train/logprobs = tensor([[-0.6776, -1.2771],
        [-0.5495, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072651743888855
Epoch 0, Step 129: train/loss = 0.4638196527957916, train/raw-loss = 0.4343361556529999, train/logprobs = tensor([[-1.1475, -4.5125],
        [-0.8180, -1.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793395131826401
Epoch 0, Step 130: train/loss = 0.4442259669303894, train/raw-loss = 0.414770245552063, train/logprobs = tensor([[-0.4267, -2.9773],
        [-0.3692, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11782273650169373
Epoch 0, Step 131: train/loss = 0.46551722288131714, train/raw-loss = 0.4370231330394745, train/logprobs = tensor([[-0.4959, -3.2066],
        [-0.4080, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11397632956504822
Epoch 0, Step 132: train/loss = 0.5433985590934753, train/raw-loss = 0.5157566070556641, train/logprobs = tensor([[-0.7252, -2.5445],
        [-0.5803, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11056800186634064
Epoch 0, Step 133: train/loss = 0.5432732105255127, train/raw-loss = 0.511476457118988, train/logprobs = tensor([[-0.9812, -2.9052],
        [-0.7186, -1.2144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12718689441680908
Epoch 0, Step 134: train/loss = 0.5200563669204712, train/raw-loss = 0.4931235909461975, train/logprobs = tensor([[-0.6258, -4.1253],
        [-0.5448, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10773114114999771
Epoch 0, Step 135: train/loss = 0.6471807956695557, train/raw-loss = 0.6246112585067749, train/logprobs = tensor([[-0.6743, -1.1632],
        [-0.4676, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09027829021215439
Epoch 0, Step 136: train/loss = 0.34158653020858765, train/raw-loss = 0.3115798234939575, train/logprobs = tensor([[-0.5870, -4.5263],
        [-0.5497, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12002674490213394
Epoch 0, Step 137: train/loss = 0.44881558418273926, train/raw-loss = 0.41755348443984985, train/logprobs = tensor([[-0.5666, -3.1385],
        [-0.4677, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12504830956459045
Epoch 0, Step 138: train/loss = 0.5599756836891174, train/raw-loss = 0.533418595790863, train/logprobs = tensor([[-0.7064, -2.0683],
        [-0.6010, -0.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622818768024445
Epoch 0, Step 139: train/loss = 0.6137480735778809, train/raw-loss = 0.5890374183654785, train/logprobs = tensor([[-0.5811, -1.5894],
        [-0.5166, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09884262084960938
Epoch 0, Step 140: train/loss = 0.5322518348693848, train/raw-loss = 0.5024313926696777, train/logprobs = tensor([[-0.9758, -2.8046],
        [-0.5644, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192818284034729
Epoch 0, Step 141: train/loss = 0.5296133160591125, train/raw-loss = 0.506657600402832, train/logprobs = tensor([[-0.3742, -3.8355],
        [-0.2935, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182311594486237
Epoch 0, Step 142: train/loss = 0.42880135774612427, train/raw-loss = 0.39794987440109253, train/logprobs = tensor([[-0.6591, -3.2249],
        [-0.4834, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12340600788593292
Epoch 0, Step 143: train/loss = 0.43558621406555176, train/raw-loss = 0.40868648886680603, train/logprobs = tensor([[-0.5645, -3.7462],
        [-0.4810, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10759885609149933
Epoch 0, Step 144: train/loss = 0.48330584168434143, train/raw-loss = 0.4507759213447571, train/logprobs = tensor([[-0.8186, -2.8804],
        [-0.5570, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13011962175369263
Epoch 0, Step 145: train/loss = 0.353307843208313, train/raw-loss = 0.3198142647743225, train/logprobs = tensor([[-0.4965, -4.3376],
        [-0.4328, -0.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13397428393363953
Epoch 0, Step 146: train/loss = 0.6153862476348877, train/raw-loss = 0.5925102829933167, train/logprobs = tensor([[-0.5222, -1.0630],
        [-0.4545, -0.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150375425815582
Epoch 0, Step 147: train/loss = 0.5247901678085327, train/raw-loss = 0.49935755133628845, train/logprobs = tensor([[-0.5354, -2.0146],
        [-0.4665, -0.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10173043608665466
Epoch 0, Step 148: train/loss = 0.5113024711608887, train/raw-loss = 0.47922903299331665, train/logprobs = tensor([[-1.7607, -3.6588],
        [-1.2451, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12829375267028809
Epoch 0, Step 149: train/loss = 0.47438672184944153, train/raw-loss = 0.443087637424469, train/logprobs = tensor([[-1.0197, -4.4059],
        [-0.5343, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12519630789756775
Epoch 0, Step 150: train/loss = 0.46836596727371216, train/raw-loss = 0.43593829870224, train/logprobs = tensor([[-0.6596, -2.9416],
        [-0.5587, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12971077859401703
Epoch 0, Step 151: train/loss = 0.43302983045578003, train/raw-loss = 0.4044422507286072, train/logprobs = tensor([[-0.3544, -3.3779],
        [-0.3140, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114350326359272
Epoch 0, Step 152: train/loss = 0.5120311975479126, train/raw-loss = 0.4817231297492981, train/logprobs = tensor([[-0.5937, -2.1374],
        [-0.5359, -0.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123213708400726
Epoch 0, Step 153: train/loss = 0.5123590230941772, train/raw-loss = 0.479633092880249, train/logprobs = tensor([[-0.7420, -2.2301],
        [-0.6242, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13090388476848602
Epoch 0, Step 154: train/loss = 0.3598903715610504, train/raw-loss = 0.3260505199432373, train/logprobs = tensor([[-0.4436, -4.3902],
        [-0.4189, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13535937666893005
Epoch 0, Step 155: train/loss = 0.5253204107284546, train/raw-loss = 0.49554479122161865, train/logprobs = tensor([[-0.5798, -2.4764],
        [-0.3958, -0.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11910244822502136
Epoch 0, Step 156: train/loss = 0.6113740801811218, train/raw-loss = 0.5869501233100891, train/logprobs = tensor([[-0.6646, -1.2880],
        [-0.5734, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09769579768180847
Epoch 0, Step 157: train/loss = 0.7088552713394165, train/raw-loss = 0.6816501617431641, train/logprobs = tensor([[-0.7199, -0.8149],
        [-0.5719, -0.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882045328617096
Epoch 0, Step 158: train/loss = 0.4308284521102905, train/raw-loss = 0.40232378244400024, train/logprobs = tensor([[-0.3495, -3.2615],
        [-0.3201, -0.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1140187457203865
Epoch 0, Step 159: train/loss = 0.613073468208313, train/raw-loss = 0.5816018581390381, train/logprobs = tensor([[-1.3325, -2.4321],
        [-0.8978, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125886470079422
Epoch 0, Step 160: train/loss = 0.5262050628662109, train/raw-loss = 0.4890550673007965, train/logprobs = tensor([[-0.5488, -2.8180],
        [-0.4890, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14860017597675323
Epoch 0, Step 161: train/loss = 0.45303845405578613, train/raw-loss = 0.4146578013896942, train/logprobs = tensor([[-0.6267, -3.2601],
        [-0.5395, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1535225510597229
Epoch 0, Step 162: train/loss = 0.4779887795448303, train/raw-loss = 0.44214576482772827, train/logprobs = tensor([[-0.4803, -2.6942],
        [-0.4543, -0.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14337210357189178
Epoch 0, Step 163: train/loss = 0.4864881932735443, train/raw-loss = 0.44962266087532043, train/logprobs = tensor([[-0.6462, -2.7130],
        [-0.5538, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14746204018592834
Epoch 0, Step 164: train/loss = 0.4361552298069, train/raw-loss = 0.3972802460193634, train/logprobs = tensor([[-0.5454, -3.4395],
        [-0.4825, -0.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15549999475479126
Epoch 0, Step 165: train/loss = 0.6135636568069458, train/raw-loss = 0.5909358263015747, train/logprobs = tensor([[-0.3474, -1.5424],
        [-0.3161, -0.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09051136672496796
Epoch 0, Step 166: train/loss = 0.4598729908466339, train/raw-loss = 0.42363399267196655, train/logprobs = tensor([[-0.3580, -3.3188],
        [-0.3909, -0.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14495594799518585
Epoch 0, Step 167: train/loss = 0.5545179843902588, train/raw-loss = 0.5167723298072815, train/logprobs = tensor([[-0.7991, -2.2434],
        [-0.6060, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098269283771515
Epoch 0, Step 168: train/loss = 0.5093149542808533, train/raw-loss = 0.470014750957489, train/logprobs = tensor([[-0.5365, -2.7985],
        [-0.4770, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15720072388648987
Epoch 0, Step 169: train/loss = 0.43620431423187256, train/raw-loss = 0.39890655875205994, train/logprobs = tensor([[-0.5649, -3.5994],
        [-0.4686, -0.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491910070180893
Epoch 0, Step 170: train/loss = 0.6627376675605774, train/raw-loss = 0.6292998194694519, train/logprobs = tensor([[-0.9688, -1.8820],
        [-0.7417, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13375136256217957
Epoch 0, Step 171: train/loss = 0.5041385889053345, train/raw-loss = 0.47054585814476013, train/logprobs = tensor([[-0.5310, -2.6949],
        [-0.5171, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13437090814113617
Epoch 0, Step 172: train/loss = 0.5235257148742676, train/raw-loss = 0.48733797669410706, train/logprobs = tensor([[-0.5449, -2.3927],
        [-0.5653, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14475096762180328
Epoch 0, Step 173: train/loss = 0.46067580580711365, train/raw-loss = 0.4240793287754059, train/logprobs = tensor([[-0.6850, -3.3488],
        [-0.6061, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14638584852218628
Epoch 0, Step 174: train/loss = 0.6333107948303223, train/raw-loss = 0.6008536219596863, train/logprobs = tensor([[-0.6278, -1.2115],
        [-0.5830, -0.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12982870638370514
Epoch 0, Step 175: train/loss = 0.35220059752464294, train/raw-loss = 0.3119925856590271, train/logprobs = tensor([[-0.3569, -4.2590],
        [-0.3525, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1608319729566574
Epoch 0, Step 176: train/loss = 0.5079306364059448, train/raw-loss = 0.46712005138397217, train/logprobs = tensor([[-0.6662, -2.4546],
        [-0.5214, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16324228048324585
Epoch 0, Step 177: train/loss = 0.6070116758346558, train/raw-loss = 0.5737899541854858, train/logprobs = tensor([[-0.3603, -1.4686],
        [-0.4184, -0.6708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13288696110248566
Epoch 0, Step 178: train/loss = 0.6442515850067139, train/raw-loss = 0.6077565550804138, train/logprobs = tensor([[-0.7148, -1.7273],
        [-0.6273, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14598043262958527
Epoch 0, Step 179: train/loss = 0.44666773080825806, train/raw-loss = 0.407920777797699, train/logprobs = tensor([[-0.5865, -3.1751],
        [-0.5727, -0.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15498767793178558
Epoch 0, Step 180: train/loss = 0.5570711493492126, train/raw-loss = 0.5251868963241577, train/logprobs = tensor([[-0.4856, -1.7981],
        [-0.4737, -0.5097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12753719091415405
Epoch 0, Step 181: train/loss = 0.6005062460899353, train/raw-loss = 0.5664678812026978, train/logprobs = tensor([[-0.5475, -1.7472],
        [-0.5344, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361534595489502
Epoch 0, Step 182: train/loss = 0.5873868465423584, train/raw-loss = 0.55061274766922, train/logprobs = tensor([[-1.0181, -2.4173],
        [-0.8043, -0.5465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14709636569023132
Epoch 0, Step 183: train/loss = 0.5307366251945496, train/raw-loss = 0.4975779354572296, train/logprobs = tensor([[-0.6443, -3.4198],
        [-0.5233, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13263478875160217
Epoch 0, Step 184: train/loss = 0.3714369237422943, train/raw-loss = 0.32731056213378906, train/logprobs = tensor([[-0.6075, -3.9934],
        [-0.6142, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17650550603866577
Epoch 0, Step 185: train/loss = 0.5224940776824951, train/raw-loss = 0.4827536642551422, train/logprobs = tensor([[-0.6260, -2.5072],
        [-0.6774, -0.5513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15896157920360565
Epoch 0, Step 186: train/loss = 0.5038917660713196, train/raw-loss = 0.46571141481399536, train/logprobs = tensor([[-1.0595, -3.9740],
        [-0.6573, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527215838432312
Epoch 0, Step 187: train/loss = 0.5413343906402588, train/raw-loss = 0.5074210166931152, train/logprobs = tensor([[-0.4199, -1.7500],
        [-0.4213, -0.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565337657928467
Epoch 0, Step 188: train/loss = 0.5162068605422974, train/raw-loss = 0.4862114191055298, train/logprobs = tensor([[-0.4803, -3.2517],
        [-0.4441, -0.5886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11998175084590912
Epoch 0, Step 189: train/loss = 0.5708786249160767, train/raw-loss = 0.5331315994262695, train/logprobs = tensor([[-1.1306, -2.0227],
        [-0.8644, -0.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098783373832703
Epoch 0, Step 190: train/loss = 0.625143826007843, train/raw-loss = 0.591515839099884, train/logprobs = tensor([[-0.5318, -1.4430],
        [-0.4777, -0.4552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134511798620224
Epoch 0, Step 191: train/loss = 0.5055431723594666, train/raw-loss = 0.4736475944519043, train/logprobs = tensor([[-0.4153, -2.6684],
        [-0.4241, -0.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1275823414325714
Epoch 0, Step 192: train/loss = 0.4711401164531708, train/raw-loss = 0.43573904037475586, train/logprobs = tensor([[-0.4601, -2.8607],
        [-0.4891, -1.1945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141604483127594
Epoch 0, Step 193: train/loss = 0.5128437280654907, train/raw-loss = 0.47825342416763306, train/logprobs = tensor([[-0.4313, -3.0443],
        [-0.4402, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13836118578910828
Epoch 0, Step 194: train/loss = 0.41863545775413513, train/raw-loss = 0.3805387318134308, train/logprobs = tensor([[-0.4792, -3.7697],
        [-0.4802, -0.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152386873960495
Epoch 0, Step 195: train/loss = 0.49457603693008423, train/raw-loss = 0.4607163667678833, train/logprobs = tensor([[-0.4070, -3.0118],
        [-0.4093, -0.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13543859124183655
Epoch 0, Step 196: train/loss = 0.41079917550086975, train/raw-loss = 0.3696565628051758, train/logprobs = tensor([[-0.6102, -3.5521],
        [-0.6490, -0.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645703911781311
Epoch 0, Step 197: train/loss = 0.6430870294570923, train/raw-loss = 0.6086283922195435, train/logprobs = tensor([[-1.3726, -2.0725],
        [-0.8546, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13783471286296844
Epoch 0, Step 198: train/loss = 0.4347122013568878, train/raw-loss = 0.3980751633644104, train/logprobs = tensor([[-0.4560, -3.4441],
        [-0.4692, -0.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14654818177223206
Epoch 0, Step 199: train/loss = 0.5224059820175171, train/raw-loss = 0.4870982766151428, train/logprobs = tensor([[-0.4759, -2.8540],
        [-0.4816, -0.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14123088121414185
Epoch 0, Step 200: train/loss = 0.4267263412475586, train/raw-loss = 0.38706496357917786, train/logprobs = tensor([[-0.5355, -5.3478],
        [-0.4625, -0.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15864552557468414
Epoch 0, Step 201: train/loss = 0.4828983545303345, train/raw-loss = 0.445039838552475, train/logprobs = tensor([[-1.7349, -4.2989],
        [-1.7650, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15143412351608276
Epoch 0, Step 202: train/loss = 0.5118522047996521, train/raw-loss = 0.47622549533843994, train/logprobs = tensor([[-0.5543, -2.6920],
        [-0.5486, -0.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14250683784484863
Epoch 0, Step 203: train/loss = 0.4638332724571228, train/raw-loss = 0.42892444133758545, train/logprobs = tensor([[-0.3694, -3.0776],
        [-0.3665, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396353542804718
Epoch 0, Step 204: train/loss = 0.5268334150314331, train/raw-loss = 0.4884355962276459, train/logprobs = tensor([[-0.5489, -2.7410],
        [-0.6231, -0.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1535913348197937
Epoch 0, Step 205: train/loss = 0.6177187561988831, train/raw-loss = 0.5852163434028625, train/logprobs = tensor([[-0.5978, -1.9871],
        [-0.5769, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13000980019569397
Epoch 0, Step 206: train/loss = 0.6120247840881348, train/raw-loss = 0.578847348690033, train/logprobs = tensor([[-0.5826, -2.1325],
        [-0.5758, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13270966708660126
Epoch 0, Step 207: train/loss = 0.5111303925514221, train/raw-loss = 0.47835585474967957, train/logprobs = tensor([[-0.4201, -2.6465],
        [-0.4175, -0.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13109830021858215
Epoch 0, Step 208: train/loss = 0.49682533740997314, train/raw-loss = 0.462141215801239, train/logprobs = tensor([[-0.4612, -3.7283],
        [-0.5004, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13873647153377533
Epoch 0, Step 209: train/loss = 0.6155033111572266, train/raw-loss = 0.5823509097099304, train/logprobs = tensor([[-0.4305, -1.8185],
        [-0.4656, -0.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13260945677757263
Epoch 0, Step 210: train/loss = 0.6219202280044556, train/raw-loss = 0.5894513130187988, train/logprobs = tensor([[-0.5058, -1.7495],
        [-0.4895, -0.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12987574934959412
Epoch 0, Step 211: train/loss = 0.45257091522216797, train/raw-loss = 0.40843409299850464, train/logprobs = tensor([[-0.6295, -3.2502],
        [-0.6890, -0.5808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1765473484992981
Epoch 0, Step 212: train/loss = 0.47995609045028687, train/raw-loss = 0.43383681774139404, train/logprobs = tensor([[-0.8744, -4.1756],
        [-0.6825, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18447726964950562
Epoch 0, Step 213: train/loss = 0.4366127848625183, train/raw-loss = 0.39336949586868286, train/logprobs = tensor([[-1.0263, -4.6096],
        [-0.8747, -0.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17297297716140747
Epoch 0, Step 214: train/loss = 0.5195342898368835, train/raw-loss = 0.4803493618965149, train/logprobs = tensor([[-0.4936, -2.7822],
        [-0.5626, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15673969686031342
Epoch 0, Step 215: train/loss = 0.3326409161090851, train/raw-loss = 0.2934592068195343, train/logprobs = tensor([[-0.4659, -5.1616],
        [-0.4834, -0.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567269265651703
Epoch 0, Step 216: train/loss = 0.3234744966030121, train/raw-loss = 0.28704026341438293, train/logprobs = tensor([[-0.3825, -6.4103],
        [-0.3325, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14573682844638824
Epoch 0, Step 217: train/loss = 0.44534096121788025, train/raw-loss = 0.40202659368515015, train/logprobs = tensor([[-0.5508, -3.3425],
        [-0.5341, -0.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17325752973556519
Epoch 0, Step 218: train/loss = 0.642791211605072, train/raw-loss = 0.6064277291297913, train/logprobs = tensor([[-0.6350, -1.8099],
        [-0.5921, -0.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14545388519763947
Epoch 0, Step 219: train/loss = 0.4088829457759857, train/raw-loss = 0.3725372552871704, train/logprobs = tensor([[-0.6249, -5.1697],
        [-0.6265, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14538268744945526
Epoch 0, Step 220: train/loss = 0.5367351770401001, train/raw-loss = 0.49554964900016785, train/logprobs = tensor([[-0.9328, -3.5092],
        [-0.6664, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16474203765392303
Epoch 0, Step 221: train/loss = 0.493775874376297, train/raw-loss = 0.4591289162635803, train/logprobs = tensor([[-0.4187, -4.1263],
        [-0.3873, -0.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13858778774738312
Epoch 0, Step 222: train/loss = 0.5146419405937195, train/raw-loss = 0.4760134816169739, train/logprobs = tensor([[-0.5591, -3.3916],
        [-0.5761, -0.6478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15451395511627197
Epoch 0, Step 223: train/loss = 0.4191223978996277, train/raw-loss = 0.3823976516723633, train/logprobs = tensor([[-0.3748, -4.4978],
        [-0.3800, -0.5637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14689911901950836
Epoch 0, Step 224: train/loss = 0.5246162414550781, train/raw-loss = 0.48541566729545593, train/logprobs = tensor([[-0.5584, -3.4335],
        [-0.6332, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15680238604545593
Epoch 0, Step 225: train/loss = 0.43252211809158325, train/raw-loss = 0.3937792479991913, train/logprobs = tensor([[-0.4747, -3.6958],
        [-0.5018, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15497148036956787
Epoch 0, Step 226: train/loss = 0.5160687565803528, train/raw-loss = 0.4811493158340454, train/logprobs = tensor([[-0.4005, -3.0465],
        [-0.4352, -0.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13967782258987427
Epoch 0, Step 227: train/loss = 0.3236370086669922, train/raw-loss = 0.2831815183162689, train/logprobs = tensor([[-0.4751, -5.8708],
        [-0.4879, -0.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16182206571102142
Epoch 0, Step 228: train/loss = 0.5875919461250305, train/raw-loss = 0.5465327501296997, train/logprobs = tensor([[-0.7120, -1.6746],
        [-0.6389, -0.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16423675417900085
Epoch 0, Step 229: train/loss = 0.7206851243972778, train/raw-loss = 0.6881735920906067, train/logprobs = tensor([[-0.4444, -0.5751],
        [-0.4294, -0.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13004596531391144
Epoch 0, Step 230: train/loss = 0.5554324984550476, train/raw-loss = 0.5217872262001038, train/logprobs = tensor([[-0.4528, -2.7498],
        [-0.4836, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13458099961280823
Epoch 0, Step 231: train/loss = 0.5910634994506836, train/raw-loss = 0.5553075671195984, train/logprobs = tensor([[-0.6508, -2.4694],
        [-0.6649, -0.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14302358031272888
Epoch 0, Step 232: train/loss = 0.5110448598861694, train/raw-loss = 0.47556230425834656, train/logprobs = tensor([[-0.5634, -2.8673],
        [-0.5918, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14193035662174225
Epoch 0, Step 233: train/loss = 0.5240350365638733, train/raw-loss = 0.4910017251968384, train/logprobs = tensor([[-0.4319, -2.4128],
        [-0.4059, -0.3854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13213306665420532
Epoch 0, Step 234: train/loss = 0.5718128085136414, train/raw-loss = 0.5270314812660217, train/logprobs = tensor([[-0.9936, -3.5386],
        [-0.8428, -0.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17912541329860687
Epoch 0, Step 235: train/loss = 0.5361694097518921, train/raw-loss = 0.4961965084075928, train/logprobs = tensor([[-0.9619, -4.7003],
        [-0.6425, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159891739487648
Epoch 0, Step 236: train/loss = 0.621403694152832, train/raw-loss = 0.5869956016540527, train/logprobs = tensor([[-0.4942, -1.6085],
        [-0.4742, -0.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13763241469860077
Epoch 0, Step 237: train/loss = 0.6398937702178955, train/raw-loss = 0.6028872728347778, train/logprobs = tensor([[-0.9835, -1.7833],
        [-0.6384, -0.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14802595973014832
Epoch 0, Step 238: train/loss = 0.6464837193489075, train/raw-loss = 0.6119354367256165, train/logprobs = tensor([[-0.5736, -2.1850],
        [-0.5522, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13819316029548645
Epoch 0, Step 239: train/loss = 0.41024118661880493, train/raw-loss = 0.3730093836784363, train/logprobs = tensor([[-0.3735, -5.0127],
        [-0.4312, -0.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14892739057540894
Epoch 0, Step 240: train/loss = 0.5066803693771362, train/raw-loss = 0.4734816253185272, train/logprobs = tensor([[-0.4200, -3.6407],
        [-0.4881, -0.6245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13279487192630768
Epoch 0, Step 241: train/loss = 0.49159687757492065, train/raw-loss = 0.46096014976501465, train/logprobs = tensor([[-0.3829, -2.6735],
        [-0.4194, -0.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12254686653614044
Epoch 0, Step 242: train/loss = 0.4973210096359253, train/raw-loss = 0.4604431986808777, train/logprobs = tensor([[-0.7095, -2.6870],
        [-0.7622, -0.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1475113183259964
Epoch 0, Step 243: train/loss = 0.5958550572395325, train/raw-loss = 0.5492904186248779, train/logprobs = tensor([[-0.9459, -3.1278],
        [-0.7052, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.186258465051651
Epoch 0, Step 244: train/loss = 0.5921463966369629, train/raw-loss = 0.5607665777206421, train/logprobs = tensor([[-0.4774, -2.4041],
        [-0.5299, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12551912665367126
Epoch 0, Step 245: train/loss = 0.47822511196136475, train/raw-loss = 0.43608105182647705, train/logprobs = tensor([[-1.0983, -5.2936],
        [-0.8613, -0.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1685762107372284
Epoch 0, Step 246: train/loss = 0.5041030645370483, train/raw-loss = 0.4681229591369629, train/logprobs = tensor([[-0.5950, -3.4545],
        [-0.6606, -0.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14392046630382538
Epoch 0, Step 247: train/loss = 0.4212782680988312, train/raw-loss = 0.38071268796920776, train/logprobs = tensor([[-0.5134, -5.5252],
        [-0.5900, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16226239502429962
Epoch 0, Step 248: train/loss = 0.43901047110557556, train/raw-loss = 0.4003966748714447, train/logprobs = tensor([[-0.4597, -3.4765],
        [-0.4912, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1544550657272339
Epoch 0, Step 249: train/loss = 0.606785774230957, train/raw-loss = 0.5739294290542603, train/logprobs = tensor([[-0.4627, -1.5515],
        [-0.4842, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131425142288208
Epoch 0, Step 250: train/loss = 0.5336998701095581, train/raw-loss = 0.5011939406394958, train/logprobs = tensor([[-0.4721, -2.3264],
        [-0.4842, -0.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13002385199069977
Epoch 0, Step 251: train/loss = 0.6049017906188965, train/raw-loss = 0.5703176259994507, train/logprobs = tensor([[-0.5922, -1.7076],
        [-0.7035, -0.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13833676278591156
Epoch 0, Step 252: train/loss = 0.6086640357971191, train/raw-loss = 0.5820804834365845, train/logprobs = tensor([[-0.3490, -2.1291],
        [-0.3727, -0.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10633408278226852
Epoch 0, Step 253: train/loss = 0.6067150831222534, train/raw-loss = 0.5742905139923096, train/logprobs = tensor([[-0.5549, -1.4838],
        [-0.5506, -0.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12969820201396942
Epoch 0, Step 254: train/loss = 0.5453914403915405, train/raw-loss = 0.5064306259155273, train/logprobs = tensor([[-0.4209, -1.9121],
        [-0.6404, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15584290027618408
Epoch 0, Step 255: train/loss = 0.6072961091995239, train/raw-loss = 0.5751614570617676, train/logprobs = tensor([[-0.4260, -1.8901],
        [-0.5189, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1285385936498642
Epoch 0, Step 256: train/loss = 0.7011165618896484, train/raw-loss = 0.6724101305007935, train/logprobs = tensor([[-0.4423, -0.4970],
        [-0.5445, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11482607573270798
Epoch 0, Step 257: train/loss = 0.4345605969429016, train/raw-loss = 0.40281301736831665, train/logprobs = tensor([[-0.3403, -3.9146],
        [-0.3995, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12699037790298462
Epoch 0, Step 258: train/loss = 0.447410523891449, train/raw-loss = 0.40586864948272705, train/logprobs = tensor([[-0.7498, -4.5685],
        [-0.6524, -0.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16616763174533844
Epoch 0, Step 259: train/loss = 0.4872307777404785, train/raw-loss = 0.4540567994117737, train/logprobs = tensor([[-0.3842, -3.5677],
        [-0.4655, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13269591331481934
Epoch 0, Step 260: train/loss = 0.5267120599746704, train/raw-loss = 0.4902113080024719, train/logprobs = tensor([[-0.5151, -2.9719],
        [-0.6969, -1.8249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14600302278995514
Epoch 0, Step 261: train/loss = 0.3080897033214569, train/raw-loss = 0.2671357989311218, train/logprobs = tensor([[-0.4034, -5.8972],
        [-0.5036, -0.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16381552815437317
Epoch 0, Step 262: train/loss = 0.5268878936767578, train/raw-loss = 0.4956667423248291, train/logprobs = tensor([[-1.2285, -4.1477],
        [-1.3605, -2.2832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248847246170044
Epoch 0, Step 263: train/loss = 0.3233358561992645, train/raw-loss = 0.28030961751937866, train/logprobs = tensor([[-0.4902, -4.5392],
        [-0.6698, -1.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17210496962070465
Epoch 0, Step 264: train/loss = 0.44710874557495117, train/raw-loss = 0.40752363204956055, train/logprobs = tensor([[-0.4679, -4.0758],
        [-0.5030, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15834055840969086
Epoch 0, Step 265: train/loss = 0.7233009934425354, train/raw-loss = 0.6937836408615112, train/logprobs = tensor([[-0.4610, -0.4623],
        [-0.5613, -0.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806955933570862
Epoch 0, Step 266: train/loss = 0.5215821266174316, train/raw-loss = 0.4910247325897217, train/logprobs = tensor([[-0.3320, -2.5581],
        [-0.3736, -0.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1222294420003891
Epoch 0, Step 267: train/loss = 0.5014140009880066, train/raw-loss = 0.46995195746421814, train/logprobs = tensor([[-0.5354, -3.4364],
        [-0.6228, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258481740951538
Epoch 0, Step 268: train/loss = 0.49630007147789, train/raw-loss = 0.4601932764053345, train/logprobs = tensor([[-0.5420, -4.0136],
        [-0.5825, -0.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14442718029022217
Epoch 0, Step 269: train/loss = 0.42717674374580383, train/raw-loss = 0.3927820324897766, train/logprobs = tensor([[-0.3588, -3.7663],
        [-0.4025, -0.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1375787854194641
Epoch 0, Step 270: train/loss = 0.44681721925735474, train/raw-loss = 0.40475213527679443, train/logprobs = tensor([[-1.4124, -6.0192],
        [-1.2676, -0.3674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.168260395526886
Epoch 0, Step 271: train/loss = 0.4836093783378601, train/raw-loss = 0.4533073902130127, train/logprobs = tensor([[-0.3335, -3.3168],
        [-0.4047, -1.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120775133371353
Epoch 0, Step 272: train/loss = 0.41138461232185364, train/raw-loss = 0.3788766860961914, train/logprobs = tensor([[-0.4794, -6.1238],
        [-0.5071, -0.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13003161549568176
Epoch 0, Step 273: train/loss = 0.511260449886322, train/raw-loss = 0.47894537448883057, train/logprobs = tensor([[-0.4188, -3.6339],
        [-0.4530, -0.3945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12926048040390015
Epoch 0, Step 274: train/loss = 0.513948380947113, train/raw-loss = 0.48203474283218384, train/logprobs = tensor([[-0.4183, -4.4592],
        [-0.4381, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12765438854694366
Epoch 0, Step 275: train/loss = 0.4245648980140686, train/raw-loss = 0.39142370223999023, train/logprobs = tensor([[-0.3835, -4.4925],
        [-0.4273, -0.9224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325647085905075
Epoch 0, Step 276: train/loss = 0.49601995944976807, train/raw-loss = 0.46321630477905273, train/logprobs = tensor([[-0.4611, -2.9437],
        [-0.5207, -0.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13121464848518372
Epoch 0, Step 277: train/loss = 0.5137726068496704, train/raw-loss = 0.48142749071121216, train/logprobs = tensor([[-0.4386, -3.4397],
        [-0.4749, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12938043475151062
Epoch 0, Step 278: train/loss = 0.42076432704925537, train/raw-loss = 0.3779129087924957, train/logprobs = tensor([[-0.5623, -3.9383],
        [-0.6847, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1714055836200714
Epoch 0, Step 279: train/loss = 0.40086832642555237, train/raw-loss = 0.3613065481185913, train/logprobs = tensor([[-0.5155, -4.8672],
        [-0.5936, -0.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15824700891971588
Epoch 0, Step 280: train/loss = 0.4319022595882416, train/raw-loss = 0.39819058775901794, train/logprobs = tensor([[-0.4832, -4.2674],
        [-0.5443, -0.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13484668731689453
Epoch 0, Step 281: train/loss = 0.3163334131240845, train/raw-loss = 0.2773168981075287, train/logprobs = tensor([[-0.5102, -6.8367],
        [-0.5786, -2.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15606603026390076
Epoch 0, Step 282: train/loss = 0.4174172282218933, train/raw-loss = 0.3830278515815735, train/logprobs = tensor([[-0.5650, -4.0937],
        [-0.6210, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1375574767589569
Epoch 0, Step 283: train/loss = 0.5752017498016357, train/raw-loss = 0.545386016368866, train/logprobs = tensor([[-0.4630, -2.6697],
        [-0.5119, -0.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11926326900720596
Epoch 0, Step 284: train/loss = 0.40614503622055054, train/raw-loss = 0.36795830726623535, train/logprobs = tensor([[-0.5329, -5.0440],
        [-0.6164, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15274670720100403
Epoch 0, Step 285: train/loss = 0.5090897679328918, train/raw-loss = 0.4758301377296448, train/logprobs = tensor([[-0.3813, -2.5423],
        [-0.4465, -0.6174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13303859531879425
Epoch 0, Step 286: train/loss = 0.42072534561157227, train/raw-loss = 0.38279297947883606, train/logprobs = tensor([[-0.5650, -3.6934],
        [-0.5720, -0.5825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15172943472862244
Epoch 0, Step 287: train/loss = 0.3781437277793884, train/raw-loss = 0.33840063214302063, train/logprobs = tensor([[-0.5901, -4.9039],
        [-0.7103, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589723527431488
Epoch 0, Step 288: train/loss = 0.5019897818565369, train/raw-loss = 0.47088056802749634, train/logprobs = tensor([[-0.5101, -3.3926],
        [-0.4986, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244368925690651
Epoch 0, Step 289: train/loss = 0.5140592455863953, train/raw-loss = 0.485392689704895, train/logprobs = tensor([[-0.4077, -4.9799],
        [-0.4151, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11466628313064575
Epoch 0, Step 290: train/loss = 0.39327213168144226, train/raw-loss = 0.360193133354187, train/logprobs = tensor([[-0.4537, -6.8981],
        [-0.5763, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13231588900089264
Epoch 0, Step 291: train/loss = 0.5020555257797241, train/raw-loss = 0.4732872247695923, train/logprobs = tensor([[-0.3831, -3.8884],
        [-0.4056, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11507304012775421
Epoch 0, Step 292: train/loss = 0.4818812608718872, train/raw-loss = 0.44425326585769653, train/logprobs = tensor([[-0.4671, -2.7394],
        [-0.5721, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15051206946372986
Epoch 0, Step 293: train/loss = 0.5169326066970825, train/raw-loss = 0.48571860790252686, train/logprobs = tensor([[-0.5684, -4.5723],
        [-0.4676, -0.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12485595047473907
Epoch 0, Step 294: train/loss = 0.530029833316803, train/raw-loss = 0.5023167133331299, train/logprobs = tensor([[-0.6524, -3.2889],
        [-0.6146, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085252463817596
Epoch 0, Step 295: train/loss = 0.48849737644195557, train/raw-loss = 0.4551132023334503, train/logprobs = tensor([[-0.5130, -4.5756],
        [-0.6058, -0.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13353675603866577
Epoch 0, Step 296: train/loss = 0.6079143285751343, train/raw-loss = 0.5803936719894409, train/logprobs = tensor([[-0.5309, -2.4043],
        [-0.5021, -0.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11008284986019135
Epoch 0, Step 297: train/loss = 0.47329139709472656, train/raw-loss = 0.44069942831993103, train/logprobs = tensor([[-0.4863, -3.7660],
        [-0.5681, -0.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303679645061493
Epoch 0, Step 298: train/loss = 0.41623032093048096, train/raw-loss = 0.3811555802822113, train/logprobs = tensor([[-0.6681, -5.8663],
        [-0.6835, -0.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402989625930786
Epoch 0, Step 299: train/loss = 0.40003105998039246, train/raw-loss = 0.3624785542488098, train/logprobs = tensor([[-0.4724, -5.3798],
        [-0.6073, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15021011233329773
Epoch 0, Step 300: train/loss = 0.3070520758628845, train/raw-loss = 0.2679344415664673, train/logprobs = tensor([[-0.5549, -7.3968],
        [-0.6078, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15647050738334656
Epoch 0, Step 301: train/loss = 0.518851101398468, train/raw-loss = 0.48840829730033875, train/logprobs = tensor([[-0.4639, -2.2128],
        [-0.5233, -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177120894193649
Epoch 0, Step 302: train/loss = 0.39615949988365173, train/raw-loss = 0.358030766248703, train/logprobs = tensor([[-0.4742, -4.6872],
        [-0.4879, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15251502394676208
Epoch 0, Step 303: train/loss = 0.49450021982192993, train/raw-loss = 0.4644925594329834, train/logprobs = tensor([[-0.4421, -2.8973],
        [-0.4929, -0.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12003049999475479
Epoch 0, Step 304: train/loss = 0.4448351263999939, train/raw-loss = 0.4051971435546875, train/logprobs = tensor([[-0.7678, -4.7778],
        [-0.5278, -0.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15855185687541962
Epoch 0, Step 305: train/loss = 0.6183834075927734, train/raw-loss = 0.587306022644043, train/logprobs = tensor([[-0.5060, -2.0505],
        [-0.5659, -0.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12430994212627411
Epoch 0, Step 306: train/loss = 0.535652220249176, train/raw-loss = 0.5049196481704712, train/logprobs = tensor([[-0.9813, -3.8079],
        [-0.8327, -1.2406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12293043732643127
Epoch 0, Step 307: train/loss = 0.49192604422569275, train/raw-loss = 0.4562789797782898, train/logprobs = tensor([[-0.5204, -3.9643],
        [-0.5458, -0.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425882875919342
Epoch 0, Step 308: train/loss = 0.4186534881591797, train/raw-loss = 0.38884836435317993, train/logprobs = tensor([[-0.7033, -7.3409],
        [-0.4888, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192205548286438
Epoch 0, Step 309: train/loss = 0.5155150294303894, train/raw-loss = 0.48438793420791626, train/logprobs = tensor([[-0.8012, -4.8141],
        [-0.6674, -0.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1245083212852478
Epoch 0, Step 310: train/loss = 0.6077090501785278, train/raw-loss = 0.578027606010437, train/logprobs = tensor([[-0.6497, -2.9960],
        [-0.6238, -0.6377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872567236423492
Epoch 0, Step 311: train/loss = 0.3953503370285034, train/raw-loss = 0.3585616946220398, train/logprobs = tensor([[-0.7236, -4.9904],
        [-0.9217, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471545696258545
Epoch 0, Step 312: train/loss = 0.40821903944015503, train/raw-loss = 0.37229764461517334, train/logprobs = tensor([[-0.5107, -5.3543],
        [-0.5519, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14368565380573273
Epoch 0, Step 313: train/loss = 0.31475692987442017, train/raw-loss = 0.2781415283679962, train/logprobs = tensor([[-0.4633, -8.3383],
        [-0.4494, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14646156132221222
Epoch 0, Step 314: train/loss = 0.5998800992965698, train/raw-loss = 0.5696584582328796, train/logprobs = tensor([[-0.4919, -2.1172],
        [-0.6251, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12088663876056671
Epoch 0, Step 315: train/loss = 0.38082143664360046, train/raw-loss = 0.340587854385376, train/logprobs = tensor([[-0.6019, -6.4518],
        [-0.6473, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16093415021896362
Epoch 0, Step 316: train/loss = 0.40875428915023804, train/raw-loss = 0.372286856174469, train/logprobs = tensor([[-0.3957, -5.8387],
        [-0.5273, -0.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14586977660655975
Epoch 0, Step 317: train/loss = 0.5790124535560608, train/raw-loss = 0.5481752157211304, train/logprobs = tensor([[-0.4019, -2.1579],
        [-0.4420, -0.6384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12334883213043213
Epoch 0, Step 318: train/loss = 0.5991692543029785, train/raw-loss = 0.5735740661621094, train/logprobs = tensor([[-0.3584, -3.0103],
        [-0.4114, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10238058865070343
Epoch 0, Step 319: train/loss = 0.32951492071151733, train/raw-loss = 0.29431813955307007, train/logprobs = tensor([[-0.3743, -6.4493],
        [-0.4355, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14078709483146667
Epoch 0, Step 320: train/loss = 0.594017744064331, train/raw-loss = 0.5637168288230896, train/logprobs = tensor([[-0.8306, -2.5142],
        [-0.8429, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212034821510315
Epoch 0, Step 321: train/loss = 0.42211291193962097, train/raw-loss = 0.3914441764354706, train/logprobs = tensor([[-0.4906, -5.7875],
        [-0.5289, -1.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267489731311798
Epoch 0, Step 322: train/loss = 0.5204861760139465, train/raw-loss = 0.48478835821151733, train/logprobs = tensor([[-0.4626, -4.7764],
        [-0.5936, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427912712097168
Epoch 0, Step 323: train/loss = 0.4082661271095276, train/raw-loss = 0.3764972686767578, train/logprobs = tensor([[-0.5271, -4.9722],
        [-0.6113, -0.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12707534432411194
Epoch 0, Step 324: train/loss = 0.4647678732872009, train/raw-loss = 0.4290023744106293, train/logprobs = tensor([[-1.1413, -5.5738],
        [-1.1004, -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430620551109314
Epoch 0, Step 325: train/loss = 0.4086119532585144, train/raw-loss = 0.3746061325073242, train/logprobs = tensor([[-0.4632, -4.4176],
        [-0.4859, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13602325320243835
Epoch 0, Step 326: train/loss = 0.5082557201385498, train/raw-loss = 0.47534674406051636, train/logprobs = tensor([[-0.7172, -2.9850],
        [-0.9205, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13163581490516663
Epoch 0, Step 327: train/loss = 0.4381430447101593, train/raw-loss = 0.4016878008842468, train/logprobs = tensor([[-0.5411, -2.8853],
        [-1.0391, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14582088589668274
Epoch 0, Step 328: train/loss = 0.567348837852478, train/raw-loss = 0.5338387489318848, train/logprobs = tensor([[-0.4448, -2.5598],
        [-0.5783, -0.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13404035568237305
Epoch 0, Step 329: train/loss = 0.5393035411834717, train/raw-loss = 0.5094711780548096, train/logprobs = tensor([[-0.5895, -3.1596],
        [-0.5967, -0.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932951211929321
Epoch 0, Step 330: train/loss = 0.5232495069503784, train/raw-loss = 0.4873940348625183, train/logprobs = tensor([[-0.4181, -4.2612],
        [-0.4660, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14342203736305237
Epoch 0, Step 331: train/loss = 0.37859371304512024, train/raw-loss = 0.3432450294494629, train/logprobs = tensor([[-0.5639, -6.7779],
        [-0.6401, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14139477908611298
Epoch 0, Step 332: train/loss = 0.6810154318809509, train/raw-loss = 0.6545455455780029, train/logprobs = tensor([[-0.6101, -0.4741],
        [-0.6505, -0.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10587943345308304
Epoch 0, Step 333: train/loss = 0.5665651559829712, train/raw-loss = 0.5358465313911438, train/logprobs = tensor([[-0.6423, -2.7105],
        [-0.7166, -0.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12287448346614838
Epoch 0, Step 334: train/loss = 0.3870869576931, train/raw-loss = 0.3540728688240051, train/logprobs = tensor([[-0.5012, -7.1625],
        [-0.5897, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320563107728958
Epoch 0, Step 335: train/loss = 0.5130548477172852, train/raw-loss = 0.47639384865760803, train/logprobs = tensor([[-0.6658, -4.3203],
        [-0.7669, -0.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14664387702941895
Epoch 0, Step 336: train/loss = 0.3940736651420593, train/raw-loss = 0.36012157797813416, train/logprobs = tensor([[-0.5442, -5.0207],
        [-0.7038, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13580851256847382
Epoch 0, Step 337: train/loss = 0.4035077691078186, train/raw-loss = 0.37469542026519775, train/logprobs = tensor([[-0.3143, -4.8118],
        [-0.3450, -0.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11524927616119385
Epoch 0, Step 338: train/loss = 0.4514197111129761, train/raw-loss = 0.4161437153816223, train/logprobs = tensor([[-0.3710, -4.1057],
        [-0.4040, -0.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14110389351844788
Epoch 0, Step 339: train/loss = 0.5137946605682373, train/raw-loss = 0.48539647459983826, train/logprobs = tensor([[-0.4734, -4.5838],
        [-0.5221, -1.5649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359286308288574
Epoch 0, Step 340: train/loss = 0.5572939515113831, train/raw-loss = 0.530276894569397, train/logprobs = tensor([[-0.4914, -3.2841],
        [-0.5750, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10806829482316971
Epoch 0, Step 341: train/loss = 0.5008619427680969, train/raw-loss = 0.4649142622947693, train/logprobs = tensor([[-0.5436, -3.4688],
        [-0.6510, -0.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1437908113002777
Epoch 0, Step 342: train/loss = 0.5975196361541748, train/raw-loss = 0.5625232458114624, train/logprobs = tensor([[-0.5240, -2.0421],
        [-0.6705, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13998550176620483
Epoch 0, Step 343: train/loss = 0.41056355834007263, train/raw-loss = 0.3706502914428711, train/logprobs = tensor([[-0.7805, -6.6931],
        [-0.8205, -0.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15965306758880615
Epoch 0, Step 344: train/loss = 0.3745179772377014, train/raw-loss = 0.33658167719841003, train/logprobs = tensor([[-0.4271, -5.8726],
        [-0.5229, -0.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1517452895641327
Epoch 0, Step 345: train/loss = 0.377835214138031, train/raw-loss = 0.34270668029785156, train/logprobs = tensor([[-0.5143, -5.6882],
        [-0.5368, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1405140459537506
Epoch 0, Step 346: train/loss = 0.3076953589916229, train/raw-loss = 0.2728537321090698, train/logprobs = tensor([[-0.4852, -8.1306],
        [-0.6096, -1.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393665373325348
Epoch 0, Step 347: train/loss = 0.5089966058731079, train/raw-loss = 0.4768698811531067, train/logprobs = tensor([[-0.4075, -2.8253],
        [-0.5101, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1285068541765213
Epoch 0, Step 348: train/loss = 0.5001480579376221, train/raw-loss = 0.47016385197639465, train/logprobs = tensor([[-0.3474, -3.8087],
        [-0.3583, -0.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11993668973445892
Epoch 0, Step 349: train/loss = 0.5145169496536255, train/raw-loss = 0.48596304655075073, train/logprobs = tensor([[-0.5376, -4.2854],
        [-0.5546, -2.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421579122543335
Epoch 0, Step 350: train/loss = 0.5996612310409546, train/raw-loss = 0.5706990957260132, train/logprobs = tensor([[-1.3293, -5.7908],
        [-0.6953, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1158483624458313
Epoch 0, Step 351: train/loss = 0.5154416561126709, train/raw-loss = 0.4767490029335022, train/logprobs = tensor([[-0.9780, -3.8253],
        [-0.9233, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547705978155136
Epoch 0, Step 352: train/loss = 0.4930376410484314, train/raw-loss = 0.45793646574020386, train/logprobs = tensor([[-0.5814, -4.7258],
        [-0.7218, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14040453732013702
Epoch 0, Step 353: train/loss = 0.517117440700531, train/raw-loss = 0.4860079884529114, train/logprobs = tensor([[-0.5792, -4.0532],
        [-0.6480, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12443775683641434
Epoch 0, Step 354: train/loss = 0.5709466934204102, train/raw-loss = 0.5459305047988892, train/logprobs = tensor([[-0.3765, -2.8851],
        [-0.4347, -0.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10006482899188995
Epoch 0, Step 355: train/loss = 0.3784831166267395, train/raw-loss = 0.3419642448425293, train/logprobs = tensor([[-0.5874, -6.2731],
        [-0.8902, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14607542753219604
Epoch 0, Step 356: train/loss = 0.6365989446640015, train/raw-loss = 0.6089661121368408, train/logprobs = tensor([[-0.4461, -1.7853],
        [-0.4053, -0.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11053130030632019
Epoch 0, Step 357: train/loss = 0.41457027196884155, train/raw-loss = 0.3736475706100464, train/logprobs = tensor([[-0.6640, -5.0338],
        [-0.7490, -0.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1636907160282135
Epoch 0, Step 358: train/loss = 0.538431704044342, train/raw-loss = 0.5012251734733582, train/logprobs = tensor([[-0.5597, -3.0512],
        [-0.5125, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14882610738277435
Epoch 0, Step 359: train/loss = 0.4485829472541809, train/raw-loss = 0.411602258682251, train/logprobs = tensor([[-1.2434, -7.0719],
        [-0.9855, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14792263507843018
Epoch 0, Step 360: train/loss = 0.47104009985923767, train/raw-loss = 0.4351359009742737, train/logprobs = tensor([[-0.4452, -5.0327],
        [-0.6389, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14361688494682312
Epoch 0, Step 361: train/loss = 0.49897587299346924, train/raw-loss = 0.4645569324493408, train/logprobs = tensor([[-0.4142, -4.4238],
        [-0.6670, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13767577707767487
Epoch 0, Step 362: train/loss = 0.36469754576683044, train/raw-loss = 0.3358761668205261, train/logprobs = tensor([[-0.4595, -6.7176],
        [-0.6040, -1.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11528553068637848
Epoch 0, Step 363: train/loss = 0.5049278140068054, train/raw-loss = 0.467194527387619, train/logprobs = tensor([[-0.5544, -3.7982],
        [-0.6098, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15093320608139038
Epoch 0, Step 364: train/loss = 0.3453480005264282, train/raw-loss = 0.30703702569007874, train/logprobs = tensor([[-0.5554, -6.4725],
        [-0.7132, -0.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15324391424655914
Epoch 0, Step 365: train/loss = 0.37948647141456604, train/raw-loss = 0.35033583641052246, train/logprobs = tensor([[-0.3978, -8.6534],
        [-0.4585, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11660268157720566
Epoch 0, Step 366: train/loss = 0.7088532447814941, train/raw-loss = 0.6826563477516174, train/logprobs = tensor([[-0.4768, -0.4643],
        [-0.4934, -0.4359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10478771477937698
Epoch 0, Step 367: train/loss = 0.48262548446655273, train/raw-loss = 0.44577476382255554, train/logprobs = tensor([[-0.5276, -3.4636],
        [-0.7340, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14740297198295593
Epoch 0, Step 368: train/loss = 0.4139564037322998, train/raw-loss = 0.3827327489852905, train/logprobs = tensor([[-0.4817, -5.4828],
        [-0.6024, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489466369152069
Epoch 0, Step 369: train/loss = 0.407029390335083, train/raw-loss = 0.36798781156539917, train/logprobs = tensor([[-0.4957, -4.9088],
        [-0.7457, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1561661809682846
Epoch 0, Step 370: train/loss = 0.6017155051231384, train/raw-loss = 0.5755444169044495, train/logprobs = tensor([[-0.4680, -2.7402],
        [-0.5225, -0.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468445718288422
Epoch 0, Step 371: train/loss = 0.30544406175613403, train/raw-loss = 0.2679670453071594, train/logprobs = tensor([[-0.5672, -8.6935],
        [-0.6855, -2.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14990797638893127
Epoch 0, Step 372: train/loss = 0.432336688041687, train/raw-loss = 0.3963147699832916, train/logprobs = tensor([[-0.5155, -4.4986],
        [-0.6081, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14408767223358154
Epoch 0, Step 373: train/loss = 0.29556068778038025, train/raw-loss = 0.2606739401817322, train/logprobs = tensor([[-0.3742, -8.8790],
        [-0.4628, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13954690098762512
Epoch 0, Step 374: train/loss = 0.40255075693130493, train/raw-loss = 0.3711220920085907, train/logprobs = tensor([[-0.5301, -5.8975],
        [-0.5787, -1.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12571465969085693
Epoch 0, Step 375: train/loss = 0.592686653137207, train/raw-loss = 0.5644416809082031, train/logprobs = tensor([[-0.5909, -3.4303],
        [-0.6221, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11297977715730667
Epoch 0, Step 376: train/loss = 0.6593445539474487, train/raw-loss = 0.6293504238128662, train/logprobs = tensor([[-0.7232, -1.8383],
        [-0.6935, -1.4870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11997660994529724
Epoch 0, Step 377: train/loss = 0.633033275604248, train/raw-loss = 0.6018493175506592, train/logprobs = tensor([[-0.4300, -2.5368],
        [-0.5418, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12473592162132263
Epoch 0, Step 378: train/loss = 0.40571558475494385, train/raw-loss = 0.371275395154953, train/logprobs = tensor([[-0.4315, -5.6327],
        [-0.5117, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13776056468486786
Epoch 0, Step 379: train/loss = 0.5367162227630615, train/raw-loss = 0.5031336545944214, train/logprobs = tensor([[-0.7513, -3.1811],
        [-0.5731, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13433010876178741
Epoch 0, Step 380: train/loss = 0.5189526677131653, train/raw-loss = 0.4812469482421875, train/logprobs = tensor([[-0.5230, -4.0019],
        [-0.6520, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15082281827926636
Epoch 0, Step 381: train/loss = 0.4917941093444824, train/raw-loss = 0.46132391691207886, train/logprobs = tensor([[-0.6144, -4.5865],
        [-0.6038, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12188062071800232
Epoch 0, Step 382: train/loss = 0.4861007630825043, train/raw-loss = 0.45291656255722046, train/logprobs = tensor([[-0.5367, -3.9626],
        [-0.6484, -0.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13273681700229645
Epoch 0, Step 383: train/loss = 0.42000287771224976, train/raw-loss = 0.37694302201271057, train/logprobs = tensor([[-0.6142, -6.2448],
        [-0.7006, -0.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17223943769931793
Epoch 0, Step 384: train/loss = 0.4901670813560486, train/raw-loss = 0.4582114815711975, train/logprobs = tensor([[-0.5602, -3.9291],
        [-0.6771, -0.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278223842382431
Epoch 0, Step 385: train/loss = 0.4405663013458252, train/raw-loss = 0.40541207790374756, train/logprobs = tensor([[-0.4790, -4.1252],
        [-0.7601, -0.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14061692357063293
Epoch 0, Step 386: train/loss = 0.3999002277851105, train/raw-loss = 0.3613152503967285, train/logprobs = tensor([[-0.4724, -6.2152],
        [-0.6035, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15433993935585022
Epoch 0, Step 387: train/loss = 0.6219796538352966, train/raw-loss = 0.5873104929924011, train/logprobs = tensor([[-0.9081, -2.4973],
        [-0.8533, -0.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386766880750656
Epoch 0, Step 388: train/loss = 0.32494643330574036, train/raw-loss = 0.2890133559703827, train/logprobs = tensor([[-0.4650, -5.2242],
        [-0.5789, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14373226463794708
Epoch 0, Step 389: train/loss = 0.40576836466789246, train/raw-loss = 0.36823466420173645, train/logprobs = tensor([[-0.4077, -5.2574],
        [-0.5592, -0.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501348614692688
Epoch 0, Step 390: train/loss = 0.48895731568336487, train/raw-loss = 0.4506162405014038, train/logprobs = tensor([[-0.5168, -3.6755],
        [-0.7430, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15336433053016663
Epoch 0, Step 391: train/loss = 0.3992043733596802, train/raw-loss = 0.3669557571411133, train/logprobs = tensor([[-0.4102, -6.2009],
        [-0.6314, -1.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12899459898471832
Epoch 0, Step 392: train/loss = 0.3818637728691101, train/raw-loss = 0.34565433859825134, train/logprobs = tensor([[-0.6499, -5.9221],
        [-0.8521, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14483779668807983
Epoch 0, Step 393: train/loss = 0.3934228718280792, train/raw-loss = 0.3490583300590515, train/logprobs = tensor([[-0.4255, -5.2091],
        [-0.6050, -0.6299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17745813727378845
Epoch 0, Step 394: train/loss = 0.48379790782928467, train/raw-loss = 0.45107027888298035, train/logprobs = tensor([[-0.4912, -3.7952],
        [-0.6148, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13091053068637848
Epoch 0, Step 395: train/loss = 0.5044031143188477, train/raw-loss = 0.4726186692714691, train/logprobs = tensor([[-0.6168, -4.5384],
        [-0.5688, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12713761627674103
Epoch 0, Step 396: train/loss = 0.482208251953125, train/raw-loss = 0.45237550139427185, train/logprobs = tensor([[-0.3766, -5.7371],
        [-0.5639, -0.8490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11933107674121857
Epoch 0, Step 397: train/loss = 0.44810110330581665, train/raw-loss = 0.41800493001937866, train/logprobs = tensor([[-0.5121, -4.7453],
        [-0.6610, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038472294807434
Epoch 0, Step 398: train/loss = 0.7247132658958435, train/raw-loss = 0.7012149691581726, train/logprobs = tensor([[-0.5481, -0.6639],
        [-0.3586, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0939931571483612
Epoch 0, Step 399: train/loss = 0.4182896316051483, train/raw-loss = 0.3831551671028137, train/logprobs = tensor([[-0.3419, -4.6986],
        [-0.4719, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14053796231746674
Epoch 0, Step 400: train/loss = 0.5042417049407959, train/raw-loss = 0.46980980038642883, train/logprobs = tensor([[-0.5952, -3.9178],
        [-0.6958, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377277970314026
Epoch 0, Step 401: train/loss = 0.49133649468421936, train/raw-loss = 0.45883339643478394, train/logprobs = tensor([[-0.5246, -4.7436],
        [-0.7148, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13001230359077454
Epoch 0, Step 402: train/loss = 0.3872540593147278, train/raw-loss = 0.3460777997970581, train/logprobs = tensor([[-0.5292, -5.2303],
        [-0.7753, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1647048443555832
Epoch 0, Step 403: train/loss = 0.38537752628326416, train/raw-loss = 0.35159552097320557, train/logprobs = tensor([[-0.3478, -6.9399],
        [-0.5325, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13512815535068512
Epoch 0, Step 404: train/loss = 0.3857389986515045, train/raw-loss = 0.34630194306373596, train/logprobs = tensor([[-0.4600, -6.4514],
        [-0.6868, -0.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15774811804294586
Epoch 0, Step 405: train/loss = 0.5491963028907776, train/raw-loss = 0.5257015228271484, train/logprobs = tensor([[-0.3845, -3.2362],
        [-0.5200, -0.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397909045219421
Epoch 0, Step 406: train/loss = 0.581398069858551, train/raw-loss = 0.5502135157585144, train/logprobs = tensor([[-0.4134, -1.5817],
        [-0.5614, -0.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12473832070827484
Epoch 0, Step 407: train/loss = 0.4923005998134613, train/raw-loss = 0.4557696580886841, train/logprobs = tensor([[-0.6066, -4.2367],
        [-0.7122, -0.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14612378180027008
Epoch 0, Step 408: train/loss = 0.2863074243068695, train/raw-loss = 0.24603280425071716, train/logprobs = tensor([[-0.4641, -7.3805],
        [-0.6554, -0.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16109852492809296
Epoch 0, Step 409: train/loss = 0.2882483899593353, train/raw-loss = 0.2579687237739563, train/logprobs = tensor([[-0.4509, -8.2365],
        [-0.5889, -1.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12111878395080566
Epoch 0, Step 410: train/loss = 0.2884092628955841, train/raw-loss = 0.2527270019054413, train/logprobs = tensor([[-0.5044, -8.7031],
        [-0.6468, -0.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14272914826869965
Epoch 0, Step 411: train/loss = 0.39699000120162964, train/raw-loss = 0.3611970543861389, train/logprobs = tensor([[-0.4347, -6.2672],
        [-0.4919, -0.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14317187666893005
Epoch 0, Step 412: train/loss = 0.46114957332611084, train/raw-loss = 0.42546331882476807, train/logprobs = tensor([[-0.4806, -3.1608],
        [-0.7217, -0.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427449882030487
Epoch 0, Step 413: train/loss = 0.5164061784744263, train/raw-loss = 0.486042320728302, train/logprobs = tensor([[-1.3546, -3.5413],
        [-1.2169, -1.3631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1214555874466896
Epoch 0, Step 414: train/loss = 0.5510619878768921, train/raw-loss = 0.522114634513855, train/logprobs = tensor([[-0.5088, -2.1590],
        [-0.6847, -0.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11578914523124695
Epoch 0, Step 415: train/loss = 0.37362241744995117, train/raw-loss = 0.3405662178993225, train/logprobs = tensor([[-0.3853, -7.8997],
        [-0.5674, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13222485780715942
Epoch 0, Step 416: train/loss = 0.49393990635871887, train/raw-loss = 0.4660428762435913, train/logprobs = tensor([[-0.4303, -4.2804],
        [-0.4868, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11158813536167145
Epoch 0, Step 417: train/loss = 0.6058038473129272, train/raw-loss = 0.5765580534934998, train/logprobs = tensor([[-0.5604, -0.9580],
        [-0.6830, -0.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11698329448699951
Epoch 0, Step 418: train/loss = 0.4332398772239685, train/raw-loss = 0.40829721093177795, train/logprobs = tensor([[-0.5147, -6.1059],
        [-0.5310, -1.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09977074712514877
Epoch 0, Step 419: train/loss = 0.3964875340461731, train/raw-loss = 0.3639969825744629, train/logprobs = tensor([[-0.4734, -5.7977],
        [-0.6149, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12996219098567963
Epoch 0, Step 420: train/loss = 0.40087610483169556, train/raw-loss = 0.3634243607521057, train/logprobs = tensor([[-0.3832, -5.8607],
        [-0.5593, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980700612068176
Epoch 0, Step 421: train/loss = 0.6689101457595825, train/raw-loss = 0.6351797580718994, train/logprobs = tensor([[-1.3717, -3.2810],
        [-0.6260, -0.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13492146134376526
Epoch 0, Step 422: train/loss = 0.4688992500305176, train/raw-loss = 0.4366791248321533, train/logprobs = tensor([[-0.4983, -3.9579],
        [-0.7263, -0.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12888048589229584
Epoch 0, Step 423: train/loss = 0.39791589975357056, train/raw-loss = 0.36793601512908936, train/logprobs = tensor([[-0.5302, -7.5452],
        [-0.5452, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11991945654153824
Epoch 0, Step 424: train/loss = 0.5074254870414734, train/raw-loss = 0.4746500253677368, train/logprobs = tensor([[-0.5295, -4.1068],
        [-0.6768, -0.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311018168926239
Epoch 0, Step 425: train/loss = 0.4655212163925171, train/raw-loss = 0.4373106062412262, train/logprobs = tensor([[-0.3824, -4.5479],
        [-0.4644, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11284243315458298
Epoch 0, Step 426: train/loss = 0.6438537836074829, train/raw-loss = 0.6163914799690247, train/logprobs = tensor([[-0.4519, -0.9690],
        [-0.6101, -0.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10984939336776733
Epoch 0, Step 427: train/loss = 0.409578412771225, train/raw-loss = 0.37659338116645813, train/logprobs = tensor([[-0.4394, -6.2321],
        [-0.5036, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13194020092487335
Epoch 0, Step 428: train/loss = 0.5020372271537781, train/raw-loss = 0.46507447957992554, train/logprobs = tensor([[-0.4679, -4.7413],
        [-0.6265, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14785103499889374
Epoch 0, Step 429: train/loss = 0.49896612763404846, train/raw-loss = 0.4665958285331726, train/logprobs = tensor([[-0.5817, -3.5492],
        [-0.6776, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12948110699653625
Epoch 0, Step 430: train/loss = 0.39284196496009827, train/raw-loss = 0.3601400554180145, train/logprobs = tensor([[-0.4220, -7.3621],
        [-0.5674, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080772757530212
Epoch 0, Step 431: train/loss = 0.28955405950546265, train/raw-loss = 0.25579705834388733, train/logprobs = tensor([[-0.3260, -8.7335],
        [-0.4460, -0.4229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350279152393341
Epoch 0, Step 432: train/loss = 0.4621509611606598, train/raw-loss = 0.4234545826911926, train/logprobs = tensor([[-0.6111, -3.7696],
        [-0.7761, -0.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15478548407554626
Epoch 0, Step 433: train/loss = 0.30227482318878174, train/raw-loss = 0.2612319588661194, train/logprobs = tensor([[-0.4365, -7.3943],
        [-0.5432, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16417154669761658
Epoch 0, Step 434: train/loss = 0.4908786714076996, train/raw-loss = 0.4582899212837219, train/logprobs = tensor([[-0.3682, -3.9566],
        [-0.5110, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13035514950752258
Epoch 0, Step 435: train/loss = 0.5437924265861511, train/raw-loss = 0.5051504373550415, train/logprobs = tensor([[-0.8315, -3.1529],
        [-0.6459, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15456807613372803
Epoch 0, Step 436: train/loss = 0.5992728471755981, train/raw-loss = 0.5716554522514343, train/logprobs = tensor([[-0.5828, -2.4866],
        [-0.7288, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11046935617923737
Epoch 0, Step 437: train/loss = 0.3971407115459442, train/raw-loss = 0.3680535852909088, train/logprobs = tensor([[-0.4010, -7.9294],
        [-0.5148, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11634853482246399
Epoch 0, Step 438: train/loss = 0.5058831572532654, train/raw-loss = 0.4717906713485718, train/logprobs = tensor([[-0.4096, -4.8059],
        [-0.5279, -0.5734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13637018203735352
Epoch 0, Step 439: train/loss = 0.4888388514518738, train/raw-loss = 0.45869317650794983, train/logprobs = tensor([[-0.4536, -4.4570],
        [-0.6353, -1.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12058264017105103
Epoch 0, Step 440: train/loss = 0.49382662773132324, train/raw-loss = 0.4675702154636383, train/logprobs = tensor([[-0.4257, -3.7993],
        [-0.5159, -0.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10502553731203079
Epoch 0, Step 441: train/loss = 0.3943709135055542, train/raw-loss = 0.36146730184555054, train/logprobs = tensor([[-0.4119, -5.6045],
        [-0.6299, -1.3042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13161437213420868
Epoch 0, Step 442: train/loss = 0.5082806348800659, train/raw-loss = 0.47542470693588257, train/logprobs = tensor([[-0.6264, -4.3945],
        [-0.7491, -0.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13142356276512146
Epoch 0, Step 443: train/loss = 0.46532735228538513, train/raw-loss = 0.4332578182220459, train/logprobs = tensor([[-0.3437, -3.9511],
        [-0.4885, -0.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282781958580017
eval/loss: 0.4805235266685486
