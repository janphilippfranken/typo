[2024-02-20 12:38:05,796][root][INFO] - beta: 0.1
[2024-02-20 12:38:05,796][root][INFO] - temperature: 1
[2024-02-20 12:38:05,796][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-dpo-beta-0.1-batch-size-63
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 10000 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-dpo-beta-0.1-batch-size-63 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-dpo-beta-0.1-batch-size-63 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-dpo-beta-0.1-batch-size-63 after each epoch.
Epoch 0, Step 0: train/loss = 0.6931471824645996, train/raw-loss = 0.7208666801452637, train/logprobs = tensor([[-0.8567, -1.2156],
        [-0.8476, -1.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6931471824645996, train/raw-loss = 0.7109076380729675, train/logprobs = tensor([[-0.7917, -0.8804],
        [-0.8114, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6931471824645996, train/raw-loss = 0.755953311920166, train/logprobs = tensor([[-0.7720, -1.5478],
        [-0.8361, -1.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6931471824645996, train/raw-loss = 0.7179770469665527, train/logprobs = tensor([[-0.6827, -0.6293],
        [-0.6894, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6931471824645996, train/raw-loss = 0.7390668392181396, train/logprobs = tensor([[-0.7873, -1.4688],
        [-0.7577, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6931471824645996, train/raw-loss = 0.7139277458190918, train/logprobs = tensor([[-1.2134, -1.5504],
        [-1.2073, -1.3387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6931471824645996, train/raw-loss = 0.7353805303573608, train/logprobs = tensor([[-0.8758, -0.9327],
        [-0.9203, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6931471824645996, train/raw-loss = 0.7237703204154968, train/logprobs = tensor([[-0.6957, -1.2325],
        [-0.7032, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6931471824645996, train/raw-loss = 0.7579247355461121, train/logprobs = tensor([[-0.7761, -1.3294],
        [-0.7729, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6931471824645996, train/raw-loss = 0.7662578821182251, train/logprobs = tensor([[-0.7630, -1.1610],
        [-0.8235, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6931471824645996, train/raw-loss = 0.9528252482414246, train/logprobs = tensor([[-1.6544, -0.8213],
        [-1.7855, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6931471824645996, train/raw-loss = 0.7284392714500427, train/logprobs = tensor([[-0.7727, -1.2645],
        [-0.7795, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6931471824645996, train/raw-loss = 0.7113129496574402, train/logprobs = tensor([[-0.9834, -1.3988],
        [-0.9941, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6931471824645996, train/raw-loss = 0.7266901731491089, train/logprobs = tensor([[-1.1752, -0.8181],
        [-1.0937, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6931471824645996, train/raw-loss = 0.7743097543716431, train/logprobs = tensor([[-1.2538, -1.9011],
        [-1.4702, -1.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6931471824645996, train/raw-loss = 0.7129801511764526, train/logprobs = tensor([[-0.6885, -1.0324],
        [-0.7137, -1.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6931471824645996, train/raw-loss = 0.743228554725647, train/logprobs = tensor([[-1.1216, -1.2548],
        [-1.1524, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6931471824645996, train/raw-loss = 0.8270686864852905, train/logprobs = tensor([[-0.7644, -1.5278],
        [-0.7810, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6931471824645996, train/raw-loss = 0.7439977526664734, train/logprobs = tensor([[-0.9630, -0.6549],
        [-0.9578, -0.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6931471824645996, train/raw-loss = 0.7276279926300049, train/logprobs = tensor([[-1.0964, -1.4710],
        [-1.0992, -1.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6931471824645996, train/raw-loss = 0.6973130702972412, train/logprobs = tensor([[-0.8472, -1.0182],
        [-0.8357, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6931471824645996, train/raw-loss = 0.7039775848388672, train/logprobs = tensor([[-0.7083, -1.0360],
        [-0.6984, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6931471824645996, train/raw-loss = 0.7530050277709961, train/logprobs = tensor([[-0.8091, -1.1550],
        [-0.8191, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6931471824645996, train/raw-loss = 0.7261473536491394, train/logprobs = tensor([[-1.0183, -1.4350],
        [-0.9749, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6931471824645996, train/raw-loss = 0.6971797943115234, train/logprobs = tensor([[-0.6654, -0.7742],
        [-0.6802, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6931471824645996, train/raw-loss = 0.7251752614974976, train/logprobs = tensor([[-1.1716, -1.0303],
        [-1.2316, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6931471824645996, train/raw-loss = 0.70379638671875, train/logprobs = tensor([[-0.7350, -0.9549],
        [-0.7174, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6931471824645996, train/raw-loss = 0.7074220180511475, train/logprobs = tensor([[-1.4871, -1.2141],
        [-1.3376, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6931471824645996, train/raw-loss = 0.7145256996154785, train/logprobs = tensor([[-1.1768, -1.5261],
        [-1.1521, -1.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6931471824645996, train/raw-loss = 0.6982137560844421, train/logprobs = tensor([[-1.2879, -1.5596],
        [-1.3244, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6931471824645996, train/raw-loss = 0.6981403231620789, train/logprobs = tensor([[-0.6286, -0.8886],
        [-0.7234, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6931471824645996, train/raw-loss = 0.6982485055923462, train/logprobs = tensor([[-1.0426, -1.2564],
        [-1.0449, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6931471824645996, train/raw-loss = 0.7000057101249695, train/logprobs = tensor([[-0.7662, -0.9416],
        [-0.7213, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6931471824645996, train/raw-loss = 0.7103248834609985, train/logprobs = tensor([[-0.7710, -1.2283],
        [-0.7452, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6931471824645996, train/raw-loss = 0.7429689168930054, train/logprobs = tensor([[-0.7235, -1.1545],
        [-0.7539, -1.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6931471824645996, train/raw-loss = 0.6994712352752686, train/logprobs = tensor([[-0.7093, -0.9209],
        [-0.7146, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6931471824645996, train/raw-loss = 0.7194889783859253, train/logprobs = tensor([[-1.3431, -1.3020],
        [-1.2419, -1.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6931471824645996, train/raw-loss = 0.7026249766349792, train/logprobs = tensor([[-1.0567, -1.1431],
        [-1.1135, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6931471824645996, train/raw-loss = 0.7575852274894714, train/logprobs = tensor([[-0.6801, -0.9989],
        [-0.6513, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6931471824645996, train/raw-loss = 0.7130106687545776, train/logprobs = tensor([[-1.2808, -1.1185],
        [-1.2735, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6931471824645996, train/raw-loss = 0.6958476901054382, train/logprobs = tensor([[-1.1721, -1.1514],
        [-1.1813, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6931471824645996, train/raw-loss = 0.7012240886688232, train/logprobs = tensor([[-1.2751, -1.4828],
        [-1.3149, -1.4134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6925873756408691, train/raw-loss = 0.693989634513855, train/logprobs = tensor([[-1.1909, -1.1918],
        [-1.2431, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016690224583726376
Epoch 0, Step 43: train/loss = 0.6927131414413452, train/raw-loss = 0.6965062618255615, train/logprobs = tensor([[-1.0258, -1.2178],
        [-1.1783, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021918972197454423
Epoch 0, Step 44: train/loss = 0.6931621432304382, train/raw-loss = 0.7202094793319702, train/logprobs = tensor([[-1.0526, -0.9066],
        [-1.0962, -0.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.435392864048481e-05
Epoch 0, Step 45: train/loss = 0.6920261383056641, train/raw-loss = 0.7310929298400879, train/logprobs = tensor([[-0.8013, -1.0669],
        [-0.8227, -0.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006956853321753442
Epoch 0, Step 46: train/loss = 0.693213939666748, train/raw-loss = 0.7033910751342773, train/logprobs = tensor([[-0.7569, -0.5593],
        [-0.8413, -0.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.007120646245312e-06
Epoch 0, Step 47: train/loss = 0.6932281851768494, train/raw-loss = 0.723875880241394, train/logprobs = tensor([[-0.7440, -0.5303],
        [-0.7534, -0.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2028183341026306e-06
Epoch 0, Step 48: train/loss = 0.6930086612701416, train/raw-loss = 0.695854663848877, train/logprobs = tensor([[-0.8830, -0.9851],
        [-0.9500, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5120856915018521e-05
Epoch 0, Step 49: train/loss = 0.6922547221183777, train/raw-loss = 0.818117618560791, train/logprobs = tensor([[-0.8026, -1.3914],
        [-0.7616, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006826878525316715
Epoch 0, Step 50: train/loss = 0.6929108500480652, train/raw-loss = 0.7085450887680054, train/logprobs = tensor([[-1.1262, -1.3593],
        [-1.1101, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.144402191741392e-05
Epoch 0, Step 51: train/loss = 0.6931514143943787, train/raw-loss = 0.7289613485336304, train/logprobs = tensor([[-0.8998, -1.3458],
        [-0.8992, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1245874449959956e-05
Epoch 0, Step 52: train/loss = 0.6928061246871948, train/raw-loss = 0.7445580959320068, train/logprobs = tensor([[-1.3426, -0.9975],
        [-1.3709, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.977995508350432e-05
Epoch 0, Step 53: train/loss = 0.6931815147399902, train/raw-loss = 0.7160205245018005, train/logprobs = tensor([[-0.9454, -0.8782],
        [-1.0229, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.712170150218299e-06
Epoch 0, Step 54: train/loss = 0.6920601725578308, train/raw-loss = 0.7263609766960144, train/logprobs = tensor([[-0.9534, -1.3870],
        [-1.0195, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004772096872329712
Epoch 0, Step 55: train/loss = 0.6930021643638611, train/raw-loss = 0.7127803564071655, train/logprobs = tensor([[-0.5890, -0.9623],
        [-0.5812, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.647561480756849e-05
Epoch 0, Step 56: train/loss = 0.6928943395614624, train/raw-loss = 0.7206723093986511, train/logprobs = tensor([[-1.1160, -1.5772],
        [-1.1647, -1.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001964647526619956
Epoch 0, Step 57: train/loss = 0.6922826170921326, train/raw-loss = 0.7052054405212402, train/logprobs = tensor([[-0.9282, -1.3599],
        [-1.0137, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003662755188997835
Epoch 0, Step 58: train/loss = 0.6926798820495605, train/raw-loss = 0.7797226905822754, train/logprobs = tensor([[-0.9256, -1.6589],
        [-1.0297, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012131500989198685
Epoch 0, Step 59: train/loss = 0.6925122737884521, train/raw-loss = 0.7865256071090698, train/logprobs = tensor([[-0.7064, -1.1741],
        [-0.7212, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002379349898546934
Epoch 0, Step 60: train/loss = 0.6930391788482666, train/raw-loss = 0.7156175374984741, train/logprobs = tensor([[-0.6136, -1.0055],
        [-0.6156, -0.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4278902199293952e-05
Epoch 0, Step 61: train/loss = 0.6921736001968384, train/raw-loss = 0.7301732897758484, train/logprobs = tensor([[-0.9859, -1.4932],
        [-1.0510, -1.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006016244878992438
Epoch 0, Step 62: train/loss = 0.6929688453674316, train/raw-loss = 0.7014269828796387, train/logprobs = tensor([[-0.9100, -0.9352],
        [-0.9331, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7829639040865004e-05
Epoch 0, Step 63: train/loss = 0.6910920143127441, train/raw-loss = 0.7570576071739197, train/logprobs = tensor([[-1.4557, -1.2753],
        [-1.5565, -1.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032831996213644743
Epoch 0, Step 64: train/loss = 0.6915637254714966, train/raw-loss = 0.6989222764968872, train/logprobs = tensor([[-0.7430, -1.1050],
        [-0.8184, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015553408302366734
Epoch 0, Step 65: train/loss = 0.692076563835144, train/raw-loss = 0.7244517207145691, train/logprobs = tensor([[-1.0169, -1.2424],
        [-1.2385, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005516185192391276
Epoch 0, Step 66: train/loss = 0.6932910680770874, train/raw-loss = 0.8149015307426453, train/logprobs = tensor([[-0.7121, -1.4810],
        [-0.6752, -1.4876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041070085717365146
Epoch 0, Step 67: train/loss = 0.692922055721283, train/raw-loss = 0.6963671445846558, train/logprobs = tensor([[-1.0507, -1.2071],
        [-1.1492, -1.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.121614569565281e-05
Epoch 0, Step 68: train/loss = 0.6918944120407104, train/raw-loss = 0.7063438892364502, train/logprobs = tensor([[-0.8972, -1.3066],
        [-0.9059, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017113026697188616
Epoch 0, Step 69: train/loss = 0.6935285925865173, train/raw-loss = 0.7012121677398682, train/logprobs = tensor([[-0.8029, -0.9025],
        [-0.8742, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009552746778354049
Epoch 0, Step 70: train/loss = 0.6923770308494568, train/raw-loss = 0.7517441511154175, train/logprobs = tensor([[-1.2945, -0.8450],
        [-1.4236, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032415357418358326
Epoch 0, Step 71: train/loss = 0.6916002035140991, train/raw-loss = 0.7217725515365601, train/logprobs = tensor([[-1.4942, -1.3589],
        [-1.5314, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014663885813206434
Epoch 0, Step 72: train/loss = 0.6923872828483582, train/raw-loss = 0.6967363357543945, train/logprobs = tensor([[-0.9629, -1.0352],
        [-1.1388, -1.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006130149122327566
Epoch 0, Step 73: train/loss = 0.6927499175071716, train/raw-loss = 0.7282726764678955, train/logprobs = tensor([[-1.3628, -1.4305],
        [-1.4024, -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001511857844889164
Epoch 0, Step 74: train/loss = 0.6923292875289917, train/raw-loss = 0.6981126070022583, train/logprobs = tensor([[-0.6080, -0.5971],
        [-0.7001, -0.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007732722442597151
Epoch 0, Step 75: train/loss = 0.691332221031189, train/raw-loss = 0.7060911059379578, train/logprobs = tensor([[-0.9017, -0.7899],
        [-1.0355, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021383920684456825
Epoch 0, Step 76: train/loss = 0.6920830607414246, train/raw-loss = 0.7476260662078857, train/logprobs = tensor([[-0.7530, -1.3170],
        [-0.8656, -1.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012010489590466022
Epoch 0, Step 77: train/loss = 0.6925961375236511, train/raw-loss = 0.7051492929458618, train/logprobs = tensor([[-0.8220, -0.8697],
        [-0.9146, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020191667135804892
Epoch 0, Step 78: train/loss = 0.6922916769981384, train/raw-loss = 0.7181391716003418, train/logprobs = tensor([[-1.0333, -1.0819],
        [-1.2308, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015773053746670485
Epoch 0, Step 79: train/loss = 0.69133460521698, train/raw-loss = 0.7445434331893921, train/logprobs = tensor([[-1.1526, -1.1910],
        [-1.3161, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018516422715038061
Epoch 0, Step 80: train/loss = 0.6919074058532715, train/raw-loss = 0.7560399770736694, train/logprobs = tensor([[-1.1682, -1.1582],
        [-1.3786, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006809717742726207
Epoch 0, Step 81: train/loss = 0.6916341781616211, train/raw-loss = 0.6947161555290222, train/logprobs = tensor([[-0.7812, -1.0255],
        [-0.9429, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016897422028705478
Epoch 0, Step 82: train/loss = 0.6916338801383972, train/raw-loss = 0.8150493502616882, train/logprobs = tensor([[-0.8067, -1.6624],
        [-0.8424, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013839754974469543
Epoch 0, Step 83: train/loss = 0.6924748420715332, train/raw-loss = 0.714448094367981, train/logprobs = tensor([[-0.9559, -1.0580],
        [-1.2207, -1.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023738350137136877
Epoch 0, Step 84: train/loss = 0.691726565361023, train/raw-loss = 0.7005478739738464, train/logprobs = tensor([[-1.0741, -1.3485],
        [-1.1327, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002227693796157837
Epoch 0, Step 85: train/loss = 0.6923741698265076, train/raw-loss = 0.7482407093048096, train/logprobs = tensor([[-1.0718, -1.1283],
        [-1.2103, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048173702089115977
Epoch 0, Step 86: train/loss = 0.6925718188285828, train/raw-loss = 0.7231234312057495, train/logprobs = tensor([[-1.1949, -0.8906],
        [-1.2963, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024312222376465797
Epoch 0, Step 87: train/loss = 0.6924543380737305, train/raw-loss = 0.7342478036880493, train/logprobs = tensor([[-0.7838, -1.2866],
        [-0.9280, -1.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042623208719305694
Epoch 0, Step 88: train/loss = 0.691597580909729, train/raw-loss = 0.7661410570144653, train/logprobs = tensor([[-1.4121, -0.8700],
        [-1.6520, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001428350806236267
Epoch 0, Step 89: train/loss = 0.6920676231384277, train/raw-loss = 0.7303303480148315, train/logprobs = tensor([[-1.0709, -0.7478],
        [-1.2566, -0.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001290412270464003
Epoch 0, Step 90: train/loss = 0.692069411277771, train/raw-loss = 0.7042840719223022, train/logprobs = tensor([[-1.0631, -1.1494],
        [-1.0751, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001043973257765174
Epoch 0, Step 91: train/loss = 0.6924914121627808, train/raw-loss = 0.8537811040878296, train/logprobs = tensor([[-0.7979, -1.4163],
        [-0.8876, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010085334070026875
Epoch 0, Step 92: train/loss = 0.6917297840118408, train/raw-loss = 0.7123022079467773, train/logprobs = tensor([[-1.3016, -1.6111],
        [-1.4996, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028084428049623966
Epoch 0, Step 93: train/loss = 0.692934513092041, train/raw-loss = 0.6969895362854004, train/logprobs = tensor([[-1.1859, -1.2206],
        [-1.3016, -1.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010299830319127068
Epoch 0, Step 94: train/loss = 0.6906894445419312, train/raw-loss = 0.7876750826835632, train/logprobs = tensor([[-1.5094, -1.0444],
        [-1.8300, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004244093783199787
Epoch 0, Step 95: train/loss = 0.6917085647583008, train/raw-loss = 0.6952065229415894, train/logprobs = tensor([[-1.4230, -1.4576],
        [-1.4675, -1.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019144847756251693
Epoch 0, Step 96: train/loss = 0.6929811239242554, train/raw-loss = 0.6988939046859741, train/logprobs = tensor([[-1.0603, -1.2796],
        [-1.0947, -1.2832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003096149885095656
Epoch 0, Step 97: train/loss = 0.6922924518585205, train/raw-loss = 0.7770963907241821, train/logprobs = tensor([[-0.8954, -1.7022],
        [-0.9934, -1.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007608268642798066
Epoch 0, Step 98: train/loss = 0.6916846036911011, train/raw-loss = 0.7172090411186218, train/logprobs = tensor([[-0.8599, -1.1927],
        [-1.0143, -1.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012926083290949464
Epoch 0, Step 99: train/loss = 0.6925140619277954, train/raw-loss = 0.7051207423210144, train/logprobs = tensor([[-0.9158, -1.1418],
        [-1.0505, -1.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019925492233596742
Epoch 0, Step 100: train/loss = 0.6917818784713745, train/raw-loss = 0.7958769798278809, train/logprobs = tensor([[-0.7229, -1.2802],
        [-0.8117, -1.1785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020314776338636875
Epoch 0, Step 101: train/loss = 0.6927312612533569, train/raw-loss = 0.694832980632782, train/logprobs = tensor([[-0.8477, -0.8481],
        [-0.9201, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.518582762917504e-05
Epoch 0, Step 102: train/loss = 0.6904823184013367, train/raw-loss = 0.7292743921279907, train/logprobs = tensor([[-0.8427, -1.6506],
        [-1.0602, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004006007686257362
Epoch 0, Step 103: train/loss = 0.6911273002624512, train/raw-loss = 0.7058980464935303, train/logprobs = tensor([[-1.2549, -1.5708],
        [-1.4395, -1.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019582584500312805
Epoch 0, Step 104: train/loss = 0.6926653385162354, train/raw-loss = 0.6939282417297363, train/logprobs = tensor([[-0.8512, -0.8288],
        [-0.9419, -0.8398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003269625303801149
Epoch 0, Step 105: train/loss = 0.6926350593566895, train/raw-loss = 0.699971079826355, train/logprobs = tensor([[-0.6569, -0.9270],
        [-0.6919, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002804911637213081
Epoch 0, Step 106: train/loss = 0.6929539442062378, train/raw-loss = 0.694462776184082, train/logprobs = tensor([[-1.1645, -1.2486],
        [-1.3405, -1.3273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002907845191657543
Epoch 0, Step 107: train/loss = 0.6901085376739502, train/raw-loss = 0.7628616094589233, train/logprobs = tensor([[-1.0600, -1.4697],
        [-1.1605, -1.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005998481065034866
