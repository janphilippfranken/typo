{"train/loss": 0.1337, "train/learning_rate": 0.0, "train/rewards/chosen": -1.234198808670044, "train/rewards/rejected": -7.42648983001709, "train/rewards/accuracies": 0.8125, "train/rewards/margins": 6.192290306091309, "train/logps/rejected": -107.64427185058594, "train/logps/chosen": -48.70210647583008, "train/logits/rejected": -3.1324853897094727, "train/logits/chosen": -3.1754612922668457, "train/epoch": 0.99, "train/global_step": 59, "_timestamp": 1709495818.3886623, "_runtime": 800.6742372512817, "_step": 60, "eval/loss": 0.08513671159744263, "eval/runtime": 18.1316, "eval/samples_per_second": 22.061, "eval/steps_per_second": 5.515, "eval/rewards/chosen": -1.1539413928985596, "eval/rewards/rejected": -9.410456657409668, "eval/rewards/accuracies": 0.949999988079071, "eval/rewards/margins": 8.256514549255371, "eval/logps/rejected": -133.37353515625, "eval/logps/chosen": -53.039058685302734, "eval/logits/rejected": -3.1056199073791504, "eval/logits/chosen": -3.180854082107544, "train/train_runtime": 754.1573, "train/train_samples_per_second": 10.077, "train/train_steps_per_second": 0.078, "train/total_flos": 0.0, "train/train_loss": 0.2303709994559571, "_wandb": {"runtime": 818}}